
The following have been reloaded with a version change:
  1) pillow/7.2.0-python-3.7.4 => pillow/6.2.1

train row : 30148
sample row: 30148
VGAN_generator(
  (input): Linear(in_features=128, out_features=400, bias=True)
  (inputbn): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=400, out_features=400, bias=True)
  (bn0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=400, bias=True)
  (bn1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=400, out_features=105, bias=True)
  (outputbn): BatchNorm1d(105, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=105, out_features=100, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (output): Linear(in_features=100, out_features=1, bias=True)
)
(0, False, 105)
-----------Epoch 0-----------
iterator 100, D_Loss:1.2961790561676025, G_Loss:1.706352949142456

iterator 200, D_Loss:1.0722646713256836, G_Loss:1.833174705505371

iterator 300, D_Loss:0.7886496782302856, G_Loss:2.690109968185425

iterator 400, D_Loss:0.7251337766647339, G_Loss:3.4306256771087646

iterator 500, D_Loss:0.6559261083602905, G_Loss:3.990328788757324

iterator 600, D_Loss:0.6912113428115845, G_Loss:4.205766201019287

iterator 700, D_Loss:0.6438854932785034, G_Loss:4.600926876068115

iterator 800, D_Loss:0.5514979958534241, G_Loss:4.860525608062744

iterator 900, D_Loss:0.6586729288101196, G_Loss:5.15604305267334

iterator 1000, D_Loss:0.6129648685455322, G_Loss:5.783524036407471

iterator 1100, D_Loss:0.5903700590133667, G_Loss:5.580471992492676

iterator 1200, D_Loss:0.577059268951416, G_Loss:5.5983357429504395

iterator 1300, D_Loss:0.5911967754364014, G_Loss:5.839593887329102

iterator 1400, D_Loss:0.694347620010376, G_Loss:5.833095073699951

iterator 1500, D_Loss:0.5360097289085388, G_Loss:6.13982629776001

iterator 1600, D_Loss:0.6269169449806213, G_Loss:5.801584243774414

iterator 1700, D_Loss:0.7529236674308777, G_Loss:5.622599124908447

iterator 1800, D_Loss:0.6363869905471802, G_Loss:5.996279239654541

iterator 1900, D_Loss:0.5628203749656677, G_Loss:5.650078773498535

iterator 2000, D_Loss:0.6111562252044678, G_Loss:5.688292503356934

iterator 2100, D_Loss:0.5370800495147705, G_Loss:5.653837203979492

iterator 2200, D_Loss:0.5546846389770508, G_Loss:5.900287628173828

iterator 2300, D_Loss:0.5704498887062073, G_Loss:5.963687419891357

iterator 2400, D_Loss:0.5312563180923462, G_Loss:5.888190269470215

iterator 2500, D_Loss:0.5729855298995972, G_Loss:5.608287811279297

iterator 2600, D_Loss:0.561884343624115, G_Loss:5.741944313049316

iterator 2700, D_Loss:0.6817173361778259, G_Loss:5.65846586227417

iterator 2800, D_Loss:0.554800271987915, G_Loss:5.7439093589782715

iterator 2900, D_Loss:0.5226954221725464, G_Loss:5.471680641174316

iterator 3000, D_Loss:0.5681073665618896, G_Loss:6.038075923919678

iterator 3100, D_Loss:0.6001197099685669, G_Loss:5.457291603088379

iterator 3200, D_Loss:0.6185587644577026, G_Loss:5.41355562210083

iterator 3300, D_Loss:0.6151876449584961, G_Loss:5.83674430847168

iterator 3400, D_Loss:0.6426011919975281, G_Loss:5.451833248138428

iterator 3500, D_Loss:0.6151705980300903, G_Loss:5.477301120758057

iterator 3600, D_Loss:0.5765836238861084, G_Loss:5.2483134269714355

iterator 3700, D_Loss:0.5819833278656006, G_Loss:5.075446605682373

iterator 3800, D_Loss:0.5313482284545898, G_Loss:5.148459434509277

iterator 3900, D_Loss:0.5943711400032043, G_Loss:4.874322891235352

iterator 4000, D_Loss:0.5462023019790649, G_Loss:4.761826038360596

iterator 4100, D_Loss:0.6378600597381592, G_Loss:4.775932312011719

iterator 4200, D_Loss:0.513934314250946, G_Loss:5.1773295402526855

iterator 4300, D_Loss:0.5832294225692749, G_Loss:4.801695823669434

iterator 4400, D_Loss:0.5859278440475464, G_Loss:4.884200096130371

iterator 4500, D_Loss:0.5403124094009399, G_Loss:4.882056713104248

iterator 4600, D_Loss:0.5896865129470825, G_Loss:4.9144721031188965

iterator 4700, D_Loss:0.669531524181366, G_Loss:4.7041521072387695

iterator 4800, D_Loss:0.7600449919700623, G_Loss:4.721129417419434

iterator 4900, D_Loss:0.5137348771095276, G_Loss:4.533430099487305

iterator 5000, D_Loss:0.6327726244926453, G_Loss:4.787165641784668

-----------Epoch 1-----------
iterator 100, D_Loss:0.5710375905036926, G_Loss:4.5141682624816895

iterator 200, D_Loss:0.7120741009712219, G_Loss:4.5960869789123535

iterator 300, D_Loss:0.5247665047645569, G_Loss:4.469340801239014

iterator 400, D_Loss:0.7222121953964233, G_Loss:4.490711212158203

iterator 500, D_Loss:0.5972719192504883, G_Loss:4.668403148651123

iterator 600, D_Loss:0.7568948864936829, G_Loss:4.014817237854004

iterator 700, D_Loss:0.7110994458198547, G_Loss:4.044303894042969

iterator 800, D_Loss:0.5772877931594849, G_Loss:4.328801155090332

iterator 900, D_Loss:0.6138947010040283, G_Loss:4.335125923156738

iterator 1000, D_Loss:0.7287372946739197, G_Loss:4.06240701675415

iterator 1100, D_Loss:0.704712450504303, G_Loss:3.998858690261841

iterator 1200, D_Loss:0.5889433026313782, G_Loss:4.0885443687438965

iterator 1300, D_Loss:0.5959519147872925, G_Loss:3.970787525177002

iterator 1400, D_Loss:0.7217387557029724, G_Loss:3.853480100631714

iterator 1500, D_Loss:0.6127052307128906, G_Loss:4.149993896484375

iterator 1600, D_Loss:0.7315486073493958, G_Loss:3.9395742416381836

iterator 1700, D_Loss:0.769846498966217, G_Loss:3.8546698093414307

iterator 1800, D_Loss:0.7217643857002258, G_Loss:3.642432451248169

iterator 1900, D_Loss:0.644170343875885, G_Loss:3.8660154342651367

iterator 2000, D_Loss:0.6819680333137512, G_Loss:3.7291789054870605

iterator 2100, D_Loss:0.6434568166732788, G_Loss:3.5208065509796143

iterator 2200, D_Loss:0.7546879053115845, G_Loss:3.8050503730773926

iterator 2300, D_Loss:0.5841396450996399, G_Loss:3.781381845474243

iterator 2400, D_Loss:0.6869857311248779, G_Loss:3.452162504196167

iterator 2500, D_Loss:0.7545008659362793, G_Loss:3.5401620864868164

iterator 2600, D_Loss:0.690994143486023, G_Loss:3.489147663116455

iterator 2700, D_Loss:0.7474274635314941, G_Loss:3.1668312549591064

iterator 2800, D_Loss:0.7010601162910461, G_Loss:3.4036383628845215

iterator 2900, D_Loss:0.6610050201416016, G_Loss:3.199697494506836

iterator 3000, D_Loss:0.6851567029953003, G_Loss:3.1255085468292236

iterator 3100, D_Loss:0.696216344833374, G_Loss:3.309418201446533

iterator 3200, D_Loss:0.7436351776123047, G_Loss:2.9580795764923096

iterator 3300, D_Loss:0.7562433481216431, G_Loss:3.245779514312744

iterator 3400, D_Loss:0.836370587348938, G_Loss:3.016489028930664

iterator 3500, D_Loss:0.7386332750320435, G_Loss:3.14996075630188

iterator 3600, D_Loss:0.686316967010498, G_Loss:3.0543875694274902

iterator 3700, D_Loss:0.7236133813858032, G_Loss:2.7023510932922363

iterator 3800, D_Loss:0.7290599346160889, G_Loss:3.099656343460083

iterator 3900, D_Loss:0.6827404499053955, G_Loss:2.78859806060791

iterator 4000, D_Loss:0.7667233943939209, G_Loss:3.1866636276245117

iterator 4100, D_Loss:0.767751932144165, G_Loss:3.1040656566619873

iterator 4200, D_Loss:0.7536516189575195, G_Loss:3.0914828777313232

iterator 4300, D_Loss:0.6784930229187012, G_Loss:2.956624984741211

iterator 4400, D_Loss:0.7505049109458923, G_Loss:3.0332396030426025

iterator 4500, D_Loss:0.6422266364097595, G_Loss:3.2461674213409424

iterator 4600, D_Loss:0.725300669670105, G_Loss:3.0196423530578613

iterator 4700, D_Loss:0.86549311876297, G_Loss:2.7440106868743896

iterator 4800, D_Loss:0.9184842109680176, G_Loss:2.8444602489471436

iterator 4900, D_Loss:0.712209939956665, G_Loss:2.999145030975342

iterator 5000, D_Loss:0.7822389602661133, G_Loss:2.871572256088257

-----------Epoch 2-----------
iterator 100, D_Loss:0.8282005786895752, G_Loss:2.717860221862793

iterator 200, D_Loss:0.8767684698104858, G_Loss:2.7738564014434814

iterator 300, D_Loss:0.7783520817756653, G_Loss:2.6906862258911133

iterator 400, D_Loss:0.861716628074646, G_Loss:2.8594374656677246

iterator 500, D_Loss:0.7765167951583862, G_Loss:2.8495371341705322

iterator 600, D_Loss:0.8427801132202148, G_Loss:2.661515474319458

iterator 700, D_Loss:0.8050175905227661, G_Loss:3.0433754920959473

iterator 800, D_Loss:0.7660326957702637, G_Loss:2.8627073764801025

iterator 900, D_Loss:0.7135105133056641, G_Loss:2.839996814727783

iterator 1000, D_Loss:0.80619877576828, G_Loss:3.0410122871398926

iterator 1100, D_Loss:0.8644071221351624, G_Loss:2.9225172996520996

iterator 1200, D_Loss:0.7845664024353027, G_Loss:2.888143301010132

iterator 1300, D_Loss:0.7177820205688477, G_Loss:2.685131549835205

iterator 1400, D_Loss:0.8535631895065308, G_Loss:2.7607855796813965

iterator 1500, D_Loss:0.8683194518089294, G_Loss:2.861617088317871

iterator 1600, D_Loss:0.7568340301513672, G_Loss:2.7125470638275146

iterator 1700, D_Loss:0.7893372774124146, G_Loss:3.0155887603759766

iterator 1800, D_Loss:0.7781496644020081, G_Loss:2.795732259750366

iterator 1900, D_Loss:0.8198720216751099, G_Loss:2.8648788928985596

iterator 2000, D_Loss:0.8609328866004944, G_Loss:2.7163329124450684

iterator 2100, D_Loss:0.8494110703468323, G_Loss:2.812013864517212

iterator 2200, D_Loss:0.7820729613304138, G_Loss:2.726832866668701

iterator 2300, D_Loss:0.7878798842430115, G_Loss:2.483072280883789

iterator 2400, D_Loss:0.7938441038131714, G_Loss:2.673431396484375

iterator 2500, D_Loss:0.8273460865020752, G_Loss:2.903048276901245

iterator 2600, D_Loss:0.8069021105766296, G_Loss:2.5016889572143555

iterator 2700, D_Loss:1.002526879310608, G_Loss:2.5668632984161377

iterator 2800, D_Loss:0.7665300965309143, G_Loss:2.600663661956787

iterator 2900, D_Loss:0.8294591903686523, G_Loss:2.459523916244507

iterator 3000, D_Loss:0.8567907810211182, G_Loss:2.59173846244812

iterator 3100, D_Loss:0.8260542154312134, G_Loss:2.5850071907043457

iterator 3200, D_Loss:0.8887448906898499, G_Loss:2.579822063446045

iterator 3300, D_Loss:0.834892749786377, G_Loss:2.462116241455078

iterator 3400, D_Loss:0.8066553473472595, G_Loss:2.789057731628418

iterator 3500, D_Loss:0.8409436345100403, G_Loss:2.377528667449951

iterator 3600, D_Loss:0.8102402687072754, G_Loss:2.6961121559143066

iterator 3700, D_Loss:0.8120287656784058, G_Loss:2.8917553424835205

iterator 3800, D_Loss:0.8517399430274963, G_Loss:2.57167387008667

iterator 3900, D_Loss:0.8171414136886597, G_Loss:2.4020533561706543

iterator 4000, D_Loss:0.8087943196296692, G_Loss:2.3286855220794678

iterator 4100, D_Loss:0.7900681495666504, G_Loss:2.5989034175872803

iterator 4200, D_Loss:0.769568681716919, G_Loss:2.291425943374634

iterator 4300, D_Loss:0.9197812080383301, G_Loss:2.7062811851501465

iterator 4400, D_Loss:0.8422884941101074, G_Loss:2.418131113052368

iterator 4500, D_Loss:0.8398470878601074, G_Loss:2.936436653137207

iterator 4600, D_Loss:0.9421743750572205, G_Loss:2.46368670463562

iterator 4700, D_Loss:0.8796007633209229, G_Loss:2.41707444190979

iterator 4800, D_Loss:0.9656091928482056, G_Loss:2.439298391342163

iterator 4900, D_Loss:0.9119371175765991, G_Loss:2.2248990535736084

iterator 5000, D_Loss:0.8292235732078552, G_Loss:2.4372401237487793

-----------Epoch 3-----------
iterator 100, D_Loss:0.9406074285507202, G_Loss:2.611550807952881

iterator 200, D_Loss:0.8970564603805542, G_Loss:2.360189437866211

iterator 300, D_Loss:0.9826382398605347, G_Loss:2.601900815963745

iterator 400, D_Loss:0.9335609674453735, G_Loss:2.2937049865722656

iterator 500, D_Loss:0.8569749593734741, G_Loss:2.1230735778808594

iterator 600, D_Loss:0.7985097169876099, G_Loss:2.4915690422058105

iterator 700, D_Loss:0.8938124775886536, G_Loss:2.5654067993164062

iterator 800, D_Loss:0.8110026121139526, G_Loss:2.124704360961914

iterator 900, D_Loss:0.9247725009918213, G_Loss:2.3722074031829834

iterator 1000, D_Loss:0.9361076354980469, G_Loss:2.436100482940674

iterator 1100, D_Loss:0.9835668802261353, G_Loss:2.366908311843872

iterator 1200, D_Loss:0.8539721369743347, G_Loss:2.5902440547943115

iterator 1300, D_Loss:0.9366562366485596, G_Loss:2.367241382598877

iterator 1400, D_Loss:0.8642851114273071, G_Loss:2.4538044929504395

iterator 1500, D_Loss:0.8858503699302673, G_Loss:2.0478148460388184

iterator 1600, D_Loss:0.8791450262069702, G_Loss:2.2900161743164062

iterator 1700, D_Loss:0.9619549512863159, G_Loss:2.14725399017334

iterator 1800, D_Loss:0.9385470151901245, G_Loss:2.2901742458343506

iterator 1900, D_Loss:0.8666629791259766, G_Loss:2.19093918800354

iterator 2000, D_Loss:0.8881385922431946, G_Loss:2.1313388347625732

iterator 2100, D_Loss:0.8265424370765686, G_Loss:2.3734171390533447

iterator 2200, D_Loss:0.9835741519927979, G_Loss:2.183115243911743

iterator 2300, D_Loss:0.8856853246688843, G_Loss:2.081256151199341

iterator 2400, D_Loss:1.010749101638794, G_Loss:2.5044496059417725

iterator 2500, D_Loss:0.9176946878433228, G_Loss:2.0508909225463867

iterator 2600, D_Loss:0.9075545072555542, G_Loss:2.3096840381622314

iterator 2700, D_Loss:0.9815627336502075, G_Loss:2.119967222213745

iterator 2800, D_Loss:0.847785472869873, G_Loss:2.4096851348876953

iterator 2900, D_Loss:0.8201956152915955, G_Loss:2.8132503032684326

iterator 3000, D_Loss:0.9110628962516785, G_Loss:2.419997215270996

iterator 3100, D_Loss:0.7730793952941895, G_Loss:2.206043004989624

iterator 3200, D_Loss:0.8525655269622803, G_Loss:2.292485475540161

iterator 3300, D_Loss:0.8441294431686401, G_Loss:2.1596932411193848

iterator 3400, D_Loss:0.9064571857452393, G_Loss:2.2253952026367188

iterator 3500, D_Loss:0.783629298210144, G_Loss:2.2829208374023438

iterator 3600, D_Loss:0.7993643879890442, G_Loss:2.040984869003296

iterator 3700, D_Loss:0.8873100876808167, G_Loss:2.216536045074463

iterator 3800, D_Loss:0.8757256269454956, G_Loss:2.057314872741699

iterator 3900, D_Loss:0.8391292095184326, G_Loss:2.068702220916748

iterator 4000, D_Loss:0.9572333097457886, G_Loss:2.0652637481689453

iterator 4100, D_Loss:0.8573815822601318, G_Loss:2.2906832695007324

iterator 4200, D_Loss:0.7803177833557129, G_Loss:2.2507810592651367

iterator 4300, D_Loss:0.8987956643104553, G_Loss:2.175880193710327

iterator 4400, D_Loss:0.8536286354064941, G_Loss:2.1106784343719482

iterator 4500, D_Loss:0.8510602712631226, G_Loss:2.2985050678253174

iterator 4600, D_Loss:0.8461000323295593, G_Loss:2.1047253608703613

iterator 4700, D_Loss:0.9847745895385742, G_Loss:2.0020556449890137

iterator 4800, D_Loss:0.9624569416046143, G_Loss:2.146637439727783

iterator 4900, D_Loss:0.9576449394226074, G_Loss:1.9894136190414429

iterator 5000, D_Loss:0.9705206155776978, G_Loss:1.865264654159546

-----------Epoch 4-----------
iterator 100, D_Loss:0.9628469944000244, G_Loss:2.0117688179016113

iterator 200, D_Loss:0.9152698516845703, G_Loss:1.993575096130371

iterator 300, D_Loss:0.8770882487297058, G_Loss:2.130904197692871

iterator 400, D_Loss:0.9230919480323792, G_Loss:2.0273358821868896

iterator 500, D_Loss:0.8648999333381653, G_Loss:2.1623337268829346

iterator 600, D_Loss:0.9464161992073059, G_Loss:2.0734002590179443

iterator 700, D_Loss:0.9887073636054993, G_Loss:1.967787265777588

iterator 800, D_Loss:0.8327536582946777, G_Loss:2.1207473278045654

iterator 900, D_Loss:0.797974705696106, G_Loss:2.0318524837493896

iterator 1000, D_Loss:0.9828178286552429, G_Loss:1.9505107402801514

iterator 1100, D_Loss:0.9606051445007324, G_Loss:1.8696082830429077

iterator 1200, D_Loss:0.8992267847061157, G_Loss:2.063636302947998

iterator 1300, D_Loss:0.8870620727539062, G_Loss:1.9797747135162354

iterator 1400, D_Loss:1.0143396854400635, G_Loss:1.879410743713379

iterator 1500, D_Loss:0.8470125794410706, G_Loss:2.05766224861145

iterator 1600, D_Loss:0.8891424536705017, G_Loss:1.960740327835083

iterator 1700, D_Loss:1.1030467748641968, G_Loss:2.0376040935516357

iterator 1800, D_Loss:1.0356619358062744, G_Loss:1.8451106548309326

iterator 1900, D_Loss:0.8926916122436523, G_Loss:1.8421930074691772

iterator 2000, D_Loss:0.9960156679153442, G_Loss:1.8807883262634277

iterator 2100, D_Loss:0.9632333517074585, G_Loss:1.8361380100250244

iterator 2200, D_Loss:0.9385727643966675, G_Loss:1.8501839637756348

iterator 2300, D_Loss:0.9855915307998657, G_Loss:2.0458576679229736

iterator 2400, D_Loss:0.9360770583152771, G_Loss:1.9801526069641113

iterator 2500, D_Loss:0.9990810751914978, G_Loss:1.8761155605316162

iterator 2600, D_Loss:1.0380133390426636, G_Loss:1.8745615482330322

iterator 2700, D_Loss:0.9989954829216003, G_Loss:1.9096267223358154

iterator 2800, D_Loss:0.9161714911460876, G_Loss:1.9731814861297607

iterator 2900, D_Loss:0.9533631801605225, G_Loss:1.9663827419281006

iterator 3000, D_Loss:1.0419650077819824, G_Loss:1.892982006072998

iterator 3100, D_Loss:0.8736433982849121, G_Loss:1.7863377332687378

iterator 3200, D_Loss:1.0635031461715698, G_Loss:1.6706737279891968

iterator 3300, D_Loss:1.0467814207077026, G_Loss:1.757309913635254

iterator 3400, D_Loss:1.053049087524414, G_Loss:1.7435874938964844

iterator 3500, D_Loss:1.0246670246124268, G_Loss:1.688481330871582

iterator 3600, D_Loss:0.9948707818984985, G_Loss:1.7444947957992554

iterator 3700, D_Loss:0.9167752265930176, G_Loss:1.908834457397461

iterator 3800, D_Loss:0.9605211019515991, G_Loss:1.7505043745040894

iterator 3900, D_Loss:1.0511854887008667, G_Loss:1.7580759525299072

iterator 4000, D_Loss:1.0391639471054077, G_Loss:1.664097785949707

iterator 4100, D_Loss:1.0517644882202148, G_Loss:1.5728553533554077

iterator 4200, D_Loss:0.9760068655014038, G_Loss:1.6999897956848145

iterator 4300, D_Loss:1.060457706451416, G_Loss:1.6721298694610596

iterator 4400, D_Loss:0.9595553874969482, G_Loss:1.6769822835922241

iterator 4500, D_Loss:1.024152398109436, G_Loss:1.6715061664581299

iterator 4600, D_Loss:1.0586802959442139, G_Loss:1.7083102464675903

iterator 4700, D_Loss:1.1121876239776611, G_Loss:1.6684396266937256

iterator 4800, D_Loss:1.0493535995483398, G_Loss:1.770010232925415

iterator 4900, D_Loss:1.05936861038208, G_Loss:1.6522884368896484

iterator 5000, D_Loss:1.0642826557159424, G_Loss:1.5912230014801025

-----------Epoch 5-----------
iterator 100, D_Loss:1.0995005369186401, G_Loss:1.6676663160324097

iterator 200, D_Loss:1.0329608917236328, G_Loss:1.660372257232666

iterator 300, D_Loss:1.0746567249298096, G_Loss:1.6122270822525024

iterator 400, D_Loss:1.0128800868988037, G_Loss:1.5333796739578247

iterator 500, D_Loss:1.042630672454834, G_Loss:1.4700841903686523

iterator 600, D_Loss:1.065131664276123, G_Loss:1.5469932556152344

iterator 700, D_Loss:1.0973308086395264, G_Loss:1.5613157749176025

iterator 800, D_Loss:1.0243563652038574, G_Loss:1.5745372772216797

iterator 900, D_Loss:1.0930581092834473, G_Loss:1.5756418704986572

iterator 1000, D_Loss:1.054610252380371, G_Loss:1.6874390840530396

iterator 1100, D_Loss:1.066901683807373, G_Loss:1.4677906036376953

iterator 1200, D_Loss:1.0466578006744385, G_Loss:1.7167270183563232

iterator 1300, D_Loss:1.0204538106918335, G_Loss:1.6012063026428223

iterator 1400, D_Loss:0.9949199557304382, G_Loss:1.7145495414733887

iterator 1500, D_Loss:1.048272728919983, G_Loss:1.5867440700531006

iterator 1600, D_Loss:1.1221072673797607, G_Loss:1.482491374015808

iterator 1700, D_Loss:1.173285722732544, G_Loss:1.4951452016830444

iterator 1800, D_Loss:1.0953389406204224, G_Loss:1.4054303169250488

iterator 1900, D_Loss:1.076774001121521, G_Loss:1.6100174188613892

iterator 2000, D_Loss:1.0646120309829712, G_Loss:1.5243394374847412

iterator 2100, D_Loss:1.0467963218688965, G_Loss:1.513922929763794

iterator 2200, D_Loss:1.1069588661193848, G_Loss:1.4130183458328247

iterator 2300, D_Loss:1.144139051437378, G_Loss:1.5284050703048706

iterator 2400, D_Loss:1.041184663772583, G_Loss:1.4777495861053467

iterator 2500, D_Loss:1.1204237937927246, G_Loss:1.4039126634597778

iterator 2600, D_Loss:1.0878233909606934, G_Loss:1.4364491701126099

iterator 2700, D_Loss:1.1476609706878662, G_Loss:1.456072211265564

iterator 2800, D_Loss:1.0627570152282715, G_Loss:1.5102272033691406

iterator 2900, D_Loss:1.055323839187622, G_Loss:1.4990997314453125

iterator 3000, D_Loss:1.1222004890441895, G_Loss:1.5218913555145264

iterator 3100, D_Loss:1.063328504562378, G_Loss:1.5194171667099

iterator 3200, D_Loss:1.092773675918579, G_Loss:1.529579758644104

iterator 3300, D_Loss:1.0748224258422852, G_Loss:1.5571048259735107

iterator 3400, D_Loss:1.0915098190307617, G_Loss:1.5999162197113037

iterator 3500, D_Loss:1.1093592643737793, G_Loss:1.4320998191833496

iterator 3600, D_Loss:1.0237274169921875, G_Loss:1.4647700786590576

iterator 3700, D_Loss:1.135000228881836, G_Loss:1.4678243398666382

iterator 3800, D_Loss:1.0393251180648804, G_Loss:1.3793039321899414

iterator 3900, D_Loss:1.0962319374084473, G_Loss:1.4325577020645142

iterator 4000, D_Loss:1.122104525566101, G_Loss:1.6203306913375854

iterator 4100, D_Loss:1.1433666944503784, G_Loss:1.3654929399490356

iterator 4200, D_Loss:1.1374824047088623, G_Loss:1.6226527690887451

iterator 4300, D_Loss:1.1431050300598145, G_Loss:1.4729831218719482

iterator 4400, D_Loss:1.1458486318588257, G_Loss:1.4689537286758423

iterator 4500, D_Loss:1.0976005792617798, G_Loss:1.5703834295272827

iterator 4600, D_Loss:1.0710066556930542, G_Loss:1.2552236318588257

iterator 4700, D_Loss:1.197521448135376, G_Loss:1.496046781539917

iterator 4800, D_Loss:1.068074345588684, G_Loss:1.6193300485610962

iterator 4900, D_Loss:1.0982508659362793, G_Loss:1.4574861526489258

iterator 5000, D_Loss:1.195756435394287, G_Loss:1.4246468544006348

-----------Epoch 6-----------
iterator 100, D_Loss:1.1339762210845947, G_Loss:1.4905914068222046

iterator 200, D_Loss:1.1212345361709595, G_Loss:1.4441875219345093

iterator 300, D_Loss:1.0928690433502197, G_Loss:1.4503400325775146

iterator 400, D_Loss:1.1686756610870361, G_Loss:1.4449721574783325

iterator 500, D_Loss:1.1399791240692139, G_Loss:1.4902640581130981

iterator 600, D_Loss:1.0666759014129639, G_Loss:1.503373384475708

iterator 700, D_Loss:1.091329574584961, G_Loss:1.4904248714447021

iterator 800, D_Loss:1.1235119104385376, G_Loss:1.358356237411499

iterator 900, D_Loss:1.230698585510254, G_Loss:1.456214189529419

iterator 1000, D_Loss:1.0785914659500122, G_Loss:1.5149041414260864

iterator 1100, D_Loss:1.1871159076690674, G_Loss:1.3397431373596191

iterator 1200, D_Loss:1.1145431995391846, G_Loss:1.4373080730438232

iterator 1300, D_Loss:1.1181787252426147, G_Loss:1.4879846572875977

iterator 1400, D_Loss:1.1275805234909058, G_Loss:1.5133082866668701

iterator 1500, D_Loss:1.1529855728149414, G_Loss:1.3485474586486816

iterator 1600, D_Loss:1.137863039970398, G_Loss:1.4307005405426025

iterator 1700, D_Loss:1.14545738697052, G_Loss:1.3583341836929321

iterator 1800, D_Loss:1.0809383392333984, G_Loss:1.4829447269439697

iterator 1900, D_Loss:1.0119543075561523, G_Loss:1.5462839603424072

iterator 2000, D_Loss:1.1321313381195068, G_Loss:1.4928101301193237

iterator 2100, D_Loss:1.1111152172088623, G_Loss:1.500624179840088

iterator 2200, D_Loss:1.1306793689727783, G_Loss:1.379496693611145

iterator 2300, D_Loss:1.1603859663009644, G_Loss:1.336920976638794

iterator 2400, D_Loss:1.1273342370986938, G_Loss:1.3388142585754395

iterator 2500, D_Loss:1.1558228731155396, G_Loss:1.2840638160705566

iterator 2600, D_Loss:1.2542426586151123, G_Loss:1.2869075536727905

iterator 2700, D_Loss:1.2330667972564697, G_Loss:1.330676555633545

iterator 2800, D_Loss:1.1356031894683838, G_Loss:1.369544267654419

iterator 2900, D_Loss:1.1681015491485596, G_Loss:1.3886058330535889

iterator 3000, D_Loss:1.1750080585479736, G_Loss:1.3207433223724365

iterator 3100, D_Loss:1.1140718460083008, G_Loss:1.4251635074615479

iterator 3200, D_Loss:1.1595244407653809, G_Loss:1.357839822769165

iterator 3300, D_Loss:1.1677205562591553, G_Loss:1.300724983215332

iterator 3400, D_Loss:1.1315957307815552, G_Loss:1.4486263990402222

iterator 3500, D_Loss:1.1201990842819214, G_Loss:1.261657953262329

iterator 3600, D_Loss:1.128949761390686, G_Loss:1.3707014322280884

iterator 3700, D_Loss:1.0887413024902344, G_Loss:1.4490011930465698

iterator 3800, D_Loss:1.163203477859497, G_Loss:1.2678985595703125

iterator 3900, D_Loss:1.153674602508545, G_Loss:1.3261070251464844

iterator 4000, D_Loss:1.1398696899414062, G_Loss:1.314705491065979

iterator 4100, D_Loss:1.1638363599777222, G_Loss:1.2973592281341553

iterator 4200, D_Loss:1.2160956859588623, G_Loss:1.2349958419799805

iterator 4300, D_Loss:1.1385297775268555, G_Loss:1.3139739036560059

iterator 4400, D_Loss:1.1789720058441162, G_Loss:1.2409799098968506

iterator 4500, D_Loss:1.1401917934417725, G_Loss:1.253612756729126

iterator 4600, D_Loss:1.1692390441894531, G_Loss:1.281855821609497

iterator 4700, D_Loss:1.2097039222717285, G_Loss:1.2607972621917725

iterator 4800, D_Loss:1.1906181573867798, G_Loss:1.297808051109314

iterator 4900, D_Loss:1.1935955286026, G_Loss:1.3626757860183716

iterator 5000, D_Loss:1.1051499843597412, G_Loss:1.3474851846694946

-----------Epoch 7-----------
iterator 100, D_Loss:1.1791017055511475, G_Loss:1.3968523740768433

iterator 200, D_Loss:1.1736619472503662, G_Loss:1.2920467853546143

iterator 300, D_Loss:1.1672141551971436, G_Loss:1.1705657243728638

iterator 400, D_Loss:1.2410262823104858, G_Loss:1.2885087728500366

iterator 500, D_Loss:1.2274377346038818, G_Loss:1.2066681385040283

iterator 600, D_Loss:1.1888022422790527, G_Loss:1.2695891857147217

iterator 700, D_Loss:1.1959491968154907, G_Loss:1.3230682611465454

iterator 800, D_Loss:1.1143916845321655, G_Loss:1.3188018798828125

iterator 900, D_Loss:1.0989758968353271, G_Loss:1.273794412612915

iterator 1000, D_Loss:1.243988037109375, G_Loss:1.4014617204666138

iterator 1100, D_Loss:1.1869829893112183, G_Loss:1.415373682975769

iterator 1200, D_Loss:1.2329789400100708, G_Loss:1.3639951944351196

iterator 1300, D_Loss:1.1717610359191895, G_Loss:1.2663732767105103

iterator 1400, D_Loss:1.201439380645752, G_Loss:1.3654601573944092

iterator 1500, D_Loss:1.164387822151184, G_Loss:1.3216657638549805

iterator 1600, D_Loss:1.116621732711792, G_Loss:1.472975730895996

iterator 1700, D_Loss:1.2237648963928223, G_Loss:1.2600739002227783

iterator 1800, D_Loss:1.1280652284622192, G_Loss:1.34516179561615

iterator 1900, D_Loss:1.2128673791885376, G_Loss:1.2657859325408936

iterator 2000, D_Loss:1.21555757522583, G_Loss:1.276124119758606

iterator 2100, D_Loss:1.1783193349838257, G_Loss:1.2381036281585693

iterator 2200, D_Loss:1.1903514862060547, G_Loss:1.307141900062561

iterator 2300, D_Loss:1.1227409839630127, G_Loss:1.2945109605789185

iterator 2400, D_Loss:1.201150894165039, G_Loss:1.349702000617981

iterator 2500, D_Loss:1.1381492614746094, G_Loss:1.3653849363327026

iterator 2600, D_Loss:1.153005838394165, G_Loss:1.4164750576019287

iterator 2700, D_Loss:1.2358388900756836, G_Loss:1.2836686372756958

iterator 2800, D_Loss:1.2617440223693848, G_Loss:1.1839051246643066

iterator 2900, D_Loss:1.2095516920089722, G_Loss:1.3111059665679932

iterator 3000, D_Loss:1.217207908630371, G_Loss:1.243186593055725

iterator 3100, D_Loss:1.1886682510375977, G_Loss:1.1365655660629272

iterator 3200, D_Loss:1.2064626216888428, G_Loss:1.2954171895980835

iterator 3300, D_Loss:1.1843764781951904, G_Loss:1.2360659837722778

iterator 3400, D_Loss:1.225435733795166, G_Loss:1.2480688095092773

iterator 3500, D_Loss:1.1537971496582031, G_Loss:1.3485443592071533

iterator 3600, D_Loss:1.2595932483673096, G_Loss:1.2494416236877441

iterator 3700, D_Loss:1.2337929010391235, G_Loss:1.2829312086105347

iterator 3800, D_Loss:1.2457305192947388, G_Loss:1.1713224649429321

iterator 3900, D_Loss:1.2146941423416138, G_Loss:1.1670857667922974

iterator 4000, D_Loss:1.183872103691101, G_Loss:1.310741901397705

iterator 4100, D_Loss:1.2664903402328491, G_Loss:1.1991465091705322

iterator 4200, D_Loss:1.220066785812378, G_Loss:1.293776273727417

iterator 4300, D_Loss:1.2290778160095215, G_Loss:1.3424195051193237

iterator 4400, D_Loss:1.2266660928726196, G_Loss:1.3218696117401123

iterator 4500, D_Loss:1.107362985610962, G_Loss:1.3902140855789185

iterator 4600, D_Loss:1.138458490371704, G_Loss:1.3434410095214844

iterator 4700, D_Loss:1.2437962293624878, G_Loss:1.2886327505111694

iterator 4800, D_Loss:1.2738537788391113, G_Loss:1.1665374040603638

iterator 4900, D_Loss:1.2471866607666016, G_Loss:1.1961021423339844

iterator 5000, D_Loss:1.1835930347442627, G_Loss:1.2381411790847778

-----------Epoch 8-----------
iterator 100, D_Loss:1.219024419784546, G_Loss:1.2819205522537231

iterator 200, D_Loss:1.2075116634368896, G_Loss:1.2880171537399292

iterator 300, D_Loss:1.2449647188186646, G_Loss:1.186362862586975

iterator 400, D_Loss:1.218896746635437, G_Loss:1.152579665184021

iterator 500, D_Loss:1.1658124923706055, G_Loss:1.2019267082214355

iterator 600, D_Loss:1.2326500415802002, G_Loss:1.208421230316162

iterator 700, D_Loss:1.2340143918991089, G_Loss:1.1246737241744995

iterator 800, D_Loss:1.2073782682418823, G_Loss:1.2029262781143188

iterator 900, D_Loss:1.2411868572235107, G_Loss:1.1945955753326416

iterator 1000, D_Loss:1.237070083618164, G_Loss:1.2079355716705322

iterator 1100, D_Loss:1.2459070682525635, G_Loss:1.2010457515716553

iterator 1200, D_Loss:1.239264726638794, G_Loss:1.2460788488388062

iterator 1300, D_Loss:1.3228957653045654, G_Loss:1.1962281465530396

iterator 1400, D_Loss:1.1820647716522217, G_Loss:1.3119256496429443

iterator 1500, D_Loss:1.2169910669326782, G_Loss:1.1972784996032715

iterator 1600, D_Loss:1.25900137424469, G_Loss:1.1187856197357178

iterator 1700, D_Loss:1.276508092880249, G_Loss:1.1530590057373047

iterator 1800, D_Loss:1.1409926414489746, G_Loss:1.2078349590301514

iterator 1900, D_Loss:1.206836223602295, G_Loss:1.250788927078247

iterator 2000, D_Loss:1.2586148977279663, G_Loss:1.2190687656402588

iterator 2100, D_Loss:1.2341275215148926, G_Loss:1.205682396888733

iterator 2200, D_Loss:1.2551627159118652, G_Loss:1.173458456993103

iterator 2300, D_Loss:1.268786907196045, G_Loss:1.1262725591659546

iterator 2400, D_Loss:1.1748337745666504, G_Loss:1.3051854372024536

iterator 2500, D_Loss:1.2684869766235352, G_Loss:1.2534112930297852

iterator 2600, D_Loss:1.2409985065460205, G_Loss:1.218608021736145

iterator 2700, D_Loss:1.1597551107406616, G_Loss:1.1974729299545288

iterator 2800, D_Loss:1.170405626296997, G_Loss:1.229141116142273

iterator 2900, D_Loss:1.3254599571228027, G_Loss:1.1278349161148071

iterator 3000, D_Loss:1.2528812885284424, G_Loss:1.1402298212051392

iterator 3100, D_Loss:1.2399089336395264, G_Loss:1.1490399837493896

iterator 3200, D_Loss:1.2305121421813965, G_Loss:1.1974643468856812

iterator 3300, D_Loss:1.2182409763336182, G_Loss:1.1420515775680542

iterator 3400, D_Loss:1.1554063558578491, G_Loss:1.269718885421753

iterator 3500, D_Loss:1.2472569942474365, G_Loss:1.16762113571167

iterator 3600, D_Loss:1.1758447885513306, G_Loss:1.1647813320159912

iterator 3700, D_Loss:1.2286336421966553, G_Loss:1.27883780002594

iterator 3800, D_Loss:1.24420166015625, G_Loss:1.2115505933761597

iterator 3900, D_Loss:1.1820006370544434, G_Loss:1.1532186269760132

iterator 4000, D_Loss:1.1204899549484253, G_Loss:1.1488815546035767

iterator 4100, D_Loss:1.3044631481170654, G_Loss:1.1526014804840088

iterator 4200, D_Loss:1.2399530410766602, G_Loss:1.1312222480773926

iterator 4300, D_Loss:1.26522958278656, G_Loss:1.1539247035980225

iterator 4400, D_Loss:1.1789803504943848, G_Loss:1.2963038682937622

iterator 4500, D_Loss:1.167938470840454, G_Loss:1.1169177293777466

iterator 4600, D_Loss:1.1947481632232666, G_Loss:1.1277236938476562

iterator 4700, D_Loss:1.2375411987304688, G_Loss:1.216509222984314

iterator 4800, D_Loss:1.2168949842453003, G_Loss:1.2137080430984497

iterator 4900, D_Loss:1.196033239364624, G_Loss:1.2022593021392822

iterator 5000, D_Loss:1.3197169303894043, G_Loss:1.1694109439849854

-----------Epoch 9-----------
iterator 100, D_Loss:1.304176926612854, G_Loss:1.1898276805877686

iterator 200, D_Loss:1.3084509372711182, G_Loss:1.1129518747329712

iterator 300, D_Loss:1.2979191541671753, G_Loss:1.0714088678359985

iterator 400, D_Loss:1.293169617652893, G_Loss:1.0986875295639038

iterator 500, D_Loss:1.2336854934692383, G_Loss:1.1320747137069702

iterator 600, D_Loss:1.2511584758758545, G_Loss:1.1353646516799927

iterator 700, D_Loss:1.251659870147705, G_Loss:1.1761494874954224

iterator 800, D_Loss:1.2102060317993164, G_Loss:1.1946614980697632

iterator 900, D_Loss:1.2116789817810059, G_Loss:1.121902585029602

iterator 1000, D_Loss:1.2309162616729736, G_Loss:1.1688462495803833

iterator 1100, D_Loss:1.3418461084365845, G_Loss:1.0854692459106445

iterator 1200, D_Loss:1.3029531240463257, G_Loss:1.0562052726745605

iterator 1300, D_Loss:1.2269351482391357, G_Loss:1.1220706701278687

iterator 1400, D_Loss:1.266459345817566, G_Loss:1.0992153882980347

iterator 1500, D_Loss:1.3173012733459473, G_Loss:1.1113463640213013

iterator 1600, D_Loss:1.262223482131958, G_Loss:1.1438820362091064

iterator 1700, D_Loss:1.2639597654342651, G_Loss:1.0996582508087158

iterator 1800, D_Loss:1.2442059516906738, G_Loss:1.1830743551254272

iterator 1900, D_Loss:1.273380994796753, G_Loss:1.094725489616394

iterator 2000, D_Loss:1.2340197563171387, G_Loss:1.1128544807434082

iterator 2100, D_Loss:1.2537641525268555, G_Loss:1.1822218894958496

iterator 2200, D_Loss:1.2628211975097656, G_Loss:1.050722360610962

iterator 2300, D_Loss:1.2060139179229736, G_Loss:1.1409040689468384

iterator 2400, D_Loss:1.1617810726165771, G_Loss:1.1458590030670166

iterator 2500, D_Loss:1.3305319547653198, G_Loss:1.0741649866104126

iterator 2600, D_Loss:1.2868345975875854, G_Loss:1.1607805490493774

iterator 2700, D_Loss:1.336763858795166, G_Loss:1.1492102146148682

iterator 2800, D_Loss:1.277704119682312, G_Loss:1.1026266813278198

iterator 2900, D_Loss:1.1805601119995117, G_Loss:1.0405999422073364

iterator 3000, D_Loss:1.2351913452148438, G_Loss:1.0521160364151

iterator 3100, D_Loss:1.2247925996780396, G_Loss:1.09270441532135

iterator 3200, D_Loss:1.3217556476593018, G_Loss:1.1416864395141602

iterator 3300, D_Loss:1.279768466949463, G_Loss:1.0923842191696167

iterator 3400, D_Loss:1.2984116077423096, G_Loss:1.1270456314086914

iterator 3500, D_Loss:1.269951343536377, G_Loss:1.0892670154571533

iterator 3600, D_Loss:1.2195063829421997, G_Loss:1.080615758895874

iterator 3700, D_Loss:1.262817621231079, G_Loss:1.176486849784851

iterator 3800, D_Loss:1.2521275281906128, G_Loss:1.0574158430099487

iterator 3900, D_Loss:1.2821345329284668, G_Loss:1.1017041206359863

iterator 4000, D_Loss:1.2522025108337402, G_Loss:1.1232091188430786

iterator 4100, D_Loss:1.2267529964447021, G_Loss:1.1521252393722534

iterator 4200, D_Loss:1.2763053178787231, G_Loss:1.1220848560333252

iterator 4300, D_Loss:1.2510948181152344, G_Loss:1.0702800750732422

iterator 4400, D_Loss:1.2774397134780884, G_Loss:1.101989507675171

iterator 4500, D_Loss:1.3296446800231934, G_Loss:1.1049360036849976

iterator 4600, D_Loss:1.2306675910949707, G_Loss:1.1139397621154785

iterator 4700, D_Loss:1.2719298601150513, G_Loss:1.095054268836975

iterator 4800, D_Loss:1.3216865062713623, G_Loss:1.0548808574676514

iterator 4900, D_Loss:1.2442457675933838, G_Loss:0.9711155891418457

iterator 5000, D_Loss:1.264481782913208, G_Loss:1.166975975036621

VGAN_generator(
  (input): Linear(in_features=128, out_features=300, bias=True)
  (inputbn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=300, out_features=300, bias=True)
  (bn0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=300, out_features=105, bias=True)
  (outputbn): BatchNorm1d(105, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=105, out_features=200, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (fc1): Linear(in_features=200, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=200, bias=True)
  (output): Linear(in_features=200, out_features=1, bias=True)
)
(0, False, 105)
-----------Epoch 0-----------
iterator 100, D_Loss:0.5771395564079285, G_Loss:7.941619396209717

iterator 200, D_Loss:0.49460113048553467, G_Loss:8.383402824401855

iterator 300, D_Loss:0.47340667247772217, G_Loss:9.110745429992676

iterator 400, D_Loss:0.5038169026374817, G_Loss:7.801514625549316

iterator 500, D_Loss:0.4581637978553772, G_Loss:7.3675007820129395

iterator 600, D_Loss:0.4853902757167816, G_Loss:7.056064605712891

iterator 700, D_Loss:0.4882580041885376, G_Loss:6.167723655700684

iterator 800, D_Loss:0.506149172782898, G_Loss:5.667821884155273

iterator 900, D_Loss:0.5000308752059937, G_Loss:5.58926248550415

iterator 1000, D_Loss:0.5195827484130859, G_Loss:5.511035442352295

iterator 1100, D_Loss:0.5475847125053406, G_Loss:5.069452285766602

iterator 1200, D_Loss:0.5583577156066895, G_Loss:5.439173221588135

iterator 1300, D_Loss:0.5590534210205078, G_Loss:5.13446569442749

iterator 1400, D_Loss:0.5907033681869507, G_Loss:4.689807415008545

iterator 1500, D_Loss:0.5981199145317078, G_Loss:4.1353373527526855

iterator 1600, D_Loss:0.5863931775093079, G_Loss:4.749764919281006

iterator 1700, D_Loss:0.6231234073638916, G_Loss:4.314691543579102

iterator 1800, D_Loss:0.6060666441917419, G_Loss:4.219964504241943

iterator 1900, D_Loss:0.6507063508033752, G_Loss:4.433915615081787

iterator 2000, D_Loss:0.5827643275260925, G_Loss:4.353289604187012

iterator 2100, D_Loss:0.6804125308990479, G_Loss:4.020328044891357

iterator 2200, D_Loss:0.657931923866272, G_Loss:3.730747938156128

iterator 2300, D_Loss:0.68161940574646, G_Loss:4.1117706298828125

iterator 2400, D_Loss:0.6553525924682617, G_Loss:3.7224104404449463

iterator 2500, D_Loss:0.7667766809463501, G_Loss:3.2430226802825928

iterator 2600, D_Loss:0.7427634000778198, G_Loss:3.520458459854126

iterator 2700, D_Loss:0.6970384120941162, G_Loss:3.5295355319976807

iterator 2800, D_Loss:0.7405731678009033, G_Loss:3.0247621536254883

iterator 2900, D_Loss:0.7105706930160522, G_Loss:3.1306540966033936

iterator 3000, D_Loss:0.7620088458061218, G_Loss:3.221740245819092

iterator 3100, D_Loss:0.7601523995399475, G_Loss:2.934873580932617

iterator 3200, D_Loss:0.7934883236885071, G_Loss:2.9103708267211914

iterator 3300, D_Loss:0.75010085105896, G_Loss:2.969717502593994

iterator 3400, D_Loss:0.7771832942962646, G_Loss:2.806969165802002

iterator 3500, D_Loss:0.7902900576591492, G_Loss:2.82858943939209

iterator 3600, D_Loss:0.7714216113090515, G_Loss:3.1300723552703857

iterator 3700, D_Loss:0.8107486963272095, G_Loss:2.758126735687256

iterator 3800, D_Loss:0.8328025341033936, G_Loss:2.9506425857543945

iterator 3900, D_Loss:0.7820772528648376, G_Loss:2.8511087894439697

iterator 4000, D_Loss:0.7979227900505066, G_Loss:2.8252272605895996

iterator 4100, D_Loss:0.8287203311920166, G_Loss:2.725163459777832

iterator 4200, D_Loss:0.7929626107215881, G_Loss:2.7784790992736816

iterator 4300, D_Loss:0.8427974581718445, G_Loss:2.750037431716919

iterator 4400, D_Loss:0.860933780670166, G_Loss:2.519155740737915

iterator 4500, D_Loss:0.873223066329956, G_Loss:2.499002456665039

iterator 4600, D_Loss:0.918986976146698, G_Loss:2.4303154945373535

iterator 4700, D_Loss:0.8497806191444397, G_Loss:2.3739092350006104

iterator 4800, D_Loss:0.8703508377075195, G_Loss:2.2166919708251953

iterator 4900, D_Loss:0.8493894338607788, G_Loss:2.4619972705841064

iterator 5000, D_Loss:0.8413310050964355, G_Loss:2.3512067794799805

-----------Epoch 1-----------
iterator 100, D_Loss:0.8265261650085449, G_Loss:2.3639707565307617

iterator 200, D_Loss:0.8710817098617554, G_Loss:2.318498134613037

iterator 300, D_Loss:0.8713250160217285, G_Loss:2.4702677726745605

iterator 400, D_Loss:0.8842093348503113, G_Loss:2.4608380794525146

iterator 500, D_Loss:0.9103268384933472, G_Loss:2.3434839248657227

iterator 600, D_Loss:0.8934454917907715, G_Loss:2.308889865875244

iterator 700, D_Loss:0.9516087174415588, G_Loss:2.3073482513427734

iterator 800, D_Loss:0.9326647520065308, G_Loss:2.0545923709869385

iterator 900, D_Loss:0.9336298704147339, G_Loss:2.1411406993865967

iterator 1000, D_Loss:0.957304060459137, G_Loss:2.199631690979004

iterator 1100, D_Loss:0.9997906684875488, G_Loss:1.8768196105957031

iterator 1200, D_Loss:0.9186512231826782, G_Loss:2.1150543689727783

iterator 1300, D_Loss:0.933923602104187, G_Loss:2.0581517219543457

iterator 1400, D_Loss:0.9512350559234619, G_Loss:2.106910467147827

iterator 1500, D_Loss:1.010607361793518, G_Loss:2.199242353439331

iterator 1600, D_Loss:0.9857289791107178, G_Loss:2.045851707458496

iterator 1700, D_Loss:0.9327362179756165, G_Loss:1.8834091424942017

iterator 1800, D_Loss:0.9928393363952637, G_Loss:2.019327163696289

iterator 1900, D_Loss:0.9378663301467896, G_Loss:2.129225254058838

iterator 2000, D_Loss:1.0175814628601074, G_Loss:1.9027924537658691

iterator 2100, D_Loss:0.9763175845146179, G_Loss:1.817400336265564

iterator 2200, D_Loss:0.9813044667243958, G_Loss:1.882107138633728

iterator 2300, D_Loss:1.0044389963150024, G_Loss:1.8336155414581299

iterator 2400, D_Loss:0.9876836538314819, G_Loss:1.8151217699050903

iterator 2500, D_Loss:0.9869057536125183, G_Loss:1.7978841066360474

iterator 2600, D_Loss:1.0624423027038574, G_Loss:1.8541682958602905

iterator 2700, D_Loss:1.0535595417022705, G_Loss:1.677638292312622

iterator 2800, D_Loss:1.0408611297607422, G_Loss:1.7610623836517334

iterator 2900, D_Loss:1.0105314254760742, G_Loss:1.675858736038208

iterator 3000, D_Loss:1.0253832340240479, G_Loss:1.805904507637024

iterator 3100, D_Loss:1.0019428730010986, G_Loss:1.7957342863082886

iterator 3200, D_Loss:1.018919825553894, G_Loss:1.8106064796447754

iterator 3300, D_Loss:1.0195934772491455, G_Loss:1.7003728151321411

iterator 3400, D_Loss:1.038059949874878, G_Loss:1.7587125301361084

iterator 3500, D_Loss:1.0244044065475464, G_Loss:1.7603719234466553

iterator 3600, D_Loss:1.0560227632522583, G_Loss:1.679083228111267

iterator 3700, D_Loss:1.0730375051498413, G_Loss:1.8285764455795288

iterator 3800, D_Loss:1.092522382736206, G_Loss:1.6347161531448364

iterator 3900, D_Loss:1.0262210369110107, G_Loss:1.8336976766586304

iterator 4000, D_Loss:1.0426150560379028, G_Loss:1.7050765752792358

iterator 4100, D_Loss:1.103569507598877, G_Loss:1.8280671834945679

iterator 4200, D_Loss:1.0525016784667969, G_Loss:1.8045353889465332

iterator 4300, D_Loss:1.0729308128356934, G_Loss:1.768746256828308

iterator 4400, D_Loss:1.0349273681640625, G_Loss:1.721863031387329

iterator 4500, D_Loss:1.0267298221588135, G_Loss:1.802398920059204

iterator 4600, D_Loss:1.031216025352478, G_Loss:1.7140988111495972

iterator 4700, D_Loss:1.0776562690734863, G_Loss:1.677964448928833

iterator 4800, D_Loss:1.053492546081543, G_Loss:1.6741002798080444

iterator 4900, D_Loss:1.0909180641174316, G_Loss:1.6625149250030518

iterator 5000, D_Loss:1.0901645421981812, G_Loss:1.6783676147460938

-----------Epoch 2-----------
iterator 100, D_Loss:1.0706533193588257, G_Loss:1.681905746459961

iterator 200, D_Loss:1.1131500005722046, G_Loss:1.675166368484497

iterator 300, D_Loss:1.0506303310394287, G_Loss:1.6697481870651245

iterator 400, D_Loss:1.0413048267364502, G_Loss:1.6697334051132202

iterator 500, D_Loss:1.0460909605026245, G_Loss:1.7100391387939453

iterator 600, D_Loss:1.1126964092254639, G_Loss:1.688906192779541

iterator 700, D_Loss:1.1200006008148193, G_Loss:1.6884387731552124

iterator 800, D_Loss:1.0896682739257812, G_Loss:1.775181770324707

iterator 900, D_Loss:1.0714901685714722, G_Loss:1.5958629846572876

iterator 1000, D_Loss:1.068129301071167, G_Loss:1.7209956645965576

iterator 1100, D_Loss:1.0586411952972412, G_Loss:1.7300876379013062

iterator 1200, D_Loss:1.0951720476150513, G_Loss:1.7271184921264648

iterator 1300, D_Loss:1.050891637802124, G_Loss:1.7081063985824585

iterator 1400, D_Loss:1.0485693216323853, G_Loss:1.6493921279907227

iterator 1500, D_Loss:1.061484932899475, G_Loss:1.6673839092254639

iterator 1600, D_Loss:1.0656135082244873, G_Loss:1.7560604810714722

iterator 1700, D_Loss:1.0753631591796875, G_Loss:1.7362982034683228

iterator 1800, D_Loss:1.101672649383545, G_Loss:1.7248189449310303

iterator 1900, D_Loss:1.095651388168335, G_Loss:1.692383885383606

iterator 2000, D_Loss:1.0740047693252563, G_Loss:1.5679863691329956

iterator 2100, D_Loss:1.1059339046478271, G_Loss:1.6771661043167114

iterator 2200, D_Loss:1.0441923141479492, G_Loss:1.669419288635254

iterator 2300, D_Loss:1.0694931745529175, G_Loss:1.6010640859603882

iterator 2400, D_Loss:1.1052762269973755, G_Loss:1.556871771812439

iterator 2500, D_Loss:1.0845093727111816, G_Loss:1.61513090133667

iterator 2600, D_Loss:1.0747345685958862, G_Loss:1.465259075164795

iterator 2700, D_Loss:1.100111722946167, G_Loss:1.6835438013076782

iterator 2800, D_Loss:1.106250286102295, G_Loss:1.5650527477264404

iterator 2900, D_Loss:1.095635175704956, G_Loss:1.5652945041656494

iterator 3000, D_Loss:1.0936894416809082, G_Loss:1.4090005159378052

iterator 3100, D_Loss:1.1345345973968506, G_Loss:1.672986388206482

iterator 3200, D_Loss:1.0841890573501587, G_Loss:1.6595946550369263

iterator 3300, D_Loss:1.0912985801696777, G_Loss:1.4945062398910522

iterator 3400, D_Loss:1.0775012969970703, G_Loss:1.5834193229675293

iterator 3500, D_Loss:1.0741817951202393, G_Loss:1.6606112718582153

iterator 3600, D_Loss:1.1227198839187622, G_Loss:1.4569560289382935

iterator 3700, D_Loss:1.1522395610809326, G_Loss:1.5169334411621094

iterator 3800, D_Loss:1.138725757598877, G_Loss:1.4624398946762085

iterator 3900, D_Loss:1.1404883861541748, G_Loss:1.5027642250061035

iterator 4000, D_Loss:1.1098370552062988, G_Loss:1.5406852960586548

iterator 4100, D_Loss:1.160501480102539, G_Loss:1.6247014999389648

iterator 4200, D_Loss:1.0888562202453613, G_Loss:1.5670655965805054

iterator 4300, D_Loss:1.1413905620574951, G_Loss:1.5041134357452393

iterator 4400, D_Loss:1.1211062669754028, G_Loss:1.4951335191726685

iterator 4500, D_Loss:1.109720230102539, G_Loss:1.443893313407898

iterator 4600, D_Loss:1.1373608112335205, G_Loss:1.427222728729248

iterator 4700, D_Loss:1.1034393310546875, G_Loss:1.5673283338546753

iterator 4800, D_Loss:1.082082748413086, G_Loss:1.4621832370758057

iterator 4900, D_Loss:1.159388780593872, G_Loss:1.4222475290298462

iterator 5000, D_Loss:1.142296314239502, G_Loss:1.4413701295852661

-----------Epoch 3-----------
iterator 100, D_Loss:1.153337001800537, G_Loss:1.4283312559127808

iterator 200, D_Loss:1.1617953777313232, G_Loss:1.4656108617782593

iterator 300, D_Loss:1.1440551280975342, G_Loss:1.4507485628128052

iterator 400, D_Loss:1.1124770641326904, G_Loss:1.5015027523040771

iterator 500, D_Loss:1.0953218936920166, G_Loss:1.4541020393371582

iterator 600, D_Loss:1.1173075437545776, G_Loss:1.5711028575897217

iterator 700, D_Loss:1.1467653512954712, G_Loss:1.457588791847229

iterator 800, D_Loss:1.1938916444778442, G_Loss:1.3900573253631592

iterator 900, D_Loss:1.1684238910675049, G_Loss:1.4212572574615479

iterator 1000, D_Loss:1.1749560832977295, G_Loss:1.4388628005981445

iterator 1100, D_Loss:1.1465619802474976, G_Loss:1.4034180641174316

iterator 1200, D_Loss:1.1315431594848633, G_Loss:1.5101745128631592

iterator 1300, D_Loss:1.166200041770935, G_Loss:1.4846603870391846

iterator 1400, D_Loss:1.1028671264648438, G_Loss:1.577218770980835

iterator 1500, D_Loss:1.138195276260376, G_Loss:1.3906506299972534

iterator 1600, D_Loss:1.1122417449951172, G_Loss:1.414408564567566

iterator 1700, D_Loss:1.174543857574463, G_Loss:1.4957259893417358

iterator 1800, D_Loss:1.2089108228683472, G_Loss:1.4678752422332764

iterator 1900, D_Loss:1.1774108409881592, G_Loss:1.5493906736373901

iterator 2000, D_Loss:1.1763362884521484, G_Loss:1.403390645980835

iterator 2100, D_Loss:1.1426377296447754, G_Loss:1.4160479307174683

iterator 2200, D_Loss:1.1457303762435913, G_Loss:1.480878472328186

iterator 2300, D_Loss:1.1379224061965942, G_Loss:1.3554965257644653

iterator 2400, D_Loss:1.1982475519180298, G_Loss:1.4087424278259277

iterator 2500, D_Loss:1.1780503988265991, G_Loss:1.3720481395721436

iterator 2600, D_Loss:1.1916515827178955, G_Loss:1.401960849761963

iterator 2700, D_Loss:1.1271213293075562, G_Loss:1.3304351568222046

iterator 2800, D_Loss:1.1763083934783936, G_Loss:1.4224399328231812

iterator 2900, D_Loss:1.1868890523910522, G_Loss:1.3933860063552856

iterator 3000, D_Loss:1.1309365034103394, G_Loss:1.36781907081604

iterator 3100, D_Loss:1.169060468673706, G_Loss:1.473993182182312

iterator 3200, D_Loss:1.186373233795166, G_Loss:1.4588826894760132

iterator 3300, D_Loss:1.1632639169692993, G_Loss:1.3627901077270508

iterator 3400, D_Loss:1.1667406558990479, G_Loss:1.278005599975586

iterator 3500, D_Loss:1.1597825288772583, G_Loss:1.2928768396377563

iterator 3600, D_Loss:1.1808631420135498, G_Loss:1.3703840970993042

iterator 3700, D_Loss:1.2165849208831787, G_Loss:1.403273105621338

iterator 3800, D_Loss:1.1569037437438965, G_Loss:1.3794801235198975

iterator 3900, D_Loss:1.1858701705932617, G_Loss:1.3797128200531006

iterator 4000, D_Loss:1.1578829288482666, G_Loss:1.3166879415512085

iterator 4100, D_Loss:1.2081146240234375, G_Loss:1.3807698488235474

iterator 4200, D_Loss:1.196129322052002, G_Loss:1.2972437143325806

iterator 4300, D_Loss:1.2147408723831177, G_Loss:1.2799065113067627

iterator 4400, D_Loss:1.1392366886138916, G_Loss:1.2841272354125977

iterator 4500, D_Loss:1.1651235818862915, G_Loss:1.4414857625961304

iterator 4600, D_Loss:1.1694538593292236, G_Loss:1.329981803894043

iterator 4700, D_Loss:1.1735217571258545, G_Loss:1.2919434309005737

iterator 4800, D_Loss:1.1874537467956543, G_Loss:1.3773257732391357

iterator 4900, D_Loss:1.1842496395111084, G_Loss:1.2499703168869019

iterator 5000, D_Loss:1.1399803161621094, G_Loss:1.3143151998519897

-----------Epoch 4-----------
iterator 100, D_Loss:1.1652989387512207, G_Loss:1.4283758401870728

iterator 200, D_Loss:1.1617083549499512, G_Loss:1.2379357814788818

iterator 300, D_Loss:1.17887544631958, G_Loss:1.2580199241638184

iterator 400, D_Loss:1.1698795557022095, G_Loss:1.3275437355041504

iterator 500, D_Loss:1.1770687103271484, G_Loss:1.3349987268447876

iterator 600, D_Loss:1.2228443622589111, G_Loss:1.2963398694992065

iterator 700, D_Loss:1.193331003189087, G_Loss:1.2911341190338135

iterator 800, D_Loss:1.1782357692718506, G_Loss:1.253239393234253

iterator 900, D_Loss:1.201192855834961, G_Loss:1.3272619247436523

iterator 1000, D_Loss:1.163925290107727, G_Loss:1.3091816902160645

iterator 1100, D_Loss:1.1791021823883057, G_Loss:1.3086249828338623

iterator 1200, D_Loss:1.1451170444488525, G_Loss:1.2750095129013062

iterator 1300, D_Loss:1.1884942054748535, G_Loss:1.337960124015808

iterator 1400, D_Loss:1.2320553064346313, G_Loss:1.234923243522644

iterator 1500, D_Loss:1.1818242073059082, G_Loss:1.3184188604354858

iterator 1600, D_Loss:1.1959340572357178, G_Loss:1.2980778217315674

iterator 1700, D_Loss:1.212899923324585, G_Loss:1.5116677284240723

iterator 1800, D_Loss:1.2110748291015625, G_Loss:1.297958254814148

iterator 1900, D_Loss:1.2049591541290283, G_Loss:1.2422295808792114

iterator 2000, D_Loss:1.1836297512054443, G_Loss:1.309342861175537

iterator 2100, D_Loss:1.2182739973068237, G_Loss:1.3162431716918945

iterator 2200, D_Loss:1.1913375854492188, G_Loss:1.2815759181976318

iterator 2300, D_Loss:1.1990296840667725, G_Loss:1.2744674682617188

iterator 2400, D_Loss:1.2225743532180786, G_Loss:1.2438889741897583

iterator 2500, D_Loss:1.2071558237075806, G_Loss:1.3922890424728394

iterator 2600, D_Loss:1.1865565776824951, G_Loss:1.248213529586792

iterator 2700, D_Loss:1.1751278638839722, G_Loss:1.2296428680419922

iterator 2800, D_Loss:1.1995973587036133, G_Loss:1.2501620054244995

iterator 2900, D_Loss:1.2083297967910767, G_Loss:1.3113118410110474

iterator 3000, D_Loss:1.201299786567688, G_Loss:1.273775577545166

iterator 3100, D_Loss:1.2187340259552002, G_Loss:1.2932608127593994

iterator 3200, D_Loss:1.229017972946167, G_Loss:1.238285779953003

iterator 3300, D_Loss:1.1963346004486084, G_Loss:1.3362736701965332

iterator 3400, D_Loss:1.217585802078247, G_Loss:1.2413972616195679

iterator 3500, D_Loss:1.19139564037323, G_Loss:1.2035887241363525

iterator 3600, D_Loss:1.2209160327911377, G_Loss:1.3118215799331665

iterator 3700, D_Loss:1.217010259628296, G_Loss:1.2823781967163086

iterator 3800, D_Loss:1.2280768156051636, G_Loss:1.2811975479125977

iterator 3900, D_Loss:1.2168660163879395, G_Loss:1.2248890399932861

iterator 4000, D_Loss:1.1848441362380981, G_Loss:1.2529270648956299

iterator 4100, D_Loss:1.2256981134414673, G_Loss:1.230346918106079

iterator 4200, D_Loss:1.1996172666549683, G_Loss:1.3587948083877563

iterator 4300, D_Loss:1.2483519315719604, G_Loss:1.369560956954956

iterator 4400, D_Loss:1.1959736347198486, G_Loss:1.3613429069519043

iterator 4500, D_Loss:1.2198150157928467, G_Loss:1.1278748512268066

iterator 4600, D_Loss:1.187585473060608, G_Loss:1.2389764785766602

iterator 4700, D_Loss:1.2210354804992676, G_Loss:1.1863431930541992

iterator 4800, D_Loss:1.2225549221038818, G_Loss:1.150362253189087

iterator 4900, D_Loss:1.2014260292053223, G_Loss:1.234468936920166

iterator 5000, D_Loss:1.1983559131622314, G_Loss:1.241919994354248

-----------Epoch 5-----------
iterator 100, D_Loss:1.2121129035949707, G_Loss:1.1469119787216187

iterator 200, D_Loss:1.2107677459716797, G_Loss:1.1526116132736206

iterator 300, D_Loss:1.1759988069534302, G_Loss:1.2443742752075195

iterator 400, D_Loss:1.2253234386444092, G_Loss:1.1943491697311401

iterator 500, D_Loss:1.2039494514465332, G_Loss:1.217774510383606

iterator 600, D_Loss:1.2565531730651855, G_Loss:1.2251770496368408

iterator 700, D_Loss:1.1969259977340698, G_Loss:1.2186564207077026

iterator 800, D_Loss:1.1991348266601562, G_Loss:1.1764899492263794

iterator 900, D_Loss:1.2180911302566528, G_Loss:1.3023006916046143

iterator 1000, D_Loss:1.1996970176696777, G_Loss:1.1749757528305054

iterator 1100, D_Loss:1.200740098953247, G_Loss:1.1824370622634888

iterator 1200, D_Loss:1.194498896598816, G_Loss:1.3107924461364746

iterator 1300, D_Loss:1.2108935117721558, G_Loss:1.1703667640686035

iterator 1400, D_Loss:1.1919877529144287, G_Loss:1.3059405088424683

iterator 1500, D_Loss:1.2031993865966797, G_Loss:1.283543348312378

iterator 1600, D_Loss:1.2074825763702393, G_Loss:1.1497613191604614

iterator 1700, D_Loss:1.2230939865112305, G_Loss:1.3065634965896606

iterator 1800, D_Loss:1.2254149913787842, G_Loss:1.1950876712799072

iterator 1900, D_Loss:1.2235325574874878, G_Loss:1.2294615507125854

iterator 2000, D_Loss:1.1907777786254883, G_Loss:1.1944748163223267

iterator 2100, D_Loss:1.2256641387939453, G_Loss:1.163814663887024

iterator 2200, D_Loss:1.1977818012237549, G_Loss:1.1541142463684082

iterator 2300, D_Loss:1.2006667852401733, G_Loss:1.2272849082946777

iterator 2400, D_Loss:1.2471582889556885, G_Loss:1.2263764142990112

iterator 2500, D_Loss:1.2412341833114624, G_Loss:1.2738866806030273

iterator 2600, D_Loss:1.2366604804992676, G_Loss:1.1952470541000366

iterator 2700, D_Loss:1.2312958240509033, G_Loss:1.1855578422546387

iterator 2800, D_Loss:1.2462300062179565, G_Loss:1.1732614040374756

iterator 2900, D_Loss:1.1898061037063599, G_Loss:1.2356821298599243

iterator 3000, D_Loss:1.2037973403930664, G_Loss:1.1385787725448608

iterator 3100, D_Loss:1.201150894165039, G_Loss:1.291670322418213

iterator 3200, D_Loss:1.2442283630371094, G_Loss:1.0805163383483887

iterator 3300, D_Loss:1.2118420600891113, G_Loss:1.1816695928573608

iterator 3400, D_Loss:1.2388966083526611, G_Loss:1.1453722715377808

iterator 3500, D_Loss:1.2403037548065186, G_Loss:1.2109261751174927

iterator 3600, D_Loss:1.2615350484848022, G_Loss:1.2794989347457886

iterator 3700, D_Loss:1.2435352802276611, G_Loss:1.1051371097564697

iterator 3800, D_Loss:1.2362102270126343, G_Loss:1.1817883253097534

iterator 3900, D_Loss:1.2274726629257202, G_Loss:1.2581281661987305

iterator 4000, D_Loss:1.2735968828201294, G_Loss:1.1781269311904907

iterator 4100, D_Loss:1.2149113416671753, G_Loss:1.1526962518692017

iterator 4200, D_Loss:1.2060424089431763, G_Loss:1.1756021976470947

iterator 4300, D_Loss:1.229006290435791, G_Loss:1.189527988433838

iterator 4400, D_Loss:1.2172751426696777, G_Loss:1.2726655006408691

iterator 4500, D_Loss:1.2616658210754395, G_Loss:1.2093340158462524

iterator 4600, D_Loss:1.2695742845535278, G_Loss:1.0624147653579712

iterator 4700, D_Loss:1.2502325773239136, G_Loss:1.0836400985717773

iterator 4800, D_Loss:1.2407511472702026, G_Loss:1.1894587278366089

iterator 4900, D_Loss:1.2258716821670532, G_Loss:1.1583333015441895

iterator 5000, D_Loss:1.2181649208068848, G_Loss:1.173050045967102

-----------Epoch 6-----------
iterator 100, D_Loss:1.2172465324401855, G_Loss:1.1780524253845215

iterator 200, D_Loss:1.2299104928970337, G_Loss:1.1746219396591187

iterator 300, D_Loss:1.222632884979248, G_Loss:1.2282147407531738

iterator 400, D_Loss:1.1984968185424805, G_Loss:1.1275628805160522

iterator 500, D_Loss:1.2399601936340332, G_Loss:1.1484251022338867

iterator 600, D_Loss:1.251528263092041, G_Loss:1.1868330240249634

iterator 700, D_Loss:1.2142763137817383, G_Loss:1.0837478637695312

iterator 800, D_Loss:1.2442864179611206, G_Loss:1.1649444103240967

iterator 900, D_Loss:1.2417792081832886, G_Loss:1.1493250131607056

iterator 1000, D_Loss:1.2362236976623535, G_Loss:1.1440805196762085

iterator 1100, D_Loss:1.2556017637252808, G_Loss:1.0982918739318848

iterator 1200, D_Loss:1.249435544013977, G_Loss:1.159242868423462

iterator 1300, D_Loss:1.241891622543335, G_Loss:1.1802070140838623

iterator 1400, D_Loss:1.2295825481414795, G_Loss:1.19342839717865

iterator 1500, D_Loss:1.2390340566635132, G_Loss:1.1160063743591309

iterator 1600, D_Loss:1.2091734409332275, G_Loss:1.1799037456512451

iterator 1700, D_Loss:1.2406394481658936, G_Loss:1.1405301094055176

iterator 1800, D_Loss:1.2448718547821045, G_Loss:1.1119309663772583

iterator 1900, D_Loss:1.257746696472168, G_Loss:1.1044296026229858

iterator 2000, D_Loss:1.2480058670043945, G_Loss:1.1772462129592896

iterator 2100, D_Loss:1.2488179206848145, G_Loss:1.1791572570800781

iterator 2200, D_Loss:1.2418122291564941, G_Loss:1.1654572486877441

iterator 2300, D_Loss:1.2326555252075195, G_Loss:1.0931469202041626

iterator 2400, D_Loss:1.2528700828552246, G_Loss:1.1520609855651855

iterator 2500, D_Loss:1.2597723007202148, G_Loss:1.122539758682251

iterator 2600, D_Loss:1.244227647781372, G_Loss:1.1694754362106323

iterator 2700, D_Loss:1.2535343170166016, G_Loss:1.0712392330169678

iterator 2800, D_Loss:1.2720558643341064, G_Loss:1.1653296947479248

iterator 2900, D_Loss:1.274003028869629, G_Loss:1.1327239274978638

iterator 3000, D_Loss:1.2405110597610474, G_Loss:1.138286828994751

iterator 3100, D_Loss:1.2260981798171997, G_Loss:1.069353699684143

iterator 3200, D_Loss:1.2359073162078857, G_Loss:1.150250792503357

iterator 3300, D_Loss:1.247114896774292, G_Loss:1.1135592460632324

iterator 3400, D_Loss:1.2460873126983643, G_Loss:1.1112911701202393

iterator 3500, D_Loss:1.2794032096862793, G_Loss:1.0898655652999878

iterator 3600, D_Loss:1.2495453357696533, G_Loss:1.1069304943084717

iterator 3700, D_Loss:1.2619658708572388, G_Loss:1.1033332347869873

iterator 3800, D_Loss:1.247210144996643, G_Loss:1.1150654554367065

iterator 3900, D_Loss:1.2439906597137451, G_Loss:1.1267650127410889

iterator 4000, D_Loss:1.2428103685379028, G_Loss:1.1094673871994019

iterator 4100, D_Loss:1.253775715827942, G_Loss:1.1044986248016357

iterator 4200, D_Loss:1.270001769065857, G_Loss:1.1547261476516724

iterator 4300, D_Loss:1.2439309358596802, G_Loss:1.123908281326294

iterator 4400, D_Loss:1.2740066051483154, G_Loss:1.1624711751937866

iterator 4500, D_Loss:1.2865829467773438, G_Loss:1.0416655540466309

iterator 4600, D_Loss:1.2592473030090332, G_Loss:1.0543638467788696

iterator 4700, D_Loss:1.2623823881149292, G_Loss:1.1397994756698608

iterator 4800, D_Loss:1.2610068321228027, G_Loss:1.0916721820831299

iterator 4900, D_Loss:1.2978699207305908, G_Loss:1.1911060810089111

iterator 5000, D_Loss:1.2138396501541138, G_Loss:1.1103719472885132

-----------Epoch 7-----------
iterator 100, D_Loss:1.2573843002319336, G_Loss:1.0434515476226807

iterator 200, D_Loss:1.2705715894699097, G_Loss:1.1066670417785645

iterator 300, D_Loss:1.2876622676849365, G_Loss:1.080163598060608

iterator 400, D_Loss:1.2509241104125977, G_Loss:1.1261249780654907

iterator 500, D_Loss:1.2613961696624756, G_Loss:1.0809051990509033

iterator 600, D_Loss:1.259498953819275, G_Loss:1.1281980276107788

iterator 700, D_Loss:1.2387781143188477, G_Loss:1.0409808158874512

iterator 800, D_Loss:1.250978708267212, G_Loss:1.1356098651885986

iterator 900, D_Loss:1.310604214668274, G_Loss:1.0848559141159058

iterator 1000, D_Loss:1.278246521949768, G_Loss:1.085996389389038

iterator 1100, D_Loss:1.2834248542785645, G_Loss:1.1016677618026733

iterator 1200, D_Loss:1.2587488889694214, G_Loss:1.1137909889221191

iterator 1300, D_Loss:1.2649009227752686, G_Loss:1.108872413635254

iterator 1400, D_Loss:1.2377254962921143, G_Loss:1.1048532724380493

iterator 1500, D_Loss:1.2491354942321777, G_Loss:1.034169316291809

iterator 1600, D_Loss:1.2803127765655518, G_Loss:1.0799962282180786

iterator 1700, D_Loss:1.2552752494812012, G_Loss:1.1104179620742798

iterator 1800, D_Loss:1.2524755001068115, G_Loss:1.1271929740905762

iterator 1900, D_Loss:1.2814152240753174, G_Loss:1.0770363807678223

iterator 2000, D_Loss:1.2683632373809814, G_Loss:1.0865671634674072

iterator 2100, D_Loss:1.2652850151062012, G_Loss:1.1384471654891968

iterator 2200, D_Loss:1.2437214851379395, G_Loss:1.0191807746887207

iterator 2300, D_Loss:1.281591773033142, G_Loss:1.1041662693023682

iterator 2400, D_Loss:1.2834961414337158, G_Loss:1.0405887365341187

iterator 2500, D_Loss:1.255723476409912, G_Loss:1.0343466997146606

iterator 2600, D_Loss:1.2850661277770996, G_Loss:1.0896737575531006

iterator 2700, D_Loss:1.2748072147369385, G_Loss:1.0779125690460205

iterator 2800, D_Loss:1.2826497554779053, G_Loss:1.067353367805481

iterator 2900, D_Loss:1.2935909032821655, G_Loss:1.063461422920227

iterator 3000, D_Loss:1.2724347114562988, G_Loss:1.001253366470337

iterator 3100, D_Loss:1.256363034248352, G_Loss:1.0441570281982422

iterator 3200, D_Loss:1.25697922706604, G_Loss:1.0607789754867554

iterator 3300, D_Loss:1.2721962928771973, G_Loss:1.071869134902954

iterator 3400, D_Loss:1.2947204113006592, G_Loss:1.0708733797073364

iterator 3500, D_Loss:1.2882049083709717, G_Loss:1.0365887880325317

iterator 3600, D_Loss:1.248694896697998, G_Loss:1.036178469657898

iterator 3700, D_Loss:1.2772700786590576, G_Loss:1.0203200578689575

iterator 3800, D_Loss:1.252305030822754, G_Loss:1.0751177072525024

iterator 3900, D_Loss:1.2589061260223389, G_Loss:1.0884764194488525

iterator 4000, D_Loss:1.2768654823303223, G_Loss:1.0595371723175049

iterator 4100, D_Loss:1.2658909559249878, G_Loss:1.0080410242080688

iterator 4200, D_Loss:1.2923041582107544, G_Loss:1.1153578758239746

iterator 4300, D_Loss:1.2741022109985352, G_Loss:1.0295740365982056

iterator 4400, D_Loss:1.290144920349121, G_Loss:1.105491280555725

iterator 4500, D_Loss:1.3041884899139404, G_Loss:1.0365899801254272

iterator 4600, D_Loss:1.2627403736114502, G_Loss:1.123209834098816

iterator 4700, D_Loss:1.282362461090088, G_Loss:1.0165431499481201

iterator 4800, D_Loss:1.2612279653549194, G_Loss:1.0521959066390991

iterator 4900, D_Loss:1.2948582172393799, G_Loss:1.0830007791519165

iterator 5000, D_Loss:1.2664998769760132, G_Loss:1.0491297245025635

-----------Epoch 8-----------
iterator 100, D_Loss:1.2947965860366821, G_Loss:1.0685795545578003

iterator 200, D_Loss:1.2774803638458252, G_Loss:1.1008683443069458

iterator 300, D_Loss:1.2741427421569824, G_Loss:1.0660507678985596

iterator 400, D_Loss:1.253406286239624, G_Loss:1.006943941116333

iterator 500, D_Loss:1.2797787189483643, G_Loss:1.1260656118392944

iterator 600, D_Loss:1.3018782138824463, G_Loss:1.0803340673446655

iterator 700, D_Loss:1.270218849182129, G_Loss:1.0723198652267456

iterator 800, D_Loss:1.2910728454589844, G_Loss:1.0844262838363647

iterator 900, D_Loss:1.312401294708252, G_Loss:1.0471515655517578

iterator 1000, D_Loss:1.2939825057983398, G_Loss:1.0542150735855103

iterator 1100, D_Loss:1.2794551849365234, G_Loss:1.0660570859909058

iterator 1200, D_Loss:1.2641444206237793, G_Loss:1.1105326414108276

iterator 1300, D_Loss:1.279803991317749, G_Loss:1.0122051239013672

iterator 1400, D_Loss:1.2880399227142334, G_Loss:1.0726045370101929

iterator 1500, D_Loss:1.2769559621810913, G_Loss:1.0856218338012695

iterator 1600, D_Loss:1.2785463333129883, G_Loss:1.0268062353134155

iterator 1700, D_Loss:1.2618224620819092, G_Loss:1.014972448348999

iterator 1800, D_Loss:1.2821507453918457, G_Loss:1.0782568454742432

iterator 1900, D_Loss:1.2737271785736084, G_Loss:1.0764672756195068

iterator 2000, D_Loss:1.2830054759979248, G_Loss:1.0540735721588135

iterator 2100, D_Loss:1.2666159868240356, G_Loss:1.0581977367401123

iterator 2200, D_Loss:1.2761529684066772, G_Loss:1.027944803237915

iterator 2300, D_Loss:1.2761306762695312, G_Loss:0.959706723690033

iterator 2400, D_Loss:1.2875603437423706, G_Loss:1.0588639974594116

iterator 2500, D_Loss:1.2875847816467285, G_Loss:1.0413154363632202

iterator 2600, D_Loss:1.2548184394836426, G_Loss:1.0846554040908813

iterator 2700, D_Loss:1.286329984664917, G_Loss:1.0507712364196777

iterator 2800, D_Loss:1.2961965799331665, G_Loss:0.9984264969825745

iterator 2900, D_Loss:1.277397632598877, G_Loss:1.0493882894515991

iterator 3000, D_Loss:1.2612824440002441, G_Loss:1.044966220855713

iterator 3100, D_Loss:1.2621634006500244, G_Loss:1.0353461503982544

iterator 3200, D_Loss:1.2729623317718506, G_Loss:1.0209097862243652

iterator 3300, D_Loss:1.2615101337432861, G_Loss:1.008884310722351

iterator 3400, D_Loss:1.27090322971344, G_Loss:1.0126651525497437

iterator 3500, D_Loss:1.2866504192352295, G_Loss:1.0527933835983276

iterator 3600, D_Loss:1.2873618602752686, G_Loss:1.0508664846420288

iterator 3700, D_Loss:1.2944546937942505, G_Loss:1.0668193101882935

iterator 3800, D_Loss:1.2977122068405151, G_Loss:1.0447126626968384

iterator 3900, D_Loss:1.2776753902435303, G_Loss:1.0285835266113281

iterator 4000, D_Loss:1.3005247116088867, G_Loss:1.0140819549560547

iterator 4100, D_Loss:1.2889971733093262, G_Loss:1.0339206457138062

iterator 4200, D_Loss:1.277469277381897, G_Loss:1.049992322921753

iterator 4300, D_Loss:1.2836294174194336, G_Loss:0.9589582681655884

iterator 4400, D_Loss:1.2732926607131958, G_Loss:1.0155208110809326

iterator 4500, D_Loss:1.314584493637085, G_Loss:1.0653427839279175

iterator 4600, D_Loss:1.2855783700942993, G_Loss:1.0426924228668213

iterator 4700, D_Loss:1.283026933670044, G_Loss:1.0165481567382812

iterator 4800, D_Loss:1.2914342880249023, G_Loss:1.0254989862442017

iterator 4900, D_Loss:1.2779358625411987, G_Loss:1.0011521577835083

iterator 5000, D_Loss:1.2621904611587524, G_Loss:1.00617516040802

-----------Epoch 9-----------
iterator 100, D_Loss:1.3075611591339111, G_Loss:1.007934808731079

iterator 200, D_Loss:1.2899410724639893, G_Loss:1.0217772722244263

iterator 300, D_Loss:1.2798573970794678, G_Loss:1.0490528345108032

iterator 400, D_Loss:1.2780288457870483, G_Loss:1.0687127113342285

iterator 500, D_Loss:1.3097832202911377, G_Loss:1.039266586303711

iterator 600, D_Loss:1.2943840026855469, G_Loss:1.0521258115768433

iterator 700, D_Loss:1.2924580574035645, G_Loss:1.0040045976638794

iterator 800, D_Loss:1.2804324626922607, G_Loss:1.0750460624694824

iterator 900, D_Loss:1.289646863937378, G_Loss:0.9764578938484192

iterator 1000, D_Loss:1.2813657522201538, G_Loss:1.055637001991272

iterator 1100, D_Loss:1.2818304300308228, G_Loss:1.0093015432357788

iterator 1200, D_Loss:1.3027739524841309, G_Loss:1.0455756187438965

iterator 1300, D_Loss:1.2625064849853516, G_Loss:1.0766708850860596

iterator 1400, D_Loss:1.2842096090316772, G_Loss:1.069502353668213

iterator 1500, D_Loss:1.2912812232971191, G_Loss:1.0278176069259644

iterator 1600, D_Loss:1.308327555656433, G_Loss:1.0219509601593018

iterator 1700, D_Loss:1.2944514751434326, G_Loss:1.0025839805603027

iterator 1800, D_Loss:1.2742366790771484, G_Loss:1.0467092990875244

iterator 1900, D_Loss:1.2873539924621582, G_Loss:1.0441852807998657

iterator 2000, D_Loss:1.2781952619552612, G_Loss:0.9917325973510742

iterator 2100, D_Loss:1.2866175174713135, G_Loss:1.08992338180542

iterator 2200, D_Loss:1.290898323059082, G_Loss:1.070583462715149

iterator 2300, D_Loss:1.2777583599090576, G_Loss:1.0512189865112305

iterator 2400, D_Loss:1.303457260131836, G_Loss:1.024833083152771

iterator 2500, D_Loss:1.2996503114700317, G_Loss:1.0367887020111084

iterator 2600, D_Loss:1.2912812232971191, G_Loss:1.0314838886260986

iterator 2700, D_Loss:1.294710397720337, G_Loss:1.034740924835205

iterator 2800, D_Loss:1.3074414730072021, G_Loss:1.02222740650177

iterator 2900, D_Loss:1.3165254592895508, G_Loss:1.0191620588302612

iterator 3000, D_Loss:1.2861926555633545, G_Loss:1.0315638780593872

iterator 3100, D_Loss:1.301931619644165, G_Loss:1.004213571548462

iterator 3200, D_Loss:1.2915071249008179, G_Loss:1.0066745281219482

iterator 3300, D_Loss:1.279051661491394, G_Loss:0.9398239850997925

iterator 3400, D_Loss:1.282519817352295, G_Loss:1.005826711654663

iterator 3500, D_Loss:1.300826072692871, G_Loss:1.0356833934783936

iterator 3600, D_Loss:1.2985835075378418, G_Loss:1.0020825862884521

iterator 3700, D_Loss:1.2953039407730103, G_Loss:1.003644347190857

iterator 3800, D_Loss:1.2995688915252686, G_Loss:0.9878914952278137

iterator 3900, D_Loss:1.3057239055633545, G_Loss:1.0095890760421753

iterator 4000, D_Loss:1.3031566143035889, G_Loss:0.9890245795249939

iterator 4100, D_Loss:1.298283338546753, G_Loss:1.0019134283065796

iterator 4200, D_Loss:1.310473918914795, G_Loss:0.9937195777893066

iterator 4300, D_Loss:1.30958092212677, G_Loss:1.015231728553772

iterator 4400, D_Loss:1.3085310459136963, G_Loss:1.042407751083374

iterator 4500, D_Loss:1.3024342060089111, G_Loss:1.062065839767456

iterator 4600, D_Loss:1.291286587715149, G_Loss:0.9884534478187561

iterator 4700, D_Loss:1.3018479347229004, G_Loss:1.0735076665878296

iterator 4800, D_Loss:1.305558443069458, G_Loss:1.021655559539795

iterator 4900, D_Loss:1.2935354709625244, G_Loss:1.001198649406433

iterator 5000, D_Loss:1.2765580415725708, G_Loss:1.0193891525268555

train row : 30148
sample row: 30148
VGAN_generator(
  (input): Linear(in_features=128, out_features=100, bias=True)
  (inputbn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=100, out_features=100, bias=True)
  (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=100, out_features=15, bias=True)
  (outputbn): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=15, out_features=100, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (output): Linear(in_features=100, out_features=1, bias=True)
)
(0, False, 15)
-----------Epoch 0-----------
iterator 100, D_Loss:1.228487253189087, G_Loss:0.7984766364097595

iterator 200, D_Loss:1.0658336877822876, G_Loss:1.1053540706634521

iterator 300, D_Loss:0.8979784250259399, G_Loss:1.57491135597229

iterator 400, D_Loss:0.8878492116928101, G_Loss:2.040571689605713

iterator 500, D_Loss:0.8269651532173157, G_Loss:2.3728981018066406

iterator 600, D_Loss:0.8032149076461792, G_Loss:2.578040599822998

iterator 700, D_Loss:0.7895388603210449, G_Loss:2.727954864501953

iterator 800, D_Loss:0.7592522501945496, G_Loss:3.049528121948242

iterator 900, D_Loss:0.6888583898544312, G_Loss:3.093456268310547

iterator 1000, D_Loss:0.6573210954666138, G_Loss:3.316035747528076

iterator 1100, D_Loss:0.638752281665802, G_Loss:3.47912335395813

iterator 1200, D_Loss:0.6947258710861206, G_Loss:3.6915218830108643

iterator 1300, D_Loss:0.6179317235946655, G_Loss:3.7136549949645996

iterator 1400, D_Loss:0.6239290237426758, G_Loss:3.7681798934936523

iterator 1500, D_Loss:0.6129788160324097, G_Loss:4.022928237915039

iterator 1600, D_Loss:0.5941043496131897, G_Loss:4.0612568855285645

iterator 1700, D_Loss:0.5704881548881531, G_Loss:4.003840923309326

iterator 1800, D_Loss:0.6347914934158325, G_Loss:4.26834774017334

iterator 1900, D_Loss:0.6163391470909119, G_Loss:4.335921764373779

iterator 2000, D_Loss:0.5477562546730042, G_Loss:4.526649475097656

iterator 2100, D_Loss:0.5876502394676208, G_Loss:4.368167400360107

iterator 2200, D_Loss:0.5538684129714966, G_Loss:4.410139083862305

iterator 2300, D_Loss:0.5721220374107361, G_Loss:4.445045471191406

iterator 2400, D_Loss:0.5462262630462646, G_Loss:4.425163745880127

iterator 2500, D_Loss:0.5604002475738525, G_Loss:4.416989803314209

iterator 2600, D_Loss:0.5650196075439453, G_Loss:4.5074076652526855

iterator 2700, D_Loss:0.5692217946052551, G_Loss:4.338435173034668

iterator 2800, D_Loss:0.5497809648513794, G_Loss:4.463451385498047

iterator 2900, D_Loss:0.52498859167099, G_Loss:4.461172580718994

iterator 3000, D_Loss:0.5722261667251587, G_Loss:4.391666412353516

iterator 3100, D_Loss:0.5630512237548828, G_Loss:4.579086780548096

iterator 3200, D_Loss:0.553178071975708, G_Loss:4.418157577514648

iterator 3300, D_Loss:0.5769211053848267, G_Loss:4.560669898986816

iterator 3400, D_Loss:0.5512811541557312, G_Loss:4.559659481048584

iterator 3500, D_Loss:0.5658256411552429, G_Loss:4.61589241027832

iterator 3600, D_Loss:0.5555480122566223, G_Loss:4.563621997833252

iterator 3700, D_Loss:0.5213900208473206, G_Loss:4.470036029815674

iterator 3800, D_Loss:0.596039354801178, G_Loss:4.705123424530029

iterator 3900, D_Loss:0.5428948998451233, G_Loss:4.559823036193848

iterator 4000, D_Loss:0.5255261659622192, G_Loss:4.6548027992248535

iterator 4100, D_Loss:0.571463406085968, G_Loss:4.568081378936768

iterator 4200, D_Loss:0.5538285374641418, G_Loss:4.496636867523193

iterator 4300, D_Loss:0.5851917266845703, G_Loss:4.599401950836182

iterator 4400, D_Loss:0.5347577929496765, G_Loss:4.602604389190674

iterator 4500, D_Loss:0.5509685277938843, G_Loss:4.65116548538208

iterator 4600, D_Loss:0.5790511965751648, G_Loss:4.575254440307617

iterator 4700, D_Loss:0.5452188849449158, G_Loss:4.7466721534729

iterator 4800, D_Loss:0.563686728477478, G_Loss:4.596609592437744

iterator 4900, D_Loss:0.527632474899292, G_Loss:4.542023658752441

iterator 5000, D_Loss:0.5298629403114319, G_Loss:4.621917247772217

-----------Epoch 1-----------
iterator 100, D_Loss:0.5368741750717163, G_Loss:4.581789970397949

iterator 200, D_Loss:0.5368332266807556, G_Loss:4.808763027191162

iterator 300, D_Loss:0.5187751650810242, G_Loss:4.779849052429199

iterator 400, D_Loss:0.5655220150947571, G_Loss:4.703836441040039

iterator 500, D_Loss:0.5459798574447632, G_Loss:4.680088043212891

iterator 600, D_Loss:0.5602279901504517, G_Loss:4.840085029602051

iterator 700, D_Loss:0.5779167413711548, G_Loss:4.516387462615967

iterator 800, D_Loss:0.5704159736633301, G_Loss:4.591750144958496

iterator 900, D_Loss:0.5258203148841858, G_Loss:4.602558135986328

iterator 1000, D_Loss:0.5388607978820801, G_Loss:4.681306838989258

iterator 1100, D_Loss:0.5545971393585205, G_Loss:4.767009258270264

iterator 1200, D_Loss:0.5608285069465637, G_Loss:4.623140335083008

iterator 1300, D_Loss:0.5641892552375793, G_Loss:4.613279819488525

iterator 1400, D_Loss:0.5172290205955505, G_Loss:4.363368988037109

iterator 1500, D_Loss:0.5369038581848145, G_Loss:4.532509803771973

iterator 1600, D_Loss:0.5180964469909668, G_Loss:4.5769500732421875

iterator 1700, D_Loss:0.5311216711997986, G_Loss:4.51784610748291

iterator 1800, D_Loss:0.5807183980941772, G_Loss:4.641589641571045

iterator 1900, D_Loss:0.5530365705490112, G_Loss:4.4813103675842285

iterator 2000, D_Loss:0.5333397388458252, G_Loss:4.51198148727417

iterator 2100, D_Loss:0.5661616325378418, G_Loss:4.4448065757751465

iterator 2200, D_Loss:0.5422397255897522, G_Loss:4.571781635284424

iterator 2300, D_Loss:0.5559996366500854, G_Loss:4.595179080963135

iterator 2400, D_Loss:0.5579068660736084, G_Loss:4.522074222564697

iterator 2500, D_Loss:0.5730173587799072, G_Loss:4.534728527069092

iterator 2600, D_Loss:0.5491931438446045, G_Loss:4.511959552764893

iterator 2700, D_Loss:0.5314048528671265, G_Loss:4.358641624450684

iterator 2800, D_Loss:0.5391969084739685, G_Loss:4.330378532409668

iterator 2900, D_Loss:0.5576657056808472, G_Loss:4.431591987609863

iterator 3000, D_Loss:0.5559497475624084, G_Loss:4.4235968589782715

iterator 3100, D_Loss:0.5464035272598267, G_Loss:4.503981113433838

iterator 3200, D_Loss:0.5698150992393494, G_Loss:4.526808261871338

iterator 3300, D_Loss:0.5512974858283997, G_Loss:4.548640251159668

iterator 3400, D_Loss:0.5446312427520752, G_Loss:4.45258092880249

iterator 3500, D_Loss:0.5564864277839661, G_Loss:4.618908882141113

iterator 3600, D_Loss:0.5464352369308472, G_Loss:4.68478536605835

iterator 3700, D_Loss:0.5273019671440125, G_Loss:4.652573108673096

iterator 3800, D_Loss:0.614029586315155, G_Loss:4.696536064147949

iterator 3900, D_Loss:0.5130553841590881, G_Loss:4.670025825500488

iterator 4000, D_Loss:0.553816556930542, G_Loss:4.567789077758789

iterator 4100, D_Loss:0.541780948638916, G_Loss:4.735885143280029

iterator 4200, D_Loss:0.5624794363975525, G_Loss:4.377547740936279

iterator 4300, D_Loss:0.5503278970718384, G_Loss:4.48374080657959

iterator 4400, D_Loss:0.5604754686355591, G_Loss:4.495823860168457

iterator 4500, D_Loss:0.5470324754714966, G_Loss:4.3914408683776855

iterator 4600, D_Loss:0.5436842441558838, G_Loss:4.483208179473877

iterator 4700, D_Loss:0.5533804297447205, G_Loss:4.363674163818359

iterator 4800, D_Loss:0.5125572681427002, G_Loss:4.506234645843506

iterator 4900, D_Loss:0.5257683396339417, G_Loss:4.3804731369018555

iterator 5000, D_Loss:0.5421921014785767, G_Loss:4.3441267013549805

-----------Epoch 2-----------
iterator 100, D_Loss:0.5392090082168579, G_Loss:4.427683353424072

iterator 200, D_Loss:0.5388663411140442, G_Loss:4.291083335876465

iterator 300, D_Loss:0.5294758081436157, G_Loss:4.788144588470459

iterator 400, D_Loss:0.5721613168716431, G_Loss:4.279351234436035

iterator 500, D_Loss:0.5476464033126831, G_Loss:4.376328945159912

iterator 600, D_Loss:0.5390100479125977, G_Loss:4.4700236320495605

iterator 700, D_Loss:0.5505682826042175, G_Loss:4.408083438873291

iterator 800, D_Loss:0.5610640048980713, G_Loss:4.210070610046387

iterator 900, D_Loss:0.525357723236084, G_Loss:4.418757438659668

iterator 1000, D_Loss:0.5504438281059265, G_Loss:4.453341007232666

iterator 1100, D_Loss:0.5243895053863525, G_Loss:4.315464019775391

iterator 1200, D_Loss:0.5716655850410461, G_Loss:4.341763019561768

iterator 1300, D_Loss:0.6103485822677612, G_Loss:4.167909622192383

iterator 1400, D_Loss:0.5306021571159363, G_Loss:4.2903900146484375

iterator 1500, D_Loss:0.5394119024276733, G_Loss:4.316984176635742

iterator 1600, D_Loss:0.5193543434143066, G_Loss:4.213243007659912

iterator 1700, D_Loss:0.5567539930343628, G_Loss:4.174805641174316

iterator 1800, D_Loss:0.5633659362792969, G_Loss:4.515441417694092

iterator 1900, D_Loss:0.5330865383148193, G_Loss:4.500268936157227

iterator 2000, D_Loss:0.5405623912811279, G_Loss:4.222295761108398

iterator 2100, D_Loss:0.5702102780342102, G_Loss:4.421109199523926

iterator 2200, D_Loss:0.5235310792922974, G_Loss:4.438493251800537

iterator 2300, D_Loss:0.5527939200401306, G_Loss:4.254234313964844

iterator 2400, D_Loss:0.57925945520401, G_Loss:4.238005638122559

iterator 2500, D_Loss:0.544921338558197, G_Loss:4.102006912231445

iterator 2600, D_Loss:0.5339497923851013, G_Loss:4.222132205963135

iterator 2700, D_Loss:0.5663080215454102, G_Loss:4.238250255584717

iterator 2800, D_Loss:0.5523557066917419, G_Loss:4.160911560058594

iterator 2900, D_Loss:0.564113438129425, G_Loss:4.316761016845703

iterator 3000, D_Loss:0.5702494382858276, G_Loss:4.163229465484619

iterator 3100, D_Loss:0.5450112223625183, G_Loss:4.111296653747559

iterator 3200, D_Loss:0.5865510702133179, G_Loss:4.096652507781982

iterator 3300, D_Loss:0.5576919317245483, G_Loss:4.134693145751953

iterator 3400, D_Loss:0.5612188577651978, G_Loss:3.9531078338623047

iterator 3500, D_Loss:0.5437623858451843, G_Loss:4.109832763671875

iterator 3600, D_Loss:0.5276533365249634, G_Loss:4.1723103523254395

iterator 3700, D_Loss:0.53525310754776, G_Loss:4.0027689933776855

iterator 3800, D_Loss:0.6013758182525635, G_Loss:4.124448299407959

iterator 3900, D_Loss:0.5705175399780273, G_Loss:4.107171058654785

iterator 4000, D_Loss:0.5183224081993103, G_Loss:3.9109835624694824

iterator 4100, D_Loss:0.5882606506347656, G_Loss:3.960050344467163

iterator 4200, D_Loss:0.6013551354408264, G_Loss:3.963355541229248

iterator 4300, D_Loss:0.5685070157051086, G_Loss:4.111737251281738

iterator 4400, D_Loss:0.5940046906471252, G_Loss:4.122244834899902

iterator 4500, D_Loss:0.607265830039978, G_Loss:3.9099020957946777

iterator 4600, D_Loss:0.5462257266044617, G_Loss:3.9423532485961914

iterator 4700, D_Loss:0.5824496746063232, G_Loss:3.994098663330078

iterator 4800, D_Loss:0.5781772136688232, G_Loss:3.976619243621826

iterator 4900, D_Loss:0.5436791181564331, G_Loss:4.097314834594727

iterator 5000, D_Loss:0.5718036890029907, G_Loss:3.937593460083008

-----------Epoch 3-----------
iterator 100, D_Loss:0.5541362166404724, G_Loss:4.102698802947998

iterator 200, D_Loss:0.5611464977264404, G_Loss:4.139161586761475

iterator 300, D_Loss:0.5728053450584412, G_Loss:4.049668788909912

iterator 400, D_Loss:0.5760390162467957, G_Loss:3.9101779460906982

iterator 500, D_Loss:0.5704525709152222, G_Loss:4.087658882141113

iterator 600, D_Loss:0.6024128198623657, G_Loss:4.039900302886963

iterator 700, D_Loss:0.5589506030082703, G_Loss:4.038070201873779

iterator 800, D_Loss:0.5837457180023193, G_Loss:3.818530797958374

iterator 900, D_Loss:0.5847707986831665, G_Loss:3.865926504135132

iterator 1000, D_Loss:0.5607288479804993, G_Loss:3.814457893371582

iterator 1100, D_Loss:0.5671021938323975, G_Loss:4.03420352935791

iterator 1200, D_Loss:0.5560858249664307, G_Loss:4.005600929260254

iterator 1300, D_Loss:0.5903450846672058, G_Loss:3.945919990539551

iterator 1400, D_Loss:0.5603690147399902, G_Loss:3.9672436714172363

iterator 1500, D_Loss:0.5659952163696289, G_Loss:3.7845444679260254

iterator 1600, D_Loss:0.5898278951644897, G_Loss:3.9968416690826416

iterator 1700, D_Loss:0.5872547030448914, G_Loss:3.7560343742370605

iterator 1800, D_Loss:0.6100946068763733, G_Loss:3.763697385787964

iterator 1900, D_Loss:0.59604811668396, G_Loss:3.830471992492676

iterator 2000, D_Loss:0.5737128853797913, G_Loss:3.8779783248901367

iterator 2100, D_Loss:0.594167947769165, G_Loss:3.8992905616760254

iterator 2200, D_Loss:0.5962004065513611, G_Loss:3.8284683227539062

iterator 2300, D_Loss:0.6053597927093506, G_Loss:3.807954788208008

iterator 2400, D_Loss:0.5795487761497498, G_Loss:3.8072733879089355

iterator 2500, D_Loss:0.6095893979072571, G_Loss:3.7960429191589355

iterator 2600, D_Loss:0.5869268178939819, G_Loss:3.729947090148926

iterator 2700, D_Loss:0.5869941711425781, G_Loss:3.8351988792419434

iterator 2800, D_Loss:0.5903967022895813, G_Loss:3.807387351989746

iterator 2900, D_Loss:0.5988894701004028, G_Loss:3.726546049118042

iterator 3000, D_Loss:0.6215002536773682, G_Loss:3.857896089553833

iterator 3100, D_Loss:0.5986025929450989, G_Loss:3.7277328968048096

iterator 3200, D_Loss:0.6347120404243469, G_Loss:3.7866766452789307

iterator 3300, D_Loss:0.596017062664032, G_Loss:3.6748366355895996

iterator 3400, D_Loss:0.5998362898826599, G_Loss:3.675675630569458

iterator 3500, D_Loss:0.6407628655433655, G_Loss:3.6224584579467773

iterator 3600, D_Loss:0.6119826436042786, G_Loss:3.5583271980285645

iterator 3700, D_Loss:0.6254825592041016, G_Loss:3.5788910388946533

iterator 3800, D_Loss:0.6070019006729126, G_Loss:3.587195873260498

iterator 3900, D_Loss:0.5943074226379395, G_Loss:3.504216432571411

iterator 4000, D_Loss:0.6193987727165222, G_Loss:3.5156991481781006

iterator 4100, D_Loss:0.6266870498657227, G_Loss:3.4080026149749756

iterator 4200, D_Loss:0.618835985660553, G_Loss:3.453982353210449

iterator 4300, D_Loss:0.6275203227996826, G_Loss:3.3742306232452393

iterator 4400, D_Loss:0.6330379247665405, G_Loss:3.4803216457366943

iterator 4500, D_Loss:0.6423978209495544, G_Loss:3.4066102504730225

iterator 4600, D_Loss:0.5915544033050537, G_Loss:3.447402000427246

iterator 4700, D_Loss:0.6137346625328064, G_Loss:3.4170656204223633

iterator 4800, D_Loss:0.6319072246551514, G_Loss:3.341540813446045

iterator 4900, D_Loss:0.5974227786064148, G_Loss:3.4038591384887695

iterator 5000, D_Loss:0.6151781678199768, G_Loss:3.4092347621917725

-----------Epoch 4-----------
iterator 100, D_Loss:0.6248253583908081, G_Loss:3.280160427093506

iterator 200, D_Loss:0.6324818730354309, G_Loss:3.4243805408477783

iterator 300, D_Loss:0.6344641447067261, G_Loss:3.3269739151000977

iterator 400, D_Loss:0.5985050797462463, G_Loss:3.340485095977783

iterator 500, D_Loss:0.6034195423126221, G_Loss:3.324345350265503

iterator 600, D_Loss:0.6148560047149658, G_Loss:3.2949748039245605

iterator 700, D_Loss:0.6113694906234741, G_Loss:3.361844062805176

iterator 800, D_Loss:0.6561657786369324, G_Loss:3.1950104236602783

iterator 900, D_Loss:0.6230421662330627, G_Loss:3.3780276775360107

iterator 1000, D_Loss:0.6007719039916992, G_Loss:3.2386693954467773

iterator 1100, D_Loss:0.6346747279167175, G_Loss:3.343264102935791

iterator 1200, D_Loss:0.6479397416114807, G_Loss:3.348115921020508

iterator 1300, D_Loss:0.6356682777404785, G_Loss:3.346309185028076

iterator 1400, D_Loss:0.6535884737968445, G_Loss:3.334886074066162

iterator 1500, D_Loss:0.6225318908691406, G_Loss:3.5111191272735596

iterator 1600, D_Loss:0.6022654175758362, G_Loss:3.398775100708008

iterator 1700, D_Loss:0.6068989038467407, G_Loss:3.425168037414551

iterator 1800, D_Loss:0.6420726776123047, G_Loss:3.4579975605010986

iterator 1900, D_Loss:0.610664427280426, G_Loss:3.440904140472412

iterator 2000, D_Loss:0.6412134766578674, G_Loss:3.4324791431427

iterator 2100, D_Loss:0.6205134987831116, G_Loss:3.458456516265869

iterator 2200, D_Loss:0.6266384720802307, G_Loss:3.3258306980133057

iterator 2300, D_Loss:0.6232818365097046, G_Loss:3.3476176261901855

iterator 2400, D_Loss:0.6404261589050293, G_Loss:3.4090962409973145

iterator 2500, D_Loss:0.6378002166748047, G_Loss:3.318591356277466

iterator 2600, D_Loss:0.6329751014709473, G_Loss:3.283320665359497

iterator 2700, D_Loss:0.6649950742721558, G_Loss:3.2238006591796875

iterator 2800, D_Loss:0.6532965302467346, G_Loss:3.1487767696380615

iterator 2900, D_Loss:0.6579390168190002, G_Loss:3.1856472492218018

iterator 3000, D_Loss:0.6427137851715088, G_Loss:3.1323423385620117

iterator 3100, D_Loss:0.6747300624847412, G_Loss:3.2290472984313965

iterator 3200, D_Loss:0.6801495552062988, G_Loss:3.2530417442321777

iterator 3300, D_Loss:0.6533443331718445, G_Loss:3.1129283905029297

iterator 3400, D_Loss:0.6547869443893433, G_Loss:3.076011896133423

iterator 3500, D_Loss:0.6672831177711487, G_Loss:3.320683479309082

iterator 3600, D_Loss:0.6423906683921814, G_Loss:3.2094340324401855

iterator 3700, D_Loss:0.6632882356643677, G_Loss:3.1959500312805176

iterator 3800, D_Loss:0.6861956119537354, G_Loss:3.2356936931610107

iterator 3900, D_Loss:0.6681236028671265, G_Loss:3.0543816089630127

iterator 4000, D_Loss:0.6302952170372009, G_Loss:3.140859365463257

iterator 4100, D_Loss:0.6284129023551941, G_Loss:3.0965325832366943

iterator 4200, D_Loss:0.6665056347846985, G_Loss:3.157031297683716

iterator 4300, D_Loss:0.645972728729248, G_Loss:3.0709640979766846

iterator 4400, D_Loss:0.6664248704910278, G_Loss:3.0714142322540283

iterator 4500, D_Loss:0.6481284499168396, G_Loss:3.1249001026153564

iterator 4600, D_Loss:0.6463356018066406, G_Loss:3.2140564918518066

iterator 4700, D_Loss:0.699532151222229, G_Loss:3.241508960723877

iterator 4800, D_Loss:0.6490205526351929, G_Loss:3.1575658321380615

iterator 4900, D_Loss:0.6480996608734131, G_Loss:3.043339729309082

iterator 5000, D_Loss:0.6556988954544067, G_Loss:3.00488543510437

-----------Epoch 5-----------
iterator 100, D_Loss:0.6664801836013794, G_Loss:3.129025459289551

iterator 200, D_Loss:0.6681264042854309, G_Loss:3.236917495727539

iterator 300, D_Loss:0.6790202856063843, G_Loss:2.9189767837524414

iterator 400, D_Loss:0.6730477809906006, G_Loss:3.101343870162964

iterator 500, D_Loss:0.7019748687744141, G_Loss:3.056570053100586

iterator 600, D_Loss:0.6471973061561584, G_Loss:3.0744974613189697

iterator 700, D_Loss:0.6791409850120544, G_Loss:3.1153621673583984

iterator 800, D_Loss:0.6847023963928223, G_Loss:3.096597671508789

iterator 900, D_Loss:0.6656205058097839, G_Loss:3.0194690227508545

iterator 1000, D_Loss:0.6697710156440735, G_Loss:2.9325203895568848

iterator 1100, D_Loss:0.6970034837722778, G_Loss:2.916116237640381

iterator 1200, D_Loss:0.6924376487731934, G_Loss:2.963298797607422

iterator 1300, D_Loss:0.6812412142753601, G_Loss:3.0153262615203857

iterator 1400, D_Loss:0.6800786256790161, G_Loss:2.9524497985839844

iterator 1500, D_Loss:0.6570538282394409, G_Loss:3.0076189041137695

iterator 1600, D_Loss:0.6613849401473999, G_Loss:3.0938663482666016

iterator 1700, D_Loss:0.6778954267501831, G_Loss:3.0469017028808594

iterator 1800, D_Loss:0.685344934463501, G_Loss:2.9434032440185547

iterator 1900, D_Loss:0.7098860144615173, G_Loss:3.0627102851867676

iterator 2000, D_Loss:0.6782140731811523, G_Loss:2.950404405593872

iterator 2100, D_Loss:0.7026859521865845, G_Loss:2.957278251647949

iterator 2200, D_Loss:0.7035968899726868, G_Loss:2.9354255199432373

iterator 2300, D_Loss:0.6876718997955322, G_Loss:2.9757113456726074

iterator 2400, D_Loss:0.6837232708930969, G_Loss:2.996436595916748

iterator 2500, D_Loss:0.677294135093689, G_Loss:2.910393238067627

iterator 2600, D_Loss:0.697255551815033, G_Loss:2.956331253051758

iterator 2700, D_Loss:0.7124336957931519, G_Loss:2.840806007385254

iterator 2800, D_Loss:0.7126322388648987, G_Loss:2.9165453910827637

iterator 2900, D_Loss:0.71075040102005, G_Loss:2.9520440101623535

iterator 3000, D_Loss:0.6779153347015381, G_Loss:2.961305618286133

iterator 3100, D_Loss:0.7037056684494019, G_Loss:2.925441265106201

iterator 3200, D_Loss:0.6746635437011719, G_Loss:2.973361015319824

iterator 3300, D_Loss:0.6808372735977173, G_Loss:2.931227207183838

iterator 3400, D_Loss:0.698174238204956, G_Loss:2.9440338611602783

iterator 3500, D_Loss:0.6705753207206726, G_Loss:2.868746757507324

iterator 3600, D_Loss:0.7011696696281433, G_Loss:2.8170039653778076

iterator 3700, D_Loss:0.6946994066238403, G_Loss:2.8083770275115967

iterator 3800, D_Loss:0.704770565032959, G_Loss:2.834444999694824

iterator 3900, D_Loss:0.7059043049812317, G_Loss:2.8525519371032715

iterator 4000, D_Loss:0.694192111492157, G_Loss:2.809384346008301

iterator 4100, D_Loss:0.6967883110046387, G_Loss:2.862992286682129

iterator 4200, D_Loss:0.7347086071968079, G_Loss:2.9166321754455566

iterator 4300, D_Loss:0.6609579920768738, G_Loss:2.7649762630462646

iterator 4400, D_Loss:0.6938414573669434, G_Loss:2.836920976638794

iterator 4500, D_Loss:0.698733925819397, G_Loss:2.8792881965637207

iterator 4600, D_Loss:0.6982791423797607, G_Loss:2.9148902893066406

iterator 4700, D_Loss:0.7261062264442444, G_Loss:2.8732752799987793

iterator 4800, D_Loss:0.6999744176864624, G_Loss:2.8585572242736816

iterator 4900, D_Loss:0.6928671598434448, G_Loss:2.81019926071167

iterator 5000, D_Loss:0.7006842494010925, G_Loss:2.7844958305358887

-----------Epoch 6-----------
iterator 100, D_Loss:0.7009443044662476, G_Loss:2.7978246212005615

iterator 200, D_Loss:0.7310677170753479, G_Loss:2.7327308654785156

iterator 300, D_Loss:0.7318354845046997, G_Loss:2.7517755031585693

iterator 400, D_Loss:0.7183209657669067, G_Loss:2.8225250244140625

iterator 500, D_Loss:0.7325221300125122, G_Loss:2.7181267738342285

iterator 600, D_Loss:0.7301712036132812, G_Loss:2.7285258769989014

iterator 700, D_Loss:0.7014341354370117, G_Loss:2.799999237060547

iterator 800, D_Loss:0.7388994097709656, G_Loss:2.719616413116455

iterator 900, D_Loss:0.6811586618423462, G_Loss:2.8217499256134033

iterator 1000, D_Loss:0.7189897298812866, G_Loss:2.806731939315796

iterator 1100, D_Loss:0.7515405416488647, G_Loss:2.842815399169922

iterator 1200, D_Loss:0.7539777755737305, G_Loss:2.722686529159546

iterator 1300, D_Loss:0.7119076251983643, G_Loss:2.7793784141540527

iterator 1400, D_Loss:0.7076311707496643, G_Loss:2.797382354736328

iterator 1500, D_Loss:0.6915191411972046, G_Loss:2.6585752964019775

iterator 1600, D_Loss:0.6929808259010315, G_Loss:2.8039283752441406

iterator 1700, D_Loss:0.6918990612030029, G_Loss:2.781745433807373

iterator 1800, D_Loss:0.7039341330528259, G_Loss:2.673330545425415

iterator 1900, D_Loss:0.7254579067230225, G_Loss:2.707359790802002

iterator 2000, D_Loss:0.735827624797821, G_Loss:2.794693946838379

iterator 2100, D_Loss:0.7625523805618286, G_Loss:2.6273529529571533

iterator 2200, D_Loss:0.7320888638496399, G_Loss:2.671973466873169

iterator 2300, D_Loss:0.746184229850769, G_Loss:2.6733829975128174

iterator 2400, D_Loss:0.7220890522003174, G_Loss:2.606109619140625

iterator 2500, D_Loss:0.7544541358947754, G_Loss:2.6336636543273926

iterator 2600, D_Loss:0.6793627738952637, G_Loss:2.752910852432251

iterator 2700, D_Loss:0.7350270748138428, G_Loss:2.7020797729492188

iterator 2800, D_Loss:0.6791556477546692, G_Loss:2.699618339538574

iterator 2900, D_Loss:0.7432073950767517, G_Loss:2.73540997505188

iterator 3000, D_Loss:0.7210765480995178, G_Loss:2.7041962146759033

iterator 3100, D_Loss:0.7591912150382996, G_Loss:2.807007312774658

iterator 3200, D_Loss:0.7417997717857361, G_Loss:2.716357707977295

iterator 3300, D_Loss:0.7125118970870972, G_Loss:2.779456377029419

iterator 3400, D_Loss:0.7500849962234497, G_Loss:2.76849365234375

iterator 3500, D_Loss:0.7448841333389282, G_Loss:2.5277531147003174

iterator 3600, D_Loss:0.6974409818649292, G_Loss:2.6482644081115723

iterator 3700, D_Loss:0.7362200021743774, G_Loss:2.651003837585449

iterator 3800, D_Loss:0.735553503036499, G_Loss:2.555436134338379

iterator 3900, D_Loss:0.7342435717582703, G_Loss:2.7000598907470703

iterator 4000, D_Loss:0.7270017862319946, G_Loss:2.6507599353790283

iterator 4100, D_Loss:0.7370002269744873, G_Loss:2.669386625289917

iterator 4200, D_Loss:0.7407618761062622, G_Loss:2.6697440147399902

iterator 4300, D_Loss:0.7308913469314575, G_Loss:2.7993617057800293

iterator 4400, D_Loss:0.6925301551818848, G_Loss:2.7338738441467285

iterator 4500, D_Loss:0.7595438957214355, G_Loss:2.8449583053588867

iterator 4600, D_Loss:0.7132135629653931, G_Loss:2.6545708179473877

iterator 4700, D_Loss:0.7789263725280762, G_Loss:2.71386456489563

iterator 4800, D_Loss:0.7597514986991882, G_Loss:2.6268646717071533

iterator 4900, D_Loss:0.7377151250839233, G_Loss:2.653075933456421

iterator 5000, D_Loss:0.7273358106613159, G_Loss:2.52128267288208

-----------Epoch 7-----------
iterator 100, D_Loss:0.7535060048103333, G_Loss:2.4808201789855957

iterator 200, D_Loss:0.7532119750976562, G_Loss:2.5914649963378906

iterator 300, D_Loss:0.7365637421607971, G_Loss:2.4687862396240234

iterator 400, D_Loss:0.7767388224601746, G_Loss:2.767158269882202

iterator 500, D_Loss:0.7733977437019348, G_Loss:2.5460591316223145

iterator 600, D_Loss:0.7749495506286621, G_Loss:2.5977566242218018

iterator 700, D_Loss:0.7696148157119751, G_Loss:2.526911735534668

iterator 800, D_Loss:0.798789381980896, G_Loss:2.5153815746307373

iterator 900, D_Loss:0.7434208393096924, G_Loss:2.5908915996551514

iterator 1000, D_Loss:0.759817361831665, G_Loss:2.471263885498047

iterator 1100, D_Loss:0.769798755645752, G_Loss:2.570189952850342

iterator 1200, D_Loss:0.7401778697967529, G_Loss:2.6201605796813965

iterator 1300, D_Loss:0.7330592274665833, G_Loss:2.6278328895568848

iterator 1400, D_Loss:0.7644107341766357, G_Loss:2.4566192626953125

iterator 1500, D_Loss:0.7513457536697388, G_Loss:2.5389933586120605

iterator 1600, D_Loss:0.7860457897186279, G_Loss:2.545485258102417

iterator 1700, D_Loss:0.7477399110794067, G_Loss:2.5199756622314453

iterator 1800, D_Loss:0.7387514114379883, G_Loss:2.6663260459899902

iterator 1900, D_Loss:0.7703578472137451, G_Loss:2.535327911376953

iterator 2000, D_Loss:0.7705031633377075, G_Loss:2.536447525024414

iterator 2100, D_Loss:0.7783253788948059, G_Loss:2.5066425800323486

iterator 2200, D_Loss:0.7934161424636841, G_Loss:2.593332529067993

iterator 2300, D_Loss:0.7835221886634827, G_Loss:2.405712127685547

iterator 2400, D_Loss:0.7682765126228333, G_Loss:2.477999687194824

iterator 2500, D_Loss:0.7815666198730469, G_Loss:2.523465633392334

iterator 2600, D_Loss:0.7539874315261841, G_Loss:2.6088037490844727

iterator 2700, D_Loss:0.7840887308120728, G_Loss:2.436563491821289

iterator 2800, D_Loss:0.7835416793823242, G_Loss:2.471378803253174

iterator 2900, D_Loss:0.7637801766395569, G_Loss:2.5312538146972656

iterator 3000, D_Loss:0.7935043573379517, G_Loss:2.413011074066162

iterator 3100, D_Loss:0.8088770508766174, G_Loss:2.448469638824463

iterator 3200, D_Loss:0.7991830706596375, G_Loss:2.4662234783172607

iterator 3300, D_Loss:0.7614055871963501, G_Loss:2.39005184173584

iterator 3400, D_Loss:0.7924181222915649, G_Loss:2.4392077922821045

iterator 3500, D_Loss:0.7719008922576904, G_Loss:2.4485950469970703

iterator 3600, D_Loss:0.76183021068573, G_Loss:2.4246103763580322

iterator 3700, D_Loss:0.7771090269088745, G_Loss:2.5298664569854736

iterator 3800, D_Loss:0.8291442394256592, G_Loss:2.421365737915039

iterator 3900, D_Loss:0.7888099551200867, G_Loss:2.4604029655456543

iterator 4000, D_Loss:0.7615963220596313, G_Loss:2.425808906555176

iterator 4100, D_Loss:0.7951251864433289, G_Loss:2.3538882732391357

iterator 4200, D_Loss:0.7531096935272217, G_Loss:2.478633403778076

iterator 4300, D_Loss:0.769985556602478, G_Loss:2.532597303390503

iterator 4400, D_Loss:0.7828901410102844, G_Loss:2.425170421600342

iterator 4500, D_Loss:0.781143069267273, G_Loss:2.5042319297790527

iterator 4600, D_Loss:0.7792961597442627, G_Loss:2.438652992248535

iterator 4700, D_Loss:0.8100412487983704, G_Loss:2.493624448776245

iterator 4800, D_Loss:0.8031247854232788, G_Loss:2.5174498558044434

iterator 4900, D_Loss:0.7953723669052124, G_Loss:2.4895172119140625

iterator 5000, D_Loss:0.7889747619628906, G_Loss:2.3920419216156006

-----------Epoch 8-----------
iterator 100, D_Loss:0.7960788011550903, G_Loss:2.3674325942993164

iterator 200, D_Loss:0.795325756072998, G_Loss:2.401456832885742

iterator 300, D_Loss:0.8208963871002197, G_Loss:2.354961395263672

iterator 400, D_Loss:0.7648553252220154, G_Loss:2.514760732650757

iterator 500, D_Loss:0.7499056458473206, G_Loss:2.334913730621338

iterator 600, D_Loss:0.7715530395507812, G_Loss:2.363701820373535

iterator 700, D_Loss:0.7956287264823914, G_Loss:2.3663623332977295

iterator 800, D_Loss:0.7885138988494873, G_Loss:2.348865270614624

iterator 900, D_Loss:0.7759232521057129, G_Loss:2.46625018119812

iterator 1000, D_Loss:0.7765251398086548, G_Loss:2.408076047897339

iterator 1100, D_Loss:0.8024059534072876, G_Loss:2.358045816421509

iterator 1200, D_Loss:0.8134073615074158, G_Loss:2.535822868347168

iterator 1300, D_Loss:0.7778638005256653, G_Loss:2.3266849517822266

iterator 1400, D_Loss:0.7978041768074036, G_Loss:2.5311331748962402

iterator 1500, D_Loss:0.7852659821510315, G_Loss:2.340198040008545

iterator 1600, D_Loss:0.72984778881073, G_Loss:2.517970085144043

iterator 1700, D_Loss:0.7810424566268921, G_Loss:2.364203929901123

iterator 1800, D_Loss:0.7930402755737305, G_Loss:2.3912088871002197

iterator 1900, D_Loss:0.8120796084403992, G_Loss:2.417642831802368

iterator 2000, D_Loss:0.794745683670044, G_Loss:2.305358409881592

iterator 2100, D_Loss:0.7881324887275696, G_Loss:2.3847568035125732

iterator 2200, D_Loss:0.7992581725120544, G_Loss:2.2517125606536865

iterator 2300, D_Loss:0.8130770921707153, G_Loss:2.311427593231201

iterator 2400, D_Loss:0.7842418551445007, G_Loss:2.3260741233825684

iterator 2500, D_Loss:0.8507553935050964, G_Loss:2.399423599243164

iterator 2600, D_Loss:0.8046099543571472, G_Loss:2.207273244857788

iterator 2700, D_Loss:0.8303762078285217, G_Loss:2.2868480682373047

iterator 2800, D_Loss:0.8152834177017212, G_Loss:2.321715831756592

iterator 2900, D_Loss:0.8035720586776733, G_Loss:2.421506404876709

iterator 3000, D_Loss:0.79738849401474, G_Loss:2.242241621017456

iterator 3100, D_Loss:0.7885631322860718, G_Loss:2.2322864532470703

iterator 3200, D_Loss:0.7680889964103699, G_Loss:2.355731248855591

iterator 3300, D_Loss:0.7808874249458313, G_Loss:2.347501039505005

iterator 3400, D_Loss:0.7700065970420837, G_Loss:2.281750440597534

iterator 3500, D_Loss:0.8577718734741211, G_Loss:2.165524482727051

iterator 3600, D_Loss:0.8338497877120972, G_Loss:2.232394218444824

iterator 3700, D_Loss:0.7908041477203369, G_Loss:2.251081705093384

iterator 3800, D_Loss:0.7839365601539612, G_Loss:2.356757164001465

iterator 3900, D_Loss:0.8034666180610657, G_Loss:2.249295473098755

iterator 4000, D_Loss:0.8188149929046631, G_Loss:2.3610641956329346

iterator 4100, D_Loss:0.7937875986099243, G_Loss:2.318146228790283

iterator 4200, D_Loss:0.8129404783248901, G_Loss:2.253966808319092

iterator 4300, D_Loss:0.8308655023574829, G_Loss:2.3186473846435547

iterator 4400, D_Loss:0.8142109513282776, G_Loss:2.390044927597046

iterator 4500, D_Loss:0.8377540111541748, G_Loss:2.3059239387512207

iterator 4600, D_Loss:0.8127673864364624, G_Loss:2.1529793739318848

iterator 4700, D_Loss:0.8267605304718018, G_Loss:2.31492018699646

iterator 4800, D_Loss:0.7919463515281677, G_Loss:2.318272590637207

iterator 4900, D_Loss:0.8199652433395386, G_Loss:2.1391847133636475

iterator 5000, D_Loss:0.7906423807144165, G_Loss:2.271358013153076

-----------Epoch 9-----------
iterator 100, D_Loss:0.8528485894203186, G_Loss:2.2810683250427246

iterator 200, D_Loss:0.8076387047767639, G_Loss:2.2319798469543457

iterator 300, D_Loss:0.8273001909255981, G_Loss:2.1437554359436035

iterator 400, D_Loss:0.8224296569824219, G_Loss:2.187502861022949

iterator 500, D_Loss:0.8381643295288086, G_Loss:2.210324287414551

iterator 600, D_Loss:0.7951986789703369, G_Loss:2.2874343395233154

iterator 700, D_Loss:0.847132682800293, G_Loss:2.1104397773742676

iterator 800, D_Loss:0.8363056182861328, G_Loss:2.2727880477905273

iterator 900, D_Loss:0.8542988896369934, G_Loss:2.272366523742676

iterator 1000, D_Loss:0.8528582453727722, G_Loss:2.2031190395355225

iterator 1100, D_Loss:0.8180489540100098, G_Loss:2.163562059402466

iterator 1200, D_Loss:0.830104410648346, G_Loss:2.1538050174713135

iterator 1300, D_Loss:0.8195596933364868, G_Loss:2.243804693222046

iterator 1400, D_Loss:0.834900975227356, G_Loss:2.1449198722839355

iterator 1500, D_Loss:0.8535655736923218, G_Loss:2.097034454345703

iterator 1600, D_Loss:0.7926977276802063, G_Loss:2.27386212348938

iterator 1700, D_Loss:0.8428746461868286, G_Loss:2.0676441192626953

iterator 1800, D_Loss:0.829791784286499, G_Loss:2.129915952682495

iterator 1900, D_Loss:0.8512042164802551, G_Loss:2.1258320808410645

iterator 2000, D_Loss:0.8522292375564575, G_Loss:2.132934331893921

iterator 2100, D_Loss:0.874639630317688, G_Loss:2.048067808151245

iterator 2200, D_Loss:0.8462238311767578, G_Loss:2.1026251316070557

iterator 2300, D_Loss:0.8375019431114197, G_Loss:2.1844897270202637

iterator 2400, D_Loss:0.8468366265296936, G_Loss:2.2027101516723633

iterator 2500, D_Loss:0.8486065864562988, G_Loss:2.1064913272857666

iterator 2600, D_Loss:0.8441264033317566, G_Loss:2.135268449783325

iterator 2700, D_Loss:0.832781195640564, G_Loss:2.0808145999908447

iterator 2800, D_Loss:0.87029629945755, G_Loss:1.9120705127716064

iterator 2900, D_Loss:0.8473212718963623, G_Loss:2.2717392444610596

iterator 3000, D_Loss:0.8817351460456848, G_Loss:2.045271158218384

iterator 3100, D_Loss:0.852617621421814, G_Loss:1.89922034740448

iterator 3200, D_Loss:0.8486854434013367, G_Loss:2.2888407707214355

iterator 3300, D_Loss:0.8626235127449036, G_Loss:2.0153422355651855

iterator 3400, D_Loss:0.8721371293067932, G_Loss:2.0628387928009033

iterator 3500, D_Loss:0.8556815981864929, G_Loss:2.1173315048217773

iterator 3600, D_Loss:0.8561328649520874, G_Loss:2.0929393768310547

iterator 3700, D_Loss:0.8615085482597351, G_Loss:1.989088535308838

iterator 3800, D_Loss:0.8625497817993164, G_Loss:2.1085903644561768

iterator 3900, D_Loss:0.8670628070831299, G_Loss:2.056581735610962

iterator 4000, D_Loss:0.8715086579322815, G_Loss:2.075584888458252

iterator 4100, D_Loss:0.8383820652961731, G_Loss:2.195755958557129

iterator 4200, D_Loss:0.88944411277771, G_Loss:1.9726345539093018

iterator 4300, D_Loss:0.866324782371521, G_Loss:2.040802240371704

iterator 4400, D_Loss:0.8426737189292908, G_Loss:2.177213191986084

iterator 4500, D_Loss:0.8273556232452393, G_Loss:2.1211984157562256

iterator 4600, D_Loss:0.9054007530212402, G_Loss:2.0298638343811035

iterator 4700, D_Loss:0.860151469707489, G_Loss:2.279883861541748

iterator 4800, D_Loss:0.8527189493179321, G_Loss:2.2013792991638184

iterator 4900, D_Loss:0.8550450801849365, G_Loss:2.1168594360351562

iterator 5000, D_Loss:0.9112837314605713, G_Loss:1.9430032968521118

VGAN_generator(
  (input): Linear(in_features=256, out_features=100, bias=True)
  (inputbn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=100, out_features=100, bias=True)
  (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=100, out_features=100, bias=True)
  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=100, out_features=15, bias=True)
  (outputbn): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=15, out_features=400, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=400, out_features=400, bias=True)
  (fc1): Linear(in_features=400, out_features=400, bias=True)
  (output): Linear(in_features=400, out_features=1, bias=True)
)
(0, False, 15)
-----------Epoch 0-----------
iterator 100, D_Loss:0.5438079237937927, G_Loss:5.632805824279785

iterator 200, D_Loss:0.5075170397758484, G_Loss:7.434718132019043

iterator 300, D_Loss:0.505500316619873, G_Loss:7.856341361999512

iterator 400, D_Loss:0.48698776960372925, G_Loss:9.760000228881836

iterator 500, D_Loss:0.44388777017593384, G_Loss:9.103960990905762

iterator 600, D_Loss:0.45540979504585266, G_Loss:10.52344799041748

iterator 700, D_Loss:0.47582003474235535, G_Loss:9.93802261352539

iterator 800, D_Loss:0.49339568614959717, G_Loss:10.385822296142578

iterator 900, D_Loss:0.4741082489490509, G_Loss:9.805055618286133

iterator 1000, D_Loss:0.47621533274650574, G_Loss:10.953892707824707

iterator 1100, D_Loss:0.4730236232280731, G_Loss:10.816178321838379

iterator 1200, D_Loss:0.48567625880241394, G_Loss:11.58369255065918

iterator 1300, D_Loss:0.4663901925086975, G_Loss:10.511408805847168

iterator 1400, D_Loss:0.47204113006591797, G_Loss:10.654547691345215

iterator 1500, D_Loss:0.5015276670455933, G_Loss:12.875092506408691

iterator 1600, D_Loss:0.4700776934623718, G_Loss:12.47449779510498

iterator 1700, D_Loss:0.4562149941921234, G_Loss:10.517180442810059

iterator 1800, D_Loss:0.4719378352165222, G_Loss:10.690593719482422

iterator 1900, D_Loss:0.4938949644565582, G_Loss:10.489974021911621

iterator 2000, D_Loss:0.4601020812988281, G_Loss:9.57254695892334

iterator 2100, D_Loss:0.5015004873275757, G_Loss:10.452997207641602

iterator 2200, D_Loss:0.49747636914253235, G_Loss:8.870757102966309

iterator 2300, D_Loss:0.47726649045944214, G_Loss:9.740641593933105

iterator 2400, D_Loss:0.483370840549469, G_Loss:8.487746238708496

iterator 2500, D_Loss:0.4757477641105652, G_Loss:10.30165958404541

iterator 2600, D_Loss:0.49977409839630127, G_Loss:9.819067001342773

iterator 2700, D_Loss:0.48402655124664307, G_Loss:9.47395133972168

iterator 2800, D_Loss:0.4884796440601349, G_Loss:9.047456741333008

iterator 2900, D_Loss:0.4526316225528717, G_Loss:8.999183654785156

iterator 3000, D_Loss:0.5143460631370544, G_Loss:8.990145683288574

iterator 3100, D_Loss:0.4751277565956116, G_Loss:8.732216835021973

iterator 3200, D_Loss:0.5008662939071655, G_Loss:8.193655967712402

iterator 3300, D_Loss:0.4969979226589203, G_Loss:7.5033721923828125

iterator 3400, D_Loss:0.47758594155311584, G_Loss:7.585102558135986

iterator 3500, D_Loss:0.5188388228416443, G_Loss:8.577376365661621

iterator 3600, D_Loss:0.49213096499443054, G_Loss:7.605123996734619

iterator 3700, D_Loss:0.5009041428565979, G_Loss:7.203641891479492

iterator 3800, D_Loss:0.546331524848938, G_Loss:6.975337028503418

iterator 3900, D_Loss:0.5300989151000977, G_Loss:7.6100358963012695

iterator 4000, D_Loss:0.47833284735679626, G_Loss:6.953244209289551

iterator 4100, D_Loss:0.5015978813171387, G_Loss:7.676792621612549

iterator 4200, D_Loss:0.5015512704849243, G_Loss:7.194080829620361

iterator 4300, D_Loss:0.5211805701255798, G_Loss:6.824307918548584

iterator 4400, D_Loss:0.48979446291923523, G_Loss:7.197425365447998

iterator 4500, D_Loss:0.4800877273082733, G_Loss:6.821113109588623

iterator 4600, D_Loss:0.48097604513168335, G_Loss:7.491812705993652

iterator 4700, D_Loss:0.4747234582901001, G_Loss:7.101555347442627

iterator 4800, D_Loss:0.5144784450531006, G_Loss:6.020164966583252

iterator 4900, D_Loss:0.4752047657966614, G_Loss:6.495119094848633

iterator 5000, D_Loss:0.510033905506134, G_Loss:6.707752704620361

-----------Epoch 1-----------
iterator 100, D_Loss:0.5297910571098328, G_Loss:6.2939276695251465

iterator 200, D_Loss:0.4965726137161255, G_Loss:6.349296569824219

iterator 300, D_Loss:0.5137303471565247, G_Loss:6.434350967407227

iterator 400, D_Loss:0.48531046509742737, G_Loss:6.783243179321289

iterator 500, D_Loss:0.5051679611206055, G_Loss:6.225397109985352

iterator 600, D_Loss:0.4780728220939636, G_Loss:6.83305025100708

iterator 700, D_Loss:0.5231687426567078, G_Loss:6.85532808303833

iterator 800, D_Loss:0.5839133262634277, G_Loss:6.116143226623535

iterator 900, D_Loss:0.48703041672706604, G_Loss:6.495287895202637

iterator 1000, D_Loss:0.46356382966041565, G_Loss:7.058837890625

iterator 1100, D_Loss:0.4908364415168762, G_Loss:6.741593837738037

iterator 1200, D_Loss:0.4901811182498932, G_Loss:6.562591552734375

iterator 1300, D_Loss:0.484197735786438, G_Loss:6.819460868835449

iterator 1400, D_Loss:0.48470979928970337, G_Loss:6.774749755859375

iterator 1500, D_Loss:0.5007466673851013, G_Loss:7.127133369445801

iterator 1600, D_Loss:0.5005989074707031, G_Loss:6.301770210266113

iterator 1700, D_Loss:0.5126507878303528, G_Loss:6.757894515991211

iterator 1800, D_Loss:0.5067808628082275, G_Loss:6.985273361206055

iterator 1900, D_Loss:0.5239090323448181, G_Loss:7.393298625946045

iterator 2000, D_Loss:0.4862464368343353, G_Loss:6.664916515350342

iterator 2100, D_Loss:0.5045262575149536, G_Loss:6.028508186340332

iterator 2200, D_Loss:0.5268953442573547, G_Loss:6.488930702209473

iterator 2300, D_Loss:0.5105311274528503, G_Loss:6.370828628540039

iterator 2400, D_Loss:0.5051275491714478, G_Loss:6.1937971115112305

iterator 2500, D_Loss:0.5338078737258911, G_Loss:7.120538711547852

iterator 2600, D_Loss:0.5329949259757996, G_Loss:6.80549430847168

iterator 2700, D_Loss:0.5245447754859924, G_Loss:6.356055736541748

iterator 2800, D_Loss:0.4983230233192444, G_Loss:6.80473518371582

iterator 2900, D_Loss:0.5571659207344055, G_Loss:6.543618679046631

iterator 3000, D_Loss:0.5282853245735168, G_Loss:6.329825401306152

iterator 3100, D_Loss:0.4931320548057556, G_Loss:5.822213172912598

iterator 3200, D_Loss:0.5087377429008484, G_Loss:6.585758209228516

iterator 3300, D_Loss:0.524304211139679, G_Loss:6.347506523132324

iterator 3400, D_Loss:0.5291497111320496, G_Loss:7.047502040863037

iterator 3500, D_Loss:0.5347418189048767, G_Loss:7.4175214767456055

iterator 3600, D_Loss:0.5473266243934631, G_Loss:7.047434329986572

iterator 3700, D_Loss:0.5141465663909912, G_Loss:6.53902530670166

iterator 3800, D_Loss:0.5325738787651062, G_Loss:6.386891841888428

iterator 3900, D_Loss:0.5021259188652039, G_Loss:6.806791305541992

iterator 4000, D_Loss:0.5015015602111816, G_Loss:6.4726972579956055

iterator 4100, D_Loss:0.5129696130752563, G_Loss:6.056502342224121

iterator 4200, D_Loss:0.5181900858879089, G_Loss:6.509047031402588

iterator 4300, D_Loss:0.5087923407554626, G_Loss:5.831050395965576

iterator 4400, D_Loss:0.5186920166015625, G_Loss:6.3280029296875

iterator 4500, D_Loss:0.5653442144393921, G_Loss:6.782395839691162

iterator 4600, D_Loss:0.5083428621292114, G_Loss:6.625244140625

iterator 4700, D_Loss:0.49310973286628723, G_Loss:6.194053649902344

iterator 4800, D_Loss:0.5254721641540527, G_Loss:6.1260786056518555

iterator 4900, D_Loss:0.5128633975982666, G_Loss:6.435789585113525

iterator 5000, D_Loss:0.5217629671096802, G_Loss:6.5824761390686035

-----------Epoch 2-----------
iterator 100, D_Loss:0.5170815587043762, G_Loss:6.193954944610596

iterator 200, D_Loss:0.5052276253700256, G_Loss:6.061188697814941

iterator 300, D_Loss:0.5425170063972473, G_Loss:6.77817964553833

iterator 400, D_Loss:0.5317882895469666, G_Loss:6.193016529083252

iterator 500, D_Loss:0.5477831363677979, G_Loss:6.659985542297363

iterator 600, D_Loss:0.5220861434936523, G_Loss:6.3880414962768555

iterator 700, D_Loss:0.53687584400177, G_Loss:6.670785427093506

iterator 800, D_Loss:0.522859513759613, G_Loss:6.122218132019043

iterator 900, D_Loss:0.4954608082771301, G_Loss:6.447178363800049

iterator 1000, D_Loss:0.5256866216659546, G_Loss:6.810904026031494

iterator 1100, D_Loss:0.5132825374603271, G_Loss:5.905632495880127

iterator 1200, D_Loss:0.5473633408546448, G_Loss:5.650178909301758

iterator 1300, D_Loss:0.5747265219688416, G_Loss:5.194591045379639

iterator 1400, D_Loss:0.5182105302810669, G_Loss:5.04841947555542

iterator 1500, D_Loss:0.5277964472770691, G_Loss:6.537840843200684

iterator 1600, D_Loss:0.53214430809021, G_Loss:6.225289344787598

iterator 1700, D_Loss:0.5275872349739075, G_Loss:6.826883316040039

iterator 1800, D_Loss:0.5273763537406921, G_Loss:5.255289554595947

iterator 1900, D_Loss:0.5415550470352173, G_Loss:5.492682456970215

iterator 2000, D_Loss:0.5877788662910461, G_Loss:5.483898162841797

iterator 2100, D_Loss:0.5814887285232544, G_Loss:6.02211856842041

iterator 2200, D_Loss:0.6052550673484802, G_Loss:5.359177112579346

iterator 2300, D_Loss:0.602175772190094, G_Loss:4.542315483093262

iterator 2400, D_Loss:0.5379672050476074, G_Loss:5.0849432945251465

iterator 2500, D_Loss:0.5991770625114441, G_Loss:5.29145622253418

iterator 2600, D_Loss:0.6265581846237183, G_Loss:5.565926551818848

iterator 2700, D_Loss:0.5715931057929993, G_Loss:5.574070930480957

iterator 2800, D_Loss:0.5291137099266052, G_Loss:5.203092575073242

iterator 2900, D_Loss:0.5360859632492065, G_Loss:5.822335243225098

iterator 3000, D_Loss:0.5897461771965027, G_Loss:5.696958541870117

iterator 3100, D_Loss:0.5409162044525146, G_Loss:5.22498083114624

iterator 3200, D_Loss:0.6621906161308289, G_Loss:5.341114521026611

iterator 3300, D_Loss:0.5743638873100281, G_Loss:4.922236442565918

iterator 3400, D_Loss:0.5341013073921204, G_Loss:5.642009258270264

iterator 3500, D_Loss:0.5893517732620239, G_Loss:5.299294471740723

iterator 3600, D_Loss:0.5979974269866943, G_Loss:4.963680267333984

iterator 3700, D_Loss:0.5771152377128601, G_Loss:4.50858211517334

iterator 3800, D_Loss:0.586611270904541, G_Loss:4.928114891052246

iterator 3900, D_Loss:0.5508556365966797, G_Loss:4.854017734527588

iterator 4000, D_Loss:0.5647432804107666, G_Loss:5.5955352783203125

iterator 4100, D_Loss:0.5749552249908447, G_Loss:4.781866550445557

iterator 4200, D_Loss:0.5704560875892639, G_Loss:4.920376300811768

iterator 4300, D_Loss:0.5577268004417419, G_Loss:4.963203430175781

iterator 4400, D_Loss:0.5753114819526672, G_Loss:4.836725234985352

iterator 4500, D_Loss:0.6089516878128052, G_Loss:5.3697733879089355

iterator 4600, D_Loss:0.5464840531349182, G_Loss:4.854980945587158

iterator 4700, D_Loss:0.5932806730270386, G_Loss:5.4197869300842285

iterator 4800, D_Loss:0.5890185236930847, G_Loss:5.353184223175049

iterator 4900, D_Loss:0.5844457149505615, G_Loss:4.709751129150391

iterator 5000, D_Loss:0.5789871215820312, G_Loss:4.648645401000977

-----------Epoch 3-----------
iterator 100, D_Loss:0.5789890885353088, G_Loss:5.126230239868164

iterator 200, D_Loss:0.602566123008728, G_Loss:5.205690383911133

iterator 300, D_Loss:0.5632101893424988, G_Loss:5.362971782684326

iterator 400, D_Loss:0.5921025276184082, G_Loss:5.458670616149902

iterator 500, D_Loss:0.6009719371795654, G_Loss:5.206489086151123

iterator 600, D_Loss:0.6291773319244385, G_Loss:4.6938066482543945

iterator 700, D_Loss:0.5628131628036499, G_Loss:4.999412536621094

iterator 800, D_Loss:0.6585513949394226, G_Loss:4.35850191116333

iterator 900, D_Loss:0.6372837424278259, G_Loss:4.497021675109863

iterator 1000, D_Loss:0.6181920766830444, G_Loss:4.570568084716797

iterator 1100, D_Loss:0.6283485293388367, G_Loss:4.700881004333496

iterator 1200, D_Loss:0.6017184853553772, G_Loss:4.323591709136963

iterator 1300, D_Loss:0.6069972515106201, G_Loss:4.628793716430664

iterator 1400, D_Loss:0.606012225151062, G_Loss:4.3015875816345215

iterator 1500, D_Loss:0.6813768148422241, G_Loss:4.474485874176025

iterator 1600, D_Loss:0.6258898973464966, G_Loss:4.314309120178223

iterator 1700, D_Loss:0.6124846339225769, G_Loss:4.248647689819336

iterator 1800, D_Loss:0.6176003217697144, G_Loss:4.499515533447266

iterator 1900, D_Loss:0.6503957509994507, G_Loss:4.26171875

iterator 2000, D_Loss:0.6488749980926514, G_Loss:3.718698024749756

iterator 2100, D_Loss:0.6737182140350342, G_Loss:3.8823418617248535

iterator 2200, D_Loss:0.6225168704986572, G_Loss:3.5621731281280518

iterator 2300, D_Loss:0.613827109336853, G_Loss:3.777634620666504

iterator 2400, D_Loss:0.6850426197052002, G_Loss:4.083688259124756

iterator 2500, D_Loss:0.6360512971878052, G_Loss:4.331691265106201

iterator 2600, D_Loss:0.6134508848190308, G_Loss:4.191118240356445

iterator 2700, D_Loss:0.66455078125, G_Loss:4.061526298522949

iterator 2800, D_Loss:0.6200239658355713, G_Loss:4.103932857513428

iterator 2900, D_Loss:0.6783505082130432, G_Loss:3.922207832336426

iterator 3000, D_Loss:0.6778469681739807, G_Loss:3.567815065383911

iterator 3100, D_Loss:0.6698362827301025, G_Loss:3.673365592956543

iterator 3200, D_Loss:0.6584566235542297, G_Loss:3.8204355239868164

iterator 3300, D_Loss:0.6490346789360046, G_Loss:3.55644154548645

iterator 3400, D_Loss:0.6179378628730774, G_Loss:4.016500949859619

iterator 3500, D_Loss:0.6591373085975647, G_Loss:3.6118204593658447

iterator 3600, D_Loss:0.636863112449646, G_Loss:3.430046558380127

iterator 3700, D_Loss:0.6530316472053528, G_Loss:3.526014804840088

iterator 3800, D_Loss:0.6373562812805176, G_Loss:3.6245410442352295

iterator 3900, D_Loss:0.653885543346405, G_Loss:3.604184627532959

iterator 4000, D_Loss:0.6639251708984375, G_Loss:3.710043430328369

iterator 4100, D_Loss:0.6355668306350708, G_Loss:3.4171102046966553

iterator 4200, D_Loss:0.7149261236190796, G_Loss:3.1893887519836426

iterator 4300, D_Loss:0.6880757808685303, G_Loss:3.638231039047241

iterator 4400, D_Loss:0.6741909980773926, G_Loss:3.261232614517212

iterator 4500, D_Loss:0.7332155704498291, G_Loss:3.241605758666992

iterator 4600, D_Loss:0.7435475587844849, G_Loss:3.2035739421844482

iterator 4700, D_Loss:0.695681095123291, G_Loss:3.4461669921875

iterator 4800, D_Loss:0.6880688667297363, G_Loss:3.0735819339752197

iterator 4900, D_Loss:0.7261053323745728, G_Loss:3.4022610187530518

iterator 5000, D_Loss:0.7352944016456604, G_Loss:3.356376886367798

-----------Epoch 4-----------
iterator 100, D_Loss:0.6849507689476013, G_Loss:3.33893084526062

iterator 200, D_Loss:0.7058525681495667, G_Loss:3.5982816219329834

iterator 300, D_Loss:0.7041451334953308, G_Loss:3.287411689758301

iterator 400, D_Loss:0.680438220500946, G_Loss:3.3144147396087646

iterator 500, D_Loss:0.6987022757530212, G_Loss:3.415609359741211

iterator 600, D_Loss:0.6798977851867676, G_Loss:3.3463525772094727

iterator 700, D_Loss:0.6808653473854065, G_Loss:3.1175060272216797

iterator 800, D_Loss:0.7324086427688599, G_Loss:3.2746667861938477

iterator 900, D_Loss:0.6957844495773315, G_Loss:3.324786901473999

iterator 1000, D_Loss:0.665042519569397, G_Loss:3.3617403507232666

iterator 1100, D_Loss:0.6919121742248535, G_Loss:3.6178219318389893

iterator 1200, D_Loss:0.6596707701683044, G_Loss:3.6218738555908203

iterator 1300, D_Loss:0.7117878794670105, G_Loss:3.2542035579681396

iterator 1400, D_Loss:0.6783552765846252, G_Loss:3.4003422260284424

iterator 1500, D_Loss:0.6838173270225525, G_Loss:3.4054553508758545

iterator 1600, D_Loss:0.6591506600379944, G_Loss:3.4345462322235107

iterator 1700, D_Loss:0.6692599654197693, G_Loss:3.219470262527466

iterator 1800, D_Loss:0.7066402435302734, G_Loss:3.305591583251953

iterator 1900, D_Loss:0.6572873592376709, G_Loss:3.1892309188842773

iterator 2000, D_Loss:0.6983039975166321, G_Loss:3.1055712699890137

iterator 2100, D_Loss:0.7127770781517029, G_Loss:3.0801453590393066

iterator 2200, D_Loss:0.7111489772796631, G_Loss:3.34324049949646

iterator 2300, D_Loss:0.7128850817680359, G_Loss:3.4024460315704346

iterator 2400, D_Loss:0.7125551700592041, G_Loss:3.3510680198669434

iterator 2500, D_Loss:0.7338926196098328, G_Loss:3.3723394870758057

iterator 2600, D_Loss:0.7207654118537903, G_Loss:3.099792003631592

iterator 2700, D_Loss:0.7952539324760437, G_Loss:3.3063607215881348

iterator 2800, D_Loss:0.7338821887969971, G_Loss:3.151327133178711

iterator 2900, D_Loss:0.7049077749252319, G_Loss:3.3717634677886963

iterator 3000, D_Loss:0.6861155033111572, G_Loss:2.835240125656128

iterator 3100, D_Loss:0.7358405590057373, G_Loss:3.0298879146575928

iterator 3200, D_Loss:0.7132474184036255, G_Loss:3.3643505573272705

iterator 3300, D_Loss:0.6575244665145874, G_Loss:3.321855306625366

iterator 3400, D_Loss:0.7027841806411743, G_Loss:3.2498180866241455

iterator 3500, D_Loss:0.6967807412147522, G_Loss:3.1136884689331055

iterator 3600, D_Loss:0.7352350354194641, G_Loss:3.300827980041504

iterator 3700, D_Loss:0.6960377097129822, G_Loss:3.1190285682678223

iterator 3800, D_Loss:0.6992155313491821, G_Loss:2.694669246673584

iterator 3900, D_Loss:0.7436536550521851, G_Loss:2.828383684158325

iterator 4000, D_Loss:0.7363630533218384, G_Loss:2.856893539428711

iterator 4100, D_Loss:0.7698848843574524, G_Loss:3.008756160736084

iterator 4200, D_Loss:0.7269434928894043, G_Loss:3.099004030227661

iterator 4300, D_Loss:0.7487449645996094, G_Loss:2.7728774547576904

iterator 4400, D_Loss:0.7445662617683411, G_Loss:2.7561750411987305

iterator 4500, D_Loss:0.7545893788337708, G_Loss:2.794410467147827

iterator 4600, D_Loss:0.7790964841842651, G_Loss:2.8100497722625732

iterator 4700, D_Loss:0.751543402671814, G_Loss:2.899585485458374

iterator 4800, D_Loss:0.7207505106925964, G_Loss:3.037738800048828

iterator 4900, D_Loss:0.7760632634162903, G_Loss:3.0329127311706543

iterator 5000, D_Loss:0.8126911520957947, G_Loss:2.784921407699585

-----------Epoch 5-----------
iterator 100, D_Loss:0.7322419881820679, G_Loss:2.9122958183288574

iterator 200, D_Loss:0.752514660358429, G_Loss:2.7714123725891113

iterator 300, D_Loss:0.7587971687316895, G_Loss:2.7136425971984863

iterator 400, D_Loss:0.7524454593658447, G_Loss:2.9701552391052246

iterator 500, D_Loss:0.8238376379013062, G_Loss:2.702270269393921

iterator 600, D_Loss:0.7593367099761963, G_Loss:2.799395799636841

iterator 700, D_Loss:0.7894997596740723, G_Loss:2.7422924041748047

iterator 800, D_Loss:0.7621759176254272, G_Loss:2.9759278297424316

iterator 900, D_Loss:0.7680379748344421, G_Loss:3.000685214996338

iterator 1000, D_Loss:0.7751115560531616, G_Loss:2.6187705993652344

iterator 1100, D_Loss:0.770106852054596, G_Loss:2.8412399291992188

iterator 1200, D_Loss:0.7503990530967712, G_Loss:2.7535383701324463

iterator 1300, D_Loss:0.7459111213684082, G_Loss:3.0767266750335693

iterator 1400, D_Loss:0.7588751316070557, G_Loss:2.696007251739502

iterator 1500, D_Loss:0.7585361003875732, G_Loss:2.9565486907958984

iterator 1600, D_Loss:0.7520850896835327, G_Loss:2.9669547080993652

iterator 1700, D_Loss:0.7637019157409668, G_Loss:2.8289573192596436

iterator 1800, D_Loss:0.7569440603256226, G_Loss:2.8877358436584473

iterator 1900, D_Loss:0.7911041975021362, G_Loss:2.8165767192840576

iterator 2000, D_Loss:0.7862322926521301, G_Loss:2.819891929626465

iterator 2100, D_Loss:0.804799497127533, G_Loss:2.9821255207061768

iterator 2200, D_Loss:0.701143741607666, G_Loss:2.950082540512085

iterator 2300, D_Loss:0.7132536768913269, G_Loss:3.0644450187683105

iterator 2400, D_Loss:0.7331827282905579, G_Loss:3.0466091632843018

iterator 2500, D_Loss:0.7846235632896423, G_Loss:2.9155113697052

iterator 2600, D_Loss:0.7463418245315552, G_Loss:3.1484389305114746

iterator 2700, D_Loss:0.749127984046936, G_Loss:2.8962109088897705

iterator 2800, D_Loss:0.749039351940155, G_Loss:2.8441600799560547

iterator 2900, D_Loss:0.7443617582321167, G_Loss:2.9708762168884277

iterator 3000, D_Loss:0.7625720500946045, G_Loss:2.7160282135009766

iterator 3100, D_Loss:0.7823805809020996, G_Loss:2.9179773330688477

iterator 3200, D_Loss:0.7128034234046936, G_Loss:2.7657687664031982

iterator 3300, D_Loss:0.6933278441429138, G_Loss:3.010920524597168

iterator 3400, D_Loss:0.7575934529304504, G_Loss:2.723628520965576

iterator 3500, D_Loss:0.7257310748100281, G_Loss:2.7164177894592285

iterator 3600, D_Loss:0.7293912768363953, G_Loss:2.936392307281494

iterator 3700, D_Loss:0.7179125547409058, G_Loss:2.955235481262207

iterator 3800, D_Loss:0.7565894722938538, G_Loss:2.88147234916687

iterator 3900, D_Loss:0.7122856974601746, G_Loss:3.1299502849578857

iterator 4000, D_Loss:0.7123557925224304, G_Loss:2.854332447052002

iterator 4100, D_Loss:0.7199957966804504, G_Loss:2.9880080223083496

iterator 4200, D_Loss:0.7656524181365967, G_Loss:3.1991071701049805

iterator 4300, D_Loss:0.7437877655029297, G_Loss:2.827284574508667

iterator 4400, D_Loss:0.732785701751709, G_Loss:3.020721912384033

iterator 4500, D_Loss:0.7580885887145996, G_Loss:2.800565481185913

iterator 4600, D_Loss:0.7568493485450745, G_Loss:2.7581515312194824

iterator 4700, D_Loss:0.7356957197189331, G_Loss:2.842251777648926

iterator 4800, D_Loss:0.7879311442375183, G_Loss:2.9096405506134033

iterator 4900, D_Loss:0.7701150178909302, G_Loss:2.7558867931365967

iterator 5000, D_Loss:0.7839216589927673, G_Loss:3.0244102478027344

-----------Epoch 6-----------
iterator 100, D_Loss:0.7625823616981506, G_Loss:3.068329334259033

iterator 200, D_Loss:0.6995148658752441, G_Loss:2.89548921585083

iterator 300, D_Loss:0.7411031723022461, G_Loss:2.672199249267578

iterator 400, D_Loss:0.7130744457244873, G_Loss:3.1665897369384766

iterator 500, D_Loss:0.7636992931365967, G_Loss:2.6415598392486572

iterator 600, D_Loss:0.7132824659347534, G_Loss:2.9059348106384277

iterator 700, D_Loss:0.7366345524787903, G_Loss:2.8913259506225586

iterator 800, D_Loss:0.7486149072647095, G_Loss:2.81335711479187

iterator 900, D_Loss:0.7590025663375854, G_Loss:2.781871795654297

iterator 1000, D_Loss:0.7656581997871399, G_Loss:3.0787012577056885

iterator 1100, D_Loss:0.7436323165893555, G_Loss:2.7312746047973633

iterator 1200, D_Loss:0.7766508460044861, G_Loss:2.7631444931030273

iterator 1300, D_Loss:0.7700920104980469, G_Loss:2.6146998405456543

iterator 1400, D_Loss:0.745172917842865, G_Loss:2.677605390548706

iterator 1500, D_Loss:0.8054289221763611, G_Loss:2.8172872066497803

iterator 1600, D_Loss:0.7183917760848999, G_Loss:2.847585916519165

iterator 1700, D_Loss:0.8007895946502686, G_Loss:2.7570905685424805

iterator 1800, D_Loss:0.7767501473426819, G_Loss:2.9331319332122803

iterator 1900, D_Loss:0.8101012110710144, G_Loss:2.793245792388916

iterator 2000, D_Loss:0.7544267177581787, G_Loss:2.7865591049194336

iterator 2100, D_Loss:0.7465242147445679, G_Loss:2.8672170639038086

iterator 2200, D_Loss:0.7599332332611084, G_Loss:2.798673391342163

iterator 2300, D_Loss:0.7776107788085938, G_Loss:2.726771831512451

iterator 2400, D_Loss:0.7400155067443848, G_Loss:2.7742295265197754

iterator 2500, D_Loss:0.7496333122253418, G_Loss:2.964007616043091

iterator 2600, D_Loss:0.7041783928871155, G_Loss:2.7101879119873047

iterator 2700, D_Loss:0.8067229390144348, G_Loss:2.634665012359619

iterator 2800, D_Loss:0.7703090310096741, G_Loss:2.991365432739258

iterator 2900, D_Loss:0.7358362674713135, G_Loss:3.014899730682373

iterator 3000, D_Loss:0.7521147131919861, G_Loss:2.8345048427581787

iterator 3100, D_Loss:0.7749475836753845, G_Loss:2.7150774002075195

iterator 3200, D_Loss:0.748915433883667, G_Loss:2.7972073554992676

iterator 3300, D_Loss:0.7627473473548889, G_Loss:2.886104106903076

iterator 3400, D_Loss:0.7861392498016357, G_Loss:2.7944185733795166

iterator 3500, D_Loss:0.7620153427124023, G_Loss:2.583268165588379

iterator 3600, D_Loss:0.722285270690918, G_Loss:2.7551424503326416

iterator 3700, D_Loss:0.7763115167617798, G_Loss:2.874002456665039

iterator 3800, D_Loss:0.7335164546966553, G_Loss:2.9741597175598145

iterator 3900, D_Loss:0.7578882575035095, G_Loss:2.8346714973449707

iterator 4000, D_Loss:0.7943324446678162, G_Loss:2.801374912261963

iterator 4100, D_Loss:0.7935240864753723, G_Loss:2.600951910018921

iterator 4200, D_Loss:0.7789258360862732, G_Loss:2.731034994125366

iterator 4300, D_Loss:0.7737102508544922, G_Loss:2.590407371520996

iterator 4400, D_Loss:0.7197408080101013, G_Loss:2.8555543422698975

iterator 4500, D_Loss:0.7823929786682129, G_Loss:2.661633253097534

iterator 4600, D_Loss:0.7530168890953064, G_Loss:2.742584705352783

iterator 4700, D_Loss:0.7387058734893799, G_Loss:2.871605396270752

iterator 4800, D_Loss:0.7264561653137207, G_Loss:2.896411180496216

iterator 4900, D_Loss:0.778823971748352, G_Loss:2.693103790283203

iterator 5000, D_Loss:0.7381390333175659, G_Loss:2.5264642238616943

-----------Epoch 7-----------
iterator 100, D_Loss:0.7573866844177246, G_Loss:2.9177963733673096

iterator 200, D_Loss:0.7329537868499756, G_Loss:2.8328092098236084

iterator 300, D_Loss:0.7340268492698669, G_Loss:2.732734203338623

iterator 400, D_Loss:0.7690828442573547, G_Loss:2.730592727661133

iterator 500, D_Loss:0.7776340246200562, G_Loss:2.7891159057617188

iterator 600, D_Loss:0.7518831491470337, G_Loss:2.8774588108062744

iterator 700, D_Loss:0.7583865523338318, G_Loss:2.57183575630188

iterator 800, D_Loss:0.8045499324798584, G_Loss:2.759418487548828

iterator 900, D_Loss:0.7792003154754639, G_Loss:2.7350575923919678

iterator 1000, D_Loss:0.7534898519515991, G_Loss:2.830425262451172

iterator 1100, D_Loss:0.7410397529602051, G_Loss:2.6822638511657715

iterator 1200, D_Loss:0.800916314125061, G_Loss:2.822922706604004

iterator 1300, D_Loss:0.7656543254852295, G_Loss:2.585265636444092

iterator 1400, D_Loss:0.7612407207489014, G_Loss:2.4740793704986572

iterator 1500, D_Loss:0.7915394902229309, G_Loss:2.7190988063812256

iterator 1600, D_Loss:0.7529864311218262, G_Loss:2.9207558631896973

iterator 1700, D_Loss:0.7925788164138794, G_Loss:2.774679660797119

iterator 1800, D_Loss:0.7977674603462219, G_Loss:2.678589105606079

iterator 1900, D_Loss:0.8421308994293213, G_Loss:2.9046597480773926

iterator 2000, D_Loss:0.7705903649330139, G_Loss:2.8947367668151855

iterator 2100, D_Loss:0.8020161390304565, G_Loss:2.6583783626556396

iterator 2200, D_Loss:0.7865413427352905, G_Loss:2.5604422092437744

iterator 2300, D_Loss:0.81593257188797, G_Loss:2.667618989944458

iterator 2400, D_Loss:0.7566688060760498, G_Loss:3.0254721641540527

iterator 2500, D_Loss:0.7697187066078186, G_Loss:2.6071817874908447

iterator 2600, D_Loss:0.8344941139221191, G_Loss:2.572760820388794

iterator 2700, D_Loss:0.7690679430961609, G_Loss:2.7318503856658936

iterator 2800, D_Loss:0.7577833533287048, G_Loss:3.1370742321014404

iterator 2900, D_Loss:0.7188658714294434, G_Loss:3.2525336742401123

iterator 3000, D_Loss:0.7378448247909546, G_Loss:2.7911739349365234

iterator 3100, D_Loss:0.7538589835166931, G_Loss:2.900515556335449

iterator 3200, D_Loss:0.7587516903877258, G_Loss:2.846393346786499

iterator 3300, D_Loss:0.7127549648284912, G_Loss:2.6213488578796387

iterator 3400, D_Loss:0.7395219206809998, G_Loss:2.8791542053222656

iterator 3500, D_Loss:0.7377420663833618, G_Loss:2.924797534942627

iterator 3600, D_Loss:0.6960865259170532, G_Loss:2.9713685512542725

iterator 3700, D_Loss:0.7525765299797058, G_Loss:2.5969901084899902

iterator 3800, D_Loss:0.7231355905532837, G_Loss:2.961184024810791

iterator 3900, D_Loss:0.7981055974960327, G_Loss:2.9731228351593018

iterator 4000, D_Loss:0.7307841181755066, G_Loss:2.747610330581665

iterator 4100, D_Loss:0.7496123909950256, G_Loss:2.6411356925964355

iterator 4200, D_Loss:0.7717996835708618, G_Loss:2.8452930450439453

iterator 4300, D_Loss:0.7683713436126709, G_Loss:2.704007625579834

iterator 4400, D_Loss:0.7698760628700256, G_Loss:2.6801586151123047

iterator 4500, D_Loss:0.7545879483222961, G_Loss:2.7057650089263916

iterator 4600, D_Loss:0.8325057029724121, G_Loss:2.8109726905822754

iterator 4700, D_Loss:0.765811562538147, G_Loss:2.912660598754883

iterator 4800, D_Loss:0.7528557777404785, G_Loss:2.8531382083892822

iterator 4900, D_Loss:0.7436485886573792, G_Loss:2.7976362705230713

iterator 5000, D_Loss:0.8113657236099243, G_Loss:3.0270395278930664

-----------Epoch 8-----------
iterator 100, D_Loss:0.7517151236534119, G_Loss:3.1753830909729004

iterator 200, D_Loss:0.7168294191360474, G_Loss:2.76821231842041

iterator 300, D_Loss:0.7537122964859009, G_Loss:2.7650132179260254

iterator 400, D_Loss:0.7565529346466064, G_Loss:3.012404441833496

iterator 500, D_Loss:0.7267739772796631, G_Loss:2.655405282974243

iterator 600, D_Loss:0.7743479609489441, G_Loss:2.911395311355591

iterator 700, D_Loss:0.7063597440719604, G_Loss:3.0046753883361816

iterator 800, D_Loss:0.7241657972335815, G_Loss:2.6959238052368164

iterator 900, D_Loss:0.7602201700210571, G_Loss:2.9398205280303955

iterator 1000, D_Loss:0.8025755286216736, G_Loss:2.4883718490600586

iterator 1100, D_Loss:0.7795276641845703, G_Loss:2.697570562362671

iterator 1200, D_Loss:0.6868183612823486, G_Loss:2.6798672676086426

iterator 1300, D_Loss:0.7258669137954712, G_Loss:2.6674318313598633

iterator 1400, D_Loss:0.7196941375732422, G_Loss:3.0845439434051514

iterator 1500, D_Loss:0.7318726181983948, G_Loss:2.8379735946655273

iterator 1600, D_Loss:0.7482157349586487, G_Loss:2.692434787750244

iterator 1700, D_Loss:0.773858904838562, G_Loss:3.108539581298828

iterator 1800, D_Loss:0.7933244705200195, G_Loss:2.9805710315704346

iterator 1900, D_Loss:0.7872086763381958, G_Loss:2.8948755264282227

iterator 2000, D_Loss:0.7444319725036621, G_Loss:2.855586528778076

iterator 2100, D_Loss:0.7675257921218872, G_Loss:2.7971389293670654

iterator 2200, D_Loss:0.7147796154022217, G_Loss:2.9762840270996094

iterator 2300, D_Loss:0.7307008504867554, G_Loss:2.8669469356536865

iterator 2400, D_Loss:0.7441307306289673, G_Loss:2.805600643157959

iterator 2500, D_Loss:0.7670955657958984, G_Loss:3.0946967601776123

iterator 2600, D_Loss:0.7376848459243774, G_Loss:3.018514394760132

iterator 2700, D_Loss:0.7574273943901062, G_Loss:2.9317140579223633

iterator 2800, D_Loss:0.7837556600570679, G_Loss:2.794062614440918

iterator 2900, D_Loss:0.7174278497695923, G_Loss:3.0076961517333984

iterator 3000, D_Loss:0.7572657465934753, G_Loss:2.90433931350708

iterator 3100, D_Loss:0.7820935249328613, G_Loss:3.033555507659912

iterator 3200, D_Loss:0.7517902851104736, G_Loss:3.004664182662964

iterator 3300, D_Loss:0.7781739234924316, G_Loss:2.9535837173461914

iterator 3400, D_Loss:0.7366412281990051, G_Loss:3.070178270339966

iterator 3500, D_Loss:0.7122361660003662, G_Loss:2.9113428592681885

iterator 3600, D_Loss:0.6844702959060669, G_Loss:2.7572708129882812

iterator 3700, D_Loss:0.749476432800293, G_Loss:2.7793753147125244

iterator 3800, D_Loss:0.7355307340621948, G_Loss:2.7988626956939697

iterator 3900, D_Loss:0.7698991894721985, G_Loss:2.8526360988616943

iterator 4000, D_Loss:0.7537869215011597, G_Loss:2.9452974796295166

iterator 4100, D_Loss:0.7579655051231384, G_Loss:2.8102235794067383

iterator 4200, D_Loss:0.766932487487793, G_Loss:2.9792516231536865

iterator 4300, D_Loss:0.7640805244445801, G_Loss:2.9068992137908936

iterator 4400, D_Loss:0.7454100847244263, G_Loss:2.8712847232818604

iterator 4500, D_Loss:0.7980180978775024, G_Loss:3.0591325759887695

iterator 4600, D_Loss:0.7141537666320801, G_Loss:2.8956398963928223

iterator 4700, D_Loss:0.7329400181770325, G_Loss:2.761536121368408

iterator 4800, D_Loss:0.7167460322380066, G_Loss:3.0080924034118652

iterator 4900, D_Loss:0.7018334269523621, G_Loss:2.823155403137207

iterator 5000, D_Loss:0.7471468448638916, G_Loss:2.9322519302368164

-----------Epoch 9-----------
iterator 100, D_Loss:0.7239662408828735, G_Loss:2.9166178703308105

iterator 200, D_Loss:0.6964437365531921, G_Loss:2.97951340675354

iterator 300, D_Loss:0.7331448197364807, G_Loss:2.892357349395752

iterator 400, D_Loss:0.7158744931221008, G_Loss:3.0133349895477295

iterator 500, D_Loss:0.7577109932899475, G_Loss:2.9429502487182617

iterator 600, D_Loss:0.7340163588523865, G_Loss:2.961270332336426

iterator 700, D_Loss:0.7051994800567627, G_Loss:2.899946451187134

iterator 800, D_Loss:0.8030598163604736, G_Loss:2.7869620323181152

iterator 900, D_Loss:0.7884702086448669, G_Loss:2.8407511711120605

iterator 1000, D_Loss:0.7558095455169678, G_Loss:2.62131404876709

iterator 1100, D_Loss:0.7901285290718079, G_Loss:2.635286569595337

iterator 1200, D_Loss:0.7805530428886414, G_Loss:2.6608357429504395

iterator 1300, D_Loss:0.7791988849639893, G_Loss:3.188681125640869

iterator 1400, D_Loss:0.7711589336395264, G_Loss:2.911066770553589

iterator 1500, D_Loss:0.7641722559928894, G_Loss:3.0416903495788574

iterator 1600, D_Loss:0.7051671743392944, G_Loss:2.790534734725952

iterator 1700, D_Loss:0.7822991013526917, G_Loss:3.1295058727264404

iterator 1800, D_Loss:0.7814213037490845, G_Loss:3.099694013595581

iterator 1900, D_Loss:0.8215177059173584, G_Loss:2.8757381439208984

iterator 2000, D_Loss:0.7596427798271179, G_Loss:2.682363986968994

iterator 2100, D_Loss:0.7609604597091675, G_Loss:2.9013190269470215

iterator 2200, D_Loss:0.7311910390853882, G_Loss:2.888150215148926

iterator 2300, D_Loss:0.707329273223877, G_Loss:2.8827850818634033

iterator 2400, D_Loss:0.7547760009765625, G_Loss:2.9999372959136963

iterator 2500, D_Loss:0.7102516889572144, G_Loss:3.0276412963867188

iterator 2600, D_Loss:0.7781786918640137, G_Loss:3.008624315261841

iterator 2700, D_Loss:0.7159871459007263, G_Loss:2.9857277870178223

iterator 2800, D_Loss:0.7527749538421631, G_Loss:3.2073006629943848

iterator 2900, D_Loss:0.7511669993400574, G_Loss:3.1138389110565186

iterator 3000, D_Loss:0.7653034925460815, G_Loss:2.8093745708465576

iterator 3100, D_Loss:0.7800807952880859, G_Loss:3.0628437995910645

iterator 3200, D_Loss:0.7470484375953674, G_Loss:2.7917861938476562

iterator 3300, D_Loss:0.7231273651123047, G_Loss:2.767756462097168

iterator 3400, D_Loss:0.7438346147537231, G_Loss:2.8877389430999756

iterator 3500, D_Loss:0.7393161058425903, G_Loss:2.7088241577148438

iterator 3600, D_Loss:0.7191876173019409, G_Loss:2.8394672870635986

iterator 3700, D_Loss:0.7593860626220703, G_Loss:2.9139926433563232

iterator 3800, D_Loss:0.7161047458648682, G_Loss:3.080167293548584

iterator 3900, D_Loss:0.7698802947998047, G_Loss:2.963177442550659

iterator 4000, D_Loss:0.7476094961166382, G_Loss:2.8785839080810547

iterator 4100, D_Loss:0.7511512041091919, G_Loss:2.905428647994995

iterator 4200, D_Loss:0.7777814269065857, G_Loss:2.746133327484131

iterator 4300, D_Loss:0.7386610507965088, G_Loss:2.999070405960083

iterator 4400, D_Loss:0.7866076231002808, G_Loss:2.9142303466796875

iterator 4500, D_Loss:0.7662918567657471, G_Loss:2.77176570892334

iterator 4600, D_Loss:0.7779383659362793, G_Loss:2.8147189617156982

iterator 4700, D_Loss:0.7540707588195801, G_Loss:2.806279182434082

iterator 4800, D_Loss:0.7788919806480408, G_Loss:2.7905709743499756

iterator 4900, D_Loss:0.7584725022315979, G_Loss:2.936062812805176

iterator 5000, D_Loss:0.7907460331916809, G_Loss:2.8282434940338135

train row : 30148
sample row: 30148
VGAN_generator(
  (input): Linear(in_features=256, out_features=400, bias=True)
  (inputbn): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=400, out_features=400, bias=True)
  (bn0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=400, bias=True)
  (bn1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=400, out_features=135, bias=True)
  (outputbn): BatchNorm1d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=135, out_features=300, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=300, out_features=300, bias=True)
  (fc1): Linear(in_features=300, out_features=300, bias=True)
  (output): Linear(in_features=300, out_features=1, bias=True)
)
(0, False, 135)
-----------Epoch 0-----------
iterator 100, D_Loss:0.5028337240219116, G_Loss:9.525386810302734

iterator 200, D_Loss:0.48870664834976196, G_Loss:10.01361083984375

iterator 300, D_Loss:0.4872882068157196, G_Loss:10.665801048278809

iterator 400, D_Loss:0.4673478603363037, G_Loss:11.19657039642334

iterator 500, D_Loss:0.4662908911705017, G_Loss:11.551486015319824

iterator 600, D_Loss:0.45668724179267883, G_Loss:11.08149528503418

iterator 700, D_Loss:0.4540368616580963, G_Loss:10.758661270141602

iterator 800, D_Loss:0.4417038857936859, G_Loss:11.036006927490234

iterator 900, D_Loss:0.4536399245262146, G_Loss:10.873464584350586

iterator 1000, D_Loss:0.4559328258037567, G_Loss:10.32109546661377

iterator 1100, D_Loss:0.4540957808494568, G_Loss:10.54374885559082

iterator 1200, D_Loss:0.43519338965415955, G_Loss:10.824108123779297

iterator 1300, D_Loss:0.4387158751487732, G_Loss:10.286312103271484

iterator 1400, D_Loss:0.44544947147369385, G_Loss:10.896347999572754

iterator 1500, D_Loss:0.43076789379119873, G_Loss:11.000205993652344

iterator 1600, D_Loss:0.4458427429199219, G_Loss:10.62093448638916

iterator 1700, D_Loss:0.4574175477027893, G_Loss:10.287381172180176

iterator 1800, D_Loss:0.46341636776924133, G_Loss:10.372231483459473

iterator 1900, D_Loss:0.4377845525741577, G_Loss:10.731481552124023

iterator 2000, D_Loss:0.4254271686077118, G_Loss:10.902608871459961

iterator 2100, D_Loss:0.4281754195690155, G_Loss:10.921051979064941

iterator 2200, D_Loss:0.4486326575279236, G_Loss:10.920486450195312

iterator 2300, D_Loss:0.4648890793323517, G_Loss:10.245418548583984

iterator 2400, D_Loss:0.459510862827301, G_Loss:9.798896789550781

iterator 2500, D_Loss:0.45062875747680664, G_Loss:10.578500747680664

iterator 2600, D_Loss:0.4431120753288269, G_Loss:10.435531616210938

iterator 2700, D_Loss:0.4451005756855011, G_Loss:9.855026245117188

iterator 2800, D_Loss:0.4526059925556183, G_Loss:9.670686721801758

iterator 2900, D_Loss:0.42566975951194763, G_Loss:10.1105375289917

iterator 3000, D_Loss:0.4404974579811096, G_Loss:10.18198013305664

iterator 3100, D_Loss:0.4578607976436615, G_Loss:9.758283615112305

iterator 3200, D_Loss:0.44970881938934326, G_Loss:10.634237289428711

iterator 3300, D_Loss:0.47090762853622437, G_Loss:9.982192993164062

iterator 3400, D_Loss:0.44304540753364563, G_Loss:10.066226959228516

iterator 3500, D_Loss:0.46390393376350403, G_Loss:9.785375595092773

iterator 3600, D_Loss:0.4479579031467438, G_Loss:9.749466896057129

iterator 3700, D_Loss:0.45466265082359314, G_Loss:9.220071792602539

iterator 3800, D_Loss:0.47622907161712646, G_Loss:9.22209358215332

iterator 3900, D_Loss:0.4729856550693512, G_Loss:9.080892562866211

iterator 4000, D_Loss:0.460667222738266, G_Loss:9.439250946044922

iterator 4100, D_Loss:0.4697549343109131, G_Loss:9.096927642822266

iterator 4200, D_Loss:0.4448123574256897, G_Loss:9.16897964477539

iterator 4300, D_Loss:0.4822213351726532, G_Loss:8.765434265136719

iterator 4400, D_Loss:0.43556106090545654, G_Loss:8.644606590270996

iterator 4500, D_Loss:0.4559975564479828, G_Loss:9.196727752685547

iterator 4600, D_Loss:0.4818482995033264, G_Loss:9.199101448059082

iterator 4700, D_Loss:0.4565050005912781, G_Loss:8.127266883850098

iterator 4800, D_Loss:0.4629988968372345, G_Loss:9.049750328063965

iterator 4900, D_Loss:0.48137471079826355, G_Loss:8.696276664733887

iterator 5000, D_Loss:0.44069522619247437, G_Loss:8.58912467956543

-----------Epoch 1-----------
iterator 100, D_Loss:0.4822215437889099, G_Loss:8.147417068481445

iterator 200, D_Loss:0.47378161549568176, G_Loss:7.8057780265808105

iterator 300, D_Loss:0.4598495364189148, G_Loss:8.216630935668945

iterator 400, D_Loss:0.48760074377059937, G_Loss:8.187259674072266

iterator 500, D_Loss:0.4752022325992584, G_Loss:8.168601989746094

iterator 600, D_Loss:0.47835150361061096, G_Loss:8.005431175231934

iterator 700, D_Loss:0.4963253140449524, G_Loss:8.0592679977417

iterator 800, D_Loss:0.5336170792579651, G_Loss:8.34492015838623

iterator 900, D_Loss:0.5256849527359009, G_Loss:7.652616500854492

iterator 1000, D_Loss:0.5002714395523071, G_Loss:7.85899019241333

iterator 1100, D_Loss:0.5002858638763428, G_Loss:7.866218566894531

iterator 1200, D_Loss:0.46515190601348877, G_Loss:8.121267318725586

iterator 1300, D_Loss:0.5307624340057373, G_Loss:7.650189399719238

iterator 1400, D_Loss:0.4799533486366272, G_Loss:7.926261901855469

iterator 1500, D_Loss:0.4579676389694214, G_Loss:7.721165657043457

iterator 1600, D_Loss:0.516792893409729, G_Loss:8.103296279907227

iterator 1700, D_Loss:0.5206403136253357, G_Loss:7.3600382804870605

iterator 1800, D_Loss:0.500724196434021, G_Loss:7.71854305267334

iterator 1900, D_Loss:0.5046259760856628, G_Loss:7.9088287353515625

iterator 2000, D_Loss:0.48245102167129517, G_Loss:7.452052593231201

iterator 2100, D_Loss:0.471091628074646, G_Loss:8.123541831970215

iterator 2200, D_Loss:0.54597008228302, G_Loss:7.073087215423584

iterator 2300, D_Loss:0.5600627064704895, G_Loss:7.093639850616455

iterator 2400, D_Loss:0.5729151964187622, G_Loss:7.3988142013549805

iterator 2500, D_Loss:0.5417518019676208, G_Loss:6.448959827423096

iterator 2600, D_Loss:0.5620957612991333, G_Loss:6.600671768188477

iterator 2700, D_Loss:0.5536072254180908, G_Loss:6.4512176513671875

iterator 2800, D_Loss:0.5047635436058044, G_Loss:6.249641418457031

iterator 2900, D_Loss:0.5685860514640808, G_Loss:6.889189720153809

iterator 3000, D_Loss:0.5802789330482483, G_Loss:6.6470723152160645

iterator 3100, D_Loss:0.49827948212623596, G_Loss:7.434607982635498

iterator 3200, D_Loss:0.5701672434806824, G_Loss:6.623348236083984

iterator 3300, D_Loss:0.499137818813324, G_Loss:6.871603012084961

iterator 3400, D_Loss:0.5226084589958191, G_Loss:6.289249420166016

iterator 3500, D_Loss:0.5364119410514832, G_Loss:6.326093673706055

iterator 3600, D_Loss:0.5088362097740173, G_Loss:6.441442489624023

iterator 3700, D_Loss:0.5115804076194763, G_Loss:6.557462215423584

iterator 3800, D_Loss:0.578728437423706, G_Loss:6.545717239379883

iterator 3900, D_Loss:0.5352805852890015, G_Loss:5.8709869384765625

iterator 4000, D_Loss:0.6315622329711914, G_Loss:6.275408744812012

iterator 4100, D_Loss:0.5644245147705078, G_Loss:6.624222755432129

iterator 4200, D_Loss:0.5611792802810669, G_Loss:5.953785419464111

iterator 4300, D_Loss:0.5016332268714905, G_Loss:5.573052883148193

iterator 4400, D_Loss:0.5444968342781067, G_Loss:6.248940944671631

iterator 4500, D_Loss:0.5733530521392822, G_Loss:5.661927223205566

iterator 4600, D_Loss:0.5726991891860962, G_Loss:6.13720703125

iterator 4700, D_Loss:0.5703824758529663, G_Loss:5.667205810546875

iterator 4800, D_Loss:0.4960439205169678, G_Loss:5.839990615844727

iterator 4900, D_Loss:0.6201202869415283, G_Loss:6.035617828369141

iterator 5000, D_Loss:0.5549786686897278, G_Loss:5.776948928833008

-----------Epoch 2-----------
iterator 100, D_Loss:0.5349182486534119, G_Loss:6.123225688934326

iterator 200, D_Loss:0.5479850769042969, G_Loss:5.655516624450684

iterator 300, D_Loss:0.5412191152572632, G_Loss:5.290244102478027

iterator 400, D_Loss:0.5702261924743652, G_Loss:6.097201824188232

iterator 500, D_Loss:0.5158838033676147, G_Loss:5.7939982414245605

iterator 600, D_Loss:0.5706114172935486, G_Loss:5.598487377166748

iterator 700, D_Loss:0.5851297378540039, G_Loss:6.043253421783447

iterator 800, D_Loss:0.5456274151802063, G_Loss:5.591118812561035

iterator 900, D_Loss:0.5817325115203857, G_Loss:5.644935607910156

iterator 1000, D_Loss:0.5894454121589661, G_Loss:5.303992748260498

iterator 1100, D_Loss:0.5432804822921753, G_Loss:5.102372646331787

iterator 1200, D_Loss:0.5300184488296509, G_Loss:5.099998474121094

iterator 1300, D_Loss:0.5906246900558472, G_Loss:4.913290500640869

iterator 1400, D_Loss:0.5513655543327332, G_Loss:5.228327751159668

iterator 1500, D_Loss:0.5419156551361084, G_Loss:5.229522705078125

iterator 1600, D_Loss:0.5518053770065308, G_Loss:5.442150592803955

iterator 1700, D_Loss:0.6161757111549377, G_Loss:4.898021697998047

iterator 1800, D_Loss:0.6008707880973816, G_Loss:5.325156211853027

iterator 1900, D_Loss:0.616797924041748, G_Loss:5.109967231750488

iterator 2000, D_Loss:0.6138719320297241, G_Loss:5.008536338806152

iterator 2100, D_Loss:0.5891526937484741, G_Loss:4.9505438804626465

iterator 2200, D_Loss:0.6165792346000671, G_Loss:5.15003776550293

iterator 2300, D_Loss:0.6097220182418823, G_Loss:4.894663333892822

iterator 2400, D_Loss:0.5624574422836304, G_Loss:5.206833362579346

iterator 2500, D_Loss:0.6314833760261536, G_Loss:4.923647403717041

iterator 2600, D_Loss:0.5524364709854126, G_Loss:4.982275009155273

iterator 2700, D_Loss:0.603187084197998, G_Loss:4.789123058319092

iterator 2800, D_Loss:0.6358401775360107, G_Loss:4.9078264236450195

iterator 2900, D_Loss:0.5809271931648254, G_Loss:4.568647861480713

iterator 3000, D_Loss:0.6132196187973022, G_Loss:4.695793628692627

iterator 3100, D_Loss:0.5934175252914429, G_Loss:4.481960773468018

iterator 3200, D_Loss:0.659524142742157, G_Loss:4.812860488891602

iterator 3300, D_Loss:0.6016026139259338, G_Loss:4.460881233215332

iterator 3400, D_Loss:0.6031703352928162, G_Loss:4.718903064727783

iterator 3500, D_Loss:0.596878170967102, G_Loss:4.385980606079102

iterator 3600, D_Loss:0.595982015132904, G_Loss:4.290452003479004

iterator 3700, D_Loss:0.6378867626190186, G_Loss:4.373774528503418

iterator 3800, D_Loss:0.641024112701416, G_Loss:4.0986738204956055

iterator 3900, D_Loss:0.6521530747413635, G_Loss:4.680564880371094

iterator 4000, D_Loss:0.6424157023429871, G_Loss:4.494063854217529

iterator 4100, D_Loss:0.6328253746032715, G_Loss:4.793116569519043

iterator 4200, D_Loss:0.613463282585144, G_Loss:4.676620960235596

iterator 4300, D_Loss:0.6526378393173218, G_Loss:4.272721290588379

iterator 4400, D_Loss:0.6369968056678772, G_Loss:4.373847484588623

iterator 4500, D_Loss:0.6559920310974121, G_Loss:4.252395153045654

iterator 4600, D_Loss:0.6261916160583496, G_Loss:4.2718424797058105

iterator 4700, D_Loss:0.6721713542938232, G_Loss:3.8974719047546387

iterator 4800, D_Loss:0.6372920274734497, G_Loss:4.23081636428833

iterator 4900, D_Loss:0.6280114054679871, G_Loss:4.106766700744629

iterator 5000, D_Loss:0.6119989156723022, G_Loss:4.107156276702881

-----------Epoch 3-----------
iterator 100, D_Loss:0.6581640243530273, G_Loss:3.9923593997955322

iterator 200, D_Loss:0.6525291204452515, G_Loss:3.884768486022949

iterator 300, D_Loss:0.6894277334213257, G_Loss:3.801711082458496

iterator 400, D_Loss:0.67896968126297, G_Loss:4.168338298797607

iterator 500, D_Loss:0.6556793451309204, G_Loss:3.892638921737671

iterator 600, D_Loss:0.6411534547805786, G_Loss:3.9917104244232178

iterator 700, D_Loss:0.655874490737915, G_Loss:4.160940170288086

iterator 800, D_Loss:0.6620177030563354, G_Loss:3.8493828773498535

iterator 900, D_Loss:0.6470530033111572, G_Loss:3.7251105308532715

iterator 1000, D_Loss:0.668074369430542, G_Loss:3.8094232082366943

iterator 1100, D_Loss:0.6303759813308716, G_Loss:3.9881746768951416

iterator 1200, D_Loss:0.6337829232215881, G_Loss:4.122878074645996

iterator 1300, D_Loss:0.6703893542289734, G_Loss:3.936959981918335

iterator 1400, D_Loss:0.6536303758621216, G_Loss:3.9525279998779297

iterator 1500, D_Loss:0.6672891974449158, G_Loss:3.752586841583252

iterator 1600, D_Loss:0.7090449333190918, G_Loss:3.6767003536224365

iterator 1700, D_Loss:0.666937530040741, G_Loss:3.607323408126831

iterator 1800, D_Loss:0.6504595279693604, G_Loss:4.021509170532227

iterator 1900, D_Loss:0.7027132511138916, G_Loss:3.7730326652526855

iterator 2000, D_Loss:0.6659924983978271, G_Loss:3.8447909355163574

iterator 2100, D_Loss:0.7335590124130249, G_Loss:3.86085844039917

iterator 2200, D_Loss:0.7172205448150635, G_Loss:3.555819511413574

iterator 2300, D_Loss:0.7152560949325562, G_Loss:3.6020114421844482

iterator 2400, D_Loss:0.708562970161438, G_Loss:3.7404062747955322

iterator 2500, D_Loss:0.6685148477554321, G_Loss:3.9108688831329346

iterator 2600, D_Loss:0.7302536964416504, G_Loss:3.457010269165039

iterator 2700, D_Loss:0.6702354550361633, G_Loss:3.5871541500091553

iterator 2800, D_Loss:0.7330631017684937, G_Loss:3.211641311645508

iterator 2900, D_Loss:0.7337273359298706, G_Loss:3.4615793228149414

iterator 3000, D_Loss:0.7224810123443604, G_Loss:3.423471212387085

iterator 3100, D_Loss:0.7110671401023865, G_Loss:3.5858325958251953

iterator 3200, D_Loss:0.718680739402771, G_Loss:3.5725371837615967

iterator 3300, D_Loss:0.6633204221725464, G_Loss:3.548079252243042

iterator 3400, D_Loss:0.696740984916687, G_Loss:3.5700843334198

iterator 3500, D_Loss:0.7365729808807373, G_Loss:3.363845109939575

iterator 3600, D_Loss:0.7083700895309448, G_Loss:3.363952159881592

iterator 3700, D_Loss:0.7344189286231995, G_Loss:3.4990334510803223

iterator 3800, D_Loss:0.7077946066856384, G_Loss:3.356333017349243

iterator 3900, D_Loss:0.7157790660858154, G_Loss:3.3888285160064697

iterator 4000, D_Loss:0.7212347984313965, G_Loss:3.355822801589966

iterator 4100, D_Loss:0.6701180338859558, G_Loss:3.452357530593872

iterator 4200, D_Loss:0.7557514309883118, G_Loss:3.2801613807678223

iterator 4300, D_Loss:0.7839241027832031, G_Loss:3.3678953647613525

iterator 4400, D_Loss:0.659579336643219, G_Loss:3.3896262645721436

iterator 4500, D_Loss:0.7466529607772827, G_Loss:3.3166427612304688

iterator 4600, D_Loss:0.6950380802154541, G_Loss:3.291083812713623

iterator 4700, D_Loss:0.7758903503417969, G_Loss:3.269106864929199

iterator 4800, D_Loss:0.7666077613830566, G_Loss:3.344329357147217

iterator 4900, D_Loss:0.7221694588661194, G_Loss:3.4534401893615723

iterator 5000, D_Loss:0.7387006878852844, G_Loss:3.244464874267578

-----------Epoch 4-----------
iterator 100, D_Loss:0.7718729972839355, G_Loss:3.2140612602233887

iterator 200, D_Loss:0.7233920097351074, G_Loss:3.44234299659729

iterator 300, D_Loss:0.7389076352119446, G_Loss:3.3220977783203125

iterator 400, D_Loss:0.723445475101471, G_Loss:3.375796318054199

iterator 500, D_Loss:0.7034639120101929, G_Loss:3.131307601928711

iterator 600, D_Loss:0.7602586150169373, G_Loss:3.4244444370269775

iterator 700, D_Loss:0.7242931723594666, G_Loss:3.045821189880371

iterator 800, D_Loss:0.7525522708892822, G_Loss:3.139730453491211

iterator 900, D_Loss:0.7674164772033691, G_Loss:3.209468126296997

iterator 1000, D_Loss:0.7167425751686096, G_Loss:3.315944194793701

iterator 1100, D_Loss:0.7581981420516968, G_Loss:3.446721315383911

iterator 1200, D_Loss:0.7608872652053833, G_Loss:3.2171823978424072

iterator 1300, D_Loss:0.7025043368339539, G_Loss:3.4715428352355957

iterator 1400, D_Loss:0.7081160545349121, G_Loss:3.4443283081054688

iterator 1500, D_Loss:0.7213160395622253, G_Loss:3.2724826335906982

iterator 1600, D_Loss:0.7249972820281982, G_Loss:3.512176990509033

iterator 1700, D_Loss:0.7453042268753052, G_Loss:3.2323620319366455

iterator 1800, D_Loss:0.7139845490455627, G_Loss:3.2635838985443115

iterator 1900, D_Loss:0.7145619988441467, G_Loss:3.3639252185821533

iterator 2000, D_Loss:0.781247079372406, G_Loss:3.183349609375

iterator 2100, D_Loss:0.7236027717590332, G_Loss:3.1929256916046143

iterator 2200, D_Loss:0.7797741293907166, G_Loss:3.0637056827545166

iterator 2300, D_Loss:0.7076388597488403, G_Loss:3.1566948890686035

iterator 2400, D_Loss:0.7523031234741211, G_Loss:3.2754111289978027

iterator 2500, D_Loss:0.7464806437492371, G_Loss:3.139403820037842

iterator 2600, D_Loss:0.7364698648452759, G_Loss:3.32553768157959

iterator 2700, D_Loss:0.7183464169502258, G_Loss:3.2214906215667725

iterator 2800, D_Loss:0.7246355414390564, G_Loss:3.5695223808288574

iterator 2900, D_Loss:0.7104167342185974, G_Loss:3.3136754035949707

iterator 3000, D_Loss:0.7455360293388367, G_Loss:3.095120429992676

iterator 3100, D_Loss:0.7576932311058044, G_Loss:3.180051803588867

iterator 3200, D_Loss:0.7330358028411865, G_Loss:3.190438985824585

iterator 3300, D_Loss:0.7246699333190918, G_Loss:3.225018262863159

iterator 3400, D_Loss:0.7202833294868469, G_Loss:3.2155869007110596

iterator 3500, D_Loss:0.7804110050201416, G_Loss:3.259887456893921

iterator 3600, D_Loss:0.7390657663345337, G_Loss:3.324286937713623

iterator 3700, D_Loss:0.7331278324127197, G_Loss:3.2240803241729736

iterator 3800, D_Loss:0.7299851775169373, G_Loss:2.987050771713257

iterator 3900, D_Loss:0.7503272891044617, G_Loss:3.297577142715454

iterator 4000, D_Loss:0.7032322883605957, G_Loss:3.474281072616577

iterator 4100, D_Loss:0.7258023619651794, G_Loss:3.503005266189575

iterator 4200, D_Loss:0.7604221105575562, G_Loss:3.031717538833618

iterator 4300, D_Loss:0.7306690812110901, G_Loss:3.3917768001556396

iterator 4400, D_Loss:0.6858398914337158, G_Loss:3.229982852935791

iterator 4500, D_Loss:0.7470932006835938, G_Loss:3.285935163497925

iterator 4600, D_Loss:0.7295197248458862, G_Loss:3.098532199859619

iterator 4700, D_Loss:0.7232198715209961, G_Loss:3.3869941234588623

iterator 4800, D_Loss:0.7111624479293823, G_Loss:3.363328695297241

iterator 4900, D_Loss:0.7372777462005615, G_Loss:3.8210597038269043

iterator 5000, D_Loss:0.732449471950531, G_Loss:3.4070281982421875

-----------Epoch 5-----------
iterator 100, D_Loss:0.778876006603241, G_Loss:3.262896776199341

iterator 200, D_Loss:0.7138619422912598, G_Loss:3.25309419631958

iterator 300, D_Loss:0.734960675239563, G_Loss:3.196057081222534

iterator 400, D_Loss:0.7371587753295898, G_Loss:3.366676092147827

iterator 500, D_Loss:0.7369623184204102, G_Loss:3.2094566822052

iterator 600, D_Loss:0.7206617593765259, G_Loss:3.55346417427063

iterator 700, D_Loss:0.7214654088020325, G_Loss:3.4109764099121094

iterator 800, D_Loss:0.7082539200782776, G_Loss:3.470595359802246

iterator 900, D_Loss:0.7498277425765991, G_Loss:3.136629343032837

iterator 1000, D_Loss:0.7537335157394409, G_Loss:3.1699163913726807

iterator 1100, D_Loss:0.7163866758346558, G_Loss:3.2261722087860107

iterator 1200, D_Loss:0.7934862971305847, G_Loss:3.2672171592712402

iterator 1300, D_Loss:0.70756995677948, G_Loss:3.325709104537964

iterator 1400, D_Loss:0.7416075468063354, G_Loss:3.2549827098846436

iterator 1500, D_Loss:0.7544658184051514, G_Loss:3.4324874877929688

iterator 1600, D_Loss:0.7622870206832886, G_Loss:3.2065179347991943

iterator 1700, D_Loss:0.708725094795227, G_Loss:3.4195127487182617

iterator 1800, D_Loss:0.6972458958625793, G_Loss:3.2286934852600098

iterator 1900, D_Loss:0.755409836769104, G_Loss:3.192171335220337

iterator 2000, D_Loss:0.7721781730651855, G_Loss:3.3526222705841064

iterator 2100, D_Loss:0.7434437870979309, G_Loss:3.2367665767669678

iterator 2200, D_Loss:0.7462484836578369, G_Loss:3.24296498298645

iterator 2300, D_Loss:0.7320312261581421, G_Loss:3.249894857406616

iterator 2400, D_Loss:0.6894346475601196, G_Loss:3.2927095890045166

iterator 2500, D_Loss:0.7075803875923157, G_Loss:3.08878755569458

iterator 2600, D_Loss:0.7607995867729187, G_Loss:3.2338528633117676

iterator 2700, D_Loss:0.7336118817329407, G_Loss:3.0146169662475586

iterator 2800, D_Loss:0.665774941444397, G_Loss:3.5183932781219482

iterator 2900, D_Loss:0.725256621837616, G_Loss:3.313044309616089

iterator 3000, D_Loss:0.7418122291564941, G_Loss:3.7226881980895996

iterator 3100, D_Loss:0.764823317527771, G_Loss:3.3533191680908203

iterator 3200, D_Loss:0.6658384203910828, G_Loss:3.4250099658966064

iterator 3300, D_Loss:0.7376100420951843, G_Loss:3.2672715187072754

iterator 3400, D_Loss:0.7481107711791992, G_Loss:3.5130722522735596

iterator 3500, D_Loss:0.7444151639938354, G_Loss:2.9928736686706543

iterator 3600, D_Loss:0.6631854176521301, G_Loss:3.3386385440826416

iterator 3700, D_Loss:0.7424964308738708, G_Loss:3.0809473991394043

iterator 3800, D_Loss:0.7166725397109985, G_Loss:3.4857940673828125

iterator 3900, D_Loss:0.6990433931350708, G_Loss:3.206730604171753

iterator 4000, D_Loss:0.6893578767776489, G_Loss:3.172259569168091

iterator 4100, D_Loss:0.7334616184234619, G_Loss:3.4419665336608887

iterator 4200, D_Loss:0.7449126243591309, G_Loss:3.156351089477539

iterator 4300, D_Loss:0.7596163749694824, G_Loss:3.1962337493896484

iterator 4400, D_Loss:0.6697934865951538, G_Loss:3.475646734237671

iterator 4500, D_Loss:0.7467431426048279, G_Loss:3.509939432144165

iterator 4600, D_Loss:0.7333471179008484, G_Loss:3.16984486579895

iterator 4700, D_Loss:0.7137206196784973, G_Loss:3.5805552005767822

iterator 4800, D_Loss:0.7378113865852356, G_Loss:3.0925135612487793

iterator 4900, D_Loss:0.7575909495353699, G_Loss:3.3451528549194336

iterator 5000, D_Loss:0.7574477791786194, G_Loss:3.1248862743377686

-----------Epoch 6-----------
iterator 100, D_Loss:0.7656289935112, G_Loss:2.91668963432312

iterator 200, D_Loss:0.6988931894302368, G_Loss:3.307284355163574

iterator 300, D_Loss:0.777732253074646, G_Loss:3.131112575531006

iterator 400, D_Loss:0.6942869424819946, G_Loss:3.370527982711792

iterator 500, D_Loss:0.7049179673194885, G_Loss:3.4876277446746826

iterator 600, D_Loss:0.7454173564910889, G_Loss:3.5077524185180664

iterator 700, D_Loss:0.711530327796936, G_Loss:3.6089227199554443

iterator 800, D_Loss:0.7429061532020569, G_Loss:3.4479081630706787

iterator 900, D_Loss:0.7424391508102417, G_Loss:3.2109429836273193

iterator 1000, D_Loss:0.7656132578849792, G_Loss:2.9198853969573975

iterator 1100, D_Loss:0.72403883934021, G_Loss:3.4803683757781982

iterator 1200, D_Loss:0.7527012825012207, G_Loss:3.5799102783203125

iterator 1300, D_Loss:0.6883175373077393, G_Loss:3.2643165588378906

iterator 1400, D_Loss:0.7913073301315308, G_Loss:3.178941249847412

iterator 1500, D_Loss:0.7398124933242798, G_Loss:3.5858154296875

iterator 1600, D_Loss:0.7166990041732788, G_Loss:3.4375174045562744

iterator 1700, D_Loss:0.688528299331665, G_Loss:3.7212576866149902

iterator 1800, D_Loss:0.7366354465484619, G_Loss:3.390340805053711

iterator 1900, D_Loss:0.703788697719574, G_Loss:3.606177806854248

iterator 2000, D_Loss:0.704587996006012, G_Loss:3.407031774520874

iterator 2100, D_Loss:0.7202568054199219, G_Loss:3.2466983795166016

iterator 2200, D_Loss:0.734640896320343, G_Loss:3.5537731647491455

iterator 2300, D_Loss:0.6962572932243347, G_Loss:3.094104528427124

iterator 2400, D_Loss:0.707815408706665, G_Loss:3.3341784477233887

iterator 2500, D_Loss:0.7706725597381592, G_Loss:3.3743367195129395

iterator 2600, D_Loss:0.7331793308258057, G_Loss:3.215951919555664

iterator 2700, D_Loss:0.7306768894195557, G_Loss:3.3574154376983643

iterator 2800, D_Loss:0.7263038754463196, G_Loss:3.308239459991455

iterator 2900, D_Loss:0.765038013458252, G_Loss:3.216762065887451

iterator 3000, D_Loss:0.7160122394561768, G_Loss:3.2026150226593018

iterator 3100, D_Loss:0.7374345660209656, G_Loss:3.5513463020324707

iterator 3200, D_Loss:0.758240818977356, G_Loss:3.2364039421081543

iterator 3300, D_Loss:0.7180702090263367, G_Loss:3.518129587173462

iterator 3400, D_Loss:0.7243116497993469, G_Loss:3.3521125316619873

iterator 3500, D_Loss:0.6836978197097778, G_Loss:3.7512905597686768

iterator 3600, D_Loss:0.7101065516471863, G_Loss:3.475111484527588

iterator 3700, D_Loss:0.7626081705093384, G_Loss:3.409010887145996

iterator 3800, D_Loss:0.6802003383636475, G_Loss:3.7285068035125732

iterator 3900, D_Loss:0.700473427772522, G_Loss:3.4512388706207275

iterator 4000, D_Loss:0.7791695594787598, G_Loss:3.5203614234924316

iterator 4100, D_Loss:0.6726715564727783, G_Loss:3.2345333099365234

iterator 4200, D_Loss:0.7434511780738831, G_Loss:3.273695945739746

iterator 4300, D_Loss:0.7048283219337463, G_Loss:3.517536163330078

iterator 4400, D_Loss:0.7060617208480835, G_Loss:3.5176589488983154

iterator 4500, D_Loss:0.7142884135246277, G_Loss:3.2956979274749756

iterator 4600, D_Loss:0.7503108978271484, G_Loss:3.1274099349975586

iterator 4700, D_Loss:0.74856036901474, G_Loss:3.4098713397979736

iterator 4800, D_Loss:0.7551791071891785, G_Loss:3.2568843364715576

iterator 4900, D_Loss:0.7334160804748535, G_Loss:3.4106736183166504

iterator 5000, D_Loss:0.708870530128479, G_Loss:3.0581870079040527

-----------Epoch 7-----------
iterator 100, D_Loss:0.7799623012542725, G_Loss:3.381883382797241

iterator 200, D_Loss:0.7003343105316162, G_Loss:3.669430732727051

iterator 300, D_Loss:0.7060996890068054, G_Loss:3.4338648319244385

iterator 400, D_Loss:0.7574092149734497, G_Loss:3.2666611671447754

iterator 500, D_Loss:0.7340688109397888, G_Loss:3.495654582977295

iterator 600, D_Loss:0.6909416913986206, G_Loss:3.28532338142395

iterator 700, D_Loss:0.7128638029098511, G_Loss:3.5738048553466797

iterator 800, D_Loss:0.6998510360717773, G_Loss:3.3606653213500977

iterator 900, D_Loss:0.7201653718948364, G_Loss:3.368971109390259

iterator 1000, D_Loss:0.7848691940307617, G_Loss:3.0937952995300293

iterator 1100, D_Loss:0.7987247705459595, G_Loss:3.1855857372283936

iterator 1200, D_Loss:0.7217177748680115, G_Loss:3.324638605117798

iterator 1300, D_Loss:0.7215489149093628, G_Loss:3.4730212688446045

iterator 1400, D_Loss:0.7542710304260254, G_Loss:3.4845659732818604

iterator 1500, D_Loss:0.6859592199325562, G_Loss:3.505079746246338

iterator 1600, D_Loss:0.7617073059082031, G_Loss:3.4181301593780518

iterator 1700, D_Loss:0.7783056497573853, G_Loss:3.4094767570495605

iterator 1800, D_Loss:0.765651285648346, G_Loss:3.0679965019226074

iterator 1900, D_Loss:0.7145693302154541, G_Loss:3.451293706893921

iterator 2000, D_Loss:0.7381985187530518, G_Loss:3.492342233657837

iterator 2100, D_Loss:0.6561042070388794, G_Loss:3.5362932682037354

iterator 2200, D_Loss:0.7150190472602844, G_Loss:3.493116617202759

iterator 2300, D_Loss:0.7350865602493286, G_Loss:3.3192355632781982

iterator 2400, D_Loss:0.7420657277107239, G_Loss:3.2638916969299316

iterator 2500, D_Loss:0.665279746055603, G_Loss:3.871764898300171

iterator 2600, D_Loss:0.7009949684143066, G_Loss:3.5217463970184326

iterator 2700, D_Loss:0.6620992422103882, G_Loss:3.3942952156066895

iterator 2800, D_Loss:0.6750297546386719, G_Loss:3.455064535140991

iterator 2900, D_Loss:0.7811927199363708, G_Loss:3.2497148513793945

iterator 3000, D_Loss:0.7196370959281921, G_Loss:3.362473249435425

iterator 3100, D_Loss:0.7202693819999695, G_Loss:3.3197555541992188

iterator 3200, D_Loss:0.7172334790229797, G_Loss:3.4092953205108643

iterator 3300, D_Loss:0.7151200175285339, G_Loss:3.173152208328247

iterator 3400, D_Loss:0.7542856931686401, G_Loss:3.4475204944610596

iterator 3500, D_Loss:0.7397124171257019, G_Loss:3.410982608795166

iterator 3600, D_Loss:0.7216352820396423, G_Loss:3.1330206394195557

iterator 3700, D_Loss:0.7180985808372498, G_Loss:3.542980909347534

iterator 3800, D_Loss:0.7404792308807373, G_Loss:3.3770902156829834

iterator 3900, D_Loss:0.7281827926635742, G_Loss:3.428881883621216

iterator 4000, D_Loss:0.7464863061904907, G_Loss:3.5443170070648193

iterator 4100, D_Loss:0.7246833443641663, G_Loss:3.4225099086761475

iterator 4200, D_Loss:0.7331886291503906, G_Loss:3.0131008625030518

iterator 4300, D_Loss:0.7151888012886047, G_Loss:3.4695348739624023

iterator 4400, D_Loss:0.7908446788787842, G_Loss:3.1381170749664307

iterator 4500, D_Loss:0.7839322090148926, G_Loss:3.2426068782806396

iterator 4600, D_Loss:0.788398027420044, G_Loss:3.110501766204834

iterator 4700, D_Loss:0.7199017405509949, G_Loss:3.2757890224456787

iterator 4800, D_Loss:0.7491206526756287, G_Loss:3.4523561000823975

iterator 4900, D_Loss:0.7420570254325867, G_Loss:3.456526041030884

iterator 5000, D_Loss:0.7368998527526855, G_Loss:3.289461374282837

-----------Epoch 8-----------
iterator 100, D_Loss:0.7024040222167969, G_Loss:3.4400250911712646

iterator 200, D_Loss:0.7202668190002441, G_Loss:3.350754976272583

iterator 300, D_Loss:0.6924833059310913, G_Loss:3.4622626304626465

iterator 400, D_Loss:0.7580469846725464, G_Loss:3.4336931705474854

iterator 500, D_Loss:0.7512731552124023, G_Loss:3.2039284706115723

iterator 600, D_Loss:0.7567487955093384, G_Loss:3.5031323432922363

iterator 700, D_Loss:0.7613099813461304, G_Loss:3.2650861740112305

iterator 800, D_Loss:0.7277011871337891, G_Loss:3.3001208305358887

iterator 900, D_Loss:0.7463322877883911, G_Loss:3.2423343658447266

iterator 1000, D_Loss:0.7274854183197021, G_Loss:3.2981624603271484

iterator 1100, D_Loss:0.7393807172775269, G_Loss:3.304478168487549

iterator 1200, D_Loss:0.7598927021026611, G_Loss:3.627528667449951

iterator 1300, D_Loss:0.7581037878990173, G_Loss:3.6804845333099365

iterator 1400, D_Loss:0.7164807319641113, G_Loss:3.316277503967285

iterator 1500, D_Loss:0.7294540405273438, G_Loss:3.814077138900757

iterator 1600, D_Loss:0.7742466926574707, G_Loss:3.1342291831970215

iterator 1700, D_Loss:0.7430478930473328, G_Loss:3.306561231613159

iterator 1800, D_Loss:0.732668936252594, G_Loss:3.230785608291626

iterator 1900, D_Loss:0.7206099033355713, G_Loss:3.227846145629883

iterator 2000, D_Loss:0.7554147839546204, G_Loss:3.0517518520355225

iterator 2100, D_Loss:0.7154662013053894, G_Loss:3.520012378692627

iterator 2200, D_Loss:0.702090859413147, G_Loss:3.5482585430145264

iterator 2300, D_Loss:0.7177711725234985, G_Loss:3.1659231185913086

iterator 2400, D_Loss:0.73752361536026, G_Loss:3.371156930923462

iterator 2500, D_Loss:0.7575720548629761, G_Loss:3.4314374923706055

iterator 2600, D_Loss:0.7689216732978821, G_Loss:3.3147668838500977

iterator 2700, D_Loss:0.8150254487991333, G_Loss:3.0913350582122803

iterator 2800, D_Loss:0.6958107352256775, G_Loss:3.3100500106811523

iterator 2900, D_Loss:0.7754693031311035, G_Loss:3.189920425415039

iterator 3000, D_Loss:0.7215647101402283, G_Loss:3.217052459716797

iterator 3100, D_Loss:0.7813571691513062, G_Loss:3.5653862953186035

iterator 3200, D_Loss:0.7498230934143066, G_Loss:3.3060598373413086

iterator 3300, D_Loss:0.7526506781578064, G_Loss:3.221843957901001

iterator 3400, D_Loss:0.7592984437942505, G_Loss:3.2272770404815674

iterator 3500, D_Loss:0.7841746807098389, G_Loss:3.2335379123687744

iterator 3600, D_Loss:0.7173746228218079, G_Loss:3.420762777328491

iterator 3700, D_Loss:0.7195855379104614, G_Loss:3.350260019302368

iterator 3800, D_Loss:0.7723623514175415, G_Loss:3.3727524280548096

iterator 3900, D_Loss:0.7519567012786865, G_Loss:3.271134614944458

iterator 4000, D_Loss:0.771452784538269, G_Loss:3.4223849773406982

iterator 4100, D_Loss:0.7677925229072571, G_Loss:3.083817481994629

iterator 4200, D_Loss:0.7430163621902466, G_Loss:3.3840699195861816

iterator 4300, D_Loss:0.7752496600151062, G_Loss:3.0661094188690186

iterator 4400, D_Loss:0.7257362008094788, G_Loss:3.3053371906280518

iterator 4500, D_Loss:0.7894800305366516, G_Loss:3.359220027923584

iterator 4600, D_Loss:0.7697718143463135, G_Loss:3.0717036724090576

iterator 4700, D_Loss:0.7093984484672546, G_Loss:3.2765696048736572

iterator 4800, D_Loss:0.7360395193099976, G_Loss:3.253917694091797

iterator 4900, D_Loss:0.7414849400520325, G_Loss:3.401395082473755

iterator 5000, D_Loss:0.7386762499809265, G_Loss:3.454901933670044

-----------Epoch 9-----------
iterator 100, D_Loss:0.7785110473632812, G_Loss:3.16969895362854

iterator 200, D_Loss:0.7323081493377686, G_Loss:3.52677059173584

iterator 300, D_Loss:0.7475215196609497, G_Loss:3.2092478275299072

iterator 400, D_Loss:0.7414135932922363, G_Loss:3.2954399585723877

iterator 500, D_Loss:0.7775754928588867, G_Loss:3.279820442199707

iterator 600, D_Loss:0.7872332334518433, G_Loss:3.3041164875030518

iterator 700, D_Loss:0.7158202528953552, G_Loss:3.6487913131713867

iterator 800, D_Loss:0.7478275895118713, G_Loss:3.625760078430176

iterator 900, D_Loss:0.7731961607933044, G_Loss:3.5876657962799072

iterator 1000, D_Loss:0.7568785548210144, G_Loss:3.1303892135620117

iterator 1100, D_Loss:0.7377591133117676, G_Loss:3.07592511177063

iterator 1200, D_Loss:0.7267754673957825, G_Loss:3.447636604309082

iterator 1300, D_Loss:0.7871355414390564, G_Loss:3.174264907836914

iterator 1400, D_Loss:0.797451913356781, G_Loss:3.2962889671325684

iterator 1500, D_Loss:0.7502312660217285, G_Loss:3.33782696723938

iterator 1600, D_Loss:0.7718411684036255, G_Loss:3.333681583404541

iterator 1700, D_Loss:0.7368521690368652, G_Loss:3.35009765625

iterator 1800, D_Loss:0.7240350246429443, G_Loss:3.4041199684143066

iterator 1900, D_Loss:0.7590216994285583, G_Loss:3.7155539989471436

iterator 2000, D_Loss:0.7756803035736084, G_Loss:3.1802077293395996

iterator 2100, D_Loss:0.741019606590271, G_Loss:2.9467780590057373

iterator 2200, D_Loss:0.7890127301216125, G_Loss:2.9909937381744385

iterator 2300, D_Loss:0.7296517491340637, G_Loss:3.382568836212158

iterator 2400, D_Loss:0.7229608297348022, G_Loss:3.58734393119812

iterator 2500, D_Loss:0.7507734298706055, G_Loss:3.357191801071167

iterator 2600, D_Loss:0.7427006363868713, G_Loss:3.2646236419677734

iterator 2700, D_Loss:0.7751575112342834, G_Loss:3.512341260910034

iterator 2800, D_Loss:0.7714561820030212, G_Loss:3.4033024311065674

iterator 2900, D_Loss:0.7404981851577759, G_Loss:3.4431464672088623

iterator 3000, D_Loss:0.7773409485816956, G_Loss:3.5017545223236084

iterator 3100, D_Loss:0.7495291233062744, G_Loss:3.5771055221557617

iterator 3200, D_Loss:0.7428406476974487, G_Loss:3.428527593612671

iterator 3300, D_Loss:0.7450942993164062, G_Loss:3.383574962615967

iterator 3400, D_Loss:0.7208055853843689, G_Loss:3.5445199012756348

iterator 3500, D_Loss:0.7699312567710876, G_Loss:3.8039748668670654

iterator 3600, D_Loss:0.7797050476074219, G_Loss:3.2929201126098633

iterator 3700, D_Loss:0.805682897567749, G_Loss:3.1414685249328613

iterator 3800, D_Loss:0.7485389113426208, G_Loss:3.3643243312835693

iterator 3900, D_Loss:0.7579325437545776, G_Loss:2.9282920360565186

iterator 4000, D_Loss:0.7666934728622437, G_Loss:3.7261855602264404

iterator 4100, D_Loss:0.746115505695343, G_Loss:3.035396099090576

iterator 4200, D_Loss:0.806972861289978, G_Loss:2.9911789894104004

iterator 4300, D_Loss:0.7678529024124146, G_Loss:3.3033509254455566

iterator 4400, D_Loss:0.7309375405311584, G_Loss:3.067880392074585

iterator 4500, D_Loss:0.7295670509338379, G_Loss:3.548633575439453

iterator 4600, D_Loss:0.7220957279205322, G_Loss:3.3801772594451904

iterator 4700, D_Loss:0.7287725210189819, G_Loss:3.223895788192749

iterator 4800, D_Loss:0.7623618841171265, G_Loss:3.3222830295562744

iterator 4900, D_Loss:0.7679516077041626, G_Loss:3.202086925506592

iterator 5000, D_Loss:0.8067704439163208, G_Loss:3.2534027099609375

VGAN_generator(
  (input): Linear(in_features=256, out_features=200, bias=True)
  (inputbn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (bn0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=200, out_features=200, bias=True)
  (bn1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=200, out_features=135, bias=True)
  (outputbn): BatchNorm1d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=135, out_features=100, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (fc1): Linear(in_features=100, out_features=100, bias=True)
  (fc2): Linear(in_features=100, out_features=100, bias=True)
  (output): Linear(in_features=100, out_features=1, bias=True)
)
(0, False, 135)
-----------Epoch 0-----------
iterator 100, D_Loss:0.5470073223114014, G_Loss:8.441478729248047

iterator 200, D_Loss:0.5131534337997437, G_Loss:9.81100845336914

iterator 300, D_Loss:0.49398207664489746, G_Loss:9.846076965332031

iterator 400, D_Loss:0.5022975206375122, G_Loss:9.264074325561523

iterator 500, D_Loss:0.48980891704559326, G_Loss:8.054426193237305

iterator 600, D_Loss:0.533318281173706, G_Loss:7.834259986877441

iterator 700, D_Loss:0.5542922019958496, G_Loss:6.347269058227539

iterator 800, D_Loss:0.5078453421592712, G_Loss:7.727381706237793

iterator 900, D_Loss:0.48890089988708496, G_Loss:6.725681304931641

iterator 1000, D_Loss:0.4977649748325348, G_Loss:6.980381965637207

iterator 1100, D_Loss:0.5504753589630127, G_Loss:5.695240020751953

iterator 1200, D_Loss:0.5024954080581665, G_Loss:6.400406360626221

iterator 1300, D_Loss:0.5869714021682739, G_Loss:5.742743492126465

iterator 1400, D_Loss:0.5467982292175293, G_Loss:5.859907627105713

iterator 1500, D_Loss:0.6059912443161011, G_Loss:5.230116844177246

iterator 1600, D_Loss:0.6049336194992065, G_Loss:4.907883167266846

iterator 1700, D_Loss:0.6590755581855774, G_Loss:4.784756183624268

iterator 1800, D_Loss:0.6841027736663818, G_Loss:4.181967735290527

iterator 1900, D_Loss:0.6818166971206665, G_Loss:4.2136030197143555

iterator 2000, D_Loss:0.6394515037536621, G_Loss:4.548837184906006

iterator 2100, D_Loss:0.6355627775192261, G_Loss:4.356594085693359

iterator 2200, D_Loss:0.7001855969429016, G_Loss:3.9210500717163086

iterator 2300, D_Loss:0.7338151931762695, G_Loss:3.27836537361145

iterator 2400, D_Loss:0.7228807210922241, G_Loss:3.529505729675293

iterator 2500, D_Loss:0.7189568281173706, G_Loss:3.7604126930236816

iterator 2600, D_Loss:0.741663932800293, G_Loss:3.47758150100708

iterator 2700, D_Loss:0.7712794542312622, G_Loss:3.1069812774658203

iterator 2800, D_Loss:0.8017572164535522, G_Loss:2.78432297706604

iterator 2900, D_Loss:0.8072298765182495, G_Loss:2.908547878265381

iterator 3000, D_Loss:0.7940840125083923, G_Loss:3.28281831741333

iterator 3100, D_Loss:0.8019713163375854, G_Loss:2.9397470951080322

iterator 3200, D_Loss:0.7871602773666382, G_Loss:3.0155515670776367

iterator 3300, D_Loss:0.8007097840309143, G_Loss:2.674243688583374

iterator 3400, D_Loss:0.8037509918212891, G_Loss:2.772665500640869

iterator 3500, D_Loss:0.7766720652580261, G_Loss:2.735673189163208

iterator 3600, D_Loss:0.8119050860404968, G_Loss:2.756263256072998

iterator 3700, D_Loss:0.8406892418861389, G_Loss:2.540052652359009

iterator 3800, D_Loss:0.9274700880050659, G_Loss:2.487217664718628

iterator 3900, D_Loss:0.7786963582038879, G_Loss:2.701866388320923

iterator 4000, D_Loss:0.8548991680145264, G_Loss:2.4397964477539062

iterator 4100, D_Loss:0.8426799178123474, G_Loss:2.2324564456939697

iterator 4200, D_Loss:0.9235837459564209, G_Loss:2.4232168197631836

iterator 4300, D_Loss:0.8550131320953369, G_Loss:2.3974437713623047

iterator 4400, D_Loss:0.8708204030990601, G_Loss:2.3285269737243652

iterator 4500, D_Loss:0.9095332026481628, G_Loss:2.5104262828826904

iterator 4600, D_Loss:0.8892514705657959, G_Loss:2.3237252235412598

iterator 4700, D_Loss:0.9288944005966187, G_Loss:2.2565202713012695

iterator 4800, D_Loss:0.8741793632507324, G_Loss:2.1480767726898193

iterator 4900, D_Loss:0.9402661323547363, G_Loss:1.9184588193893433

iterator 5000, D_Loss:0.9473466873168945, G_Loss:1.9371862411499023

-----------Epoch 1-----------
iterator 100, D_Loss:0.9195303916931152, G_Loss:2.195937395095825

iterator 200, D_Loss:0.9238119125366211, G_Loss:2.1924691200256348

iterator 300, D_Loss:0.9873842000961304, G_Loss:1.8932695388793945

iterator 400, D_Loss:1.0155601501464844, G_Loss:1.8900511264801025

iterator 500, D_Loss:0.9713743925094604, G_Loss:1.835153341293335

iterator 600, D_Loss:0.9791263937950134, G_Loss:1.8872053623199463

iterator 700, D_Loss:1.0344464778900146, G_Loss:1.7819443941116333

iterator 800, D_Loss:1.019843578338623, G_Loss:1.9381084442138672

iterator 900, D_Loss:1.0501983165740967, G_Loss:1.7690412998199463

iterator 1000, D_Loss:1.0467886924743652, G_Loss:1.707421898841858

iterator 1100, D_Loss:0.9813182353973389, G_Loss:1.7756417989730835

iterator 1200, D_Loss:0.9967744946479797, G_Loss:1.6974295377731323

iterator 1300, D_Loss:1.010266661643982, G_Loss:1.915220022201538

iterator 1400, D_Loss:1.0493531227111816, G_Loss:1.7176260948181152

iterator 1500, D_Loss:1.0540671348571777, G_Loss:1.6461621522903442

iterator 1600, D_Loss:1.0708684921264648, G_Loss:1.596947431564331

iterator 1700, D_Loss:1.1051692962646484, G_Loss:1.4957188367843628

iterator 1800, D_Loss:1.0531553030014038, G_Loss:1.6749666929244995

iterator 1900, D_Loss:1.003517746925354, G_Loss:1.7142261266708374

iterator 2000, D_Loss:1.0418126583099365, G_Loss:1.7207282781600952

iterator 2100, D_Loss:1.1011393070220947, G_Loss:1.4909286499023438

iterator 2200, D_Loss:1.0646307468414307, G_Loss:1.652570128440857

iterator 2300, D_Loss:1.1557632684707642, G_Loss:1.4396878480911255

iterator 2400, D_Loss:1.0953930616378784, G_Loss:1.4453500509262085

iterator 2500, D_Loss:1.123779058456421, G_Loss:1.5095772743225098

iterator 2600, D_Loss:1.0981101989746094, G_Loss:1.4832651615142822

iterator 2700, D_Loss:1.0952420234680176, G_Loss:1.4003292322158813

iterator 2800, D_Loss:1.079244613647461, G_Loss:1.7018369436264038

iterator 2900, D_Loss:1.12261164188385, G_Loss:1.5370293855667114

iterator 3000, D_Loss:1.1219022274017334, G_Loss:1.595440149307251

iterator 3100, D_Loss:1.1274338960647583, G_Loss:1.4321961402893066

iterator 3200, D_Loss:1.1342650651931763, G_Loss:1.3771533966064453

iterator 3300, D_Loss:1.1018368005752563, G_Loss:1.5178929567337036

iterator 3400, D_Loss:1.1523747444152832, G_Loss:1.3676791191101074

iterator 3500, D_Loss:1.0836089849472046, G_Loss:1.506532073020935

iterator 3600, D_Loss:1.1469974517822266, G_Loss:1.439020037651062

iterator 3700, D_Loss:1.1211066246032715, G_Loss:1.3066377639770508

iterator 3800, D_Loss:1.1217771768569946, G_Loss:1.4130595922470093

iterator 3900, D_Loss:1.100648283958435, G_Loss:1.4039450883865356

iterator 4000, D_Loss:1.1659867763519287, G_Loss:1.4339983463287354

iterator 4100, D_Loss:1.112972617149353, G_Loss:1.3027195930480957

iterator 4200, D_Loss:1.1556873321533203, G_Loss:1.3034058809280396

iterator 4300, D_Loss:1.159449815750122, G_Loss:1.3400615453720093

iterator 4400, D_Loss:1.1408700942993164, G_Loss:1.3728952407836914

iterator 4500, D_Loss:1.1386163234710693, G_Loss:1.352512240409851

iterator 4600, D_Loss:1.0880295038223267, G_Loss:1.5430313348770142

iterator 4700, D_Loss:1.135063648223877, G_Loss:1.4815312623977661

iterator 4800, D_Loss:1.1934337615966797, G_Loss:1.401300311088562

iterator 4900, D_Loss:1.1316664218902588, G_Loss:1.5285511016845703

iterator 5000, D_Loss:1.1856297254562378, G_Loss:1.277954339981079

-----------Epoch 2-----------
iterator 100, D_Loss:1.1283353567123413, G_Loss:1.3854687213897705

iterator 200, D_Loss:1.1392455101013184, G_Loss:1.4831701517105103

iterator 300, D_Loss:1.1362814903259277, G_Loss:1.409942626953125

iterator 400, D_Loss:1.154191493988037, G_Loss:1.5032259225845337

iterator 500, D_Loss:1.1411082744598389, G_Loss:1.4264847040176392

iterator 600, D_Loss:1.1378382444381714, G_Loss:1.5820454359054565

iterator 700, D_Loss:1.153205394744873, G_Loss:1.4271560907363892

iterator 800, D_Loss:1.1387437582015991, G_Loss:1.3289605379104614

iterator 900, D_Loss:1.1553550958633423, G_Loss:1.356353521347046

iterator 1000, D_Loss:1.1383392810821533, G_Loss:1.4348093271255493

iterator 1100, D_Loss:1.129831075668335, G_Loss:1.482648253440857

iterator 1200, D_Loss:1.142073392868042, G_Loss:1.3175137042999268

iterator 1300, D_Loss:1.1475238800048828, G_Loss:1.2800331115722656

iterator 1400, D_Loss:1.1217039823532104, G_Loss:1.5329463481903076

iterator 1500, D_Loss:1.123558759689331, G_Loss:1.2850133180618286

iterator 1600, D_Loss:1.1690950393676758, G_Loss:1.2906043529510498

iterator 1700, D_Loss:1.1707358360290527, G_Loss:1.271405816078186

iterator 1800, D_Loss:1.1447471380233765, G_Loss:1.3601714372634888

iterator 1900, D_Loss:1.1238083839416504, G_Loss:1.5941716432571411

iterator 2000, D_Loss:1.1216371059417725, G_Loss:1.4396766424179077

iterator 2100, D_Loss:1.1358461380004883, G_Loss:1.2827857732772827

iterator 2200, D_Loss:1.1200252771377563, G_Loss:1.446765422821045

iterator 2300, D_Loss:1.1837434768676758, G_Loss:1.3554126024246216

iterator 2400, D_Loss:1.1837581396102905, G_Loss:1.268101453781128

iterator 2500, D_Loss:1.1589561700820923, G_Loss:1.3613749742507935

iterator 2600, D_Loss:1.1359050273895264, G_Loss:1.2512099742889404

iterator 2700, D_Loss:1.120870590209961, G_Loss:1.3886041641235352

iterator 2800, D_Loss:1.1460020542144775, G_Loss:1.2574883699417114

iterator 2900, D_Loss:1.1169989109039307, G_Loss:1.5103141069412231

iterator 3000, D_Loss:1.1313550472259521, G_Loss:1.427876591682434

iterator 3100, D_Loss:1.0834782123565674, G_Loss:1.5295594930648804

iterator 3200, D_Loss:1.11111581325531, G_Loss:1.4909895658493042

iterator 3300, D_Loss:1.1106641292572021, G_Loss:1.4625648260116577

iterator 3400, D_Loss:1.1031111478805542, G_Loss:1.5220216512680054

iterator 3500, D_Loss:1.1482332944869995, G_Loss:1.371239185333252

iterator 3600, D_Loss:1.116988182067871, G_Loss:1.4318840503692627

iterator 3700, D_Loss:1.1567752361297607, G_Loss:1.3379602432250977

iterator 3800, D_Loss:1.1500356197357178, G_Loss:1.3844436407089233

iterator 3900, D_Loss:1.1467876434326172, G_Loss:1.3160830736160278

iterator 4000, D_Loss:1.1410646438598633, G_Loss:1.3787137269973755

iterator 4100, D_Loss:1.1000635623931885, G_Loss:1.553707480430603

iterator 4200, D_Loss:1.1391898393630981, G_Loss:1.232536792755127

iterator 4300, D_Loss:1.097731590270996, G_Loss:1.5741382837295532

iterator 4400, D_Loss:1.137428879737854, G_Loss:1.4118915796279907

iterator 4500, D_Loss:1.1663151979446411, G_Loss:1.4424726963043213

iterator 4600, D_Loss:1.1333539485931396, G_Loss:1.452377438545227

iterator 4700, D_Loss:1.14255952835083, G_Loss:1.3655225038528442

iterator 4800, D_Loss:1.1160147190093994, G_Loss:1.4248065948486328

iterator 4900, D_Loss:1.1312135457992554, G_Loss:1.5058417320251465

iterator 5000, D_Loss:1.1199886798858643, G_Loss:1.4045372009277344

-----------Epoch 3-----------
iterator 100, D_Loss:1.1067763566970825, G_Loss:1.3820639848709106

iterator 200, D_Loss:1.1609662771224976, G_Loss:1.2461365461349487

iterator 300, D_Loss:1.1790359020233154, G_Loss:1.4891626834869385

iterator 400, D_Loss:1.1388434171676636, G_Loss:1.405833125114441

iterator 500, D_Loss:1.1037476062774658, G_Loss:1.5202511548995972

iterator 600, D_Loss:1.1507129669189453, G_Loss:1.2954720258712769

iterator 700, D_Loss:1.1740516424179077, G_Loss:1.330367088317871

iterator 800, D_Loss:1.152505874633789, G_Loss:1.5193215608596802

iterator 900, D_Loss:1.141160249710083, G_Loss:1.4315210580825806

iterator 1000, D_Loss:1.1126561164855957, G_Loss:1.5099002122879028

iterator 1100, D_Loss:1.0811083316802979, G_Loss:1.3834210634231567

iterator 1200, D_Loss:1.1566648483276367, G_Loss:1.2553881406784058

iterator 1300, D_Loss:1.116235613822937, G_Loss:1.5189361572265625

iterator 1400, D_Loss:1.1179765462875366, G_Loss:1.4722824096679688

iterator 1500, D_Loss:1.0873613357543945, G_Loss:1.4116077423095703

iterator 1600, D_Loss:1.142552137374878, G_Loss:1.391736388206482

iterator 1700, D_Loss:1.0975394248962402, G_Loss:1.3867861032485962

iterator 1800, D_Loss:1.170628309249878, G_Loss:1.3393440246582031

iterator 1900, D_Loss:1.1402208805084229, G_Loss:1.5141500234603882

iterator 2000, D_Loss:1.1376744508743286, G_Loss:1.4558184146881104

iterator 2100, D_Loss:1.1148251295089722, G_Loss:1.4355883598327637

iterator 2200, D_Loss:1.0660005807876587, G_Loss:1.6214956045150757

iterator 2300, D_Loss:1.090893030166626, G_Loss:1.428296446800232

iterator 2400, D_Loss:1.1055265665054321, G_Loss:1.6216963529586792

iterator 2500, D_Loss:1.0804523229599, G_Loss:1.5291441679000854

iterator 2600, D_Loss:1.1198785305023193, G_Loss:1.5261050462722778

iterator 2700, D_Loss:1.1124416589736938, G_Loss:1.3677951097488403

iterator 2800, D_Loss:1.1165125370025635, G_Loss:1.4513696432113647

iterator 2900, D_Loss:1.092739224433899, G_Loss:1.4827139377593994

iterator 3000, D_Loss:1.097400426864624, G_Loss:1.620671033859253

iterator 3100, D_Loss:1.096378207206726, G_Loss:1.5325406789779663

iterator 3200, D_Loss:1.1109617948532104, G_Loss:1.4927905797958374

iterator 3300, D_Loss:1.105127215385437, G_Loss:1.3675870895385742

iterator 3400, D_Loss:1.086094856262207, G_Loss:1.4404070377349854

iterator 3500, D_Loss:1.091139793395996, G_Loss:1.5899771451950073

iterator 3600, D_Loss:1.0868362188339233, G_Loss:1.5405961275100708

iterator 3700, D_Loss:1.1157286167144775, G_Loss:1.5640283823013306

iterator 3800, D_Loss:1.116025447845459, G_Loss:1.4776744842529297

iterator 3900, D_Loss:1.122231125831604, G_Loss:1.36375892162323

iterator 4000, D_Loss:1.0773411989212036, G_Loss:1.57016122341156

iterator 4100, D_Loss:1.0673911571502686, G_Loss:1.6363253593444824

iterator 4200, D_Loss:1.0718380212783813, G_Loss:1.5427721738815308

iterator 4300, D_Loss:1.1239614486694336, G_Loss:1.5745630264282227

iterator 4400, D_Loss:1.1247646808624268, G_Loss:1.4457815885543823

iterator 4500, D_Loss:1.1033719778060913, G_Loss:1.4559475183486938

iterator 4600, D_Loss:1.112915277481079, G_Loss:1.4353053569793701

iterator 4700, D_Loss:1.074498176574707, G_Loss:1.5339497327804565

iterator 4800, D_Loss:1.0569472312927246, G_Loss:2.022304058074951

iterator 4900, D_Loss:1.11649489402771, G_Loss:1.6292338371276855

iterator 5000, D_Loss:1.0704894065856934, G_Loss:2.0336380004882812

-----------Epoch 4-----------
iterator 100, D_Loss:1.0658836364746094, G_Loss:1.6126735210418701

iterator 200, D_Loss:1.140403151512146, G_Loss:1.3645719289779663

iterator 300, D_Loss:1.116047978401184, G_Loss:1.4029541015625

iterator 400, D_Loss:1.1389901638031006, G_Loss:1.6094313859939575

iterator 500, D_Loss:1.0889856815338135, G_Loss:1.416843056678772

iterator 600, D_Loss:1.0756243467330933, G_Loss:1.5073494911193848

iterator 700, D_Loss:1.0630227327346802, G_Loss:1.5765819549560547

iterator 800, D_Loss:1.0077317953109741, G_Loss:1.7040001153945923

iterator 900, D_Loss:1.1343005895614624, G_Loss:1.5264074802398682

iterator 1000, D_Loss:1.0930891036987305, G_Loss:1.3626282215118408

iterator 1100, D_Loss:1.1137163639068604, G_Loss:1.5081652402877808

iterator 1200, D_Loss:1.1360760927200317, G_Loss:1.3528332710266113

iterator 1300, D_Loss:1.12931489944458, G_Loss:1.5099308490753174

iterator 1400, D_Loss:1.133832335472107, G_Loss:1.3620437383651733

iterator 1500, D_Loss:1.0902986526489258, G_Loss:1.423604130744934

iterator 1600, D_Loss:1.0919291973114014, G_Loss:1.5298813581466675

iterator 1700, D_Loss:1.1146519184112549, G_Loss:1.4138844013214111

iterator 1800, D_Loss:1.1036601066589355, G_Loss:1.5866323709487915

iterator 1900, D_Loss:1.1367871761322021, G_Loss:1.4694223403930664

iterator 2000, D_Loss:1.0500471591949463, G_Loss:1.8158557415008545

iterator 2100, D_Loss:1.1512473821640015, G_Loss:1.6518892049789429

iterator 2200, D_Loss:1.1112408638000488, G_Loss:1.5303244590759277

iterator 2300, D_Loss:1.0811580419540405, G_Loss:1.7281242609024048

iterator 2400, D_Loss:1.0989453792572021, G_Loss:1.4296246767044067

iterator 2500, D_Loss:1.0831117630004883, G_Loss:1.4902088642120361

iterator 2600, D_Loss:1.1101927757263184, G_Loss:1.4969639778137207

iterator 2700, D_Loss:1.0828216075897217, G_Loss:1.5495827198028564

iterator 2800, D_Loss:1.1549248695373535, G_Loss:1.2077374458312988

iterator 2900, D_Loss:1.0906046628952026, G_Loss:1.524843454360962

iterator 3000, D_Loss:1.1196759939193726, G_Loss:1.54082453250885

iterator 3100, D_Loss:1.1250797510147095, G_Loss:1.4574164152145386

iterator 3200, D_Loss:1.0676463842391968, G_Loss:1.669466257095337

iterator 3300, D_Loss:1.0936973094940186, G_Loss:1.5448956489562988

iterator 3400, D_Loss:1.0734026432037354, G_Loss:1.3859609365463257

iterator 3500, D_Loss:1.1138641834259033, G_Loss:1.6013232469558716

iterator 3600, D_Loss:1.133399248123169, G_Loss:1.448991298675537

iterator 3700, D_Loss:1.0991789102554321, G_Loss:1.4423457384109497

iterator 3800, D_Loss:1.131218671798706, G_Loss:1.4631977081298828

iterator 3900, D_Loss:1.1333568096160889, G_Loss:1.393908143043518

iterator 4000, D_Loss:1.141615390777588, G_Loss:1.4827184677124023

iterator 4100, D_Loss:1.045337438583374, G_Loss:1.6676712036132812

iterator 4200, D_Loss:1.0995806455612183, G_Loss:1.6185476779937744

iterator 4300, D_Loss:1.1435115337371826, G_Loss:1.3774440288543701

iterator 4400, D_Loss:1.0962375402450562, G_Loss:1.6660091876983643

iterator 4500, D_Loss:1.1017110347747803, G_Loss:1.506901502609253

iterator 4600, D_Loss:1.1117042303085327, G_Loss:1.5135729312896729

iterator 4700, D_Loss:1.109751582145691, G_Loss:1.5600626468658447

iterator 4800, D_Loss:1.1582555770874023, G_Loss:1.7059179544448853

iterator 4900, D_Loss:1.101386308670044, G_Loss:1.519260048866272

iterator 5000, D_Loss:1.1618711948394775, G_Loss:1.407273292541504

-----------Epoch 5-----------
iterator 100, D_Loss:1.0541932582855225, G_Loss:1.6071193218231201

iterator 200, D_Loss:1.1313132047653198, G_Loss:1.572231411933899

iterator 300, D_Loss:1.0949620008468628, G_Loss:1.4229986667633057

iterator 400, D_Loss:1.057908058166504, G_Loss:1.6320282220840454

iterator 500, D_Loss:1.1508526802062988, G_Loss:1.3568248748779297

iterator 600, D_Loss:1.0452009439468384, G_Loss:2.0340986251831055

iterator 700, D_Loss:1.0823373794555664, G_Loss:1.6229794025421143

iterator 800, D_Loss:1.0910136699676514, G_Loss:1.473534107208252

iterator 900, D_Loss:1.117732048034668, G_Loss:1.459140419960022

iterator 1000, D_Loss:1.1281547546386719, G_Loss:1.4111697673797607

iterator 1100, D_Loss:1.1483852863311768, G_Loss:1.4350099563598633

iterator 1200, D_Loss:1.1223547458648682, G_Loss:1.4289915561676025

iterator 1300, D_Loss:1.1225669384002686, G_Loss:1.4812400341033936

iterator 1400, D_Loss:1.1076698303222656, G_Loss:1.4895740747451782

iterator 1500, D_Loss:1.098581075668335, G_Loss:1.7066516876220703

iterator 1600, D_Loss:1.0856733322143555, G_Loss:1.4794671535491943

iterator 1700, D_Loss:1.1247674226760864, G_Loss:1.262981653213501

iterator 1800, D_Loss:1.1199674606323242, G_Loss:1.4591310024261475

iterator 1900, D_Loss:1.1735568046569824, G_Loss:1.4002909660339355

iterator 2000, D_Loss:1.1406538486480713, G_Loss:1.3334300518035889

iterator 2100, D_Loss:1.1658759117126465, G_Loss:1.3060907125473022

iterator 2200, D_Loss:1.1213939189910889, G_Loss:1.4801244735717773

iterator 2300, D_Loss:1.1272772550582886, G_Loss:1.4834707975387573

iterator 2400, D_Loss:1.1641089916229248, G_Loss:1.2901743650436401

iterator 2500, D_Loss:1.1293891668319702, G_Loss:1.5408124923706055

iterator 2600, D_Loss:1.1281341314315796, G_Loss:1.5740697383880615

iterator 2700, D_Loss:1.1162965297698975, G_Loss:1.4915658235549927

iterator 2800, D_Loss:1.0852421522140503, G_Loss:1.457883596420288

iterator 2900, D_Loss:1.1088210344314575, G_Loss:1.4049779176712036

iterator 3000, D_Loss:1.0956186056137085, G_Loss:1.5077154636383057

iterator 3100, D_Loss:1.125807285308838, G_Loss:1.5204191207885742

iterator 3200, D_Loss:1.1795653104782104, G_Loss:1.3897182941436768

iterator 3300, D_Loss:1.1073060035705566, G_Loss:1.4497519731521606

iterator 3400, D_Loss:1.168394684791565, G_Loss:1.382031798362732

iterator 3500, D_Loss:1.1632304191589355, G_Loss:1.404163122177124

iterator 3600, D_Loss:1.1497974395751953, G_Loss:1.405473232269287

iterator 3700, D_Loss:1.1385958194732666, G_Loss:1.5140092372894287

iterator 3800, D_Loss:1.1175860166549683, G_Loss:1.3467469215393066

iterator 3900, D_Loss:1.1164114475250244, G_Loss:1.3512558937072754

iterator 4000, D_Loss:1.1295382976531982, G_Loss:1.414988398551941

iterator 4100, D_Loss:1.1275330781936646, G_Loss:1.6128199100494385

iterator 4200, D_Loss:1.1040754318237305, G_Loss:1.4104831218719482

iterator 4300, D_Loss:1.1066001653671265, G_Loss:1.4550236463546753

iterator 4400, D_Loss:1.1256225109100342, G_Loss:1.337597370147705

iterator 4500, D_Loss:1.174278974533081, G_Loss:1.3914539813995361

iterator 4600, D_Loss:1.1334710121154785, G_Loss:1.724498987197876

iterator 4700, D_Loss:1.0540176630020142, G_Loss:2.0792315006256104

iterator 4800, D_Loss:1.0883629322052002, G_Loss:1.636009693145752

iterator 4900, D_Loss:1.1244908571243286, G_Loss:1.6256998777389526

iterator 5000, D_Loss:1.1227052211761475, G_Loss:1.6087383031845093

-----------Epoch 6-----------
iterator 100, D_Loss:1.1442701816558838, G_Loss:1.9880928993225098

iterator 200, D_Loss:1.1086230278015137, G_Loss:1.5617387294769287

iterator 300, D_Loss:1.125885009765625, G_Loss:1.5765457153320312

iterator 400, D_Loss:1.0853371620178223, G_Loss:1.608808994293213

iterator 500, D_Loss:1.1021538972854614, G_Loss:1.7163625955581665

iterator 600, D_Loss:1.124658465385437, G_Loss:1.5230424404144287

iterator 700, D_Loss:1.1526225805282593, G_Loss:1.288536548614502

iterator 800, D_Loss:1.137178659439087, G_Loss:1.4888331890106201

iterator 900, D_Loss:1.1175379753112793, G_Loss:1.4407508373260498

iterator 1000, D_Loss:1.1196601390838623, G_Loss:1.4737051725387573

iterator 1100, D_Loss:1.1629499197006226, G_Loss:1.4435703754425049

iterator 1200, D_Loss:1.1173827648162842, G_Loss:1.5854274034500122

iterator 1300, D_Loss:1.1226112842559814, G_Loss:1.4757680892944336

iterator 1400, D_Loss:1.1703377962112427, G_Loss:1.366533637046814

iterator 1500, D_Loss:1.1119202375411987, G_Loss:1.5310108661651611

iterator 1600, D_Loss:1.134021520614624, G_Loss:1.430283784866333

iterator 1700, D_Loss:1.1735310554504395, G_Loss:1.151552438735962

iterator 1800, D_Loss:1.0655946731567383, G_Loss:1.4856033325195312

iterator 1900, D_Loss:1.134350061416626, G_Loss:1.9460848569869995

iterator 2000, D_Loss:1.1620163917541504, G_Loss:1.5167988538742065

iterator 2100, D_Loss:1.100090742111206, G_Loss:1.4578089714050293

iterator 2200, D_Loss:1.0850712060928345, G_Loss:1.3934333324432373

iterator 2300, D_Loss:1.1061779260635376, G_Loss:1.5401766300201416

iterator 2400, D_Loss:1.14326012134552, G_Loss:1.4398471117019653

iterator 2500, D_Loss:1.0981955528259277, G_Loss:1.6326359510421753

iterator 2600, D_Loss:1.1341629028320312, G_Loss:1.463142991065979

iterator 2700, D_Loss:1.1871116161346436, G_Loss:1.2141368389129639

iterator 2800, D_Loss:1.1338820457458496, G_Loss:1.473211407661438

iterator 2900, D_Loss:1.1119917631149292, G_Loss:1.682018756866455

iterator 3000, D_Loss:1.1421010494232178, G_Loss:1.4553868770599365

iterator 3100, D_Loss:1.1666240692138672, G_Loss:1.5405694246292114

iterator 3200, D_Loss:1.1404221057891846, G_Loss:1.220941185951233

iterator 3300, D_Loss:1.0792951583862305, G_Loss:1.4232078790664673

iterator 3400, D_Loss:1.2101233005523682, G_Loss:1.384258508682251

iterator 3500, D_Loss:1.136393666267395, G_Loss:1.4185675382614136

iterator 3600, D_Loss:1.1039190292358398, G_Loss:1.4355189800262451

iterator 3700, D_Loss:1.188716173171997, G_Loss:1.373197317123413

iterator 3800, D_Loss:1.1451126337051392, G_Loss:1.515878438949585

iterator 3900, D_Loss:1.1594653129577637, G_Loss:1.2960008382797241

iterator 4000, D_Loss:1.1288542747497559, G_Loss:1.4414899349212646

iterator 4100, D_Loss:1.1369068622589111, G_Loss:1.3447877168655396

iterator 4200, D_Loss:1.1584467887878418, G_Loss:1.372689962387085

iterator 4300, D_Loss:1.0947341918945312, G_Loss:1.4310294389724731

iterator 4400, D_Loss:1.0983655452728271, G_Loss:1.4717695713043213

iterator 4500, D_Loss:1.1312181949615479, G_Loss:1.4169414043426514

iterator 4600, D_Loss:1.168464183807373, G_Loss:1.466456413269043

iterator 4700, D_Loss:1.1671031713485718, G_Loss:1.3850793838500977

iterator 4800, D_Loss:1.079782485961914, G_Loss:1.9050463438034058

iterator 4900, D_Loss:1.136894702911377, G_Loss:1.5189951658248901

iterator 5000, D_Loss:1.1433345079421997, G_Loss:1.4498955011367798

-----------Epoch 7-----------
iterator 100, D_Loss:1.1226292848587036, G_Loss:1.5937466621398926

iterator 200, D_Loss:1.1343367099761963, G_Loss:1.5162909030914307

iterator 300, D_Loss:1.164198875427246, G_Loss:1.4595675468444824

iterator 400, D_Loss:1.1209479570388794, G_Loss:1.4330374002456665

iterator 500, D_Loss:1.0597997903823853, G_Loss:1.8055567741394043

iterator 600, D_Loss:1.115079402923584, G_Loss:1.430448055267334

iterator 700, D_Loss:1.119747281074524, G_Loss:1.5791019201278687

iterator 800, D_Loss:1.093268871307373, G_Loss:1.4623358249664307

iterator 900, D_Loss:1.1466740369796753, G_Loss:1.5123175382614136

iterator 1000, D_Loss:1.1418957710266113, G_Loss:1.4688782691955566

iterator 1100, D_Loss:1.1354973316192627, G_Loss:1.3853754997253418

iterator 1200, D_Loss:1.1480443477630615, G_Loss:1.5250493288040161

iterator 1300, D_Loss:1.110520601272583, G_Loss:1.5772536993026733

iterator 1400, D_Loss:1.1455477476119995, G_Loss:1.3745214939117432

iterator 1500, D_Loss:1.1443250179290771, G_Loss:1.468193769454956

iterator 1600, D_Loss:1.1333311796188354, G_Loss:1.558746337890625

iterator 1700, D_Loss:1.1437009572982788, G_Loss:1.5743155479431152

iterator 1800, D_Loss:1.1731374263763428, G_Loss:1.608044147491455

iterator 1900, D_Loss:1.1000447273254395, G_Loss:1.3845419883728027

iterator 2000, D_Loss:1.1296087503433228, G_Loss:1.3875832557678223

iterator 2100, D_Loss:1.1764471530914307, G_Loss:1.435699701309204

iterator 2200, D_Loss:1.1454977989196777, G_Loss:1.4679611921310425

iterator 2300, D_Loss:1.1086506843566895, G_Loss:1.4354898929595947

iterator 2400, D_Loss:1.1419070959091187, G_Loss:1.597620964050293

iterator 2500, D_Loss:1.1034212112426758, G_Loss:1.5004132986068726

iterator 2600, D_Loss:1.1428381204605103, G_Loss:1.440799593925476

iterator 2700, D_Loss:1.0865957736968994, G_Loss:1.6381049156188965

iterator 2800, D_Loss:1.1206085681915283, G_Loss:1.435447335243225

iterator 2900, D_Loss:1.1414347887039185, G_Loss:1.562248945236206

iterator 3000, D_Loss:1.1445354223251343, G_Loss:1.434226393699646

iterator 3100, D_Loss:1.1585369110107422, G_Loss:1.3798357248306274

iterator 3200, D_Loss:1.1182527542114258, G_Loss:1.449952244758606

iterator 3300, D_Loss:1.1051924228668213, G_Loss:1.5813112258911133

iterator 3400, D_Loss:1.1027982234954834, G_Loss:1.4386417865753174

iterator 3500, D_Loss:1.0976898670196533, G_Loss:1.4833381175994873

iterator 3600, D_Loss:0.9841963052749634, G_Loss:2.0716381072998047

iterator 3700, D_Loss:1.060947060585022, G_Loss:1.4629873037338257

iterator 3800, D_Loss:1.073948621749878, G_Loss:1.8774516582489014

iterator 3900, D_Loss:1.1007533073425293, G_Loss:1.4264265298843384

iterator 4000, D_Loss:1.0277323722839355, G_Loss:1.5292165279388428

iterator 4100, D_Loss:1.1067830324172974, G_Loss:1.475766897201538

iterator 4200, D_Loss:1.1311266422271729, G_Loss:1.6079027652740479

iterator 4300, D_Loss:1.093630075454712, G_Loss:1.4220173358917236

iterator 4400, D_Loss:1.1054303646087646, G_Loss:1.364216923713684

iterator 4500, D_Loss:1.1340563297271729, G_Loss:1.5477806329727173

iterator 4600, D_Loss:1.1974974870681763, G_Loss:1.5269150733947754

iterator 4700, D_Loss:1.1194629669189453, G_Loss:1.3961424827575684

iterator 4800, D_Loss:1.122960090637207, G_Loss:1.4218451976776123

iterator 4900, D_Loss:1.0222419500350952, G_Loss:1.9147872924804688

iterator 5000, D_Loss:1.136953592300415, G_Loss:1.4679170846939087

-----------Epoch 8-----------
iterator 100, D_Loss:1.1007421016693115, G_Loss:1.522434115409851

iterator 200, D_Loss:1.1032145023345947, G_Loss:1.4328933954238892

iterator 300, D_Loss:1.0968952178955078, G_Loss:1.5299097299575806

iterator 400, D_Loss:1.118198037147522, G_Loss:1.4237955808639526

iterator 500, D_Loss:1.0825313329696655, G_Loss:1.4625205993652344

iterator 600, D_Loss:1.1048033237457275, G_Loss:1.540657639503479

iterator 700, D_Loss:1.1662358045578003, G_Loss:1.3206313848495483

iterator 800, D_Loss:1.0798115730285645, G_Loss:1.8841434717178345

iterator 900, D_Loss:1.1777291297912598, G_Loss:1.4017406702041626

iterator 1000, D_Loss:1.147489070892334, G_Loss:1.4180434942245483

iterator 1100, D_Loss:1.2021827697753906, G_Loss:1.4450993537902832

iterator 1200, D_Loss:1.066499948501587, G_Loss:1.8561269044876099

iterator 1300, D_Loss:1.0860124826431274, G_Loss:1.6714067459106445

iterator 1400, D_Loss:1.118812084197998, G_Loss:1.501821756362915

iterator 1500, D_Loss:1.140739917755127, G_Loss:1.23027503490448

iterator 1600, D_Loss:1.1276390552520752, G_Loss:1.450486660003662

iterator 1700, D_Loss:1.0754859447479248, G_Loss:1.5438288450241089

iterator 1800, D_Loss:1.1572842597961426, G_Loss:1.533903956413269

iterator 1900, D_Loss:1.1221041679382324, G_Loss:1.4047605991363525

iterator 2000, D_Loss:1.069716453552246, G_Loss:1.520811676979065

iterator 2100, D_Loss:1.115342378616333, G_Loss:1.3768227100372314

iterator 2200, D_Loss:1.1395161151885986, G_Loss:1.448620080947876

iterator 2300, D_Loss:1.1567318439483643, G_Loss:1.3083386421203613

iterator 2400, D_Loss:1.0913299322128296, G_Loss:1.6904845237731934

iterator 2500, D_Loss:1.116881012916565, G_Loss:1.4664380550384521

iterator 2600, D_Loss:1.1579620838165283, G_Loss:1.4449894428253174

iterator 2700, D_Loss:1.1196173429489136, G_Loss:1.2788641452789307

iterator 2800, D_Loss:1.0878782272338867, G_Loss:1.5152852535247803

iterator 2900, D_Loss:1.1704192161560059, G_Loss:1.4395337104797363

iterator 3000, D_Loss:1.1064835786819458, G_Loss:1.3896076679229736

iterator 3100, D_Loss:1.1636512279510498, G_Loss:1.572585105895996

iterator 3200, D_Loss:1.1519263982772827, G_Loss:1.3043692111968994

iterator 3300, D_Loss:1.1180518865585327, G_Loss:1.6173418760299683

iterator 3400, D_Loss:1.1209793090820312, G_Loss:1.4425603151321411

iterator 3500, D_Loss:1.1266899108886719, G_Loss:1.4657618999481201

iterator 3600, D_Loss:1.1689475774765015, G_Loss:1.5067832469940186

iterator 3700, D_Loss:1.1437703371047974, G_Loss:1.4623537063598633

iterator 3800, D_Loss:1.0569065809249878, G_Loss:1.7314140796661377

iterator 3900, D_Loss:1.0642285346984863, G_Loss:1.6796560287475586

iterator 4000, D_Loss:1.1718766689300537, G_Loss:1.4150985479354858

iterator 4100, D_Loss:1.1251232624053955, G_Loss:1.489881992340088

iterator 4200, D_Loss:1.1121666431427002, G_Loss:1.5202051401138306

iterator 4300, D_Loss:1.141379952430725, G_Loss:1.540682315826416

iterator 4400, D_Loss:1.1845266819000244, G_Loss:1.3901996612548828

iterator 4500, D_Loss:1.1029422283172607, G_Loss:1.6296933889389038

iterator 4600, D_Loss:1.1281628608703613, G_Loss:1.3267879486083984

iterator 4700, D_Loss:1.1068649291992188, G_Loss:1.515804409980774

iterator 4800, D_Loss:1.1904765367507935, G_Loss:1.256021499633789

iterator 4900, D_Loss:1.1114367246627808, G_Loss:1.6913039684295654

iterator 5000, D_Loss:1.1338189840316772, G_Loss:1.652313232421875

-----------Epoch 9-----------
iterator 100, D_Loss:1.1197664737701416, G_Loss:1.4562259912490845

iterator 200, D_Loss:1.1127612590789795, G_Loss:1.6818156242370605

iterator 300, D_Loss:1.1895194053649902, G_Loss:1.477284550666809

iterator 400, D_Loss:1.1212303638458252, G_Loss:1.6825374364852905

iterator 500, D_Loss:1.1250697374343872, G_Loss:1.4680087566375732

iterator 600, D_Loss:1.0767395496368408, G_Loss:1.4833229780197144

iterator 700, D_Loss:1.144839882850647, G_Loss:1.6905403137207031

iterator 800, D_Loss:1.0881563425064087, G_Loss:1.588637351989746

iterator 900, D_Loss:1.141517996788025, G_Loss:1.52436363697052

iterator 1000, D_Loss:1.129453182220459, G_Loss:1.4988709688186646

iterator 1100, D_Loss:1.091631293296814, G_Loss:1.5481829643249512

iterator 1200, D_Loss:1.1218857765197754, G_Loss:1.5567736625671387

iterator 1300, D_Loss:1.1772875785827637, G_Loss:1.504913091659546

iterator 1400, D_Loss:1.0933669805526733, G_Loss:1.4584341049194336

iterator 1500, D_Loss:1.1449406147003174, G_Loss:1.5754609107971191

iterator 1600, D_Loss:1.1068812608718872, G_Loss:1.419886589050293

iterator 1700, D_Loss:1.0808210372924805, G_Loss:1.5066123008728027

iterator 1800, D_Loss:1.1703290939331055, G_Loss:1.394948124885559

iterator 1900, D_Loss:1.078510046005249, G_Loss:1.472862720489502

iterator 2000, D_Loss:1.1123969554901123, G_Loss:1.490699052810669

iterator 2100, D_Loss:1.153468370437622, G_Loss:1.4072556495666504

iterator 2200, D_Loss:1.1201202869415283, G_Loss:1.54914128780365

iterator 2300, D_Loss:1.1180806159973145, G_Loss:1.406243085861206

iterator 2400, D_Loss:1.169629454612732, G_Loss:1.235563039779663

iterator 2500, D_Loss:1.136065125465393, G_Loss:1.673643946647644

iterator 2600, D_Loss:1.1409308910369873, G_Loss:1.4098457098007202

iterator 2700, D_Loss:1.161226511001587, G_Loss:1.418541431427002

iterator 2800, D_Loss:1.1156041622161865, G_Loss:1.445129632949829

iterator 2900, D_Loss:1.0979814529418945, G_Loss:1.6988840103149414

iterator 3000, D_Loss:1.0933868885040283, G_Loss:1.4392247200012207

iterator 3100, D_Loss:1.120859146118164, G_Loss:1.6652345657348633

iterator 3200, D_Loss:1.1851294040679932, G_Loss:1.2733558416366577

iterator 3300, D_Loss:1.0924599170684814, G_Loss:1.6428273916244507

iterator 3400, D_Loss:1.1507052183151245, G_Loss:1.4326485395431519

iterator 3500, D_Loss:1.2042009830474854, G_Loss:1.3098208904266357

iterator 3600, D_Loss:1.122385025024414, G_Loss:1.299884557723999

iterator 3700, D_Loss:1.1019032001495361, G_Loss:1.4845620393753052

iterator 3800, D_Loss:1.149165391921997, G_Loss:1.4347758293151855

iterator 3900, D_Loss:1.1301991939544678, G_Loss:1.2354756593704224

iterator 4000, D_Loss:1.1205039024353027, G_Loss:1.9127289056777954

iterator 4100, D_Loss:1.1312209367752075, G_Loss:1.390518069267273

iterator 4200, D_Loss:1.1651769876480103, G_Loss:1.525913119316101

iterator 4300, D_Loss:1.1237090826034546, G_Loss:1.496416449546814

iterator 4400, D_Loss:1.0893032550811768, G_Loss:1.5498888492584229

iterator 4500, D_Loss:1.1127307415008545, G_Loss:1.7964897155761719

iterator 4600, D_Loss:1.126163363456726, G_Loss:1.477441430091858

iterator 4700, D_Loss:1.0704474449157715, G_Loss:2.004995346069336

iterator 4800, D_Loss:1.1029305458068848, G_Loss:1.3974013328552246

iterator 4900, D_Loss:1.1674858331680298, G_Loss:1.4431767463684082

iterator 5000, D_Loss:1.1188061237335205, G_Loss:1.5500520467758179

train row : 30148
sample row: 30148
VGAN_generator(
  (input): Linear(in_features=128, out_features=100, bias=True)
  (inputbn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=100, out_features=45, bias=True)
  (outputbn): BatchNorm1d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=45, out_features=400, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=400, out_features=400, bias=True)
  (output): Linear(in_features=400, out_features=1, bias=True)
)
(0, False, 45)
-----------Epoch 0-----------
iterator 100, D_Loss:0.5226553082466125, G_Loss:10.907844543457031

iterator 200, D_Loss:0.5081183314323425, G_Loss:9.135859489440918

iterator 300, D_Loss:0.42987778782844543, G_Loss:10.230077743530273

iterator 400, D_Loss:0.45654505491256714, G_Loss:8.52822494506836

iterator 500, D_Loss:0.43352043628692627, G_Loss:10.676607131958008

iterator 600, D_Loss:0.461174339056015, G_Loss:10.393533706665039

iterator 700, D_Loss:0.4681609570980072, G_Loss:9.71227741241455

iterator 800, D_Loss:0.4836849570274353, G_Loss:9.961298942565918

iterator 900, D_Loss:0.4790565073490143, G_Loss:9.166658401489258

iterator 1000, D_Loss:0.45845046639442444, G_Loss:9.494219779968262

iterator 1100, D_Loss:0.48239055275917053, G_Loss:8.93083381652832

iterator 1200, D_Loss:0.45781803131103516, G_Loss:8.041044235229492

iterator 1300, D_Loss:0.4735410213470459, G_Loss:8.40513801574707

iterator 1400, D_Loss:0.5220788717269897, G_Loss:7.734180450439453

iterator 1500, D_Loss:0.4726429283618927, G_Loss:7.981432914733887

iterator 1600, D_Loss:0.48649802803993225, G_Loss:7.840526103973389

iterator 1700, D_Loss:0.5303391218185425, G_Loss:7.6301984786987305

iterator 1800, D_Loss:0.5004270076751709, G_Loss:7.192549705505371

iterator 1900, D_Loss:0.460675984621048, G_Loss:7.483188629150391

iterator 2000, D_Loss:0.4629656970500946, G_Loss:7.481216907501221

iterator 2100, D_Loss:0.4496317505836487, G_Loss:7.1343302726745605

iterator 2200, D_Loss:0.4798154830932617, G_Loss:7.564268112182617

iterator 2300, D_Loss:0.44438835978507996, G_Loss:6.952395915985107

iterator 2400, D_Loss:0.5389986038208008, G_Loss:6.440301895141602

iterator 2500, D_Loss:0.4669187664985657, G_Loss:7.046016693115234

iterator 2600, D_Loss:0.5177938342094421, G_Loss:6.410084247589111

iterator 2700, D_Loss:0.49035409092903137, G_Loss:6.545144081115723

iterator 2800, D_Loss:0.5504164099693298, G_Loss:6.386371612548828

iterator 2900, D_Loss:0.5159597992897034, G_Loss:6.278878211975098

iterator 3000, D_Loss:0.5529709458351135, G_Loss:5.964151382446289

iterator 3100, D_Loss:0.48363563418388367, G_Loss:6.649567604064941

iterator 3200, D_Loss:0.5202818512916565, G_Loss:6.37447452545166

iterator 3300, D_Loss:0.5649914741516113, G_Loss:5.646254539489746

iterator 3400, D_Loss:0.5040544867515564, G_Loss:6.19569206237793

iterator 3500, D_Loss:0.5473487973213196, G_Loss:6.120303153991699

iterator 3600, D_Loss:0.5332303047180176, G_Loss:6.072168350219727

iterator 3700, D_Loss:0.5769739747047424, G_Loss:6.073705196380615

iterator 3800, D_Loss:0.5408554673194885, G_Loss:7.119156837463379

iterator 3900, D_Loss:0.5418112874031067, G_Loss:6.009706020355225

iterator 4000, D_Loss:0.5795063972473145, G_Loss:5.502810478210449

iterator 4100, D_Loss:0.5954059958457947, G_Loss:5.222073554992676

iterator 4200, D_Loss:0.5932559967041016, G_Loss:5.553584098815918

iterator 4300, D_Loss:0.6087599396705627, G_Loss:5.161427021026611

iterator 4400, D_Loss:0.6068580746650696, G_Loss:5.077430725097656

iterator 4500, D_Loss:0.6176032423973083, G_Loss:5.13037633895874

iterator 4600, D_Loss:0.5958112478256226, G_Loss:4.910649299621582

iterator 4700, D_Loss:0.5842516422271729, G_Loss:4.954225540161133

iterator 4800, D_Loss:0.6266945600509644, G_Loss:4.7791900634765625

iterator 4900, D_Loss:0.5837399959564209, G_Loss:4.432240962982178

iterator 5000, D_Loss:0.6398042440414429, G_Loss:5.134552478790283

-----------Epoch 1-----------
iterator 100, D_Loss:0.5918331146240234, G_Loss:5.40280294418335

iterator 200, D_Loss:0.6366795897483826, G_Loss:4.001611232757568

iterator 300, D_Loss:0.6195215582847595, G_Loss:4.220905303955078

iterator 400, D_Loss:0.6452857255935669, G_Loss:4.023794174194336

iterator 500, D_Loss:0.6378337740898132, G_Loss:4.457425117492676

iterator 600, D_Loss:0.6842732429504395, G_Loss:4.1398024559021

iterator 700, D_Loss:0.5359653830528259, G_Loss:4.520723342895508

iterator 800, D_Loss:0.6421636939048767, G_Loss:4.299950122833252

iterator 900, D_Loss:0.6624723672866821, G_Loss:3.721972942352295

iterator 1000, D_Loss:0.6494240164756775, G_Loss:3.7085800170898438

iterator 1100, D_Loss:0.7350069284439087, G_Loss:4.121937274932861

iterator 1200, D_Loss:0.6463989019393921, G_Loss:4.39378023147583

iterator 1300, D_Loss:0.6937446594238281, G_Loss:3.585570812225342

iterator 1400, D_Loss:0.6592855453491211, G_Loss:3.7952029705047607

iterator 1500, D_Loss:0.6396397948265076, G_Loss:3.686739683151245

iterator 1600, D_Loss:0.6631178855895996, G_Loss:3.643822431564331

iterator 1700, D_Loss:0.7684941291809082, G_Loss:3.7984204292297363

iterator 1800, D_Loss:0.7008708715438843, G_Loss:3.60835599899292

iterator 1900, D_Loss:0.6957464218139648, G_Loss:3.610199213027954

iterator 2000, D_Loss:0.6637464761734009, G_Loss:3.3147122859954834

iterator 2100, D_Loss:0.7062247395515442, G_Loss:3.6433122158050537

iterator 2200, D_Loss:0.7169670462608337, G_Loss:3.293611526489258

iterator 2300, D_Loss:0.7291345000267029, G_Loss:3.3337974548339844

iterator 2400, D_Loss:0.8224687576293945, G_Loss:3.528917074203491

iterator 2500, D_Loss:0.7501264810562134, G_Loss:3.250847816467285

iterator 2600, D_Loss:0.7327533960342407, G_Loss:3.3086085319519043

iterator 2700, D_Loss:0.7150530815124512, G_Loss:3.2834179401397705

iterator 2800, D_Loss:0.7489073872566223, G_Loss:3.278062105178833

iterator 2900, D_Loss:0.8056212663650513, G_Loss:3.1050732135772705

iterator 3000, D_Loss:0.7413105964660645, G_Loss:3.4079678058624268

iterator 3100, D_Loss:0.77012038230896, G_Loss:3.2766408920288086

iterator 3200, D_Loss:0.813117504119873, G_Loss:3.2746458053588867

iterator 3300, D_Loss:0.6802996397018433, G_Loss:3.3899857997894287

iterator 3400, D_Loss:0.7860042452812195, G_Loss:3.0729243755340576

iterator 3500, D_Loss:0.7191857099533081, G_Loss:3.542372465133667

iterator 3600, D_Loss:0.8721292614936829, G_Loss:3.1945114135742188

iterator 3700, D_Loss:0.8037500381469727, G_Loss:3.3538763523101807

iterator 3800, D_Loss:0.7805806994438171, G_Loss:3.8384816646575928

iterator 3900, D_Loss:0.8674426078796387, G_Loss:3.0882270336151123

iterator 4000, D_Loss:0.7992027997970581, G_Loss:2.905672311782837

iterator 4100, D_Loss:0.7367410659790039, G_Loss:3.2536730766296387

iterator 4200, D_Loss:0.8412655591964722, G_Loss:3.014727830886841

iterator 4300, D_Loss:0.7862405776977539, G_Loss:2.7368483543395996

iterator 4400, D_Loss:0.8075690269470215, G_Loss:2.95432448387146

iterator 4500, D_Loss:0.8192286491394043, G_Loss:2.8080408573150635

iterator 4600, D_Loss:0.7760896682739258, G_Loss:3.1969287395477295

iterator 4700, D_Loss:0.8146461248397827, G_Loss:3.10565447807312

iterator 4800, D_Loss:0.7931980490684509, G_Loss:2.536344528198242

iterator 4900, D_Loss:0.7862218022346497, G_Loss:2.993321418762207

iterator 5000, D_Loss:0.7823026180267334, G_Loss:2.7628121376037598

-----------Epoch 2-----------
iterator 100, D_Loss:0.7750260233879089, G_Loss:3.107457160949707

iterator 200, D_Loss:0.8130302429199219, G_Loss:2.7854502201080322

iterator 300, D_Loss:0.8493807315826416, G_Loss:2.8777236938476562

iterator 400, D_Loss:0.797511100769043, G_Loss:2.9330053329467773

iterator 500, D_Loss:0.8395382761955261, G_Loss:3.1402595043182373

iterator 600, D_Loss:0.876541793346405, G_Loss:2.730839729309082

iterator 700, D_Loss:0.727057158946991, G_Loss:3.0379631519317627

iterator 800, D_Loss:0.7493109107017517, G_Loss:3.0180463790893555

iterator 900, D_Loss:0.8351737856864929, G_Loss:2.9745278358459473

iterator 1000, D_Loss:0.8240160942077637, G_Loss:2.435253620147705

iterator 1100, D_Loss:0.777319610118866, G_Loss:2.7848849296569824

iterator 1200, D_Loss:0.9363322257995605, G_Loss:2.774151086807251

iterator 1300, D_Loss:0.9133485555648804, G_Loss:2.454549789428711

iterator 1400, D_Loss:0.882885217666626, G_Loss:2.9657044410705566

iterator 1500, D_Loss:0.8186376094818115, G_Loss:3.137112617492676

iterator 1600, D_Loss:0.797861635684967, G_Loss:3.0340826511383057

iterator 1700, D_Loss:0.7648874521255493, G_Loss:3.0379345417022705

iterator 1800, D_Loss:0.9125478863716125, G_Loss:2.996551036834717

iterator 1900, D_Loss:0.8124756813049316, G_Loss:3.279825448989868

iterator 2000, D_Loss:0.8069184422492981, G_Loss:3.3942136764526367

iterator 2100, D_Loss:0.8381370306015015, G_Loss:3.227898359298706

iterator 2200, D_Loss:0.8515489101409912, G_Loss:3.035935401916504

iterator 2300, D_Loss:0.7545474767684937, G_Loss:3.232638359069824

iterator 2400, D_Loss:0.8112781047821045, G_Loss:2.5087876319885254

iterator 2500, D_Loss:0.9084330201148987, G_Loss:2.764707088470459

iterator 2600, D_Loss:0.7678717970848083, G_Loss:3.5230908393859863

iterator 2700, D_Loss:0.8218720555305481, G_Loss:2.896624803543091

iterator 2800, D_Loss:0.759232759475708, G_Loss:3.153984785079956

iterator 2900, D_Loss:0.7761520147323608, G_Loss:3.0758585929870605

iterator 3000, D_Loss:0.7621538043022156, G_Loss:2.8297736644744873

iterator 3100, D_Loss:0.8205451369285583, G_Loss:3.0723624229431152

iterator 3200, D_Loss:0.7913939356803894, G_Loss:2.9595580101013184

iterator 3300, D_Loss:0.7729155421257019, G_Loss:3.4278345108032227

iterator 3400, D_Loss:0.8350570201873779, G_Loss:3.1545701026916504

iterator 3500, D_Loss:0.8136306405067444, G_Loss:3.570044755935669

iterator 3600, D_Loss:0.7759100198745728, G_Loss:3.2608275413513184

iterator 3700, D_Loss:0.7841298580169678, G_Loss:2.9936068058013916

iterator 3800, D_Loss:0.7831122875213623, G_Loss:3.7761547565460205

iterator 3900, D_Loss:0.8183170557022095, G_Loss:3.0649850368499756

iterator 4000, D_Loss:0.7503656148910522, G_Loss:2.7703821659088135

iterator 4100, D_Loss:0.8282957077026367, G_Loss:3.084838628768921

iterator 4200, D_Loss:0.8392452001571655, G_Loss:3.137026071548462

iterator 4300, D_Loss:0.8263248801231384, G_Loss:3.0941214561462402

iterator 4400, D_Loss:0.8395431041717529, G_Loss:3.285412073135376

iterator 4500, D_Loss:0.8629518747329712, G_Loss:2.723151922225952

iterator 4600, D_Loss:0.8016527891159058, G_Loss:2.654115915298462

iterator 4700, D_Loss:0.8645397424697876, G_Loss:3.243924379348755

iterator 4800, D_Loss:0.7185734510421753, G_Loss:3.3103983402252197

iterator 4900, D_Loss:0.7906528115272522, G_Loss:3.0091328620910645

iterator 5000, D_Loss:0.6942778825759888, G_Loss:3.0974643230438232

-----------Epoch 3-----------
iterator 100, D_Loss:0.935879111289978, G_Loss:2.8590734004974365

iterator 200, D_Loss:0.7679868340492249, G_Loss:3.2157998085021973

iterator 300, D_Loss:0.7764637470245361, G_Loss:2.9656171798706055

iterator 400, D_Loss:0.8291977643966675, G_Loss:3.2778730392456055

iterator 500, D_Loss:0.8424249291419983, G_Loss:3.1803815364837646

iterator 600, D_Loss:0.9036848545074463, G_Loss:3.385563611984253

iterator 700, D_Loss:0.8082327246665955, G_Loss:3.80130934715271

iterator 800, D_Loss:0.8012080192565918, G_Loss:3.2812318801879883

iterator 900, D_Loss:0.8310019969940186, G_Loss:3.236985921859741

iterator 1000, D_Loss:0.8278138637542725, G_Loss:2.7042717933654785

iterator 1100, D_Loss:0.8426233530044556, G_Loss:3.364168167114258

iterator 1200, D_Loss:0.7808279395103455, G_Loss:2.840468168258667

iterator 1300, D_Loss:0.8184453248977661, G_Loss:3.1837263107299805

iterator 1400, D_Loss:0.9007207155227661, G_Loss:3.163788318634033

iterator 1500, D_Loss:0.8058860301971436, G_Loss:2.935410499572754

iterator 1600, D_Loss:0.7325748205184937, G_Loss:3.1181480884552

iterator 1700, D_Loss:0.7681586742401123, G_Loss:3.359177589416504

iterator 1800, D_Loss:0.8741564154624939, G_Loss:3.2669928073883057

iterator 1900, D_Loss:0.7382752895355225, G_Loss:3.337479591369629

iterator 2000, D_Loss:0.9249396324157715, G_Loss:2.9902210235595703

iterator 2100, D_Loss:0.7481397986412048, G_Loss:3.247084617614746

iterator 2200, D_Loss:0.8684507608413696, G_Loss:3.008686065673828

iterator 2300, D_Loss:0.8364987373352051, G_Loss:3.66564679145813

iterator 2400, D_Loss:0.8249081969261169, G_Loss:3.7356815338134766

iterator 2500, D_Loss:0.8902793526649475, G_Loss:3.212625741958618

iterator 2600, D_Loss:0.7716471552848816, G_Loss:3.5003347396850586

iterator 2700, D_Loss:0.7887184619903564, G_Loss:3.317225694656372

iterator 2800, D_Loss:0.7520288228988647, G_Loss:3.5847020149230957

iterator 2900, D_Loss:0.740662693977356, G_Loss:3.2978436946868896

iterator 3000, D_Loss:0.8331348896026611, G_Loss:3.0514376163482666

iterator 3100, D_Loss:0.7902082204818726, G_Loss:3.5482919216156006

iterator 3200, D_Loss:0.8328688144683838, G_Loss:3.8490757942199707

iterator 3300, D_Loss:0.727104902267456, G_Loss:3.49005126953125

iterator 3400, D_Loss:0.8028504252433777, G_Loss:3.7755672931671143

iterator 3500, D_Loss:0.7004431486129761, G_Loss:3.243739366531372

iterator 3600, D_Loss:0.716971755027771, G_Loss:3.6344234943389893

iterator 3700, D_Loss:0.8001909255981445, G_Loss:2.866971015930176

iterator 3800, D_Loss:0.7962056994438171, G_Loss:4.032786846160889

iterator 3900, D_Loss:0.8379173278808594, G_Loss:3.003157377243042

iterator 4000, D_Loss:0.8312040567398071, G_Loss:2.8497376441955566

iterator 4100, D_Loss:0.774398684501648, G_Loss:3.482760190963745

iterator 4200, D_Loss:0.7924993634223938, G_Loss:3.2363955974578857

iterator 4300, D_Loss:0.7539702653884888, G_Loss:3.1728241443634033

iterator 4400, D_Loss:0.812996506690979, G_Loss:3.1461782455444336

iterator 4500, D_Loss:0.8003926277160645, G_Loss:3.4988882541656494

iterator 4600, D_Loss:0.7108431458473206, G_Loss:3.2127840518951416

iterator 4700, D_Loss:0.7614121437072754, G_Loss:3.5626771450042725

iterator 4800, D_Loss:0.8169547319412231, G_Loss:3.5252251625061035

iterator 4900, D_Loss:0.7678779363632202, G_Loss:3.4024627208709717

iterator 5000, D_Loss:0.7271625399589539, G_Loss:3.252079963684082

-----------Epoch 4-----------
iterator 100, D_Loss:0.7996923923492432, G_Loss:3.4794373512268066

iterator 200, D_Loss:0.7390429973602295, G_Loss:3.269989490509033

iterator 300, D_Loss:0.808483362197876, G_Loss:3.35152268409729

iterator 400, D_Loss:0.7511451244354248, G_Loss:3.795654058456421

iterator 500, D_Loss:0.7397062182426453, G_Loss:3.1927919387817383

iterator 600, D_Loss:0.8732292652130127, G_Loss:3.076564073562622

iterator 700, D_Loss:0.8119680285453796, G_Loss:2.8495166301727295

iterator 800, D_Loss:0.8090177774429321, G_Loss:3.2845101356506348

iterator 900, D_Loss:0.7777912020683289, G_Loss:3.0797488689422607

iterator 1000, D_Loss:0.7989240884780884, G_Loss:3.3265771865844727

iterator 1100, D_Loss:0.730318546295166, G_Loss:3.6414332389831543

iterator 1200, D_Loss:0.749272346496582, G_Loss:2.938349723815918

iterator 1300, D_Loss:0.7444334030151367, G_Loss:3.4762275218963623

iterator 1400, D_Loss:0.8231288194656372, G_Loss:3.562206745147705

iterator 1500, D_Loss:0.7114005088806152, G_Loss:3.6262989044189453

iterator 1600, D_Loss:0.7372217178344727, G_Loss:3.201096534729004

iterator 1700, D_Loss:0.866563081741333, G_Loss:3.1321403980255127

iterator 1800, D_Loss:0.8221215605735779, G_Loss:2.812744379043579

iterator 1900, D_Loss:0.802973747253418, G_Loss:3.4863779544830322

iterator 2000, D_Loss:0.8384408354759216, G_Loss:3.597837448120117

iterator 2100, D_Loss:0.9173311591148376, G_Loss:3.5735087394714355

iterator 2200, D_Loss:0.707211971282959, G_Loss:3.4968862533569336

iterator 2300, D_Loss:0.7637088298797607, G_Loss:3.0715043544769287

iterator 2400, D_Loss:0.7413849830627441, G_Loss:3.7269649505615234

iterator 2500, D_Loss:0.6904577612876892, G_Loss:3.605038642883301

iterator 2600, D_Loss:0.7597208023071289, G_Loss:3.806441068649292

iterator 2700, D_Loss:0.706883430480957, G_Loss:4.138277530670166

iterator 2800, D_Loss:0.7148597240447998, G_Loss:3.8124191761016846

iterator 2900, D_Loss:0.8883448243141174, G_Loss:3.6566059589385986

iterator 3000, D_Loss:0.7939766049385071, G_Loss:4.106241226196289

iterator 3100, D_Loss:0.8052768111228943, G_Loss:3.533381223678589

iterator 3200, D_Loss:0.6948704123497009, G_Loss:3.4882354736328125

iterator 3300, D_Loss:0.7008898258209229, G_Loss:5.156747817993164

iterator 3400, D_Loss:0.8534606099128723, G_Loss:3.9000415802001953

iterator 3500, D_Loss:0.7580009698867798, G_Loss:3.4259591102600098

iterator 3600, D_Loss:0.8207284212112427, G_Loss:3.513934850692749

iterator 3700, D_Loss:0.8359503746032715, G_Loss:3.965393543243408

iterator 3800, D_Loss:0.7205883264541626, G_Loss:4.002556800842285

iterator 3900, D_Loss:0.8238548040390015, G_Loss:3.8979251384735107

iterator 4000, D_Loss:0.8109140396118164, G_Loss:2.9496562480926514

iterator 4100, D_Loss:0.7721314430236816, G_Loss:3.1302504539489746

iterator 4200, D_Loss:0.7642027735710144, G_Loss:4.229774475097656

iterator 4300, D_Loss:0.7510716319084167, G_Loss:3.2182199954986572

iterator 4400, D_Loss:0.7529313564300537, G_Loss:3.486574649810791

iterator 4500, D_Loss:0.7769483923912048, G_Loss:3.3096516132354736

iterator 4600, D_Loss:0.8430087566375732, G_Loss:3.495621919631958

iterator 4700, D_Loss:0.827844500541687, G_Loss:3.480823040008545

iterator 4800, D_Loss:0.8328473567962646, G_Loss:3.3092522621154785

iterator 4900, D_Loss:0.8196130394935608, G_Loss:3.6958320140838623

iterator 5000, D_Loss:0.7491004467010498, G_Loss:3.6032025814056396

-----------Epoch 5-----------
iterator 100, D_Loss:0.7421995997428894, G_Loss:3.0470123291015625

iterator 200, D_Loss:0.7338865399360657, G_Loss:3.2971715927124023

iterator 300, D_Loss:0.814793586730957, G_Loss:3.4894025325775146

iterator 400, D_Loss:0.7837132811546326, G_Loss:2.703585147857666

iterator 500, D_Loss:0.8233554363250732, G_Loss:3.4725501537323

iterator 600, D_Loss:0.7273299098014832, G_Loss:3.4509072303771973

iterator 700, D_Loss:0.7507622241973877, G_Loss:2.7871711254119873

iterator 800, D_Loss:0.7883578538894653, G_Loss:4.0643157958984375

iterator 900, D_Loss:0.7169485092163086, G_Loss:3.7626516819000244

iterator 1000, D_Loss:0.6748107671737671, G_Loss:2.8826935291290283

iterator 1100, D_Loss:0.8249320387840271, G_Loss:3.3794338703155518

iterator 1200, D_Loss:0.787668764591217, G_Loss:3.5161170959472656

iterator 1300, D_Loss:0.7561175227165222, G_Loss:3.5590500831604004

iterator 1400, D_Loss:0.7801907062530518, G_Loss:3.385631799697876

iterator 1500, D_Loss:0.7889025211334229, G_Loss:3.2229905128479004

iterator 1600, D_Loss:0.8104018568992615, G_Loss:3.4456076622009277

iterator 1700, D_Loss:0.808570921421051, G_Loss:3.913740634918213

iterator 1800, D_Loss:0.7864336371421814, G_Loss:3.5033042430877686

iterator 1900, D_Loss:0.8955520391464233, G_Loss:3.355865478515625

iterator 2000, D_Loss:0.8509505987167358, G_Loss:3.121274471282959

iterator 2100, D_Loss:0.7301974892616272, G_Loss:4.127178192138672

iterator 2200, D_Loss:0.7422704696655273, G_Loss:3.736323356628418

iterator 2300, D_Loss:0.7923833727836609, G_Loss:3.3988144397735596

iterator 2400, D_Loss:0.8078404068946838, G_Loss:3.4047703742980957

iterator 2500, D_Loss:0.8123170137405396, G_Loss:3.584425210952759

iterator 2600, D_Loss:0.7050372958183289, G_Loss:4.121688365936279

iterator 2700, D_Loss:0.8345690369606018, G_Loss:3.2602286338806152

iterator 2800, D_Loss:0.8291481733322144, G_Loss:4.2374186515808105

iterator 2900, D_Loss:0.8376222252845764, G_Loss:3.266514301300049

iterator 3000, D_Loss:0.767711877822876, G_Loss:3.3705556392669678

iterator 3100, D_Loss:0.8491858839988708, G_Loss:3.3741562366485596

iterator 3200, D_Loss:0.729485273361206, G_Loss:3.358685255050659

iterator 3300, D_Loss:0.8057036995887756, G_Loss:3.354240894317627

iterator 3400, D_Loss:0.7382700443267822, G_Loss:3.789724349975586

iterator 3500, D_Loss:0.7243145704269409, G_Loss:3.9327118396759033

iterator 3600, D_Loss:0.7833237648010254, G_Loss:3.8321030139923096

iterator 3700, D_Loss:0.79569011926651, G_Loss:3.7894067764282227

iterator 3800, D_Loss:0.747208833694458, G_Loss:3.3635928630828857

iterator 3900, D_Loss:0.7926766872406006, G_Loss:3.6206727027893066

iterator 4000, D_Loss:0.75737464427948, G_Loss:4.269131660461426

iterator 4100, D_Loss:0.776944100856781, G_Loss:3.4027748107910156

iterator 4200, D_Loss:0.7373659610748291, G_Loss:3.9324638843536377

iterator 4300, D_Loss:0.7181867957115173, G_Loss:3.129164695739746

iterator 4400, D_Loss:0.763487696647644, G_Loss:3.1482319831848145

iterator 4500, D_Loss:0.8565713167190552, G_Loss:3.164194345474243

iterator 4600, D_Loss:0.7580410838127136, G_Loss:3.311732053756714

iterator 4700, D_Loss:0.773098349571228, G_Loss:3.6705167293548584

iterator 4800, D_Loss:0.761141300201416, G_Loss:3.4147558212280273

iterator 4900, D_Loss:0.7627575397491455, G_Loss:3.053011894226074

iterator 5000, D_Loss:0.8858723640441895, G_Loss:3.5150609016418457

-----------Epoch 6-----------
iterator 100, D_Loss:0.7347951531410217, G_Loss:3.6363964080810547

iterator 200, D_Loss:0.8734704256057739, G_Loss:3.2687289714813232

iterator 300, D_Loss:0.7103801965713501, G_Loss:3.5778629779815674

iterator 400, D_Loss:0.8267905712127686, G_Loss:3.79472017288208

iterator 500, D_Loss:0.6941322088241577, G_Loss:3.361708402633667

iterator 600, D_Loss:0.7645782828330994, G_Loss:3.3883540630340576

iterator 700, D_Loss:0.7748323678970337, G_Loss:4.356773376464844

iterator 800, D_Loss:0.7968236207962036, G_Loss:3.6735315322875977

iterator 900, D_Loss:0.8330667614936829, G_Loss:3.560636520385742

iterator 1000, D_Loss:0.8505162000656128, G_Loss:4.008739471435547

iterator 1100, D_Loss:0.7277520895004272, G_Loss:3.45059871673584

iterator 1200, D_Loss:0.7140846252441406, G_Loss:3.362778902053833

iterator 1300, D_Loss:0.6684048771858215, G_Loss:3.661949872970581

iterator 1400, D_Loss:0.8035897016525269, G_Loss:3.2381131649017334

iterator 1500, D_Loss:0.722412109375, G_Loss:3.700650691986084

iterator 1600, D_Loss:0.762014627456665, G_Loss:4.159191608428955

iterator 1700, D_Loss:0.8879411220550537, G_Loss:3.102074146270752

iterator 1800, D_Loss:0.759079098701477, G_Loss:3.313465118408203

iterator 1900, D_Loss:0.7201473116874695, G_Loss:3.816030263900757

iterator 2000, D_Loss:0.7088096737861633, G_Loss:3.184767484664917

iterator 2100, D_Loss:0.7979918122291565, G_Loss:3.1168196201324463

iterator 2200, D_Loss:0.706427276134491, G_Loss:4.070011615753174

iterator 2300, D_Loss:0.6690840125083923, G_Loss:3.663221836090088

iterator 2400, D_Loss:0.7083117961883545, G_Loss:3.313194751739502

iterator 2500, D_Loss:0.6781033277511597, G_Loss:4.060987949371338

iterator 2600, D_Loss:0.8481554388999939, G_Loss:3.8769123554229736

iterator 2700, D_Loss:0.8488075733184814, G_Loss:3.307530403137207

iterator 2800, D_Loss:0.787056565284729, G_Loss:3.7763314247131348

iterator 2900, D_Loss:0.686988115310669, G_Loss:3.650489091873169

iterator 3000, D_Loss:0.6711897253990173, G_Loss:3.561673402786255

iterator 3100, D_Loss:0.8078905344009399, G_Loss:3.0606396198272705

iterator 3200, D_Loss:0.8381803035736084, G_Loss:3.2378945350646973

iterator 3300, D_Loss:0.6972002983093262, G_Loss:3.531156539916992

iterator 3400, D_Loss:0.722673237323761, G_Loss:4.014913558959961

iterator 3500, D_Loss:0.7640191316604614, G_Loss:3.3004117012023926

iterator 3600, D_Loss:0.7902296781539917, G_Loss:3.5317955017089844

iterator 3700, D_Loss:0.7676485776901245, G_Loss:3.887326955795288

iterator 3800, D_Loss:0.8279390335083008, G_Loss:3.535426378250122

iterator 3900, D_Loss:0.8066974878311157, G_Loss:3.0934441089630127

iterator 4000, D_Loss:0.8650712370872498, G_Loss:3.0070114135742188

iterator 4100, D_Loss:0.6897388696670532, G_Loss:3.8272953033447266

iterator 4200, D_Loss:0.8270763754844666, G_Loss:2.483799457550049

iterator 4300, D_Loss:0.7308235168457031, G_Loss:3.266634464263916

iterator 4400, D_Loss:0.7809838056564331, G_Loss:4.16949462890625

iterator 4500, D_Loss:0.8171730041503906, G_Loss:3.7037670612335205

iterator 4600, D_Loss:0.7477765083312988, G_Loss:3.432443141937256

iterator 4700, D_Loss:0.754279375076294, G_Loss:3.113142251968384

iterator 4800, D_Loss:0.7001866698265076, G_Loss:3.688502311706543

iterator 4900, D_Loss:0.9050478339195251, G_Loss:3.3189523220062256

iterator 5000, D_Loss:0.814712405204773, G_Loss:3.9638466835021973

-----------Epoch 7-----------
iterator 100, D_Loss:0.7816401720046997, G_Loss:3.916079521179199

iterator 200, D_Loss:0.8627886772155762, G_Loss:3.466982841491699

iterator 300, D_Loss:0.8211897611618042, G_Loss:3.278332471847534

iterator 400, D_Loss:0.8836495876312256, G_Loss:3.7041542530059814

iterator 500, D_Loss:0.7842174768447876, G_Loss:3.533909797668457

iterator 600, D_Loss:0.9606548547744751, G_Loss:3.302910566329956

iterator 700, D_Loss:0.8284231424331665, G_Loss:3.450739622116089

iterator 800, D_Loss:0.7043571472167969, G_Loss:3.2641615867614746

iterator 900, D_Loss:0.8142527937889099, G_Loss:3.3851239681243896

iterator 1000, D_Loss:0.7340251803398132, G_Loss:3.520866870880127

iterator 1100, D_Loss:0.7427513599395752, G_Loss:3.0824713706970215

iterator 1200, D_Loss:0.7566631436347961, G_Loss:3.485098361968994

iterator 1300, D_Loss:0.7812025547027588, G_Loss:3.4475150108337402

iterator 1400, D_Loss:0.7979744672775269, G_Loss:3.4232683181762695

iterator 1500, D_Loss:0.8028091192245483, G_Loss:3.2845418453216553

iterator 1600, D_Loss:0.693347692489624, G_Loss:3.5693464279174805

iterator 1700, D_Loss:0.9223344326019287, G_Loss:3.690300464630127

iterator 1800, D_Loss:0.8541603088378906, G_Loss:3.416360378265381

iterator 1900, D_Loss:0.8348121643066406, G_Loss:3.1232972145080566

iterator 2000, D_Loss:0.827318012714386, G_Loss:3.485389232635498

iterator 2100, D_Loss:0.8415765762329102, G_Loss:3.497211217880249

iterator 2200, D_Loss:0.6914156079292297, G_Loss:3.203401803970337

iterator 2300, D_Loss:0.8725849986076355, G_Loss:3.27400279045105

iterator 2400, D_Loss:0.7053455114364624, G_Loss:3.2571353912353516

iterator 2500, D_Loss:0.693654477596283, G_Loss:3.7312259674072266

iterator 2600, D_Loss:0.7903328537940979, G_Loss:3.803600311279297

iterator 2700, D_Loss:0.8184245824813843, G_Loss:3.5084965229034424

iterator 2800, D_Loss:0.7904956340789795, G_Loss:3.6305713653564453

iterator 2900, D_Loss:0.7865331172943115, G_Loss:3.205092191696167

iterator 3000, D_Loss:0.821032702922821, G_Loss:2.81607985496521

iterator 3100, D_Loss:0.7829115986824036, G_Loss:3.0741236209869385

iterator 3200, D_Loss:0.6823195815086365, G_Loss:3.623377799987793

iterator 3300, D_Loss:0.8354818224906921, G_Loss:3.689628839492798

iterator 3400, D_Loss:0.774083137512207, G_Loss:3.1268324851989746

iterator 3500, D_Loss:0.7720547914505005, G_Loss:3.1027636528015137

iterator 3600, D_Loss:0.8068547248840332, G_Loss:3.706493377685547

iterator 3700, D_Loss:0.7620993852615356, G_Loss:3.5734920501708984

iterator 3800, D_Loss:0.7459901571273804, G_Loss:3.1885030269622803

iterator 3900, D_Loss:0.854656994342804, G_Loss:4.0835089683532715

iterator 4000, D_Loss:0.7591636776924133, G_Loss:3.3081929683685303

iterator 4100, D_Loss:0.7845137715339661, G_Loss:3.5017852783203125

iterator 4200, D_Loss:0.7366828918457031, G_Loss:2.817955732345581

iterator 4300, D_Loss:0.8236329555511475, G_Loss:3.039813280105591

iterator 4400, D_Loss:0.7946840524673462, G_Loss:3.6736061573028564

iterator 4500, D_Loss:0.7967393398284912, G_Loss:2.8559694290161133

iterator 4600, D_Loss:0.7642531394958496, G_Loss:3.589258909225464

iterator 4700, D_Loss:0.7573416233062744, G_Loss:3.470799684524536

iterator 4800, D_Loss:0.7521828413009644, G_Loss:3.179546356201172

iterator 4900, D_Loss:0.7593178749084473, G_Loss:3.6943180561065674

iterator 5000, D_Loss:0.7814716696739197, G_Loss:3.4724972248077393

-----------Epoch 8-----------
iterator 100, D_Loss:0.8023951053619385, G_Loss:3.20763897895813

iterator 200, D_Loss:0.8176798820495605, G_Loss:4.404271125793457

iterator 300, D_Loss:0.8335807919502258, G_Loss:3.396754026412964

iterator 400, D_Loss:0.7675407528877258, G_Loss:3.473680257797241

iterator 500, D_Loss:0.7890710830688477, G_Loss:3.360891342163086

iterator 600, D_Loss:0.8107263445854187, G_Loss:3.445760488510132

iterator 700, D_Loss:0.8003140687942505, G_Loss:2.8989999294281006

iterator 800, D_Loss:0.7477766275405884, G_Loss:3.387632369995117

iterator 900, D_Loss:0.8318948149681091, G_Loss:3.3579540252685547

iterator 1000, D_Loss:0.8535125255584717, G_Loss:3.4380950927734375

iterator 1100, D_Loss:0.7550053596496582, G_Loss:3.2044949531555176

iterator 1200, D_Loss:0.8131725788116455, G_Loss:3.252737283706665

iterator 1300, D_Loss:0.8386658430099487, G_Loss:2.878251552581787

iterator 1400, D_Loss:0.8316829204559326, G_Loss:3.496415853500366

iterator 1500, D_Loss:0.7950478792190552, G_Loss:3.389946937561035

iterator 1600, D_Loss:0.8967006206512451, G_Loss:3.6875553131103516

iterator 1700, D_Loss:0.7494368553161621, G_Loss:3.2080442905426025

iterator 1800, D_Loss:0.7996847629547119, G_Loss:3.3027405738830566

iterator 1900, D_Loss:0.796879768371582, G_Loss:2.9306304454803467

iterator 2000, D_Loss:0.7709988951683044, G_Loss:3.1359548568725586

iterator 2100, D_Loss:0.7909018993377686, G_Loss:3.09224271774292

iterator 2200, D_Loss:0.8335414528846741, G_Loss:3.305198907852173

iterator 2300, D_Loss:0.770086407661438, G_Loss:3.615400791168213

iterator 2400, D_Loss:0.7275422215461731, G_Loss:2.9687585830688477

iterator 2500, D_Loss:0.8175313472747803, G_Loss:3.1747231483459473

iterator 2600, D_Loss:0.7660112380981445, G_Loss:3.3195464611053467

iterator 2700, D_Loss:0.8449345827102661, G_Loss:4.211662292480469

iterator 2800, D_Loss:0.9150810241699219, G_Loss:3.4970884323120117

iterator 2900, D_Loss:0.7972453236579895, G_Loss:3.1718599796295166

iterator 3000, D_Loss:0.735304057598114, G_Loss:3.7378039360046387

iterator 3100, D_Loss:0.788926362991333, G_Loss:3.285301923751831

iterator 3200, D_Loss:0.8137232065200806, G_Loss:3.4829626083374023

iterator 3300, D_Loss:0.7509303092956543, G_Loss:4.2191853523254395

iterator 3400, D_Loss:0.8056280612945557, G_Loss:3.602609157562256

iterator 3500, D_Loss:0.7789081335067749, G_Loss:4.044776439666748

iterator 3600, D_Loss:0.7706142663955688, G_Loss:3.360393524169922

iterator 3700, D_Loss:0.8483840227127075, G_Loss:3.138213634490967

iterator 3800, D_Loss:0.8005989789962769, G_Loss:3.584453582763672

iterator 3900, D_Loss:0.8203817009925842, G_Loss:3.665698766708374

iterator 4000, D_Loss:0.7407859563827515, G_Loss:3.5782506465911865

iterator 4100, D_Loss:0.7708144187927246, G_Loss:3.184960126876831

iterator 4200, D_Loss:0.7906018495559692, G_Loss:3.107125997543335

iterator 4300, D_Loss:0.8537184596061707, G_Loss:3.0003905296325684

iterator 4400, D_Loss:0.7968722581863403, G_Loss:3.148313045501709

iterator 4500, D_Loss:0.7908608913421631, G_Loss:2.9665708541870117

iterator 4600, D_Loss:0.8214190602302551, G_Loss:3.8174071311950684

iterator 4700, D_Loss:0.8102166056632996, G_Loss:3.2980191707611084

iterator 4800, D_Loss:0.8200256824493408, G_Loss:3.160348653793335

iterator 4900, D_Loss:0.7320727705955505, G_Loss:3.1147680282592773

iterator 5000, D_Loss:0.860066831111908, G_Loss:3.3741989135742188

-----------Epoch 9-----------
iterator 100, D_Loss:0.8800848126411438, G_Loss:3.521597385406494

iterator 200, D_Loss:0.7894766926765442, G_Loss:4.1482768058776855

iterator 300, D_Loss:0.7683466672897339, G_Loss:3.0743236541748047

iterator 400, D_Loss:0.7436090707778931, G_Loss:3.592672109603882

iterator 500, D_Loss:0.7491037845611572, G_Loss:3.0468976497650146

iterator 600, D_Loss:0.7561097145080566, G_Loss:3.3400187492370605

iterator 700, D_Loss:0.7913298010826111, G_Loss:4.203283786773682

iterator 800, D_Loss:0.8613045811653137, G_Loss:2.8980095386505127

iterator 900, D_Loss:0.7634875774383545, G_Loss:3.2444875240325928

iterator 1000, D_Loss:0.7634667158126831, G_Loss:3.2925775051116943

iterator 1100, D_Loss:0.6740497946739197, G_Loss:3.7819550037384033

iterator 1200, D_Loss:0.7775166034698486, G_Loss:2.9800000190734863

iterator 1300, D_Loss:0.7617692947387695, G_Loss:3.769484043121338

iterator 1400, D_Loss:0.8356474041938782, G_Loss:4.035904884338379

iterator 1500, D_Loss:0.80782151222229, G_Loss:2.896718978881836

iterator 1600, D_Loss:0.7611804008483887, G_Loss:3.1347463130950928

iterator 1700, D_Loss:0.917599081993103, G_Loss:3.243957281112671

iterator 1800, D_Loss:0.7869468927383423, G_Loss:2.922044515609741

iterator 1900, D_Loss:0.8842802047729492, G_Loss:3.3715097904205322

iterator 2000, D_Loss:0.8022160530090332, G_Loss:3.6908507347106934

iterator 2100, D_Loss:0.7341052889823914, G_Loss:3.942986011505127

iterator 2200, D_Loss:0.7912070155143738, G_Loss:3.6042425632476807

iterator 2300, D_Loss:0.761661171913147, G_Loss:3.4957821369171143

iterator 2400, D_Loss:0.8265690207481384, G_Loss:2.8236782550811768

iterator 2500, D_Loss:0.8336889147758484, G_Loss:3.459853172302246

iterator 2600, D_Loss:0.8150947690010071, G_Loss:3.539196014404297

iterator 2700, D_Loss:0.854989767074585, G_Loss:3.561434268951416

iterator 2800, D_Loss:0.7706974744796753, G_Loss:3.2175230979919434

iterator 2900, D_Loss:0.7863272428512573, G_Loss:3.170391321182251

iterator 3000, D_Loss:0.8192927837371826, G_Loss:3.1846210956573486

iterator 3100, D_Loss:0.7599023580551147, G_Loss:3.6490769386291504

iterator 3200, D_Loss:0.8643486499786377, G_Loss:3.4191181659698486

iterator 3300, D_Loss:0.752619743347168, G_Loss:3.811612844467163

iterator 3400, D_Loss:0.7371022701263428, G_Loss:3.126681327819824

iterator 3500, D_Loss:0.866035521030426, G_Loss:3.2966973781585693

iterator 3600, D_Loss:0.9132220149040222, G_Loss:3.760544538497925

iterator 3700, D_Loss:0.7343543171882629, G_Loss:3.6445472240448

iterator 3800, D_Loss:0.7938014268875122, G_Loss:3.376110315322876

iterator 3900, D_Loss:0.8541759848594666, G_Loss:3.3691060543060303

iterator 4000, D_Loss:0.783470869064331, G_Loss:3.1527793407440186

iterator 4100, D_Loss:0.7782306671142578, G_Loss:4.227633953094482

iterator 4200, D_Loss:0.7193858027458191, G_Loss:3.7502636909484863

iterator 4300, D_Loss:0.7248052358627319, G_Loss:3.221167802810669

iterator 4400, D_Loss:0.8600324988365173, G_Loss:3.6325314044952393

iterator 4500, D_Loss:0.8588661551475525, G_Loss:2.803114891052246

iterator 4600, D_Loss:0.875964343547821, G_Loss:3.789515256881714

iterator 4700, D_Loss:0.7931303977966309, G_Loss:3.4511377811431885

iterator 4800, D_Loss:0.8585470914840698, G_Loss:3.402211904525757

iterator 4900, D_Loss:0.8582266569137573, G_Loss:3.5019710063934326

iterator 5000, D_Loss:0.8148415088653564, G_Loss:3.238090991973877

VGAN_generator(
  (input): Linear(in_features=128, out_features=200, bias=True)
  (inputbn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (bn0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=200, out_features=200, bias=True)
  (bn1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=200, out_features=200, bias=True)
  (bn2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=200, out_features=45, bias=True)
  (outputbn): BatchNorm1d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=45, out_features=300, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=300, out_features=300, bias=True)
  (fc1): Linear(in_features=300, out_features=300, bias=True)
  (output): Linear(in_features=300, out_features=1, bias=True)
)
(0, False, 45)
-----------Epoch 0-----------
iterator 100, D_Loss:0.5319156050682068, G_Loss:8.826647758483887

iterator 200, D_Loss:0.45860034227371216, G_Loss:11.366049766540527

iterator 300, D_Loss:0.44867581129074097, G_Loss:11.78145980834961

iterator 400, D_Loss:0.47178366780281067, G_Loss:11.177865982055664

iterator 500, D_Loss:0.4436870515346527, G_Loss:10.954803466796875

iterator 600, D_Loss:0.4583820402622223, G_Loss:10.091963768005371

iterator 700, D_Loss:0.4439013600349426, G_Loss:11.060548782348633

iterator 800, D_Loss:0.4591464698314667, G_Loss:9.993831634521484

iterator 900, D_Loss:0.4720916450023651, G_Loss:9.924511909484863

iterator 1000, D_Loss:0.4589235782623291, G_Loss:9.171764373779297

iterator 1100, D_Loss:0.47558286786079407, G_Loss:8.656327247619629

iterator 1200, D_Loss:0.4674709439277649, G_Loss:9.090579986572266

iterator 1300, D_Loss:0.46324002742767334, G_Loss:8.466856002807617

iterator 1400, D_Loss:0.4789621829986572, G_Loss:8.80502700805664

iterator 1500, D_Loss:0.44348520040512085, G_Loss:8.960306167602539

iterator 1600, D_Loss:0.47621503472328186, G_Loss:8.28718376159668

iterator 1700, D_Loss:0.5106648802757263, G_Loss:8.007962226867676

iterator 1800, D_Loss:0.5224875807762146, G_Loss:7.615174293518066

iterator 1900, D_Loss:0.48325711488723755, G_Loss:8.025914192199707

iterator 2000, D_Loss:0.47880658507347107, G_Loss:7.537208080291748

iterator 2100, D_Loss:0.45502328872680664, G_Loss:6.904603004455566

iterator 2200, D_Loss:0.4786040186882019, G_Loss:7.951840400695801

iterator 2300, D_Loss:0.5073041915893555, G_Loss:7.122215747833252

iterator 2400, D_Loss:0.47947609424591064, G_Loss:6.990530014038086

iterator 2500, D_Loss:0.475124716758728, G_Loss:7.868285179138184

iterator 2600, D_Loss:0.49400267004966736, G_Loss:7.1870527267456055

iterator 2700, D_Loss:0.4912276566028595, G_Loss:6.679867744445801

iterator 2800, D_Loss:0.5136287212371826, G_Loss:7.258345127105713

iterator 2900, D_Loss:0.47107750177383423, G_Loss:7.00841760635376

iterator 3000, D_Loss:0.5001519322395325, G_Loss:6.685588359832764

iterator 3100, D_Loss:0.4937038719654083, G_Loss:6.237168788909912

iterator 3200, D_Loss:0.5300773978233337, G_Loss:6.101341247558594

iterator 3300, D_Loss:0.534531831741333, G_Loss:6.153316020965576

iterator 3400, D_Loss:0.5151747465133667, G_Loss:7.143945693969727

iterator 3500, D_Loss:0.5053038597106934, G_Loss:6.440452575683594

iterator 3600, D_Loss:0.5208052396774292, G_Loss:6.1562275886535645

iterator 3700, D_Loss:0.5672975778579712, G_Loss:6.3299102783203125

iterator 3800, D_Loss:0.5232465267181396, G_Loss:6.434794902801514

iterator 3900, D_Loss:0.5093272924423218, G_Loss:5.52048921585083

iterator 4000, D_Loss:0.5104770660400391, G_Loss:5.829801082611084

iterator 4100, D_Loss:0.49821537733078003, G_Loss:5.88827657699585

iterator 4200, D_Loss:0.5626945495605469, G_Loss:5.375992774963379

iterator 4300, D_Loss:0.5751729011535645, G_Loss:5.524209499359131

iterator 4400, D_Loss:0.5405676364898682, G_Loss:5.313450336456299

iterator 4500, D_Loss:0.6006428003311157, G_Loss:5.095046520233154

iterator 4600, D_Loss:0.6167827248573303, G_Loss:4.771393775939941

iterator 4700, D_Loss:0.5350143909454346, G_Loss:5.073022365570068

iterator 4800, D_Loss:0.5382516384124756, G_Loss:5.190219402313232

iterator 4900, D_Loss:0.5540099143981934, G_Loss:5.395218849182129

iterator 5000, D_Loss:0.5421465635299683, G_Loss:5.079502105712891

-----------Epoch 1-----------
iterator 100, D_Loss:0.5999680161476135, G_Loss:5.094348907470703

iterator 200, D_Loss:0.6068145036697388, G_Loss:5.628976821899414

iterator 300, D_Loss:0.553713321685791, G_Loss:4.7514967918396

iterator 400, D_Loss:0.6090257167816162, G_Loss:4.623469829559326

iterator 500, D_Loss:0.5612460374832153, G_Loss:5.1057353019714355

iterator 600, D_Loss:0.5982646942138672, G_Loss:4.809843063354492

iterator 700, D_Loss:0.6109540462493896, G_Loss:4.800821781158447

iterator 800, D_Loss:0.5911864042282104, G_Loss:5.1355366706848145

iterator 900, D_Loss:0.6262232661247253, G_Loss:4.836191177368164

iterator 1000, D_Loss:0.5965460538864136, G_Loss:4.843441009521484

iterator 1100, D_Loss:0.5832123160362244, G_Loss:4.674347877502441

iterator 1200, D_Loss:0.6839377880096436, G_Loss:4.2913689613342285

iterator 1300, D_Loss:0.580406665802002, G_Loss:4.748658657073975

iterator 1400, D_Loss:0.6007786989212036, G_Loss:4.336203575134277

iterator 1500, D_Loss:0.6165552735328674, G_Loss:4.77801513671875

iterator 1600, D_Loss:0.6116409301757812, G_Loss:4.758822917938232

iterator 1700, D_Loss:0.6210809946060181, G_Loss:4.561557292938232

iterator 1800, D_Loss:0.6410980224609375, G_Loss:4.372298240661621

iterator 1900, D_Loss:0.589157223701477, G_Loss:4.766068458557129

iterator 2000, D_Loss:0.6063028573989868, G_Loss:4.521966934204102

iterator 2100, D_Loss:0.6160756945610046, G_Loss:4.291072845458984

iterator 2200, D_Loss:0.600411057472229, G_Loss:4.430917739868164

iterator 2300, D_Loss:0.5826079249382019, G_Loss:4.443530559539795

iterator 2400, D_Loss:0.6122052073478699, G_Loss:4.383630752563477

iterator 2500, D_Loss:0.6106558442115784, G_Loss:4.258038520812988

iterator 2600, D_Loss:0.6284447312355042, G_Loss:3.963989734649658

iterator 2700, D_Loss:0.656112551689148, G_Loss:4.155757427215576

iterator 2800, D_Loss:0.6403620839118958, G_Loss:3.843557119369507

iterator 2900, D_Loss:0.6503584384918213, G_Loss:4.260081768035889

iterator 3000, D_Loss:0.6762822270393372, G_Loss:3.958688974380493

iterator 3100, D_Loss:0.6462555527687073, G_Loss:3.9307751655578613

iterator 3200, D_Loss:0.6566466093063354, G_Loss:4.12410831451416

iterator 3300, D_Loss:0.6597920060157776, G_Loss:3.9665091037750244

iterator 3400, D_Loss:0.6384642720222473, G_Loss:4.14471435546875

iterator 3500, D_Loss:0.6995983719825745, G_Loss:3.9843835830688477

iterator 3600, D_Loss:0.6385830044746399, G_Loss:4.241524696350098

iterator 3700, D_Loss:0.6414951682090759, G_Loss:3.8201496601104736

iterator 3800, D_Loss:0.6199013590812683, G_Loss:4.1879754066467285

iterator 3900, D_Loss:0.6885765790939331, G_Loss:3.7821807861328125

iterator 4000, D_Loss:0.6967215538024902, G_Loss:3.6513922214508057

iterator 4100, D_Loss:0.6712163686752319, G_Loss:4.124020576477051

iterator 4200, D_Loss:0.6663167476654053, G_Loss:3.7881271839141846

iterator 4300, D_Loss:0.6549052000045776, G_Loss:3.816134452819824

iterator 4400, D_Loss:0.6774866580963135, G_Loss:3.622549295425415

iterator 4500, D_Loss:0.701261043548584, G_Loss:3.6713175773620605

iterator 4600, D_Loss:0.6490421891212463, G_Loss:3.8767850399017334

iterator 4700, D_Loss:0.7005041837692261, G_Loss:3.8682363033294678

iterator 4800, D_Loss:0.6560888886451721, G_Loss:3.7589240074157715

iterator 4900, D_Loss:0.7135661840438843, G_Loss:3.6732335090637207

iterator 5000, D_Loss:0.711317777633667, G_Loss:3.5910818576812744

-----------Epoch 2-----------
iterator 100, D_Loss:0.6836128830909729, G_Loss:3.705432176589966

iterator 200, D_Loss:0.7192130088806152, G_Loss:3.5294277667999268

iterator 300, D_Loss:0.7212957143783569, G_Loss:3.6921768188476562

iterator 400, D_Loss:0.6799154877662659, G_Loss:3.7232601642608643

iterator 500, D_Loss:0.6898921728134155, G_Loss:3.591762065887451

iterator 600, D_Loss:0.7128868699073792, G_Loss:3.4890527725219727

iterator 700, D_Loss:0.7183905839920044, G_Loss:3.524609088897705

iterator 800, D_Loss:0.6928125619888306, G_Loss:3.792793035507202

iterator 900, D_Loss:0.6647036671638489, G_Loss:3.6123414039611816

iterator 1000, D_Loss:0.7462092041969299, G_Loss:3.365760326385498

iterator 1100, D_Loss:0.7570210695266724, G_Loss:3.3422393798828125

iterator 1200, D_Loss:0.7673055529594421, G_Loss:3.189100980758667

iterator 1300, D_Loss:0.724449634552002, G_Loss:3.9688549041748047

iterator 1400, D_Loss:0.7088704109191895, G_Loss:3.414597988128662

iterator 1500, D_Loss:0.6846027374267578, G_Loss:3.621781826019287

iterator 1600, D_Loss:0.7697439789772034, G_Loss:3.454899311065674

iterator 1700, D_Loss:0.7208686470985413, G_Loss:3.749562978744507

iterator 1800, D_Loss:0.7158972024917603, G_Loss:3.6885414123535156

iterator 1900, D_Loss:0.6983799934387207, G_Loss:3.3498358726501465

iterator 2000, D_Loss:0.7047759294509888, G_Loss:3.5782711505889893

iterator 2100, D_Loss:0.7063505053520203, G_Loss:3.253077507019043

iterator 2200, D_Loss:0.7607865333557129, G_Loss:3.047637701034546

iterator 2300, D_Loss:0.7125765681266785, G_Loss:3.789003849029541

iterator 2400, D_Loss:0.7525996565818787, G_Loss:3.5803921222686768

iterator 2500, D_Loss:0.7089998722076416, G_Loss:4.00406551361084

iterator 2600, D_Loss:0.7246869206428528, G_Loss:3.31931209564209

iterator 2700, D_Loss:0.7577371597290039, G_Loss:3.558048963546753

iterator 2800, D_Loss:0.7370374798774719, G_Loss:3.203611135482788

iterator 2900, D_Loss:0.703567624092102, G_Loss:3.4381258487701416

iterator 3000, D_Loss:0.7619295716285706, G_Loss:3.5199990272521973

iterator 3100, D_Loss:0.6957153081893921, G_Loss:3.7738022804260254

iterator 3200, D_Loss:0.7323307991027832, G_Loss:3.9393255710601807

iterator 3300, D_Loss:0.6931240558624268, G_Loss:3.9512805938720703

iterator 3400, D_Loss:0.7775403261184692, G_Loss:3.557176113128662

iterator 3500, D_Loss:0.7204994559288025, G_Loss:3.7561302185058594

iterator 3600, D_Loss:0.6907739043235779, G_Loss:3.4400269985198975

iterator 3700, D_Loss:0.7169073224067688, G_Loss:3.378260612487793

iterator 3800, D_Loss:0.7370088696479797, G_Loss:3.863842010498047

iterator 3900, D_Loss:0.6869426965713501, G_Loss:3.5956013202667236

iterator 4000, D_Loss:0.726950466632843, G_Loss:3.829765796661377

iterator 4100, D_Loss:0.6750131249427795, G_Loss:3.6621499061584473

iterator 4200, D_Loss:0.7039070129394531, G_Loss:3.6172327995300293

iterator 4300, D_Loss:0.6598734855651855, G_Loss:3.979909658432007

iterator 4400, D_Loss:0.631833016872406, G_Loss:3.656909942626953

iterator 4500, D_Loss:0.6700692772865295, G_Loss:3.9531404972076416

iterator 4600, D_Loss:0.7351041436195374, G_Loss:3.3467001914978027

iterator 4700, D_Loss:0.6633504033088684, G_Loss:3.776865243911743

iterator 4800, D_Loss:0.7140293121337891, G_Loss:3.8611998558044434

iterator 4900, D_Loss:0.6677988767623901, G_Loss:3.4728612899780273

iterator 5000, D_Loss:0.6672243475914001, G_Loss:3.5059304237365723

-----------Epoch 3-----------
iterator 100, D_Loss:0.7394646406173706, G_Loss:3.6979119777679443

iterator 200, D_Loss:0.6573635339736938, G_Loss:3.812730073928833

iterator 300, D_Loss:0.6880640387535095, G_Loss:3.835285186767578

iterator 400, D_Loss:0.7329747080802917, G_Loss:3.6431868076324463

iterator 500, D_Loss:0.7499404549598694, G_Loss:3.3698923587799072

iterator 600, D_Loss:0.71729975938797, G_Loss:3.6671411991119385

iterator 700, D_Loss:0.7178038954734802, G_Loss:3.6042439937591553

iterator 800, D_Loss:0.644512414932251, G_Loss:3.6624393463134766

iterator 900, D_Loss:0.6790867447853088, G_Loss:3.575080156326294

iterator 1000, D_Loss:0.7235274910926819, G_Loss:3.537706136703491

iterator 1100, D_Loss:0.6285364031791687, G_Loss:3.550381660461426

iterator 1200, D_Loss:0.6730063557624817, G_Loss:3.41896653175354

iterator 1300, D_Loss:0.7132931351661682, G_Loss:3.8625099658966064

iterator 1400, D_Loss:0.7027523517608643, G_Loss:3.425785779953003

iterator 1500, D_Loss:0.7257086038589478, G_Loss:3.535916328430176

iterator 1600, D_Loss:0.7236509323120117, G_Loss:3.820981979370117

iterator 1700, D_Loss:0.6775160431861877, G_Loss:3.8576085567474365

iterator 1800, D_Loss:0.7224974036216736, G_Loss:3.7595784664154053

iterator 1900, D_Loss:0.6294682621955872, G_Loss:3.571920394897461

iterator 2000, D_Loss:0.744497537612915, G_Loss:3.4379758834838867

iterator 2100, D_Loss:0.669603168964386, G_Loss:3.5595014095306396

iterator 2200, D_Loss:0.6455802321434021, G_Loss:3.6177186965942383

iterator 2300, D_Loss:0.685526967048645, G_Loss:3.7650036811828613

iterator 2400, D_Loss:0.7285714149475098, G_Loss:3.6075735092163086

iterator 2500, D_Loss:0.6669024229049683, G_Loss:3.658146858215332

iterator 2600, D_Loss:0.707976758480072, G_Loss:3.7903356552124023

iterator 2700, D_Loss:0.7281584739685059, G_Loss:3.695266008377075

iterator 2800, D_Loss:0.6457281708717346, G_Loss:3.9362049102783203

iterator 2900, D_Loss:0.7191475629806519, G_Loss:3.6232776641845703

iterator 3000, D_Loss:0.6533889770507812, G_Loss:3.839590072631836

iterator 3100, D_Loss:0.6379101276397705, G_Loss:3.738590955734253

iterator 3200, D_Loss:0.7027538418769836, G_Loss:3.5271825790405273

iterator 3300, D_Loss:0.6941925287246704, G_Loss:4.167916297912598

iterator 3400, D_Loss:0.7046908140182495, G_Loss:3.5011162757873535

iterator 3500, D_Loss:0.6667007207870483, G_Loss:3.7063064575195312

iterator 3600, D_Loss:0.6761826276779175, G_Loss:3.143583059310913

iterator 3700, D_Loss:0.6974684000015259, G_Loss:3.7093682289123535

iterator 3800, D_Loss:0.6673771739006042, G_Loss:3.7989470958709717

iterator 3900, D_Loss:0.7194474935531616, G_Loss:4.218964099884033

iterator 4000, D_Loss:0.6841938495635986, G_Loss:3.723482608795166

iterator 4100, D_Loss:0.7030183672904968, G_Loss:3.7075119018554688

iterator 4200, D_Loss:0.6798436641693115, G_Loss:3.695725917816162

iterator 4300, D_Loss:0.6503348350524902, G_Loss:3.8171017169952393

iterator 4400, D_Loss:0.6949164271354675, G_Loss:3.671339273452759

iterator 4500, D_Loss:0.6169039607048035, G_Loss:3.786817789077759

iterator 4600, D_Loss:0.6790086030960083, G_Loss:3.643794059753418

iterator 4700, D_Loss:0.696556031703949, G_Loss:3.695172071456909

iterator 4800, D_Loss:0.7409456372261047, G_Loss:3.707599401473999

iterator 4900, D_Loss:0.703914999961853, G_Loss:3.5584964752197266

iterator 5000, D_Loss:0.6770828366279602, G_Loss:3.6614301204681396

-----------Epoch 4-----------
iterator 100, D_Loss:0.6735354065895081, G_Loss:3.7112715244293213

iterator 200, D_Loss:0.68379807472229, G_Loss:3.7977917194366455

iterator 300, D_Loss:0.6719146370887756, G_Loss:3.9190216064453125

iterator 400, D_Loss:0.7454915046691895, G_Loss:3.511969566345215

iterator 500, D_Loss:0.7017722725868225, G_Loss:4.027037143707275

iterator 600, D_Loss:0.6951496601104736, G_Loss:3.7371132373809814

iterator 700, D_Loss:0.752181351184845, G_Loss:3.4562110900878906

iterator 800, D_Loss:0.7119067907333374, G_Loss:3.5912814140319824

iterator 900, D_Loss:0.656747579574585, G_Loss:4.029431343078613

iterator 1000, D_Loss:0.7228283882141113, G_Loss:3.553663492202759

iterator 1100, D_Loss:0.6719818115234375, G_Loss:3.968658447265625

iterator 1200, D_Loss:0.703965961933136, G_Loss:3.8154635429382324

iterator 1300, D_Loss:0.7247602939605713, G_Loss:3.5686213970184326

iterator 1400, D_Loss:0.7244473099708557, G_Loss:3.530272960662842

iterator 1500, D_Loss:0.728026807308197, G_Loss:3.580411434173584

iterator 1600, D_Loss:0.7330875396728516, G_Loss:3.8630619049072266

iterator 1700, D_Loss:0.6627820134162903, G_Loss:3.712336540222168

iterator 1800, D_Loss:0.6967560648918152, G_Loss:3.767568588256836

iterator 1900, D_Loss:0.6669048070907593, G_Loss:3.583526611328125

iterator 2000, D_Loss:0.6730816960334778, G_Loss:4.081131458282471

iterator 2100, D_Loss:0.711679220199585, G_Loss:3.691019296646118

iterator 2200, D_Loss:0.690254807472229, G_Loss:3.791081428527832

iterator 2300, D_Loss:0.6900033950805664, G_Loss:3.40629506111145

iterator 2400, D_Loss:0.7205931544303894, G_Loss:3.9718220233917236

iterator 2500, D_Loss:0.6828374862670898, G_Loss:4.0326666831970215

iterator 2600, D_Loss:0.6835043430328369, G_Loss:3.6412479877471924

iterator 2700, D_Loss:0.710659384727478, G_Loss:3.7566070556640625

iterator 2800, D_Loss:0.6831992864608765, G_Loss:3.4961390495300293

iterator 2900, D_Loss:0.6649090051651001, G_Loss:3.7092349529266357

iterator 3000, D_Loss:0.7045385241508484, G_Loss:3.6015658378601074

iterator 3100, D_Loss:0.7166882753372192, G_Loss:3.685467004776001

iterator 3200, D_Loss:0.6841177940368652, G_Loss:3.7549924850463867

iterator 3300, D_Loss:0.6904060244560242, G_Loss:3.5757248401641846

iterator 3400, D_Loss:0.7350035905838013, G_Loss:3.6344423294067383

iterator 3500, D_Loss:0.7182332277297974, G_Loss:3.495943307876587

iterator 3600, D_Loss:0.6722093224525452, G_Loss:3.7369773387908936

iterator 3700, D_Loss:0.7366459369659424, G_Loss:3.7776870727539062

iterator 3800, D_Loss:0.6956393718719482, G_Loss:3.6079726219177246

iterator 3900, D_Loss:0.6831750869750977, G_Loss:3.831533193588257

iterator 4000, D_Loss:0.74534010887146, G_Loss:3.801964044570923

iterator 4100, D_Loss:0.6957060098648071, G_Loss:3.9763119220733643

iterator 4200, D_Loss:0.6973219513893127, G_Loss:3.9208462238311768

iterator 4300, D_Loss:0.6941958665847778, G_Loss:3.6400232315063477

iterator 4400, D_Loss:0.7251726388931274, G_Loss:4.052274703979492

iterator 4500, D_Loss:0.6515546441078186, G_Loss:3.65205717086792

iterator 4600, D_Loss:0.6858448386192322, G_Loss:3.75417160987854

iterator 4700, D_Loss:0.7662686109542847, G_Loss:3.5654115676879883

iterator 4800, D_Loss:0.6803417205810547, G_Loss:3.8245627880096436

iterator 4900, D_Loss:0.7334209680557251, G_Loss:4.0575079917907715

iterator 5000, D_Loss:0.6950199007987976, G_Loss:3.7096197605133057

-----------Epoch 5-----------
iterator 100, D_Loss:0.7115805745124817, G_Loss:3.752915143966675

iterator 200, D_Loss:0.6981146335601807, G_Loss:3.818981647491455

iterator 300, D_Loss:0.6248675584793091, G_Loss:4.007665157318115

iterator 400, D_Loss:0.6946614384651184, G_Loss:4.054532051086426

iterator 500, D_Loss:0.7412890195846558, G_Loss:3.3451409339904785

iterator 600, D_Loss:0.7115565538406372, G_Loss:3.8193774223327637

iterator 700, D_Loss:0.7113518714904785, G_Loss:3.7118189334869385

iterator 800, D_Loss:0.6950975060462952, G_Loss:3.9129974842071533

iterator 900, D_Loss:0.7092212438583374, G_Loss:3.8207757472991943

iterator 1000, D_Loss:0.6951934695243835, G_Loss:3.469184398651123

iterator 1100, D_Loss:0.6884849071502686, G_Loss:3.458892583847046

iterator 1200, D_Loss:0.6975548267364502, G_Loss:3.523862600326538

iterator 1300, D_Loss:0.6831836104393005, G_Loss:3.563246726989746

iterator 1400, D_Loss:0.7146618962287903, G_Loss:3.3718631267547607

iterator 1500, D_Loss:0.7066178321838379, G_Loss:3.6367006301879883

iterator 1600, D_Loss:0.7031505703926086, G_Loss:3.60895037651062

iterator 1700, D_Loss:0.7055232524871826, G_Loss:3.8142151832580566

iterator 1800, D_Loss:0.7024261951446533, G_Loss:3.705440044403076

iterator 1900, D_Loss:0.7220320701599121, G_Loss:3.627595901489258

iterator 2000, D_Loss:0.6473283767700195, G_Loss:3.7530741691589355

iterator 2100, D_Loss:0.6773930788040161, G_Loss:3.3769278526306152

iterator 2200, D_Loss:0.7683024406433105, G_Loss:3.945744752883911

iterator 2300, D_Loss:0.7516493201255798, G_Loss:3.4555301666259766

iterator 2400, D_Loss:0.705711841583252, G_Loss:3.406531810760498

iterator 2500, D_Loss:0.6657615303993225, G_Loss:3.817279815673828

iterator 2600, D_Loss:0.7352257966995239, G_Loss:3.7256646156311035

iterator 2700, D_Loss:0.705795407295227, G_Loss:3.5208449363708496

iterator 2800, D_Loss:0.7812937498092651, G_Loss:3.918388605117798

iterator 2900, D_Loss:0.7510613203048706, G_Loss:3.4034314155578613

iterator 3000, D_Loss:0.7344366312026978, G_Loss:3.957383394241333

iterator 3100, D_Loss:0.6533485651016235, G_Loss:3.7050387859344482

iterator 3200, D_Loss:0.7130630016326904, G_Loss:3.4438652992248535

iterator 3300, D_Loss:0.7476741075515747, G_Loss:4.038511753082275

iterator 3400, D_Loss:0.7320510149002075, G_Loss:3.5011370182037354

iterator 3500, D_Loss:0.7445921897888184, G_Loss:3.771455764770508

iterator 3600, D_Loss:0.7309569120407104, G_Loss:3.7821261882781982

iterator 3700, D_Loss:0.7183960676193237, G_Loss:3.3975868225097656

iterator 3800, D_Loss:0.6868139505386353, G_Loss:3.695990562438965

iterator 3900, D_Loss:0.7401489019393921, G_Loss:3.6072750091552734

iterator 4000, D_Loss:0.7044159173965454, G_Loss:3.6149730682373047

iterator 4100, D_Loss:0.7273098230361938, G_Loss:3.987269401550293

iterator 4200, D_Loss:0.7440861463546753, G_Loss:3.468564748764038

iterator 4300, D_Loss:0.7013868689537048, G_Loss:3.6566479206085205

iterator 4400, D_Loss:0.6869182586669922, G_Loss:3.7347450256347656

iterator 4500, D_Loss:0.7348021864891052, G_Loss:3.3604514598846436

iterator 4600, D_Loss:0.703012228012085, G_Loss:3.6134984493255615

iterator 4700, D_Loss:0.7378606200218201, G_Loss:3.7038755416870117

iterator 4800, D_Loss:0.7016026973724365, G_Loss:3.512439727783203

iterator 4900, D_Loss:0.699130654335022, G_Loss:3.3519608974456787

iterator 5000, D_Loss:0.7436602115631104, G_Loss:3.6736433506011963

-----------Epoch 6-----------
iterator 100, D_Loss:0.7263627052307129, G_Loss:3.5322439670562744

iterator 200, D_Loss:0.6964459419250488, G_Loss:3.290184259414673

iterator 300, D_Loss:0.7151129245758057, G_Loss:3.409841299057007

iterator 400, D_Loss:0.7350078821182251, G_Loss:3.3097362518310547

iterator 500, D_Loss:0.738021969795227, G_Loss:3.5320205688476562

iterator 600, D_Loss:0.7424787282943726, G_Loss:3.243216037750244

iterator 700, D_Loss:0.7112202048301697, G_Loss:3.51285457611084

iterator 800, D_Loss:0.7226032018661499, G_Loss:3.511366605758667

iterator 900, D_Loss:0.7362930774688721, G_Loss:3.626380443572998

iterator 1000, D_Loss:0.7347947955131531, G_Loss:3.579601526260376

iterator 1100, D_Loss:0.7460564374923706, G_Loss:3.436446189880371

iterator 1200, D_Loss:0.7224818468093872, G_Loss:3.4540977478027344

iterator 1300, D_Loss:0.747416615486145, G_Loss:3.520810842514038

iterator 1400, D_Loss:0.737827479839325, G_Loss:3.5449626445770264

iterator 1500, D_Loss:0.6970282196998596, G_Loss:3.8118743896484375

iterator 1600, D_Loss:0.7622178196907043, G_Loss:3.205195903778076

iterator 1700, D_Loss:0.7317132949829102, G_Loss:3.6294212341308594

iterator 1800, D_Loss:0.7046656608581543, G_Loss:3.291257619857788

iterator 1900, D_Loss:0.7127452492713928, G_Loss:3.622631788253784

iterator 2000, D_Loss:0.7169193625450134, G_Loss:3.4792075157165527

iterator 2100, D_Loss:0.7094311714172363, G_Loss:3.858257293701172

iterator 2200, D_Loss:0.7235105633735657, G_Loss:4.007436275482178

iterator 2300, D_Loss:0.7110503911972046, G_Loss:3.594796895980835

iterator 2400, D_Loss:0.7706497311592102, G_Loss:3.65450119972229

iterator 2500, D_Loss:0.6801640391349792, G_Loss:3.69649600982666

iterator 2600, D_Loss:0.705947995185852, G_Loss:4.0246262550354

iterator 2700, D_Loss:0.731034517288208, G_Loss:3.5377299785614014

iterator 2800, D_Loss:0.6931705474853516, G_Loss:3.8164148330688477

iterator 2900, D_Loss:0.7230036854743958, G_Loss:3.341636896133423

iterator 3000, D_Loss:0.7859504222869873, G_Loss:3.0446996688842773

iterator 3100, D_Loss:0.7246806621551514, G_Loss:3.526498317718506

iterator 3200, D_Loss:0.7657078504562378, G_Loss:3.273327350616455

iterator 3300, D_Loss:0.7432330846786499, G_Loss:4.0486907958984375

iterator 3400, D_Loss:0.738926351070404, G_Loss:3.5672638416290283

iterator 3500, D_Loss:0.713272750377655, G_Loss:3.4600465297698975

iterator 3600, D_Loss:0.7118306756019592, G_Loss:3.0992701053619385

iterator 3700, D_Loss:0.7253789901733398, G_Loss:3.3002915382385254

iterator 3800, D_Loss:0.7444279789924622, G_Loss:3.535672903060913

iterator 3900, D_Loss:0.7387296557426453, G_Loss:3.496655225753784

iterator 4000, D_Loss:0.7952486872673035, G_Loss:3.1345736980438232

iterator 4100, D_Loss:0.7193648815155029, G_Loss:3.6265175342559814

iterator 4200, D_Loss:0.7409998178482056, G_Loss:3.481091022491455

iterator 4300, D_Loss:0.6680006384849548, G_Loss:3.5899126529693604

iterator 4400, D_Loss:0.6952106952667236, G_Loss:3.604931116104126

iterator 4500, D_Loss:0.7490335702896118, G_Loss:3.651911973953247

iterator 4600, D_Loss:0.7663170099258423, G_Loss:3.089263916015625

iterator 4700, D_Loss:0.7482471466064453, G_Loss:3.7060751914978027

iterator 4800, D_Loss:0.7285903692245483, G_Loss:3.5227065086364746

iterator 4900, D_Loss:0.7296966910362244, G_Loss:3.574453353881836

iterator 5000, D_Loss:0.7082354426383972, G_Loss:3.571837902069092

-----------Epoch 7-----------
iterator 100, D_Loss:0.7412793040275574, G_Loss:3.289802074432373

iterator 200, D_Loss:0.7422149181365967, G_Loss:3.1137681007385254

iterator 300, D_Loss:0.7430039048194885, G_Loss:3.538557767868042

iterator 400, D_Loss:0.743677020072937, G_Loss:3.8569555282592773

iterator 500, D_Loss:0.7879964709281921, G_Loss:3.3554630279541016

iterator 600, D_Loss:0.7276108264923096, G_Loss:3.5003573894500732

iterator 700, D_Loss:0.7171339988708496, G_Loss:4.198208808898926

iterator 800, D_Loss:0.7486954927444458, G_Loss:3.5519585609436035

iterator 900, D_Loss:0.7241722941398621, G_Loss:3.3845221996307373

iterator 1000, D_Loss:0.7956374287605286, G_Loss:3.53813099861145

iterator 1100, D_Loss:0.7389639616012573, G_Loss:3.6458580493927

iterator 1200, D_Loss:0.7056681513786316, G_Loss:3.7021610736846924

iterator 1300, D_Loss:0.7300065159797668, G_Loss:4.083573341369629

iterator 1400, D_Loss:0.6549983024597168, G_Loss:3.853865385055542

iterator 1500, D_Loss:0.7400027513504028, G_Loss:3.2192602157592773

iterator 1600, D_Loss:0.7458446025848389, G_Loss:3.470944881439209

iterator 1700, D_Loss:0.8153444528579712, G_Loss:3.0958023071289062

iterator 1800, D_Loss:0.7279561161994934, G_Loss:3.5398244857788086

iterator 1900, D_Loss:0.7557236552238464, G_Loss:3.3683526515960693

iterator 2000, D_Loss:0.7246507406234741, G_Loss:3.285161256790161

iterator 2100, D_Loss:0.6927525997161865, G_Loss:3.9364216327667236

iterator 2200, D_Loss:0.7514522671699524, G_Loss:3.4365878105163574

iterator 2300, D_Loss:0.7233796119689941, G_Loss:3.4637672901153564

iterator 2400, D_Loss:0.7297158241271973, G_Loss:3.3534576892852783

iterator 2500, D_Loss:0.7085328102111816, G_Loss:3.308199882507324

iterator 2600, D_Loss:0.7904869318008423, G_Loss:3.619988203048706

iterator 2700, D_Loss:0.781204104423523, G_Loss:3.5140726566314697

iterator 2800, D_Loss:0.8016876578330994, G_Loss:3.0653746128082275

iterator 2900, D_Loss:0.744030773639679, G_Loss:3.491312026977539

iterator 3000, D_Loss:0.6987488865852356, G_Loss:3.422548770904541

iterator 3100, D_Loss:0.7413896322250366, G_Loss:3.475071907043457

iterator 3200, D_Loss:0.7987282276153564, G_Loss:3.1233110427856445

iterator 3300, D_Loss:0.7719990015029907, G_Loss:3.114154815673828

iterator 3400, D_Loss:0.7351200580596924, G_Loss:3.506199359893799

iterator 3500, D_Loss:0.7540323138237, G_Loss:3.1962709426879883

iterator 3600, D_Loss:0.6943837404251099, G_Loss:3.436980724334717

iterator 3700, D_Loss:0.7583162784576416, G_Loss:3.7881522178649902

iterator 3800, D_Loss:0.7628971338272095, G_Loss:3.4632315635681152

iterator 3900, D_Loss:0.7981074452400208, G_Loss:3.435030937194824

iterator 4000, D_Loss:0.7842570543289185, G_Loss:3.7494449615478516

iterator 4100, D_Loss:0.7187879085540771, G_Loss:3.636267900466919

iterator 4200, D_Loss:0.7875714302062988, G_Loss:3.040421724319458

iterator 4300, D_Loss:0.7487695813179016, G_Loss:3.9952595233917236

iterator 4400, D_Loss:0.7213177680969238, G_Loss:3.654900550842285

iterator 4500, D_Loss:0.7071585059165955, G_Loss:3.420741558074951

iterator 4600, D_Loss:0.7253290414810181, G_Loss:3.2690484523773193

iterator 4700, D_Loss:0.7488057017326355, G_Loss:3.2614481449127197

iterator 4800, D_Loss:0.7302066683769226, G_Loss:3.434384822845459

iterator 4900, D_Loss:0.733173668384552, G_Loss:3.163233995437622

iterator 5000, D_Loss:0.7086136341094971, G_Loss:3.613312244415283

-----------Epoch 8-----------
iterator 100, D_Loss:0.7709211111068726, G_Loss:3.064619779586792

iterator 200, D_Loss:0.7529861330986023, G_Loss:3.0351898670196533

iterator 300, D_Loss:0.7498964071273804, G_Loss:3.382772922515869

iterator 400, D_Loss:0.7271543145179749, G_Loss:3.262730121612549

iterator 500, D_Loss:0.7465189695358276, G_Loss:3.3815455436706543

iterator 600, D_Loss:0.6926438808441162, G_Loss:3.65214204788208

iterator 700, D_Loss:0.7297041416168213, G_Loss:3.7983152866363525

iterator 800, D_Loss:0.7647542357444763, G_Loss:3.3246805667877197

iterator 900, D_Loss:0.6877025961875916, G_Loss:3.487314224243164

iterator 1000, D_Loss:0.76009202003479, G_Loss:3.4127132892608643

iterator 1100, D_Loss:0.7697137594223022, G_Loss:3.498288154602051

iterator 1200, D_Loss:0.7193166017532349, G_Loss:3.4778857231140137

iterator 1300, D_Loss:0.7166992425918579, G_Loss:3.6460208892822266

iterator 1400, D_Loss:0.7351412773132324, G_Loss:3.4498560428619385

iterator 1500, D_Loss:0.7266930341720581, G_Loss:3.351328134536743

iterator 1600, D_Loss:0.7206836342811584, G_Loss:3.439335823059082

iterator 1700, D_Loss:0.7184445858001709, G_Loss:3.1712143421173096

iterator 1800, D_Loss:0.7347339987754822, G_Loss:3.4083375930786133

iterator 1900, D_Loss:0.7355289459228516, G_Loss:3.5464305877685547

iterator 2000, D_Loss:0.7490957975387573, G_Loss:3.375974416732788

iterator 2100, D_Loss:0.7710940837860107, G_Loss:3.6081814765930176

iterator 2200, D_Loss:0.768872082233429, G_Loss:3.514678955078125

iterator 2300, D_Loss:0.7242283821105957, G_Loss:3.5537221431732178

iterator 2400, D_Loss:0.7704501152038574, G_Loss:3.621941328048706

iterator 2500, D_Loss:0.7404313087463379, G_Loss:3.3329763412475586

iterator 2600, D_Loss:0.7022846341133118, G_Loss:3.31620454788208

iterator 2700, D_Loss:0.7534487247467041, G_Loss:3.5590016841888428

iterator 2800, D_Loss:0.7330923080444336, G_Loss:3.8788774013519287

iterator 2900, D_Loss:0.7432273626327515, G_Loss:3.5058810710906982

iterator 3000, D_Loss:0.732021689414978, G_Loss:3.2309176921844482

iterator 3100, D_Loss:0.7532089948654175, G_Loss:3.0350615978240967

iterator 3200, D_Loss:0.8048483729362488, G_Loss:3.7933175563812256

iterator 3300, D_Loss:0.7478232383728027, G_Loss:3.3927786350250244

iterator 3400, D_Loss:0.7257226705551147, G_Loss:3.4359519481658936

iterator 3500, D_Loss:0.7480694055557251, G_Loss:3.5552189350128174

iterator 3600, D_Loss:0.7885607481002808, G_Loss:3.6129698753356934

iterator 3700, D_Loss:0.7855850458145142, G_Loss:3.4612090587615967

iterator 3800, D_Loss:0.7411996126174927, G_Loss:3.496234655380249

iterator 3900, D_Loss:0.738445520401001, G_Loss:3.383373498916626

iterator 4000, D_Loss:0.7470731735229492, G_Loss:3.483523368835449

iterator 4100, D_Loss:0.744155764579773, G_Loss:3.627006769180298

iterator 4200, D_Loss:0.7566141486167908, G_Loss:3.240715503692627

iterator 4300, D_Loss:0.7753032445907593, G_Loss:3.4779672622680664

iterator 4400, D_Loss:0.7468291521072388, G_Loss:3.242321491241455

iterator 4500, D_Loss:0.7433285713195801, G_Loss:3.510207176208496

iterator 4600, D_Loss:0.7992769479751587, G_Loss:3.2628703117370605

iterator 4700, D_Loss:0.7683914303779602, G_Loss:3.2829339504241943

iterator 4800, D_Loss:0.750473141670227, G_Loss:3.0657336711883545

iterator 4900, D_Loss:0.7268858551979065, G_Loss:3.4973337650299072

iterator 5000, D_Loss:0.7143840789794922, G_Loss:3.448981761932373

-----------Epoch 9-----------
iterator 100, D_Loss:0.8207683563232422, G_Loss:3.093416213989258

iterator 200, D_Loss:0.7141821980476379, G_Loss:3.3513526916503906

iterator 300, D_Loss:0.7689605951309204, G_Loss:3.324355363845825

iterator 400, D_Loss:0.7415937185287476, G_Loss:3.3475213050842285

iterator 500, D_Loss:0.7826271057128906, G_Loss:3.2783608436584473

iterator 600, D_Loss:0.7510169148445129, G_Loss:3.426983118057251

iterator 700, D_Loss:0.7613319754600525, G_Loss:2.9543018341064453

iterator 800, D_Loss:0.7771122455596924, G_Loss:3.6381101608276367

iterator 900, D_Loss:0.7506240606307983, G_Loss:3.9810540676116943

iterator 1000, D_Loss:0.7493706941604614, G_Loss:3.4209954738616943

iterator 1100, D_Loss:0.784164309501648, G_Loss:3.5724029541015625

iterator 1200, D_Loss:0.7494442462921143, G_Loss:3.2851691246032715

iterator 1300, D_Loss:0.7461001873016357, G_Loss:3.7186148166656494

iterator 1400, D_Loss:0.7395510673522949, G_Loss:3.4583780765533447

iterator 1500, D_Loss:0.7641156315803528, G_Loss:3.5566585063934326

iterator 1600, D_Loss:0.7946874499320984, G_Loss:3.0720956325531006

iterator 1700, D_Loss:0.7916022539138794, G_Loss:3.207655668258667

iterator 1800, D_Loss:0.7268238067626953, G_Loss:3.1321773529052734

iterator 1900, D_Loss:0.7613701224327087, G_Loss:3.1677472591400146

iterator 2000, D_Loss:0.7641444206237793, G_Loss:3.3775177001953125

iterator 2100, D_Loss:0.7839317917823792, G_Loss:3.2307748794555664

iterator 2200, D_Loss:0.7647840976715088, G_Loss:3.357290744781494

iterator 2300, D_Loss:0.743597149848938, G_Loss:3.325695753097534

iterator 2400, D_Loss:0.7758110761642456, G_Loss:3.291231393814087

iterator 2500, D_Loss:0.7665784358978271, G_Loss:3.3505589962005615

iterator 2600, D_Loss:0.7616397142410278, G_Loss:3.443765878677368

iterator 2700, D_Loss:0.7402663230895996, G_Loss:3.5061426162719727

iterator 2800, D_Loss:0.7559070587158203, G_Loss:3.2646632194519043

iterator 2900, D_Loss:0.7638993859291077, G_Loss:3.181251287460327

iterator 3000, D_Loss:0.7533756494522095, G_Loss:3.8559207916259766

iterator 3100, D_Loss:0.8095587491989136, G_Loss:3.1858646869659424

iterator 3200, D_Loss:0.7258367538452148, G_Loss:3.873985767364502

iterator 3300, D_Loss:0.8093583583831787, G_Loss:2.985980749130249

iterator 3400, D_Loss:0.7752109169960022, G_Loss:3.624286413192749

iterator 3500, D_Loss:0.7444198131561279, G_Loss:3.4519731998443604

iterator 3600, D_Loss:0.7608247995376587, G_Loss:3.2203245162963867

iterator 3700, D_Loss:0.7843080759048462, G_Loss:3.179792881011963

iterator 3800, D_Loss:0.7826869487762451, G_Loss:3.297767400741577

iterator 3900, D_Loss:0.7183723449707031, G_Loss:3.3504464626312256

iterator 4000, D_Loss:0.7952401638031006, G_Loss:3.322662830352783

iterator 4100, D_Loss:0.7395567893981934, G_Loss:3.2492105960845947

iterator 4200, D_Loss:0.8052382469177246, G_Loss:3.5588862895965576

iterator 4300, D_Loss:0.7703526616096497, G_Loss:3.251736640930176

iterator 4400, D_Loss:0.6854792833328247, G_Loss:3.7306039333343506

iterator 4500, D_Loss:0.7330708503723145, G_Loss:3.3605289459228516

iterator 4600, D_Loss:0.6981848478317261, G_Loss:3.2710649967193604

iterator 4700, D_Loss:0.7620318531990051, G_Loss:3.4767072200775146

iterator 4800, D_Loss:0.7445657253265381, G_Loss:3.143571138381958

iterator 4900, D_Loss:0.7658072710037231, G_Loss:3.606851816177368

iterator 5000, D_Loss:0.7875684499740601, G_Loss:3.5935959815979004

train row : 30148
sample row: 30148
LGAN_generator(
  (LSTM): LSTMCell(500, 500)
  (gmfc00): Linear(in_features=100, out_features=1, bias=True)
  (gmfc01): Linear(in_features=100, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=100, bias=True)
  (gmfe00): Linear(in_features=500, out_features=100, bias=True)
  (gmfe01): Linear(in_features=500, out_features=100, bias=True)
  (fc10): Linear(in_features=100, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=100, bias=True)
  (fe1): Linear(in_features=500, out_features=100, bias=True)
  (gmfc20): Linear(in_features=100, out_features=1, bias=True)
  (gmfc21): Linear(in_features=100, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=100, bias=True)
  (gmfe20): Linear(in_features=500, out_features=100, bias=True)
  (gmfe21): Linear(in_features=500, out_features=100, bias=True)
  (fc30): Linear(in_features=100, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=100, bias=True)
  (fe3): Linear(in_features=500, out_features=100, bias=True)
  (gmfc40): Linear(in_features=100, out_features=1, bias=True)
  (gmfc41): Linear(in_features=100, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=100, bias=True)
  (gmfe40): Linear(in_features=500, out_features=100, bias=True)
  (gmfe41): Linear(in_features=500, out_features=100, bias=True)
  (fc50): Linear(in_features=100, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=100, bias=True)
  (fe5): Linear(in_features=500, out_features=100, bias=True)
  (fc60): Linear(in_features=100, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=100, bias=True)
  (fe6): Linear(in_features=500, out_features=100, bias=True)
  (fc70): Linear(in_features=100, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=100, bias=True)
  (fe7): Linear(in_features=500, out_features=100, bias=True)
  (fc80): Linear(in_features=100, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=100, bias=True)
  (fe8): Linear(in_features=500, out_features=100, bias=True)
  (fc90): Linear(in_features=100, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=100, bias=True)
  (fe9): Linear(in_features=500, out_features=100, bias=True)
  (gmfc100): Linear(in_features=100, out_features=1, bias=True)
  (gmfc101): Linear(in_features=100, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=100, bias=True)
  (gmfe100): Linear(in_features=500, out_features=100, bias=True)
  (gmfe101): Linear(in_features=500, out_features=100, bias=True)
  (gmfc110): Linear(in_features=100, out_features=1, bias=True)
  (gmfc111): Linear(in_features=100, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=100, bias=True)
  (gmfe110): Linear(in_features=500, out_features=100, bias=True)
  (gmfe111): Linear(in_features=500, out_features=100, bias=True)
  (gmfc120): Linear(in_features=100, out_features=1, bias=True)
  (gmfc121): Linear(in_features=100, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=100, bias=True)
  (gmfe120): Linear(in_features=500, out_features=100, bias=True)
  (gmfe121): Linear(in_features=500, out_features=100, bias=True)
  (fc130): Linear(in_features=100, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=100, bias=True)
  (fe13): Linear(in_features=500, out_features=100, bias=True)
  (fc140): Linear(in_features=100, out_features=2, bias=True)
  (fc141): Linear(in_features=2, out_features=100, bias=True)
  (fe14): Linear(in_features=500, out_features=100, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=100, bias=True)
  (inputbn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=100, out_features=100, bias=True)
  (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=100, out_features=100, bias=True)
  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=100, out_features=1, bias=True)
)
(0, False, 135)
-----------Epoch 0-----------
iterator 100, D_Loss:1.4002270698547363, G_Loss:1.1939849853515625

iterator 200, D_Loss:1.4274656772613525, G_Loss:1.0994523763656616

iterator 300, D_Loss:1.4167864322662354, G_Loss:1.029848337173462

iterator 400, D_Loss:1.4342067241668701, G_Loss:0.9516621828079224

iterator 500, D_Loss:1.4136613607406616, G_Loss:1.0118969678878784

iterator 600, D_Loss:1.3915627002716064, G_Loss:0.9679998159408569

iterator 700, D_Loss:1.362697720527649, G_Loss:1.095823884010315

iterator 800, D_Loss:1.4307806491851807, G_Loss:1.0282738208770752

iterator 900, D_Loss:1.3746590614318848, G_Loss:0.9704467058181763

iterator 1000, D_Loss:1.3840558528900146, G_Loss:0.9987704157829285

iterator 1100, D_Loss:1.4013640880584717, G_Loss:0.9713189005851746

iterator 1200, D_Loss:1.3920257091522217, G_Loss:1.0176200866699219

iterator 1300, D_Loss:1.3685755729675293, G_Loss:1.1362673044204712

iterator 1400, D_Loss:1.3607892990112305, G_Loss:1.0903960466384888

iterator 1500, D_Loss:1.3652054071426392, G_Loss:1.0388569831848145

iterator 1600, D_Loss:1.3684948682785034, G_Loss:1.058230996131897

iterator 1700, D_Loss:1.3821775913238525, G_Loss:1.0469694137573242

iterator 1800, D_Loss:1.3658833503723145, G_Loss:0.9925298094749451

iterator 1900, D_Loss:1.373287320137024, G_Loss:1.1165846586227417

iterator 2000, D_Loss:1.3605644702911377, G_Loss:1.0286107063293457

iterator 2100, D_Loss:1.3502094745635986, G_Loss:1.0281596183776855

iterator 2200, D_Loss:1.4025298357009888, G_Loss:0.984943687915802

iterator 2300, D_Loss:1.3988926410675049, G_Loss:0.9764219522476196

iterator 2400, D_Loss:1.3543198108673096, G_Loss:0.944290041923523

iterator 2500, D_Loss:1.3496298789978027, G_Loss:1.0572772026062012

iterator 2600, D_Loss:1.3260955810546875, G_Loss:1.0747402906417847

iterator 2700, D_Loss:1.3449170589447021, G_Loss:1.028029441833496

iterator 2800, D_Loss:1.3512177467346191, G_Loss:1.123077630996704

iterator 2900, D_Loss:1.3347315788269043, G_Loss:1.113203525543213

iterator 3000, D_Loss:1.325691819190979, G_Loss:0.9557040333747864

iterator 3100, D_Loss:1.3526272773742676, G_Loss:1.147186279296875

iterator 3200, D_Loss:1.3195594549179077, G_Loss:0.9922765493392944

iterator 3300, D_Loss:1.3427850008010864, G_Loss:1.2612404823303223

iterator 3400, D_Loss:1.3714814186096191, G_Loss:1.0422065258026123

iterator 3500, D_Loss:1.373532772064209, G_Loss:0.9764483571052551

iterator 3600, D_Loss:1.3424617052078247, G_Loss:1.0760905742645264

iterator 3700, D_Loss:1.3421282768249512, G_Loss:1.036412239074707

iterator 3800, D_Loss:1.3421926498413086, G_Loss:1.0835731029510498

iterator 3900, D_Loss:1.358431100845337, G_Loss:1.1029863357543945

iterator 4000, D_Loss:1.3504631519317627, G_Loss:1.0498197078704834

iterator 4100, D_Loss:1.3781297206878662, G_Loss:1.0086406469345093

iterator 4200, D_Loss:1.354548692703247, G_Loss:1.0502108335494995

iterator 4300, D_Loss:1.3211028575897217, G_Loss:1.1171205043792725

iterator 4400, D_Loss:1.340165615081787, G_Loss:0.9749511480331421

iterator 4500, D_Loss:1.3780220746994019, G_Loss:0.9383870363235474

iterator 4600, D_Loss:1.3747812509536743, G_Loss:1.0546141862869263

iterator 4700, D_Loss:1.3551042079925537, G_Loss:1.1069570779800415

iterator 4800, D_Loss:1.369516372680664, G_Loss:1.0533974170684814

iterator 4900, D_Loss:1.3691792488098145, G_Loss:0.97133469581604

iterator 5000, D_Loss:1.3550022840499878, G_Loss:1.0234827995300293

-----------Epoch 1-----------
iterator 100, D_Loss:1.3885833024978638, G_Loss:1.0379960536956787

iterator 200, D_Loss:1.3193812370300293, G_Loss:1.1046193838119507

iterator 300, D_Loss:1.3530640602111816, G_Loss:1.0216666460037231

iterator 400, D_Loss:1.3815486431121826, G_Loss:0.9636111259460449

iterator 500, D_Loss:1.2918334007263184, G_Loss:1.0599360466003418

iterator 600, D_Loss:1.3858877420425415, G_Loss:0.9854224920272827

iterator 700, D_Loss:1.3627111911773682, G_Loss:1.2394793033599854

iterator 800, D_Loss:1.364727258682251, G_Loss:1.061601161956787

iterator 900, D_Loss:1.4084417819976807, G_Loss:0.9878413677215576

iterator 1000, D_Loss:1.3265485763549805, G_Loss:0.9974682331085205

iterator 1100, D_Loss:1.3377516269683838, G_Loss:1.004694938659668

iterator 1200, D_Loss:1.322413682937622, G_Loss:1.1204688549041748

iterator 1300, D_Loss:1.3361618518829346, G_Loss:1.1182342767715454

iterator 1400, D_Loss:1.3587979078292847, G_Loss:1.1282570362091064

iterator 1500, D_Loss:1.3604989051818848, G_Loss:1.1032016277313232

iterator 1600, D_Loss:1.3214044570922852, G_Loss:1.0501266717910767

iterator 1700, D_Loss:1.3333983421325684, G_Loss:1.0538599491119385

iterator 1800, D_Loss:1.4064431190490723, G_Loss:1.0114936828613281

iterator 1900, D_Loss:1.3544336557388306, G_Loss:1.0943992137908936

iterator 2000, D_Loss:1.2848591804504395, G_Loss:1.0801185369491577

iterator 2100, D_Loss:1.402670979499817, G_Loss:1.0939178466796875

iterator 2200, D_Loss:1.389510154724121, G_Loss:1.0100127458572388

iterator 2300, D_Loss:1.3453108072280884, G_Loss:1.0651829242706299

iterator 2400, D_Loss:1.2569879293441772, G_Loss:0.981414794921875

iterator 2500, D_Loss:1.2764642238616943, G_Loss:1.1306735277175903

iterator 2600, D_Loss:1.297336220741272, G_Loss:1.0831378698349

iterator 2700, D_Loss:1.25327467918396, G_Loss:1.0354816913604736

iterator 2800, D_Loss:1.330496072769165, G_Loss:1.1976033449172974

iterator 2900, D_Loss:1.2891749143600464, G_Loss:1.208040475845337

iterator 3000, D_Loss:1.2310643196105957, G_Loss:1.060280442237854

iterator 3100, D_Loss:1.3351211547851562, G_Loss:1.0801359415054321

iterator 3200, D_Loss:1.2729789018630981, G_Loss:1.2055702209472656

iterator 3300, D_Loss:1.2334758043289185, G_Loss:1.4995567798614502

iterator 3400, D_Loss:1.2422065734863281, G_Loss:0.9982650876045227

iterator 3500, D_Loss:1.1034327745437622, G_Loss:1.1989309787750244

iterator 3600, D_Loss:1.2455480098724365, G_Loss:1.3051800727844238

iterator 3700, D_Loss:1.2675411701202393, G_Loss:1.1126508712768555

iterator 3800, D_Loss:1.362776279449463, G_Loss:1.034867286682129

iterator 3900, D_Loss:1.103703260421753, G_Loss:1.2597625255584717

iterator 4000, D_Loss:1.2437331676483154, G_Loss:1.2530804872512817

iterator 4100, D_Loss:1.4730966091156006, G_Loss:1.269047498703003

iterator 4200, D_Loss:1.2602217197418213, G_Loss:1.304724097251892

iterator 4300, D_Loss:1.3632280826568604, G_Loss:1.0577857494354248

iterator 4400, D_Loss:1.1252152919769287, G_Loss:1.3591264486312866

iterator 4500, D_Loss:1.164156436920166, G_Loss:0.9320041537284851

iterator 4600, D_Loss:1.1821379661560059, G_Loss:1.058699607849121

iterator 4700, D_Loss:1.1688330173492432, G_Loss:1.1840415000915527

iterator 4800, D_Loss:1.284140944480896, G_Loss:1.280327320098877

iterator 4900, D_Loss:1.3693552017211914, G_Loss:1.4513380527496338

iterator 5000, D_Loss:1.5171362161636353, G_Loss:1.2894930839538574

-----------Epoch 2-----------
iterator 100, D_Loss:1.3314799070358276, G_Loss:1.0161828994750977

iterator 200, D_Loss:1.1231286525726318, G_Loss:0.9800212383270264

iterator 300, D_Loss:1.2202306985855103, G_Loss:1.799465298652649

iterator 400, D_Loss:1.2996015548706055, G_Loss:0.9240341782569885

iterator 500, D_Loss:1.5494364500045776, G_Loss:1.2165095806121826

iterator 600, D_Loss:1.163318157196045, G_Loss:0.9086635112762451

iterator 700, D_Loss:1.272146224975586, G_Loss:1.1692132949829102

iterator 800, D_Loss:1.3219139575958252, G_Loss:1.1115630865097046

iterator 900, D_Loss:1.4673058986663818, G_Loss:1.3011529445648193

iterator 1000, D_Loss:1.2745376825332642, G_Loss:1.2619792222976685

iterator 1100, D_Loss:1.364725112915039, G_Loss:1.0086181163787842

iterator 1200, D_Loss:1.1851437091827393, G_Loss:1.2891026735305786

iterator 1300, D_Loss:1.4358861446380615, G_Loss:1.54728364944458

iterator 1400, D_Loss:1.0360625982284546, G_Loss:1.7532681226730347

iterator 1500, D_Loss:1.1298984289169312, G_Loss:1.7035484313964844

iterator 1600, D_Loss:1.404098391532898, G_Loss:1.6131614446640015

iterator 1700, D_Loss:1.2693567276000977, G_Loss:1.364258050918579

iterator 1800, D_Loss:1.0225274562835693, G_Loss:1.471407175064087

iterator 1900, D_Loss:1.014725923538208, G_Loss:1.7542710304260254

iterator 2000, D_Loss:1.0827083587646484, G_Loss:1.2455346584320068

iterator 2100, D_Loss:1.0396018028259277, G_Loss:1.642922282218933

iterator 2200, D_Loss:1.2561150789260864, G_Loss:1.572603702545166

iterator 2300, D_Loss:0.9285565614700317, G_Loss:2.0572452545166016

iterator 2400, D_Loss:1.0055044889450073, G_Loss:1.695326328277588

iterator 2500, D_Loss:1.202616572380066, G_Loss:1.3011654615402222

iterator 2600, D_Loss:1.1125295162200928, G_Loss:1.3796800374984741

iterator 2700, D_Loss:1.1479758024215698, G_Loss:1.3351026773452759

iterator 2800, D_Loss:1.3643193244934082, G_Loss:1.2271931171417236

iterator 2900, D_Loss:1.343616008758545, G_Loss:1.137460708618164

iterator 3000, D_Loss:1.2537965774536133, G_Loss:1.205944538116455

iterator 3100, D_Loss:1.2437700033187866, G_Loss:1.4728314876556396

iterator 3200, D_Loss:1.056757926940918, G_Loss:1.24350905418396

iterator 3300, D_Loss:1.441939353942871, G_Loss:1.50139319896698

iterator 3400, D_Loss:1.1516542434692383, G_Loss:1.7470710277557373

iterator 3500, D_Loss:1.256260633468628, G_Loss:1.242876648902893

iterator 3600, D_Loss:1.0995683670043945, G_Loss:2.174666404724121

iterator 3700, D_Loss:1.3101978302001953, G_Loss:1.6917524337768555

iterator 3800, D_Loss:0.9406856298446655, G_Loss:1.5255546569824219

iterator 3900, D_Loss:1.2697951793670654, G_Loss:1.6765925884246826

iterator 4000, D_Loss:1.2358537912368774, G_Loss:1.435595154762268

iterator 4100, D_Loss:1.175855278968811, G_Loss:0.983855128288269

iterator 4200, D_Loss:1.23594069480896, G_Loss:0.9546237587928772

iterator 4300, D_Loss:1.2562105655670166, G_Loss:1.5967930555343628

iterator 4400, D_Loss:1.3226017951965332, G_Loss:1.5941641330718994

iterator 4500, D_Loss:1.1915278434753418, G_Loss:1.447759985923767

iterator 4600, D_Loss:1.1744983196258545, G_Loss:1.5287185907363892

iterator 4700, D_Loss:1.2135416269302368, G_Loss:1.4796336889266968

iterator 4800, D_Loss:1.051157832145691, G_Loss:1.6689869165420532

iterator 4900, D_Loss:1.5121395587921143, G_Loss:1.080629587173462

iterator 5000, D_Loss:1.0531651973724365, G_Loss:1.5897153615951538

-----------Epoch 3-----------
iterator 100, D_Loss:0.9829994440078735, G_Loss:1.7888928651809692

iterator 200, D_Loss:1.2946380376815796, G_Loss:1.7239680290222168

iterator 300, D_Loss:0.961482048034668, G_Loss:1.6717753410339355

iterator 400, D_Loss:1.0274394750595093, G_Loss:1.6423282623291016

iterator 500, D_Loss:1.3994264602661133, G_Loss:1.6190506219863892

iterator 600, D_Loss:0.8569216132164001, G_Loss:1.9878430366516113

iterator 700, D_Loss:1.0122560262680054, G_Loss:2.1155641078948975

iterator 800, D_Loss:0.9972461462020874, G_Loss:2.126574754714966

iterator 900, D_Loss:1.207854986190796, G_Loss:1.5588314533233643

iterator 1000, D_Loss:1.195267915725708, G_Loss:1.8334805965423584

iterator 1100, D_Loss:1.1210824251174927, G_Loss:1.4553629159927368

iterator 1200, D_Loss:1.2420576810836792, G_Loss:2.1417903900146484

iterator 1300, D_Loss:1.0908669233322144, G_Loss:1.4758449792861938

iterator 1400, D_Loss:1.3403894901275635, G_Loss:1.0355318784713745

iterator 1500, D_Loss:1.482175588607788, G_Loss:2.1192550659179688

iterator 1600, D_Loss:1.1954610347747803, G_Loss:1.2997753620147705

iterator 1700, D_Loss:0.9569445848464966, G_Loss:1.4438295364379883

iterator 1800, D_Loss:1.1570086479187012, G_Loss:1.80690336227417

iterator 1900, D_Loss:1.0975887775421143, G_Loss:2.05845308303833

iterator 2000, D_Loss:1.060198426246643, G_Loss:1.2450965642929077

iterator 2100, D_Loss:1.1584527492523193, G_Loss:2.6831860542297363

iterator 2200, D_Loss:1.022552728652954, G_Loss:1.7906842231750488

iterator 2300, D_Loss:0.9733413457870483, G_Loss:1.61910080909729

iterator 2400, D_Loss:1.57753586769104, G_Loss:1.3302276134490967

iterator 2500, D_Loss:1.0330629348754883, G_Loss:1.7414889335632324

iterator 2600, D_Loss:1.2242578268051147, G_Loss:0.8272801637649536

iterator 2700, D_Loss:1.4286236763000488, G_Loss:1.6276357173919678

iterator 2800, D_Loss:0.9591923356056213, G_Loss:1.6669334173202515

iterator 2900, D_Loss:1.1467807292938232, G_Loss:1.1067707538604736

iterator 3000, D_Loss:1.174891710281372, G_Loss:1.2056235074996948

iterator 3100, D_Loss:1.271466851234436, G_Loss:1.966941237449646

iterator 3200, D_Loss:1.3106980323791504, G_Loss:1.7325149774551392

iterator 3300, D_Loss:1.2183201313018799, G_Loss:1.428849220275879

iterator 3400, D_Loss:0.7610232830047607, G_Loss:2.0953786373138428

iterator 3500, D_Loss:1.2163125276565552, G_Loss:1.693665862083435

iterator 3600, D_Loss:0.963210940361023, G_Loss:1.7736341953277588

iterator 3700, D_Loss:1.1122387647628784, G_Loss:1.8485755920410156

iterator 3800, D_Loss:1.4616398811340332, G_Loss:1.8070154190063477

iterator 3900, D_Loss:0.9185435771942139, G_Loss:1.9286015033721924

iterator 4000, D_Loss:1.4256219863891602, G_Loss:0.9937072992324829

iterator 4100, D_Loss:0.935560941696167, G_Loss:2.487889289855957

iterator 4200, D_Loss:0.8675497770309448, G_Loss:1.8941373825073242

iterator 4300, D_Loss:1.188852071762085, G_Loss:1.6509746313095093

iterator 4400, D_Loss:1.332474946975708, G_Loss:2.033879280090332

iterator 4500, D_Loss:1.1461727619171143, G_Loss:1.351089596748352

iterator 4600, D_Loss:1.0645296573638916, G_Loss:1.4247357845306396

iterator 4700, D_Loss:1.07599675655365, G_Loss:1.2168731689453125

iterator 4800, D_Loss:1.0865850448608398, G_Loss:1.7130610942840576

iterator 4900, D_Loss:1.1524786949157715, G_Loss:0.9444258809089661

iterator 5000, D_Loss:1.2670968770980835, G_Loss:1.4481240510940552

-----------Epoch 4-----------
iterator 100, D_Loss:1.4447441101074219, G_Loss:2.0092692375183105

iterator 200, D_Loss:1.0579183101654053, G_Loss:1.3253333568572998

iterator 300, D_Loss:0.9759304523468018, G_Loss:1.143418312072754

iterator 400, D_Loss:0.9165679216384888, G_Loss:1.768311619758606

iterator 500, D_Loss:1.1500601768493652, G_Loss:1.3635203838348389

iterator 600, D_Loss:1.0875617265701294, G_Loss:1.7383500337600708

iterator 700, D_Loss:2.0010643005371094, G_Loss:2.2551727294921875

iterator 800, D_Loss:0.9792816638946533, G_Loss:2.4115519523620605

iterator 900, D_Loss:1.2888672351837158, G_Loss:2.329158067703247

iterator 1000, D_Loss:1.3764686584472656, G_Loss:1.3492923974990845

iterator 1100, D_Loss:1.214943528175354, G_Loss:1.6467199325561523

iterator 1200, D_Loss:1.3601523637771606, G_Loss:1.28468656539917

iterator 1300, D_Loss:0.9462497234344482, G_Loss:2.542901039123535

iterator 1400, D_Loss:0.9359393119812012, G_Loss:2.7029595375061035

iterator 1500, D_Loss:1.0522292852401733, G_Loss:2.258491039276123

iterator 1600, D_Loss:1.057511329650879, G_Loss:2.022320508956909

iterator 1700, D_Loss:1.306416630744934, G_Loss:1.9669523239135742

iterator 1800, D_Loss:0.7137385606765747, G_Loss:2.2013161182403564

iterator 1900, D_Loss:1.793772578239441, G_Loss:2.124211311340332

iterator 2000, D_Loss:1.3462499380111694, G_Loss:1.289635419845581

iterator 2100, D_Loss:1.4154129028320312, G_Loss:0.9203746318817139

iterator 2200, D_Loss:0.8997719287872314, G_Loss:2.1961588859558105

iterator 2300, D_Loss:1.0487669706344604, G_Loss:1.4271734952926636

iterator 2400, D_Loss:1.435404658317566, G_Loss:1.5742831230163574

iterator 2500, D_Loss:1.2634847164154053, G_Loss:1.4763513803482056

iterator 2600, D_Loss:1.151465892791748, G_Loss:1.479184865951538

iterator 2700, D_Loss:1.1202949285507202, G_Loss:1.8184810876846313

iterator 2800, D_Loss:0.7357950806617737, G_Loss:1.953401803970337

iterator 2900, D_Loss:0.9639034271240234, G_Loss:2.0822553634643555

iterator 3000, D_Loss:1.086717128753662, G_Loss:1.8424113988876343

iterator 3100, D_Loss:0.9867169857025146, G_Loss:1.9192748069763184

iterator 3200, D_Loss:0.9331841468811035, G_Loss:2.064222574234009

iterator 3300, D_Loss:1.0270925760269165, G_Loss:2.466322660446167

iterator 3400, D_Loss:1.098581075668335, G_Loss:1.216726541519165

iterator 3500, D_Loss:1.1276419162750244, G_Loss:2.1601195335388184

iterator 3600, D_Loss:0.9990465641021729, G_Loss:1.4092098474502563

iterator 3700, D_Loss:0.8414610624313354, G_Loss:1.981992483139038

iterator 3800, D_Loss:0.703729510307312, G_Loss:2.292102575302124

iterator 3900, D_Loss:0.8866825699806213, G_Loss:1.948578953742981

iterator 4000, D_Loss:1.6296582221984863, G_Loss:1.8513139486312866

iterator 4100, D_Loss:0.926520586013794, G_Loss:1.4201312065124512

iterator 4200, D_Loss:1.7968019247055054, G_Loss:2.272824287414551

iterator 4300, D_Loss:0.8745291233062744, G_Loss:1.4401612281799316

iterator 4400, D_Loss:1.57969331741333, G_Loss:1.5322591066360474

iterator 4500, D_Loss:1.0610134601593018, G_Loss:0.8230236768722534

iterator 4600, D_Loss:1.0116726160049438, G_Loss:0.8744946718215942

iterator 4700, D_Loss:0.8869015574455261, G_Loss:1.8832443952560425

iterator 4800, D_Loss:1.1269956827163696, G_Loss:1.2768923044204712

iterator 4900, D_Loss:1.2017426490783691, G_Loss:1.817109227180481

iterator 5000, D_Loss:1.4473850727081299, G_Loss:1.3088974952697754

-----------Epoch 5-----------
iterator 100, D_Loss:1.276324987411499, G_Loss:1.8031435012817383

iterator 200, D_Loss:1.0969263315200806, G_Loss:1.3870617151260376

iterator 300, D_Loss:1.2456305027008057, G_Loss:1.2208274602890015

iterator 400, D_Loss:1.0217509269714355, G_Loss:1.4497499465942383

iterator 500, D_Loss:1.5647438764572144, G_Loss:2.068669557571411

iterator 600, D_Loss:1.3474016189575195, G_Loss:2.1667864322662354

iterator 700, D_Loss:1.6415026187896729, G_Loss:1.197906255722046

iterator 800, D_Loss:1.124429702758789, G_Loss:1.5629513263702393

iterator 900, D_Loss:0.9406312704086304, G_Loss:1.7110161781311035

iterator 1000, D_Loss:1.0589075088500977, G_Loss:1.4558978080749512

iterator 1100, D_Loss:1.4848988056182861, G_Loss:2.395787477493286

iterator 1200, D_Loss:1.128536581993103, G_Loss:1.3359415531158447

iterator 1300, D_Loss:0.9498322010040283, G_Loss:2.6755056381225586

iterator 1400, D_Loss:1.0789248943328857, G_Loss:1.5277146100997925

iterator 1500, D_Loss:1.5222588777542114, G_Loss:1.716991662979126

iterator 1600, D_Loss:1.1615877151489258, G_Loss:2.043755531311035

iterator 1700, D_Loss:1.2094279527664185, G_Loss:1.7020723819732666

iterator 1800, D_Loss:1.215447187423706, G_Loss:0.7994153499603271

iterator 1900, D_Loss:1.1519509553909302, G_Loss:1.9595654010772705

iterator 2000, D_Loss:1.3863918781280518, G_Loss:1.6062620878219604

iterator 2100, D_Loss:1.0625779628753662, G_Loss:1.4458168745040894

iterator 2200, D_Loss:1.0567513704299927, G_Loss:1.4999656677246094

iterator 2300, D_Loss:1.1197179555892944, G_Loss:1.6687023639678955

iterator 2400, D_Loss:0.9928911924362183, G_Loss:1.4521050453186035

iterator 2500, D_Loss:1.4007568359375, G_Loss:1.2807329893112183

iterator 2600, D_Loss:1.0416622161865234, G_Loss:1.9267009496688843

iterator 2700, D_Loss:1.284301519393921, G_Loss:1.3091524839401245

iterator 2800, D_Loss:0.9991083145141602, G_Loss:2.3629651069641113

iterator 2900, D_Loss:1.282515048980713, G_Loss:2.334895133972168

iterator 3000, D_Loss:0.9821197986602783, G_Loss:1.4472887516021729

iterator 3100, D_Loss:1.0696606636047363, G_Loss:1.787057876586914

iterator 3200, D_Loss:0.8829572796821594, G_Loss:1.3254591226577759

iterator 3300, D_Loss:0.9281861782073975, G_Loss:1.869978666305542

iterator 3400, D_Loss:1.1997772455215454, G_Loss:1.5646679401397705

iterator 3500, D_Loss:0.8150902986526489, G_Loss:2.247706890106201

iterator 3600, D_Loss:0.9453344941139221, G_Loss:1.5326977968215942

iterator 3700, D_Loss:1.0315184593200684, G_Loss:0.9861197471618652

iterator 3800, D_Loss:1.6225134134292603, G_Loss:1.8280810117721558

iterator 3900, D_Loss:0.9397739768028259, G_Loss:1.5714280605316162

iterator 4000, D_Loss:1.1279414892196655, G_Loss:2.369255304336548

iterator 4100, D_Loss:0.9724675416946411, G_Loss:1.604520320892334

iterator 4200, D_Loss:0.9679511785507202, G_Loss:1.840416669845581

iterator 4300, D_Loss:1.3511006832122803, G_Loss:2.1661152839660645

iterator 4400, D_Loss:1.151393175125122, G_Loss:0.917820930480957

iterator 4500, D_Loss:0.939450740814209, G_Loss:0.9780405759811401

iterator 4600, D_Loss:0.8772792816162109, G_Loss:1.8702137470245361

iterator 4700, D_Loss:1.0525411367416382, G_Loss:1.861822485923767

iterator 4800, D_Loss:1.501170039176941, G_Loss:1.0648176670074463

iterator 4900, D_Loss:0.9983909130096436, G_Loss:1.5944888591766357

iterator 5000, D_Loss:1.2672642469406128, G_Loss:1.5725781917572021

-----------Epoch 6-----------
iterator 100, D_Loss:0.9859342575073242, G_Loss:2.626322031021118

iterator 200, D_Loss:1.1541688442230225, G_Loss:1.4240403175354004

iterator 300, D_Loss:0.9361332654953003, G_Loss:2.1302292346954346

iterator 400, D_Loss:1.067262887954712, G_Loss:2.7905220985412598

iterator 500, D_Loss:1.3956286907196045, G_Loss:1.8701748847961426

iterator 600, D_Loss:0.939233660697937, G_Loss:1.5409797430038452

iterator 700, D_Loss:1.035601258277893, G_Loss:2.0259554386138916

iterator 800, D_Loss:0.7107740640640259, G_Loss:1.3987466096878052

iterator 900, D_Loss:1.2676506042480469, G_Loss:2.0434484481811523

iterator 1000, D_Loss:1.3070237636566162, G_Loss:1.9125146865844727

iterator 1100, D_Loss:1.4430959224700928, G_Loss:1.8020000457763672

iterator 1200, D_Loss:1.091361165046692, G_Loss:1.8467583656311035

iterator 1300, D_Loss:1.092515230178833, G_Loss:1.5183409452438354

iterator 1400, D_Loss:1.2817546129226685, G_Loss:1.5936359167099

iterator 1500, D_Loss:1.2147077322006226, G_Loss:1.577634572982788

iterator 1600, D_Loss:1.0574533939361572, G_Loss:2.2005794048309326

iterator 1700, D_Loss:0.9828740358352661, G_Loss:1.5205408334732056

iterator 1800, D_Loss:0.8993339538574219, G_Loss:1.8664580583572388

iterator 1900, D_Loss:1.0433813333511353, G_Loss:1.5474125146865845

iterator 2000, D_Loss:0.8837873339653015, G_Loss:1.6876780986785889

iterator 2100, D_Loss:1.3499256372451782, G_Loss:1.339372158050537

iterator 2200, D_Loss:1.2878981828689575, G_Loss:1.4185302257537842

iterator 2300, D_Loss:1.8536821603775024, G_Loss:3.012622356414795

iterator 2400, D_Loss:1.0144240856170654, G_Loss:1.9395664930343628

iterator 2500, D_Loss:1.612422227859497, G_Loss:1.7652568817138672

iterator 2600, D_Loss:1.246199607849121, G_Loss:2.6110734939575195

iterator 2700, D_Loss:0.9320960640907288, G_Loss:1.6404879093170166

iterator 2800, D_Loss:0.7576048970222473, G_Loss:1.5630700588226318

iterator 2900, D_Loss:1.4608368873596191, G_Loss:2.1076509952545166

iterator 3000, D_Loss:0.913515567779541, G_Loss:1.3336094617843628

iterator 3100, D_Loss:1.0219740867614746, G_Loss:1.5247328281402588

iterator 3200, D_Loss:0.9860226511955261, G_Loss:2.3791706562042236

iterator 3300, D_Loss:1.0705513954162598, G_Loss:1.5445642471313477

iterator 3400, D_Loss:0.8519471883773804, G_Loss:2.25732421875

iterator 3500, D_Loss:0.6643748879432678, G_Loss:1.892975091934204

iterator 3600, D_Loss:1.392905592918396, G_Loss:2.1768877506256104

iterator 3700, D_Loss:1.0665173530578613, G_Loss:1.6829745769500732

iterator 3800, D_Loss:0.9912512302398682, G_Loss:1.368814468383789

iterator 3900, D_Loss:1.1464637517929077, G_Loss:2.6840455532073975

iterator 4000, D_Loss:1.3139864206314087, G_Loss:1.8366961479187012

iterator 4100, D_Loss:1.2272001504898071, G_Loss:1.786543369293213

iterator 4200, D_Loss:1.0416640043258667, G_Loss:2.183535575866699

iterator 4300, D_Loss:1.852295160293579, G_Loss:2.028517961502075

iterator 4400, D_Loss:1.1618527173995972, G_Loss:1.685745120048523

iterator 4500, D_Loss:1.106906771659851, G_Loss:1.141349196434021

iterator 4600, D_Loss:1.4561338424682617, G_Loss:1.122911810874939

iterator 4700, D_Loss:0.9745128154754639, G_Loss:2.096215009689331

iterator 4800, D_Loss:1.030160665512085, G_Loss:1.3772951364517212

iterator 4900, D_Loss:1.2509398460388184, G_Loss:1.5147887468338013

iterator 5000, D_Loss:1.434583067893982, G_Loss:1.8738329410552979

-----------Epoch 7-----------
iterator 100, D_Loss:1.2695614099502563, G_Loss:1.4100497961044312

iterator 200, D_Loss:1.338322401046753, G_Loss:1.248319387435913

iterator 300, D_Loss:1.2762566804885864, G_Loss:1.1567498445510864

iterator 400, D_Loss:1.0637154579162598, G_Loss:1.1575573682785034

iterator 500, D_Loss:1.1485426425933838, G_Loss:1.6111469268798828

iterator 600, D_Loss:1.2151274681091309, G_Loss:1.5268075466156006

iterator 700, D_Loss:1.3346889019012451, G_Loss:1.350192666053772

iterator 800, D_Loss:0.8334587216377258, G_Loss:2.3597989082336426

iterator 900, D_Loss:1.3322582244873047, G_Loss:2.2817976474761963

iterator 1000, D_Loss:0.9317453503608704, G_Loss:1.9884655475616455

iterator 1100, D_Loss:1.3155088424682617, G_Loss:1.4582667350769043

iterator 1200, D_Loss:1.1188195943832397, G_Loss:2.157726287841797

iterator 1300, D_Loss:1.1152338981628418, G_Loss:1.5271378755569458

iterator 1400, D_Loss:1.1822631359100342, G_Loss:1.5311150550842285

iterator 1500, D_Loss:1.1927353143692017, G_Loss:1.5662139654159546

iterator 1600, D_Loss:1.4226436614990234, G_Loss:1.0325708389282227

iterator 1700, D_Loss:1.6058367490768433, G_Loss:1.8550715446472168

iterator 1800, D_Loss:0.9172430038452148, G_Loss:1.8921260833740234

iterator 1900, D_Loss:1.0360392332077026, G_Loss:2.0960144996643066

iterator 2000, D_Loss:1.0465065240859985, G_Loss:2.204108476638794

iterator 2100, D_Loss:1.2382681369781494, G_Loss:1.5708301067352295

iterator 2200, D_Loss:1.328023910522461, G_Loss:2.5491881370544434

iterator 2300, D_Loss:0.9529556035995483, G_Loss:1.2867282629013062

iterator 2400, D_Loss:1.0100510120391846, G_Loss:1.6764142513275146

iterator 2500, D_Loss:1.8926098346710205, G_Loss:1.8500237464904785

iterator 2600, D_Loss:1.1249529123306274, G_Loss:1.7683372497558594

iterator 2700, D_Loss:1.0470292568206787, G_Loss:1.1195366382598877

iterator 2800, D_Loss:0.8050925135612488, G_Loss:1.6788769960403442

iterator 2900, D_Loss:1.1029878854751587, G_Loss:1.7362682819366455

iterator 3000, D_Loss:1.1681663990020752, G_Loss:2.107985496520996

iterator 3100, D_Loss:1.4520902633666992, G_Loss:2.6164801120758057

iterator 3200, D_Loss:0.9250756502151489, G_Loss:1.9367423057556152

iterator 3300, D_Loss:0.8809399604797363, G_Loss:1.1924304962158203

iterator 3400, D_Loss:1.1351292133331299, G_Loss:2.553506851196289

iterator 3500, D_Loss:0.8156309127807617, G_Loss:3.015965700149536

iterator 3600, D_Loss:1.1738660335540771, G_Loss:2.286454200744629

iterator 3700, D_Loss:1.0054035186767578, G_Loss:1.4151558876037598

iterator 3800, D_Loss:0.9418154358863831, G_Loss:1.5349067449569702

iterator 3900, D_Loss:1.120947241783142, G_Loss:3.0297718048095703

iterator 4000, D_Loss:0.7310857772827148, G_Loss:1.648241400718689

iterator 4100, D_Loss:1.6840794086456299, G_Loss:1.113746166229248

iterator 4200, D_Loss:1.077781319618225, G_Loss:1.0141557455062866

iterator 4300, D_Loss:1.2273117303848267, G_Loss:1.452265739440918

iterator 4400, D_Loss:1.231677770614624, G_Loss:1.9275121688842773

iterator 4500, D_Loss:1.039839744567871, G_Loss:1.5343283414840698

iterator 4600, D_Loss:0.7960278391838074, G_Loss:2.2785696983337402

iterator 4700, D_Loss:1.3622417449951172, G_Loss:1.6419906616210938

iterator 4800, D_Loss:0.8026010394096375, G_Loss:2.684948205947876

iterator 4900, D_Loss:0.842936635017395, G_Loss:1.3968513011932373

iterator 5000, D_Loss:1.3231782913208008, G_Loss:2.5360989570617676

-----------Epoch 8-----------
iterator 100, D_Loss:1.336951494216919, G_Loss:1.2887282371520996

iterator 200, D_Loss:1.1109460592269897, G_Loss:2.9128530025482178

iterator 300, D_Loss:0.8883914947509766, G_Loss:1.1313880681991577

iterator 400, D_Loss:1.5663204193115234, G_Loss:1.9224870204925537

iterator 500, D_Loss:1.4557708501815796, G_Loss:1.1851904392242432

iterator 600, D_Loss:1.2427829504013062, G_Loss:1.4486247301101685

iterator 700, D_Loss:1.4007374048233032, G_Loss:2.4669394493103027

iterator 800, D_Loss:0.8819658756256104, G_Loss:1.2289526462554932

iterator 900, D_Loss:0.9999547004699707, G_Loss:1.0201495885849

iterator 1000, D_Loss:1.0119154453277588, G_Loss:1.3945914506912231

iterator 1100, D_Loss:1.476255178451538, G_Loss:1.9943621158599854

iterator 1200, D_Loss:1.5159862041473389, G_Loss:3.3446645736694336

iterator 1300, D_Loss:1.2986724376678467, G_Loss:2.7938594818115234

iterator 1400, D_Loss:0.9215468168258667, G_Loss:1.3113853931427002

iterator 1500, D_Loss:0.7242502570152283, G_Loss:2.015044927597046

iterator 1600, D_Loss:1.6224737167358398, G_Loss:2.519852876663208

iterator 1700, D_Loss:1.3969165086746216, G_Loss:3.417783737182617

iterator 1800, D_Loss:0.8238111734390259, G_Loss:2.2088770866394043

iterator 1900, D_Loss:0.8938978314399719, G_Loss:1.867370843887329

iterator 2000, D_Loss:1.776404619216919, G_Loss:1.8654992580413818

iterator 2100, D_Loss:0.9586047530174255, G_Loss:3.7113113403320312

iterator 2200, D_Loss:0.8235554695129395, G_Loss:0.8776633739471436

iterator 2300, D_Loss:1.08798348903656, G_Loss:2.3845980167388916

iterator 2400, D_Loss:1.0592658519744873, G_Loss:2.7438976764678955

iterator 2500, D_Loss:0.7968096733093262, G_Loss:2.130906581878662

iterator 2600, D_Loss:1.0541768074035645, G_Loss:2.551666259765625

iterator 2700, D_Loss:0.8964494466781616, G_Loss:2.1706700325012207

iterator 2800, D_Loss:0.8836032152175903, G_Loss:3.0257294178009033

iterator 2900, D_Loss:0.9218924045562744, G_Loss:1.6266233921051025

iterator 3000, D_Loss:0.7702243328094482, G_Loss:2.4259214401245117

iterator 3100, D_Loss:1.027789831161499, G_Loss:1.979874849319458

iterator 3200, D_Loss:0.9009650349617004, G_Loss:2.2080063819885254

iterator 3300, D_Loss:0.6673292517662048, G_Loss:2.9094560146331787

iterator 3400, D_Loss:0.7117668986320496, G_Loss:1.342369556427002

iterator 3500, D_Loss:1.1432156562805176, G_Loss:1.9860937595367432

iterator 3600, D_Loss:1.4185216426849365, G_Loss:1.798619031906128

iterator 3700, D_Loss:0.8999028205871582, G_Loss:2.2569799423217773

iterator 3800, D_Loss:0.8135780692100525, G_Loss:1.550506830215454

iterator 3900, D_Loss:1.06791090965271, G_Loss:2.2932047843933105

iterator 4000, D_Loss:0.8091028332710266, G_Loss:2.406010150909424

iterator 4100, D_Loss:0.9165591597557068, G_Loss:1.1470431089401245

iterator 4200, D_Loss:0.8039313554763794, G_Loss:3.7049880027770996

iterator 4300, D_Loss:1.513512134552002, G_Loss:2.606423854827881

iterator 4400, D_Loss:1.82289457321167, G_Loss:1.7966715097427368

iterator 4500, D_Loss:0.6956833004951477, G_Loss:1.407847285270691

iterator 4600, D_Loss:0.8339697122573853, G_Loss:2.7206339836120605

iterator 4700, D_Loss:0.8306770324707031, G_Loss:1.921686053276062

iterator 4800, D_Loss:0.7276690006256104, G_Loss:2.14143443107605

iterator 4900, D_Loss:0.8313238620758057, G_Loss:3.518125295639038

iterator 5000, D_Loss:0.9155875444412231, G_Loss:1.8529562950134277

-----------Epoch 9-----------
iterator 100, D_Loss:0.8898845314979553, G_Loss:1.8876336812973022

iterator 200, D_Loss:0.9143937230110168, G_Loss:1.3197835683822632

iterator 300, D_Loss:0.8835587501525879, G_Loss:1.378754734992981

iterator 400, D_Loss:1.330549955368042, G_Loss:2.640939950942993

iterator 500, D_Loss:1.9376976490020752, G_Loss:1.8062201738357544

iterator 600, D_Loss:1.1261683702468872, G_Loss:2.0234851837158203

iterator 700, D_Loss:1.0769076347351074, G_Loss:1.8832101821899414

iterator 800, D_Loss:1.0810129642486572, G_Loss:2.792475700378418

iterator 900, D_Loss:0.7317489981651306, G_Loss:1.3788294792175293

iterator 1000, D_Loss:1.1365962028503418, G_Loss:3.2384424209594727

iterator 1100, D_Loss:0.8999364376068115, G_Loss:2.6507015228271484

iterator 1200, D_Loss:1.6702752113342285, G_Loss:2.0312016010284424

iterator 1300, D_Loss:0.9100092649459839, G_Loss:1.3687820434570312

iterator 1400, D_Loss:1.2029132843017578, G_Loss:3.4987597465515137

iterator 1500, D_Loss:1.1362311840057373, G_Loss:1.4339834451675415

iterator 1600, D_Loss:0.8838571310043335, G_Loss:2.593724489212036

iterator 1700, D_Loss:1.487313985824585, G_Loss:1.9828959703445435

iterator 1800, D_Loss:0.9476302862167358, G_Loss:2.094773292541504

iterator 1900, D_Loss:1.0699925422668457, G_Loss:1.503287434577942

iterator 2000, D_Loss:1.3850510120391846, G_Loss:2.1605851650238037

iterator 2100, D_Loss:1.6665338277816772, G_Loss:2.736077070236206

iterator 2200, D_Loss:0.8416996598243713, G_Loss:4.493304252624512

iterator 2300, D_Loss:0.9929841756820679, G_Loss:1.9707276821136475

iterator 2400, D_Loss:0.732806921005249, G_Loss:3.6838433742523193

iterator 2500, D_Loss:0.8961809873580933, G_Loss:1.7404403686523438

iterator 2600, D_Loss:0.7450629472732544, G_Loss:1.5634031295776367

iterator 2700, D_Loss:1.0245640277862549, G_Loss:2.261528968811035

iterator 2800, D_Loss:0.6614097356796265, G_Loss:2.6094820499420166

iterator 2900, D_Loss:0.7768324613571167, G_Loss:2.3471548557281494

iterator 3000, D_Loss:1.064884066581726, G_Loss:1.2800322771072388

iterator 3100, D_Loss:1.7303826808929443, G_Loss:1.4346545934677124

iterator 3200, D_Loss:0.8486818075180054, G_Loss:1.753074288368225

iterator 3300, D_Loss:0.8210027813911438, G_Loss:1.3988420963287354

iterator 3400, D_Loss:0.772956132888794, G_Loss:2.048651695251465

iterator 3500, D_Loss:0.8519178628921509, G_Loss:1.559183120727539

iterator 3600, D_Loss:0.879420280456543, G_Loss:2.6483354568481445

iterator 3700, D_Loss:0.8390446901321411, G_Loss:1.890885829925537

iterator 3800, D_Loss:1.2023448944091797, G_Loss:2.993101119995117

iterator 3900, D_Loss:0.8385537266731262, G_Loss:1.6912975311279297

iterator 4000, D_Loss:0.9169453382492065, G_Loss:2.1886708736419678

iterator 4100, D_Loss:0.9535457491874695, G_Loss:1.1148951053619385

iterator 4200, D_Loss:0.6863290071487427, G_Loss:2.1707189083099365

iterator 4300, D_Loss:1.2065443992614746, G_Loss:2.227491855621338

iterator 4400, D_Loss:1.0185693502426147, G_Loss:1.7971415519714355

iterator 4500, D_Loss:0.6871687173843384, G_Loss:1.031177282333374

iterator 4600, D_Loss:1.0329259634017944, G_Loss:1.8327571153640747

iterator 4700, D_Loss:0.9258782267570496, G_Loss:1.5377576351165771

iterator 4800, D_Loss:1.399200677871704, G_Loss:1.6352276802062988

iterator 4900, D_Loss:1.0697085857391357, G_Loss:1.318547010421753

iterator 5000, D_Loss:1.1862847805023193, G_Loss:1.4189136028289795

LGAN_generator(
  (LSTM): LSTMCell(600, 300)
  (gmfc00): Linear(in_features=400, out_features=1, bias=True)
  (gmfc01): Linear(in_features=400, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=400, bias=True)
  (gmfe00): Linear(in_features=300, out_features=400, bias=True)
  (gmfe01): Linear(in_features=300, out_features=400, bias=True)
  (fc10): Linear(in_features=400, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=400, bias=True)
  (fe1): Linear(in_features=300, out_features=400, bias=True)
  (gmfc20): Linear(in_features=400, out_features=1, bias=True)
  (gmfc21): Linear(in_features=400, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=400, bias=True)
  (gmfe20): Linear(in_features=300, out_features=400, bias=True)
  (gmfe21): Linear(in_features=300, out_features=400, bias=True)
  (fc30): Linear(in_features=400, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=400, bias=True)
  (fe3): Linear(in_features=300, out_features=400, bias=True)
  (gmfc40): Linear(in_features=400, out_features=1, bias=True)
  (gmfc41): Linear(in_features=400, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=400, bias=True)
  (gmfe40): Linear(in_features=300, out_features=400, bias=True)
  (gmfe41): Linear(in_features=300, out_features=400, bias=True)
  (fc50): Linear(in_features=400, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=400, bias=True)
  (fe5): Linear(in_features=300, out_features=400, bias=True)
  (fc60): Linear(in_features=400, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=400, bias=True)
  (fe6): Linear(in_features=300, out_features=400, bias=True)
  (fc70): Linear(in_features=400, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=400, bias=True)
  (fe7): Linear(in_features=300, out_features=400, bias=True)
  (fc80): Linear(in_features=400, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=400, bias=True)
  (fe8): Linear(in_features=300, out_features=400, bias=True)
  (fc90): Linear(in_features=400, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=400, bias=True)
  (fe9): Linear(in_features=300, out_features=400, bias=True)
  (gmfc100): Linear(in_features=400, out_features=1, bias=True)
  (gmfc101): Linear(in_features=400, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=400, bias=True)
  (gmfe100): Linear(in_features=300, out_features=400, bias=True)
  (gmfe101): Linear(in_features=300, out_features=400, bias=True)
  (gmfc110): Linear(in_features=400, out_features=1, bias=True)
  (gmfc111): Linear(in_features=400, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=400, bias=True)
  (gmfe110): Linear(in_features=300, out_features=400, bias=True)
  (gmfe111): Linear(in_features=300, out_features=400, bias=True)
  (gmfc120): Linear(in_features=400, out_features=1, bias=True)
  (gmfc121): Linear(in_features=400, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=400, bias=True)
  (gmfe120): Linear(in_features=300, out_features=400, bias=True)
  (gmfe121): Linear(in_features=300, out_features=400, bias=True)
  (fc130): Linear(in_features=400, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=400, bias=True)
  (fe13): Linear(in_features=300, out_features=400, bias=True)
  (fc140): Linear(in_features=400, out_features=2, bias=True)
  (fc141): Linear(in_features=2, out_features=400, bias=True)
  (fe14): Linear(in_features=300, out_features=400, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=200, bias=True)
  (inputbn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (bn0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=200, out_features=200, bias=True)
  (bn1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=200, out_features=200, bias=True)
  (bn2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=200, out_features=200, bias=True)
  (bn3): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc4): Linear(in_features=200, out_features=200, bias=True)
  (bn4): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=200, out_features=1, bias=True)
)
(0, False, 135)
-----------Epoch 0-----------
iterator 100, D_Loss:1.3737965822219849, G_Loss:1.035611867904663

iterator 200, D_Loss:1.3401365280151367, G_Loss:1.003636121749878

iterator 300, D_Loss:1.2669506072998047, G_Loss:1.048567771911621

iterator 400, D_Loss:0.9141737818717957, G_Loss:2.1814050674438477

iterator 500, D_Loss:0.5510886907577515, G_Loss:3.381507396697998

iterator 600, D_Loss:0.4950527548789978, G_Loss:5.624265193939209

iterator 700, D_Loss:0.4526978135108948, G_Loss:6.102156162261963

iterator 800, D_Loss:0.4365360140800476, G_Loss:7.273514747619629

iterator 900, D_Loss:0.4244680404663086, G_Loss:7.965009689331055

iterator 1000, D_Loss:0.45547762513160706, G_Loss:7.111093521118164

iterator 1100, D_Loss:0.4258790910243988, G_Loss:8.521363258361816

iterator 1200, D_Loss:0.42935043573379517, G_Loss:8.161614418029785

iterator 1300, D_Loss:0.41693589091300964, G_Loss:9.107892036437988

iterator 1400, D_Loss:0.43813079595565796, G_Loss:9.704514503479004

iterator 1500, D_Loss:0.43568071722984314, G_Loss:10.790633201599121

iterator 1600, D_Loss:0.4232045114040375, G_Loss:9.894412994384766

iterator 1700, D_Loss:0.4209348261356354, G_Loss:10.800264358520508

iterator 1800, D_Loss:0.43482232093811035, G_Loss:9.364398002624512

iterator 1900, D_Loss:0.4222148060798645, G_Loss:8.799748420715332

iterator 2000, D_Loss:0.4344325363636017, G_Loss:10.433833122253418

iterator 2100, D_Loss:0.4119430482387543, G_Loss:10.188279151916504

iterator 2200, D_Loss:0.42968276143074036, G_Loss:10.397481918334961

iterator 2300, D_Loss:0.4513058066368103, G_Loss:9.837157249450684

iterator 2400, D_Loss:0.430531769990921, G_Loss:11.036083221435547

iterator 2500, D_Loss:0.42238330841064453, G_Loss:10.867119789123535

iterator 2600, D_Loss:0.4177769422531128, G_Loss:10.940351486206055

iterator 2700, D_Loss:0.4596538841724396, G_Loss:12.524240493774414

iterator 2800, D_Loss:0.4286858141422272, G_Loss:7.606792449951172

iterator 2900, D_Loss:0.4238820970058441, G_Loss:11.42121696472168

iterator 3000, D_Loss:0.4451950788497925, G_Loss:7.7339677810668945

iterator 3100, D_Loss:0.4260965585708618, G_Loss:12.480953216552734

iterator 3200, D_Loss:0.4385664761066437, G_Loss:13.743255615234375

iterator 3300, D_Loss:0.43112605810165405, G_Loss:12.806173324584961

iterator 3400, D_Loss:0.43350866436958313, G_Loss:16.7027587890625

iterator 3500, D_Loss:0.4023449420928955, G_Loss:13.910821914672852

iterator 3600, D_Loss:0.44310542941093445, G_Loss:14.425215721130371

iterator 3700, D_Loss:0.43341609835624695, G_Loss:17.144899368286133

iterator 3800, D_Loss:0.41854530572891235, G_Loss:16.648279190063477

iterator 3900, D_Loss:0.41873329877853394, G_Loss:15.675671577453613

iterator 4000, D_Loss:0.43325960636138916, G_Loss:14.41629695892334

iterator 4100, D_Loss:0.41749632358551025, G_Loss:14.721189498901367

iterator 4200, D_Loss:0.4236583709716797, G_Loss:14.31127643585205

iterator 4300, D_Loss:0.4029444754123688, G_Loss:15.0576810836792

iterator 4400, D_Loss:0.44595545530319214, G_Loss:14.661393165588379

iterator 4500, D_Loss:0.4275994598865509, G_Loss:15.715734481811523

iterator 4600, D_Loss:0.4430663585662842, G_Loss:19.731433868408203

iterator 4700, D_Loss:0.4234134554862976, G_Loss:17.80504035949707

iterator 4800, D_Loss:0.42633622884750366, G_Loss:16.229341506958008

iterator 4900, D_Loss:0.4429240822792053, G_Loss:17.239959716796875

iterator 5000, D_Loss:0.41157230734825134, G_Loss:16.475791931152344

-----------Epoch 1-----------
iterator 100, D_Loss:0.4325661063194275, G_Loss:15.132705688476562

iterator 200, D_Loss:0.42945587635040283, G_Loss:15.43339729309082

iterator 300, D_Loss:0.4338366985321045, G_Loss:17.614639282226562

iterator 400, D_Loss:0.4235524833202362, G_Loss:15.789472579956055

iterator 500, D_Loss:0.420312762260437, G_Loss:16.350351333618164

iterator 600, D_Loss:0.42835134267807007, G_Loss:17.4686336517334

iterator 700, D_Loss:0.4333353340625763, G_Loss:15.367437362670898

iterator 800, D_Loss:0.4165593087673187, G_Loss:16.00338363647461

iterator 900, D_Loss:0.44299939274787903, G_Loss:21.399341583251953

iterator 1000, D_Loss:0.4132981300354004, G_Loss:18.2635555267334

iterator 1100, D_Loss:0.4169802963733673, G_Loss:20.103633880615234

iterator 1200, D_Loss:0.4365883469581604, G_Loss:20.89535140991211

iterator 1300, D_Loss:0.4181724190711975, G_Loss:20.783796310424805

iterator 1400, D_Loss:0.41815730929374695, G_Loss:18.12373161315918

iterator 1500, D_Loss:0.4256877899169922, G_Loss:17.210294723510742

iterator 1600, D_Loss:0.4069313704967499, G_Loss:15.590457916259766

iterator 1700, D_Loss:0.4097197651863098, G_Loss:21.49815559387207

iterator 1800, D_Loss:0.4290730655193329, G_Loss:19.34109878540039

iterator 1900, D_Loss:0.4246630072593689, G_Loss:19.55748748779297

iterator 2000, D_Loss:0.4106033444404602, G_Loss:20.99566650390625

iterator 2100, D_Loss:0.42637112736701965, G_Loss:19.750537872314453

iterator 2200, D_Loss:0.4195529520511627, G_Loss:17.672466278076172

iterator 2300, D_Loss:0.42581334710121155, G_Loss:16.37545394897461

iterator 2400, D_Loss:0.4119155704975128, G_Loss:13.883048057556152

iterator 2500, D_Loss:0.42708519101142883, G_Loss:15.50155258178711

iterator 2600, D_Loss:0.41468116641044617, G_Loss:16.83506202697754

iterator 2700, D_Loss:0.4180751442909241, G_Loss:15.766130447387695

iterator 2800, D_Loss:0.43035614490509033, G_Loss:14.376351356506348

iterator 2900, D_Loss:0.41676849126815796, G_Loss:15.444271087646484

iterator 3000, D_Loss:0.4298509955406189, G_Loss:14.972314834594727

iterator 3100, D_Loss:0.4124794006347656, G_Loss:15.628520965576172

iterator 3200, D_Loss:0.4247146248817444, G_Loss:15.789959907531738

iterator 3300, D_Loss:0.4176579415798187, G_Loss:14.285635948181152

iterator 3400, D_Loss:0.42436710000038147, G_Loss:13.179695129394531

iterator 3500, D_Loss:0.4015488028526306, G_Loss:15.052629470825195

iterator 3600, D_Loss:0.4098888039588928, G_Loss:13.474227905273438

iterator 3700, D_Loss:0.4025682806968689, G_Loss:13.675554275512695

iterator 3800, D_Loss:0.4366462230682373, G_Loss:13.860269546508789

iterator 3900, D_Loss:0.4103142321109772, G_Loss:13.431206703186035

iterator 4000, D_Loss:0.43485093116760254, G_Loss:10.887789726257324

iterator 4100, D_Loss:0.42406073212623596, G_Loss:14.318292617797852

iterator 4200, D_Loss:0.41797199845314026, G_Loss:13.446535110473633

iterator 4300, D_Loss:0.4184950888156891, G_Loss:17.202558517456055

iterator 4400, D_Loss:0.4164596498012543, G_Loss:18.62950325012207

iterator 4500, D_Loss:0.4260967969894409, G_Loss:17.812725067138672

iterator 4600, D_Loss:0.41256773471832275, G_Loss:16.942556381225586

iterator 4700, D_Loss:0.4178914427757263, G_Loss:16.782272338867188

iterator 4800, D_Loss:0.4287550747394562, G_Loss:14.911489486694336

iterator 4900, D_Loss:0.42625269293785095, G_Loss:16.49219512939453

iterator 5000, D_Loss:0.4175136685371399, G_Loss:16.326942443847656

-----------Epoch 2-----------
iterator 100, D_Loss:0.4300226867198944, G_Loss:17.267704010009766

iterator 200, D_Loss:0.4137723743915558, G_Loss:17.66759490966797

iterator 300, D_Loss:0.41108012199401855, G_Loss:16.849788665771484

iterator 400, D_Loss:0.4258224666118622, G_Loss:16.85422134399414

iterator 500, D_Loss:0.41616272926330566, G_Loss:16.9434814453125

iterator 600, D_Loss:0.4240618944168091, G_Loss:17.73984146118164

iterator 700, D_Loss:0.4149864912033081, G_Loss:14.270820617675781

iterator 800, D_Loss:0.4310331642627716, G_Loss:18.024494171142578

iterator 900, D_Loss:0.43913567066192627, G_Loss:20.461257934570312

iterator 1000, D_Loss:0.40635865926742554, G_Loss:18.536849975585938

iterator 1100, D_Loss:0.43825677037239075, G_Loss:20.62128448486328

iterator 1200, D_Loss:0.42491984367370605, G_Loss:18.03882598876953

iterator 1300, D_Loss:0.4247616231441498, G_Loss:16.799530029296875

iterator 1400, D_Loss:0.43151217699050903, G_Loss:19.523887634277344

iterator 1500, D_Loss:0.4275176227092743, G_Loss:19.390501022338867

iterator 1600, D_Loss:0.42235299944877625, G_Loss:18.118789672851562

iterator 1700, D_Loss:0.4258989691734314, G_Loss:21.824432373046875

iterator 1800, D_Loss:0.4118956923484802, G_Loss:19.72665023803711

iterator 1900, D_Loss:0.421662837266922, G_Loss:21.532878875732422

iterator 2000, D_Loss:0.4239501655101776, G_Loss:20.711654663085938

iterator 2100, D_Loss:0.42767295241355896, G_Loss:19.627275466918945

iterator 2200, D_Loss:0.42395085096359253, G_Loss:18.832304000854492

iterator 2300, D_Loss:0.4185306429862976, G_Loss:18.732812881469727

iterator 2400, D_Loss:0.41698157787323, G_Loss:19.129549026489258

iterator 2500, D_Loss:0.42805469036102295, G_Loss:17.32501983642578

iterator 2600, D_Loss:0.4408262372016907, G_Loss:19.140743255615234

iterator 2700, D_Loss:0.4185299873352051, G_Loss:17.358957290649414

iterator 2800, D_Loss:0.4353017508983612, G_Loss:17.27118492126465

iterator 2900, D_Loss:0.42909398674964905, G_Loss:18.212112426757812

iterator 3000, D_Loss:0.4275971055030823, G_Loss:18.886640548706055

iterator 3100, D_Loss:0.4195254445075989, G_Loss:21.892967224121094

iterator 3200, D_Loss:0.41342872381210327, G_Loss:18.504640579223633

iterator 3300, D_Loss:0.4205962121486664, G_Loss:19.40237808227539

iterator 3400, D_Loss:0.412793904542923, G_Loss:19.26123046875

iterator 3500, D_Loss:0.4133607745170593, G_Loss:17.89779281616211

iterator 3600, D_Loss:0.42624202370643616, G_Loss:19.890213012695312

iterator 3700, D_Loss:0.4224817156791687, G_Loss:16.863393783569336

iterator 3800, D_Loss:0.4254138171672821, G_Loss:19.347496032714844

iterator 3900, D_Loss:0.43001118302345276, G_Loss:18.820663452148438

iterator 4000, D_Loss:0.44671428203582764, G_Loss:18.884586334228516

iterator 4100, D_Loss:0.40342313051223755, G_Loss:18.396041870117188

iterator 4200, D_Loss:0.42030349373817444, G_Loss:18.188133239746094

iterator 4300, D_Loss:0.4092656672000885, G_Loss:17.67241096496582

iterator 4400, D_Loss:0.41468194127082825, G_Loss:18.236530303955078

iterator 4500, D_Loss:0.4276673197746277, G_Loss:17.383441925048828

iterator 4600, D_Loss:0.4320381283760071, G_Loss:17.025508880615234

iterator 4700, D_Loss:0.4397314786911011, G_Loss:17.020320892333984

iterator 4800, D_Loss:0.409499853849411, G_Loss:18.060029983520508

iterator 4900, D_Loss:0.42331546545028687, G_Loss:17.42257308959961

iterator 5000, D_Loss:0.4421329200267792, G_Loss:17.23356819152832

-----------Epoch 3-----------
iterator 100, D_Loss:0.43384137749671936, G_Loss:16.603897094726562

iterator 200, D_Loss:0.42156854271888733, G_Loss:15.501317977905273

iterator 300, D_Loss:0.4242432713508606, G_Loss:14.705642700195312

iterator 400, D_Loss:0.4127310812473297, G_Loss:15.23304271697998

iterator 500, D_Loss:0.41869044303894043, G_Loss:16.6907958984375

iterator 600, D_Loss:0.4127599000930786, G_Loss:16.221454620361328

iterator 700, D_Loss:0.44040557742118835, G_Loss:15.812639236450195

iterator 800, D_Loss:0.4342246651649475, G_Loss:16.496231079101562

iterator 900, D_Loss:0.42229658365249634, G_Loss:15.919103622436523

iterator 1000, D_Loss:0.42232587933540344, G_Loss:16.578384399414062

iterator 1100, D_Loss:0.41775837540626526, G_Loss:15.712936401367188

iterator 1200, D_Loss:0.42555785179138184, G_Loss:16.222585678100586

iterator 1300, D_Loss:0.4167327582836151, G_Loss:14.723812103271484

iterator 1400, D_Loss:0.41851478815078735, G_Loss:17.757644653320312

iterator 1500, D_Loss:0.42861270904541016, G_Loss:17.301485061645508

iterator 1600, D_Loss:0.4341225326061249, G_Loss:17.20011329650879

iterator 1700, D_Loss:0.42538535594940186, G_Loss:17.289216995239258

iterator 1800, D_Loss:0.42189309000968933, G_Loss:16.94223403930664

iterator 1900, D_Loss:0.42934271693229675, G_Loss:16.093496322631836

iterator 2000, D_Loss:0.4187287390232086, G_Loss:16.251483917236328

iterator 2100, D_Loss:0.42698875069618225, G_Loss:19.462175369262695

iterator 2200, D_Loss:0.43050673604011536, G_Loss:18.998910903930664

iterator 2300, D_Loss:0.41268280148506165, G_Loss:18.629119873046875

iterator 2400, D_Loss:0.41164708137512207, G_Loss:18.40967559814453

iterator 2500, D_Loss:0.4319777190685272, G_Loss:19.545488357543945

iterator 2600, D_Loss:0.4251694083213806, G_Loss:19.154781341552734

iterator 2700, D_Loss:0.4142822325229645, G_Loss:24.979660034179688

iterator 2800, D_Loss:0.42359912395477295, G_Loss:22.363712310791016

iterator 2900, D_Loss:0.4286934435367584, G_Loss:22.23467254638672

iterator 3000, D_Loss:0.4026784300804138, G_Loss:21.28118133544922

iterator 3100, D_Loss:0.4102163314819336, G_Loss:19.949609756469727

iterator 3200, D_Loss:0.4395501911640167, G_Loss:20.34000587463379

iterator 3300, D_Loss:0.40373659133911133, G_Loss:19.068567276000977

iterator 3400, D_Loss:0.40933847427368164, G_Loss:18.332958221435547

iterator 3500, D_Loss:0.4256756901741028, G_Loss:19.85601043701172

iterator 3600, D_Loss:0.4410046637058258, G_Loss:20.100521087646484

iterator 3700, D_Loss:0.4139659106731415, G_Loss:20.211185455322266

iterator 3800, D_Loss:0.41776588559150696, G_Loss:18.098217010498047

iterator 3900, D_Loss:0.4165806174278259, G_Loss:19.511934280395508

iterator 4000, D_Loss:0.42337897419929504, G_Loss:17.89992332458496

iterator 4100, D_Loss:0.4109390079975128, G_Loss:18.611173629760742

iterator 4200, D_Loss:0.4273255169391632, G_Loss:18.001169204711914

iterator 4300, D_Loss:0.43161311745643616, G_Loss:20.158164978027344

iterator 4400, D_Loss:0.42918992042541504, G_Loss:18.181385040283203

iterator 4500, D_Loss:0.4150979816913605, G_Loss:18.533029556274414

iterator 4600, D_Loss:0.4216003119945526, G_Loss:19.714494705200195

iterator 4700, D_Loss:0.42268672585487366, G_Loss:19.45172882080078

iterator 4800, D_Loss:0.43234679102897644, G_Loss:21.71350860595703

iterator 4900, D_Loss:0.4233238399028778, G_Loss:20.580204010009766

iterator 5000, D_Loss:0.41973254084587097, G_Loss:20.530317306518555

-----------Epoch 4-----------
iterator 100, D_Loss:0.4188241958618164, G_Loss:22.668289184570312

iterator 200, D_Loss:0.40598711371421814, G_Loss:21.887784957885742

iterator 300, D_Loss:0.4166903793811798, G_Loss:22.0157470703125

iterator 400, D_Loss:0.4257895350456238, G_Loss:23.341480255126953

iterator 500, D_Loss:0.4140806794166565, G_Loss:23.530414581298828

iterator 600, D_Loss:0.41846004128456116, G_Loss:23.64585304260254

iterator 700, D_Loss:0.40863361954689026, G_Loss:23.931970596313477

iterator 800, D_Loss:0.43199533224105835, G_Loss:23.342309951782227

iterator 900, D_Loss:0.412286639213562, G_Loss:24.07988739013672

iterator 1000, D_Loss:0.42320847511291504, G_Loss:23.340396881103516

iterator 1100, D_Loss:0.4238130748271942, G_Loss:22.553115844726562

iterator 1200, D_Loss:0.44042572379112244, G_Loss:21.304039001464844

iterator 1300, D_Loss:0.42708444595336914, G_Loss:18.073362350463867

iterator 1400, D_Loss:0.43391722440719604, G_Loss:23.326934814453125

iterator 1500, D_Loss:0.413964182138443, G_Loss:23.475749969482422

iterator 1600, D_Loss:0.41225406527519226, G_Loss:23.329193115234375

iterator 1700, D_Loss:0.440541535615921, G_Loss:22.964191436767578

iterator 1800, D_Loss:0.39760178327560425, G_Loss:23.35171890258789

iterator 1900, D_Loss:0.4174182116985321, G_Loss:21.702638626098633

iterator 2000, D_Loss:0.4212118983268738, G_Loss:20.671539306640625

iterator 2100, D_Loss:0.43121975660324097, G_Loss:20.138240814208984

iterator 2200, D_Loss:0.42236092686653137, G_Loss:19.73834991455078

iterator 2300, D_Loss:0.4038723111152649, G_Loss:21.19622230529785

iterator 2400, D_Loss:0.4234582185745239, G_Loss:21.23478889465332

iterator 2500, D_Loss:0.45208442211151123, G_Loss:24.008956909179688

iterator 2600, D_Loss:0.42257973551750183, G_Loss:20.403034210205078

iterator 2700, D_Loss:0.4375794231891632, G_Loss:21.117183685302734

iterator 2800, D_Loss:0.4385165572166443, G_Loss:19.652114868164062

iterator 2900, D_Loss:0.4222721755504608, G_Loss:20.208763122558594

iterator 3000, D_Loss:0.4422917664051056, G_Loss:21.860214233398438

iterator 3100, D_Loss:0.41171351075172424, G_Loss:20.827774047851562

iterator 3200, D_Loss:0.4153920114040375, G_Loss:20.371679306030273

iterator 3300, D_Loss:0.42024144530296326, G_Loss:21.597286224365234

iterator 3400, D_Loss:0.411456435918808, G_Loss:23.034072875976562

iterator 3500, D_Loss:0.4478861689567566, G_Loss:22.448986053466797

iterator 3600, D_Loss:0.4106181859970093, G_Loss:20.7517147064209

iterator 3700, D_Loss:0.42525598406791687, G_Loss:21.254806518554688

iterator 3800, D_Loss:0.4118683338165283, G_Loss:23.773048400878906

iterator 3900, D_Loss:0.41411885619163513, G_Loss:23.412246704101562

iterator 4000, D_Loss:0.4273441731929779, G_Loss:22.796112060546875

iterator 4100, D_Loss:0.40678539872169495, G_Loss:21.599328994750977

iterator 4200, D_Loss:0.4194069504737854, G_Loss:21.92840576171875

iterator 4300, D_Loss:0.4196649193763733, G_Loss:21.360565185546875

iterator 4400, D_Loss:0.4267551898956299, G_Loss:20.264999389648438

iterator 4500, D_Loss:0.42380794882774353, G_Loss:20.609169006347656

iterator 4600, D_Loss:0.42278382182121277, G_Loss:20.526180267333984

iterator 4700, D_Loss:0.4304635226726532, G_Loss:18.962112426757812

iterator 4800, D_Loss:0.4097384214401245, G_Loss:20.61880111694336

iterator 4900, D_Loss:0.4222576320171356, G_Loss:21.723159790039062

iterator 5000, D_Loss:0.4654645621776581, G_Loss:21.018688201904297

-----------Epoch 5-----------
iterator 100, D_Loss:0.4240320026874542, G_Loss:20.575820922851562

iterator 200, D_Loss:0.41858190298080444, G_Loss:20.744897842407227

iterator 300, D_Loss:0.415195107460022, G_Loss:22.042808532714844

iterator 400, D_Loss:0.4167664051055908, G_Loss:21.08961296081543

iterator 500, D_Loss:0.4163537621498108, G_Loss:20.108989715576172

iterator 600, D_Loss:0.4305388033390045, G_Loss:24.38864517211914

iterator 700, D_Loss:0.4321165382862091, G_Loss:24.14200210571289

iterator 800, D_Loss:0.43529629707336426, G_Loss:23.349502563476562

iterator 900, D_Loss:0.4361116290092468, G_Loss:22.192792892456055

iterator 1000, D_Loss:0.4426836669445038, G_Loss:22.97492218017578

iterator 1100, D_Loss:0.42982980608940125, G_Loss:23.470678329467773

iterator 1200, D_Loss:0.4085638225078583, G_Loss:24.104015350341797

iterator 1300, D_Loss:0.4408743679523468, G_Loss:24.689285278320312

iterator 1400, D_Loss:0.4038476347923279, G_Loss:23.377227783203125

iterator 1500, D_Loss:0.4236367344856262, G_Loss:21.80552864074707

iterator 1600, D_Loss:0.42672431468963623, G_Loss:19.92400360107422

iterator 1700, D_Loss:0.4284065067768097, G_Loss:21.234622955322266

iterator 1800, D_Loss:0.42469727993011475, G_Loss:19.763532638549805

iterator 1900, D_Loss:0.4211203157901764, G_Loss:18.82329559326172

iterator 2000, D_Loss:0.4189010560512543, G_Loss:18.744117736816406

iterator 2100, D_Loss:0.4210595488548279, G_Loss:19.340892791748047

iterator 2200, D_Loss:0.43177953362464905, G_Loss:19.41143798828125

iterator 2300, D_Loss:0.44404882192611694, G_Loss:19.58344078063965

iterator 2400, D_Loss:0.42294299602508545, G_Loss:20.590679168701172

iterator 2500, D_Loss:0.4312607944011688, G_Loss:21.734495162963867

iterator 2600, D_Loss:0.4353438913822174, G_Loss:22.77176284790039

iterator 2700, D_Loss:0.4232955873012543, G_Loss:21.654903411865234

iterator 2800, D_Loss:0.42528221011161804, G_Loss:21.05056381225586

iterator 2900, D_Loss:0.4281322956085205, G_Loss:21.497053146362305

iterator 3000, D_Loss:0.4354678690433502, G_Loss:21.072444915771484

iterator 3100, D_Loss:0.39960968494415283, G_Loss:21.825725555419922

iterator 3200, D_Loss:0.43756067752838135, G_Loss:21.74532699584961

iterator 3300, D_Loss:0.4302631616592407, G_Loss:21.635162353515625

iterator 3400, D_Loss:0.4231223165988922, G_Loss:22.368446350097656

iterator 3500, D_Loss:0.4171021282672882, G_Loss:25.845539093017578

iterator 3600, D_Loss:0.419573575258255, G_Loss:22.131088256835938

iterator 3700, D_Loss:0.4424726366996765, G_Loss:21.410566329956055

iterator 3800, D_Loss:0.435099333524704, G_Loss:20.100879669189453

iterator 3900, D_Loss:0.406870573759079, G_Loss:21.701793670654297

iterator 4000, D_Loss:0.4236736297607422, G_Loss:21.560638427734375

iterator 4100, D_Loss:0.42616093158721924, G_Loss:21.582229614257812

iterator 4200, D_Loss:0.4374113976955414, G_Loss:22.150360107421875

iterator 4300, D_Loss:0.426675409078598, G_Loss:21.916580200195312

iterator 4400, D_Loss:0.43534621596336365, G_Loss:23.03628921508789

iterator 4500, D_Loss:0.40043461322784424, G_Loss:23.318275451660156

iterator 4600, D_Loss:0.4161944091320038, G_Loss:20.939311981201172

iterator 4700, D_Loss:0.42054781317710876, G_Loss:19.03017807006836

iterator 4800, D_Loss:0.4266965389251709, G_Loss:21.20342254638672

iterator 4900, D_Loss:0.41334015130996704, G_Loss:20.599443435668945

iterator 5000, D_Loss:0.42425110936164856, G_Loss:20.517425537109375

-----------Epoch 6-----------
iterator 100, D_Loss:0.4211544394493103, G_Loss:20.179607391357422

iterator 200, D_Loss:0.42169392108917236, G_Loss:20.14383316040039

iterator 300, D_Loss:0.44147762656211853, G_Loss:21.76959991455078

iterator 400, D_Loss:0.43530458211898804, G_Loss:21.20650863647461

iterator 500, D_Loss:0.4169798195362091, G_Loss:20.1177921295166

iterator 600, D_Loss:0.41078895330429077, G_Loss:21.90948486328125

iterator 700, D_Loss:0.41813623905181885, G_Loss:22.10614776611328

iterator 800, D_Loss:0.44779518246650696, G_Loss:21.931026458740234

iterator 900, D_Loss:0.4345022439956665, G_Loss:19.52252960205078

iterator 1000, D_Loss:0.43965789675712585, G_Loss:24.014068603515625

iterator 1100, D_Loss:0.4407435953617096, G_Loss:22.753421783447266

iterator 1200, D_Loss:0.43310123682022095, G_Loss:22.985504150390625

iterator 1300, D_Loss:0.43113264441490173, G_Loss:24.638099670410156

iterator 1400, D_Loss:0.42662134766578674, G_Loss:25.896743774414062

iterator 1500, D_Loss:0.42002806067466736, G_Loss:23.95258903503418

iterator 1600, D_Loss:0.4179740250110626, G_Loss:23.247852325439453

iterator 1700, D_Loss:0.40745115280151367, G_Loss:25.645198822021484

iterator 1800, D_Loss:0.4264697730541229, G_Loss:26.220355987548828

iterator 1900, D_Loss:0.4428374767303467, G_Loss:26.205768585205078

iterator 2000, D_Loss:0.4131310284137726, G_Loss:23.723045349121094

iterator 2100, D_Loss:0.4327661395072937, G_Loss:25.498924255371094

iterator 2200, D_Loss:0.41601020097732544, G_Loss:22.104711532592773

iterator 2300, D_Loss:0.42555803060531616, G_Loss:22.140804290771484

iterator 2400, D_Loss:0.41897228360176086, G_Loss:21.76095962524414

iterator 2500, D_Loss:0.42604368925094604, G_Loss:22.757585525512695

iterator 2600, D_Loss:0.40587934851646423, G_Loss:21.856399536132812

iterator 2700, D_Loss:0.4068146049976349, G_Loss:20.53870391845703

iterator 2800, D_Loss:0.41419973969459534, G_Loss:22.23260498046875

iterator 2900, D_Loss:0.42730674147605896, G_Loss:23.17550277709961

iterator 3000, D_Loss:0.43025898933410645, G_Loss:20.855758666992188

iterator 3100, D_Loss:0.40832504630088806, G_Loss:21.74480438232422

iterator 3200, D_Loss:0.4262460172176361, G_Loss:22.439895629882812

iterator 3300, D_Loss:0.4266745448112488, G_Loss:22.03196144104004

iterator 3400, D_Loss:0.41507795453071594, G_Loss:22.797080993652344

iterator 3500, D_Loss:0.41885441541671753, G_Loss:21.09286880493164

iterator 3600, D_Loss:0.4158148467540741, G_Loss:22.172832489013672

iterator 3700, D_Loss:0.42485514283180237, G_Loss:23.723785400390625

iterator 3800, D_Loss:0.42178764939308167, G_Loss:21.195587158203125

iterator 3900, D_Loss:0.41978347301483154, G_Loss:22.483680725097656

iterator 4000, D_Loss:0.4008322060108185, G_Loss:21.591201782226562

iterator 4100, D_Loss:0.41396939754486084, G_Loss:21.770034790039062

iterator 4200, D_Loss:0.42808112502098083, G_Loss:22.19094467163086

iterator 4300, D_Loss:0.4266818165779114, G_Loss:22.66847801208496

iterator 4400, D_Loss:0.4203275740146637, G_Loss:22.30447006225586

iterator 4500, D_Loss:0.43515241146087646, G_Loss:22.110950469970703

iterator 4600, D_Loss:0.42993149161338806, G_Loss:21.85101890563965

iterator 4700, D_Loss:0.4300779700279236, G_Loss:21.90093994140625

iterator 4800, D_Loss:0.43108290433883667, G_Loss:22.009700775146484

iterator 4900, D_Loss:0.4378844201564789, G_Loss:24.2227840423584

iterator 5000, D_Loss:0.4231705665588379, G_Loss:24.301469802856445

-----------Epoch 7-----------
iterator 100, D_Loss:0.43504223227500916, G_Loss:22.391246795654297

iterator 200, D_Loss:0.4343065321445465, G_Loss:21.769569396972656

iterator 300, D_Loss:0.4234538972377777, G_Loss:21.6377010345459

iterator 400, D_Loss:0.41881901025772095, G_Loss:23.10628890991211

iterator 500, D_Loss:0.4137935936450958, G_Loss:22.484663009643555

iterator 600, D_Loss:0.42603933811187744, G_Loss:21.854106903076172

iterator 700, D_Loss:0.4259376525878906, G_Loss:21.808128356933594

iterator 800, D_Loss:0.436836302280426, G_Loss:22.815425872802734

iterator 900, D_Loss:0.43401989340782166, G_Loss:22.160381317138672

iterator 1000, D_Loss:0.4069354832172394, G_Loss:22.46051788330078

iterator 1100, D_Loss:0.43039849400520325, G_Loss:21.501556396484375

iterator 1200, D_Loss:0.4072349965572357, G_Loss:23.264625549316406

iterator 1300, D_Loss:0.42940500378608704, G_Loss:23.13477325439453

iterator 1400, D_Loss:0.4169470965862274, G_Loss:23.628877639770508

iterator 1500, D_Loss:0.41894039511680603, G_Loss:23.817115783691406

iterator 1600, D_Loss:0.4206872582435608, G_Loss:21.396942138671875

iterator 1700, D_Loss:0.42764508724212646, G_Loss:21.33568000793457

iterator 1800, D_Loss:0.43039998412132263, G_Loss:21.69770050048828

iterator 1900, D_Loss:0.41286540031433105, G_Loss:22.494121551513672

iterator 2000, D_Loss:0.42582011222839355, G_Loss:22.558555603027344

iterator 2100, D_Loss:0.42871758341789246, G_Loss:23.538009643554688

iterator 2200, D_Loss:0.4322552978992462, G_Loss:22.064720153808594

iterator 2300, D_Loss:0.42619845271110535, G_Loss:22.192970275878906

iterator 2400, D_Loss:0.4092424511909485, G_Loss:21.644386291503906

iterator 2500, D_Loss:0.4461367726325989, G_Loss:23.292762756347656

iterator 2600, D_Loss:0.41677311062812805, G_Loss:23.28388786315918

iterator 2700, D_Loss:0.42307916283607483, G_Loss:23.68756866455078

iterator 2800, D_Loss:0.4337092936038971, G_Loss:21.61423110961914

iterator 2900, D_Loss:0.4240129590034485, G_Loss:22.042415618896484

iterator 3000, D_Loss:0.4072932302951813, G_Loss:21.4775390625

iterator 3100, D_Loss:0.448169082403183, G_Loss:24.174333572387695

iterator 3200, D_Loss:0.43053704500198364, G_Loss:22.705738067626953

iterator 3300, D_Loss:0.42762717604637146, G_Loss:24.172222137451172

iterator 3400, D_Loss:0.4240224063396454, G_Loss:23.07292938232422

iterator 3500, D_Loss:0.4317476451396942, G_Loss:24.04730224609375

iterator 3600, D_Loss:0.42908740043640137, G_Loss:24.497581481933594

iterator 3700, D_Loss:0.4164908528327942, G_Loss:24.587438583374023

iterator 3800, D_Loss:0.41756391525268555, G_Loss:23.649333953857422

iterator 3900, D_Loss:0.4328281879425049, G_Loss:21.251998901367188

iterator 4000, D_Loss:0.4149564504623413, G_Loss:22.333932876586914

iterator 4100, D_Loss:0.4221358597278595, G_Loss:24.130802154541016

iterator 4200, D_Loss:0.42136329412460327, G_Loss:24.736846923828125

iterator 4300, D_Loss:0.4351169764995575, G_Loss:21.975921630859375

iterator 4400, D_Loss:0.4362274408340454, G_Loss:22.241056442260742

iterator 4500, D_Loss:0.4196036458015442, G_Loss:23.09130096435547

iterator 4600, D_Loss:0.41985443234443665, G_Loss:22.99620819091797

iterator 4700, D_Loss:0.4466937482357025, G_Loss:22.987775802612305

iterator 4800, D_Loss:0.4280344545841217, G_Loss:22.2200927734375

iterator 4900, D_Loss:0.42608335614204407, G_Loss:22.154949188232422

iterator 5000, D_Loss:0.43039220571517944, G_Loss:23.63870620727539

-----------Epoch 8-----------
iterator 100, D_Loss:0.40246665477752686, G_Loss:23.960247039794922

iterator 200, D_Loss:0.4005710780620575, G_Loss:23.530046463012695

iterator 300, D_Loss:0.4325520694255829, G_Loss:22.966297149658203

iterator 400, D_Loss:0.4216659665107727, G_Loss:23.84941864013672

iterator 500, D_Loss:0.41465601325035095, G_Loss:23.8099422454834

iterator 600, D_Loss:0.4187256097793579, G_Loss:23.443775177001953

iterator 700, D_Loss:0.4324527680873871, G_Loss:22.352630615234375

iterator 800, D_Loss:0.4223514795303345, G_Loss:20.484344482421875

iterator 900, D_Loss:0.4280118942260742, G_Loss:22.52450942993164

iterator 1000, D_Loss:0.4082448184490204, G_Loss:22.54977798461914

iterator 1100, D_Loss:0.41951292753219604, G_Loss:22.396259307861328

iterator 1200, D_Loss:0.4234813153743744, G_Loss:22.243480682373047

iterator 1300, D_Loss:0.40359240770339966, G_Loss:22.882728576660156

iterator 1400, D_Loss:0.42063185572624207, G_Loss:21.277793884277344

iterator 1500, D_Loss:0.4224390387535095, G_Loss:21.164798736572266

iterator 1600, D_Loss:0.42042678594589233, G_Loss:22.092117309570312

iterator 1700, D_Loss:0.42691904306411743, G_Loss:21.696943283081055

iterator 1800, D_Loss:0.42516279220581055, G_Loss:22.38119888305664

iterator 1900, D_Loss:0.40933337807655334, G_Loss:24.092226028442383

iterator 2000, D_Loss:0.4300379157066345, G_Loss:24.068283081054688

iterator 2100, D_Loss:0.42066049575805664, G_Loss:23.978862762451172

iterator 2200, D_Loss:0.4370080232620239, G_Loss:24.704193115234375

iterator 2300, D_Loss:0.40578052401542664, G_Loss:25.27783203125

iterator 2400, D_Loss:0.43357428908348083, G_Loss:27.17072296142578

iterator 2500, D_Loss:0.43483421206474304, G_Loss:26.734844207763672

iterator 2600, D_Loss:0.4194895029067993, G_Loss:26.0184268951416

iterator 2700, D_Loss:0.4357718527317047, G_Loss:26.367259979248047

iterator 2800, D_Loss:0.42913904786109924, G_Loss:25.457599639892578

iterator 2900, D_Loss:0.41460874676704407, G_Loss:25.35588264465332

iterator 3000, D_Loss:0.41923758387565613, G_Loss:26.438636779785156

iterator 3100, D_Loss:0.4191424250602722, G_Loss:25.1258487701416

iterator 3200, D_Loss:0.4217221438884735, G_Loss:26.590717315673828

iterator 3300, D_Loss:0.4251706898212433, G_Loss:27.828041076660156

iterator 3400, D_Loss:0.4342627227306366, G_Loss:26.703689575195312

iterator 3500, D_Loss:0.40718746185302734, G_Loss:25.190601348876953

iterator 3600, D_Loss:0.4153979420661926, G_Loss:26.647247314453125

iterator 3700, D_Loss:0.42416679859161377, G_Loss:25.374954223632812

iterator 3800, D_Loss:0.42525410652160645, G_Loss:25.947166442871094

iterator 3900, D_Loss:0.42683377861976624, G_Loss:24.36050796508789

iterator 4000, D_Loss:0.4358082115650177, G_Loss:24.28628921508789

iterator 4100, D_Loss:0.4282228350639343, G_Loss:27.742952346801758

iterator 4200, D_Loss:0.429088294506073, G_Loss:26.275728225708008

iterator 4300, D_Loss:0.4117979407310486, G_Loss:26.567264556884766

iterator 4400, D_Loss:0.4221600592136383, G_Loss:25.597858428955078

iterator 4500, D_Loss:0.42385536432266235, G_Loss:27.028308868408203

iterator 4600, D_Loss:0.4174330234527588, G_Loss:27.27042007446289

iterator 4700, D_Loss:0.4103655517101288, G_Loss:25.294200897216797

iterator 4800, D_Loss:0.4283319413661957, G_Loss:26.201915740966797

iterator 4900, D_Loss:0.4392206072807312, G_Loss:25.295074462890625

iterator 5000, D_Loss:0.40975677967071533, G_Loss:23.012983322143555

-----------Epoch 9-----------
iterator 100, D_Loss:0.4174584150314331, G_Loss:24.265621185302734

iterator 200, D_Loss:0.43311306834220886, G_Loss:22.761438369750977

iterator 300, D_Loss:0.4307277202606201, G_Loss:22.823083877563477

iterator 400, D_Loss:0.4189172387123108, G_Loss:22.32209014892578

iterator 500, D_Loss:0.4226868152618408, G_Loss:23.242778778076172

iterator 600, D_Loss:0.44906362891197205, G_Loss:22.442522048950195

iterator 700, D_Loss:0.4317631125450134, G_Loss:21.899436950683594

iterator 800, D_Loss:0.4408489763736725, G_Loss:22.59331703186035

iterator 900, D_Loss:0.42633846402168274, G_Loss:21.937639236450195

iterator 1000, D_Loss:0.4060117304325104, G_Loss:20.25094985961914

iterator 1100, D_Loss:0.42559814453125, G_Loss:20.803573608398438

iterator 1200, D_Loss:0.42696699500083923, G_Loss:21.93130874633789

iterator 1300, D_Loss:0.4265151917934418, G_Loss:22.857585906982422

iterator 1400, D_Loss:0.42702898383140564, G_Loss:21.409740447998047

iterator 1500, D_Loss:0.43363067507743835, G_Loss:22.03003692626953

iterator 1600, D_Loss:0.4462747871875763, G_Loss:21.646800994873047

iterator 1700, D_Loss:0.4297639727592468, G_Loss:22.0165958404541

iterator 1800, D_Loss:0.41329318284988403, G_Loss:21.721363067626953

iterator 1900, D_Loss:0.4179767072200775, G_Loss:21.83353042602539

iterator 2000, D_Loss:0.4233325719833374, G_Loss:21.579105377197266

iterator 2100, D_Loss:0.4001225233078003, G_Loss:21.40180778503418

iterator 2200, D_Loss:0.43111422657966614, G_Loss:22.119857788085938

iterator 2300, D_Loss:0.42723020911216736, G_Loss:21.290924072265625

iterator 2400, D_Loss:0.413438618183136, G_Loss:21.07500457763672

iterator 2500, D_Loss:0.42596232891082764, G_Loss:22.047767639160156

iterator 2600, D_Loss:0.41391608119010925, G_Loss:21.922887802124023

iterator 2700, D_Loss:0.4173881709575653, G_Loss:22.586471557617188

iterator 2800, D_Loss:0.42986777424812317, G_Loss:21.87452507019043

iterator 2900, D_Loss:0.42004576325416565, G_Loss:21.61347770690918

iterator 3000, D_Loss:0.4236385226249695, G_Loss:21.68509292602539

iterator 3100, D_Loss:0.44618186354637146, G_Loss:19.769472122192383

iterator 3200, D_Loss:0.4350818395614624, G_Loss:21.456260681152344

iterator 3300, D_Loss:0.44691959023475647, G_Loss:20.83786392211914

iterator 3400, D_Loss:0.40281951427459717, G_Loss:20.91564178466797

iterator 3500, D_Loss:0.41983065009117126, G_Loss:21.307209014892578

iterator 3600, D_Loss:0.4344342350959778, G_Loss:20.32901382446289

iterator 3700, D_Loss:0.4204944372177124, G_Loss:21.274181365966797

iterator 3800, D_Loss:0.42894914746284485, G_Loss:19.99346923828125

iterator 3900, D_Loss:0.42238110303878784, G_Loss:21.95541763305664

iterator 4000, D_Loss:0.4205862879753113, G_Loss:23.25331687927246

iterator 4100, D_Loss:0.42785876989364624, G_Loss:21.67563247680664

iterator 4200, D_Loss:0.44018805027008057, G_Loss:23.49905014038086

iterator 4300, D_Loss:0.44091129302978516, G_Loss:24.86127471923828

iterator 4400, D_Loss:0.41516998410224915, G_Loss:23.830326080322266

iterator 4500, D_Loss:0.4145148694515228, G_Loss:23.68368148803711

iterator 4600, D_Loss:0.4333599805831909, G_Loss:23.153724670410156

iterator 4700, D_Loss:0.4373176693916321, G_Loss:22.237682342529297

iterator 4800, D_Loss:0.4175764322280884, G_Loss:21.530960083007812

iterator 4900, D_Loss:0.43038251996040344, G_Loss:22.37339210510254

iterator 5000, D_Loss:0.43254202604293823, G_Loss:22.13477325439453

train row : 30148
sample row: 30148
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [32,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [33,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [34,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [35,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [36,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [37,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [38,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [39,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [40,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [41,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [42,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [43,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [44,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [45,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [46,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [47,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [48,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [49,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [0,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [1,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [2,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [3,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [4,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [5,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [6,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [7,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [8,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [9,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [10,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [11,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [12,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [13,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [14,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [15,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [16,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [17,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [18,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [19,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [20,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [21,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [22,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [23,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [24,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [25,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [26,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [27,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [28,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [29,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [30,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [31,0,0] Assertion `input >= 0. && input <= 1.` failed.
LGAN_generator(
  (LSTM): LSTMCell(300, 300)
  (gmfc00): Linear(in_features=200, out_features=1, bias=True)
  (gmfc01): Linear(in_features=200, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=200, bias=True)
  (gmfe00): Linear(in_features=300, out_features=200, bias=True)
  (gmfe01): Linear(in_features=300, out_features=200, bias=True)
  (fc10): Linear(in_features=200, out_features=1, bias=True)
  (fc11): Linear(in_features=1, out_features=200, bias=True)
  (fe1): Linear(in_features=300, out_features=200, bias=True)
  (gmfc20): Linear(in_features=200, out_features=1, bias=True)
  (gmfc21): Linear(in_features=200, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=200, bias=True)
  (gmfe20): Linear(in_features=300, out_features=200, bias=True)
  (gmfe21): Linear(in_features=300, out_features=200, bias=True)
  (fc30): Linear(in_features=200, out_features=1, bias=True)
  (fc31): Linear(in_features=1, out_features=200, bias=True)
  (fe3): Linear(in_features=300, out_features=200, bias=True)
  (gmfc40): Linear(in_features=200, out_features=1, bias=True)
  (gmfc41): Linear(in_features=200, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=200, bias=True)
  (gmfe40): Linear(in_features=300, out_features=200, bias=True)
  (gmfe41): Linear(in_features=300, out_features=200, bias=True)
  (fc50): Linear(in_features=200, out_features=1, bias=True)
  (fc51): Linear(in_features=1, out_features=200, bias=True)
  (fe5): Linear(in_features=300, out_features=200, bias=True)
  (fc60): Linear(in_features=200, out_features=1, bias=True)
  (fc61): Linear(in_features=1, out_features=200, bias=True)
  (fe6): Linear(in_features=300, out_features=200, bias=True)
  (fc70): Linear(in_features=200, out_features=1, bias=True)
  (fc71): Linear(in_features=1, out_features=200, bias=True)
  (fe7): Linear(in_features=300, out_features=200, bias=True)
  (fc80): Linear(in_features=200, out_features=1, bias=True)
  (fc81): Linear(in_features=1, out_features=200, bias=True)
  (fe8): Linear(in_features=300, out_features=200, bias=True)
  (fc90): Linear(in_features=200, out_features=1, bias=True)
  (fc91): Linear(in_features=1, out_features=200, bias=True)
  (fe9): Linear(in_features=300, out_features=200, bias=True)
  (gmfc100): Linear(in_features=200, out_features=1, bias=True)
  (gmfc101): Linear(in_features=200, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=200, bias=True)
  (gmfe100): Linear(in_features=300, out_features=200, bias=True)
  (gmfe101): Linear(in_features=300, out_features=200, bias=True)
  (gmfc110): Linear(in_features=200, out_features=1, bias=True)
  (gmfc111): Linear(in_features=200, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=200, bias=True)
  (gmfe110): Linear(in_features=300, out_features=200, bias=True)
  (gmfe111): Linear(in_features=300, out_features=200, bias=True)
  (gmfc120): Linear(in_features=200, out_features=1, bias=True)
  (gmfc121): Linear(in_features=200, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=200, bias=True)
  (gmfe120): Linear(in_features=300, out_features=200, bias=True)
  (gmfe121): Linear(in_features=300, out_features=200, bias=True)
  (fc130): Linear(in_features=200, out_features=1, bias=True)
  (fc131): Linear(in_features=1, out_features=200, bias=True)
  (fe13): Linear(in_features=300, out_features=200, bias=True)
  (fc140): Linear(in_features=200, out_features=1, bias=True)
  (fc141): Linear(in_features=1, out_features=200, bias=True)
  (fe14): Linear(in_features=300, out_features=200, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=45, out_features=500, bias=True)
  (inputbn): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=500, out_features=500, bias=True)
  (bn0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=500, out_features=500, bias=True)
  (bn1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=500, out_features=500, bias=True)
  (bn2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=500, out_features=500, bias=True)
  (bn3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=500, out_features=1, bias=True)
)
(0, False, 45)
-----------Epoch 0-----------
iterator 100, D_Loss:1.37733793258667, G_Loss:1.1149535179138184

iterator 200, D_Loss:1.3834394216537476, G_Loss:1.0760622024536133

iterator 300, D_Loss:1.3757259845733643, G_Loss:1.1087863445281982

iterator 400, D_Loss:1.3943278789520264, G_Loss:1.0411598682403564

iterator 500, D_Loss:1.3569886684417725, G_Loss:1.0718088150024414

iterator 600, D_Loss:1.243656873703003, G_Loss:1.2161180973052979

iterator 700, D_Loss:1.3618342876434326, G_Loss:1.2369322776794434

iterator 800, D_Loss:1.120198369026184, G_Loss:1.5614311695098877

iterator 900, D_Loss:0.989737868309021, G_Loss:2.0303738117218018

iterator 1000, D_Loss:1.0607000589370728, G_Loss:1.9300835132598877

iterator 1100, D_Loss:0.8681721687316895, G_Loss:2.189950466156006

iterator 1200, D_Loss:0.7254036664962769, G_Loss:2.8891184329986572

iterator 1300, D_Loss:0.7713422179222107, G_Loss:1.7005010843276978

iterator 1400, D_Loss:1.3992458581924438, G_Loss:1.688746690750122

iterator 1500, D_Loss:0.6485813856124878, G_Loss:2.3006937503814697

iterator 1600, D_Loss:1.4264917373657227, G_Loss:3.297074794769287

iterator 1700, D_Loss:0.6870254278182983, G_Loss:3.707662343978882

iterator 1800, D_Loss:0.5274162292480469, G_Loss:3.8694396018981934

iterator 1900, D_Loss:0.5164856910705566, G_Loss:4.358100891113281

iterator 2000, D_Loss:0.5286073088645935, G_Loss:4.562134265899658

iterator 2100, D_Loss:0.6477804183959961, G_Loss:4.470519065856934

iterator 2200, D_Loss:0.5108782052993774, G_Loss:1.9966553449630737

iterator 2300, D_Loss:0.5932123064994812, G_Loss:1.8080074787139893

iterator 2400, D_Loss:0.5207117199897766, G_Loss:5.941692352294922

iterator 2500, D_Loss:0.5036741495132446, G_Loss:3.9544525146484375

iterator 2600, D_Loss:0.48639222979545593, G_Loss:4.997265338897705

iterator 2700, D_Loss:0.5038338899612427, G_Loss:6.116087913513184

iterator 2800, D_Loss:0.7742843627929688, G_Loss:5.158028602600098

iterator 2900, D_Loss:0.4793313443660736, G_Loss:6.337738990783691

iterator 3000, D_Loss:0.4280312955379486, G_Loss:5.15078067779541

iterator 3100, D_Loss:0.4261947572231293, G_Loss:7.39957332611084

iterator 3200, D_Loss:0.4367595314979553, G_Loss:6.403289318084717

iterator 3300, D_Loss:0.421495646238327, G_Loss:5.14229154586792

iterator 3400, D_Loss:0.44245585799217224, G_Loss:7.172472953796387

iterator 3500, D_Loss:0.46981722116470337, G_Loss:5.175102710723877

iterator 3600, D_Loss:0.4344733953475952, G_Loss:6.213497638702393

iterator 3700, D_Loss:0.4263170659542084, G_Loss:7.132772922515869

iterator 3800, D_Loss:0.5010998845100403, G_Loss:6.527149200439453

iterator 3900, D_Loss:0.4354307949542999, G_Loss:5.317575454711914

iterator 4000, D_Loss:0.4418065547943115, G_Loss:7.915742874145508

iterator 4100, D_Loss:0.4392324686050415, G_Loss:8.115422248840332

iterator 4200, D_Loss:0.4239392876625061, G_Loss:7.883910655975342

iterator 4300, D_Loss:0.46653491258621216, G_Loss:7.158691883087158

iterator 4400, D_Loss:0.6464653611183167, G_Loss:4.3803935050964355

iterator 4500, D_Loss:0.43720710277557373, G_Loss:8.351634979248047

Process Process-9:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 141, in thread_run
    V_Train(search, path, sample_it, gen, dis, config["n_epochs"], param["lr"], train_it, param["z_dim"], dataset, col_type, sample_times,itertimes = 100, steps_per_epoch = config["steps_per_epoch"],GPU=GPU,KL=KL)
  File "/home/youran/Daisy/Daisy/synthesizer/train.py", line 113, in V_Train
    D_Loss2 = F.binary_cross_entropy(y_fake, fake_label)
  File "/usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/8.3.0-10.1.243/openmpi/3.1.4/pytorch/1.4.0-python-3.7.4/lib/python3.7/site-packages/torch/nn/functional.py", line 2077, in binary_cross_entropy
    input, target, weight, reduction_enum)
RuntimeError: reduce failed to synchronize: cudaErrorAssert: device-side assert triggered
LGAN_generator(
  (LSTM): LSTMCell(650, 200)
  (gmfc00): Linear(in_features=600, out_features=1, bias=True)
  (gmfc01): Linear(in_features=600, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=600, bias=True)
  (gmfe00): Linear(in_features=200, out_features=600, bias=True)
  (gmfe01): Linear(in_features=200, out_features=600, bias=True)
  (fc10): Linear(in_features=600, out_features=1, bias=True)
  (fc11): Linear(in_features=1, out_features=600, bias=True)
  (fe1): Linear(in_features=200, out_features=600, bias=True)
  (gmfc20): Linear(in_features=600, out_features=1, bias=True)
  (gmfc21): Linear(in_features=600, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=600, bias=True)
  (gmfe20): Linear(in_features=200, out_features=600, bias=True)
  (gmfe21): Linear(in_features=200, out_features=600, bias=True)
  (fc30): Linear(in_features=600, out_features=1, bias=True)
  (fc31): Linear(in_features=1, out_features=600, bias=True)
  (fe3): Linear(in_features=200, out_features=600, bias=True)
  (gmfc40): Linear(in_features=600, out_features=1, bias=True)
  (gmfc41): Linear(in_features=600, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=600, bias=True)
  (gmfe40): Linear(in_features=200, out_features=600, bias=True)
  (gmfe41): Linear(in_features=200, out_features=600, bias=True)
  (fc50): Linear(in_features=600, out_features=1, bias=True)
  (fc51): Linear(in_features=1, out_features=600, bias=True)
  (fe5): Linear(in_features=200, out_features=600, bias=True)
  (fc60): Linear(in_features=600, out_features=1, bias=True)
  (fc61): Linear(in_features=1, out_features=600, bias=True)
  (fe6): Linear(in_features=200, out_features=600, bias=True)
  (fc70): Linear(in_features=600, out_features=1, bias=True)
  (fc71): Linear(in_features=1, out_features=600, bias=True)
  (fe7): Linear(in_features=200, out_features=600, bias=True)
  (fc80): Linear(in_features=600, out_features=1, bias=True)
  (fc81): Linear(in_features=1, out_features=600, bias=True)
  (fe8): Linear(in_features=200, out_features=600, bias=True)
  (fc90): Linear(in_features=600, out_features=1, bias=True)
  (fc91): Linear(in_features=1, out_features=600, bias=True)
  (fe9): Linear(in_features=200, out_features=600, bias=True)
  (gmfc100): Linear(in_features=600, out_features=1, bias=True)
  (gmfc101): Linear(in_features=600, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=600, bias=True)
  (gmfe100): Linear(in_features=200, out_features=600, bias=True)
  (gmfe101): Linear(in_features=200, out_features=600, bias=True)
  (gmfc110): Linear(in_features=600, out_features=1, bias=True)
  (gmfc111): Linear(in_features=600, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=600, bias=True)
  (gmfe110): Linear(in_features=200, out_features=600, bias=True)
  (gmfe111): Linear(in_features=200, out_features=600, bias=True)
  (gmfc120): Linear(in_features=600, out_features=1, bias=True)
  (gmfc121): Linear(in_features=600, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=600, bias=True)
  (gmfe120): Linear(in_features=200, out_features=600, bias=True)
  (gmfe121): Linear(in_features=200, out_features=600, bias=True)
  (fc130): Linear(in_features=600, out_features=1, bias=True)
  (fc131): Linear(in_features=1, out_features=600, bias=True)
  (fe13): Linear(in_features=200, out_features=600, bias=True)
  (fc140): Linear(in_features=600, out_features=1, bias=True)
  (fc141): Linear(in_features=1, out_features=600, bias=True)
  (fe14): Linear(in_features=200, out_features=600, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=45, out_features=500, bias=True)
  (inputbn): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=500, out_features=500, bias=True)
  (bn0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=500, out_features=1, bias=True)
)
(0, False, 45)
-----------Epoch 0-----------
iterator 100, D_Loss:1.3873233795166016, G_Loss:0.9777670502662659

iterator 200, D_Loss:1.282775640487671, G_Loss:1.0027467012405396

iterator 300, D_Loss:1.2084695100784302, G_Loss:1.082014560699463

iterator 400, D_Loss:1.0885664224624634, G_Loss:1.2575874328613281

iterator 500, D_Loss:0.9628073573112488, G_Loss:1.323317050933838

iterator 600, D_Loss:1.0422117710113525, G_Loss:1.3523337841033936

iterator 700, D_Loss:0.9865706562995911, G_Loss:1.4507066011428833

iterator 800, D_Loss:1.056462049484253, G_Loss:1.4148458242416382

iterator 900, D_Loss:0.9018371105194092, G_Loss:1.6042864322662354

iterator 1000, D_Loss:0.977709174156189, G_Loss:1.4491183757781982

iterator 1100, D_Loss:1.006312608718872, G_Loss:1.4621230363845825

iterator 1200, D_Loss:0.9481773376464844, G_Loss:1.652474045753479

iterator 1300, D_Loss:0.9009000658988953, G_Loss:1.6584479808807373

iterator 1400, D_Loss:0.8908636569976807, G_Loss:1.6237812042236328

iterator 1500, D_Loss:0.9052569270133972, G_Loss:1.7580108642578125

iterator 1600, D_Loss:0.9521807432174683, G_Loss:1.6259607076644897

iterator 1700, D_Loss:1.1485651731491089, G_Loss:1.3868783712387085

iterator 1800, D_Loss:1.0387500524520874, G_Loss:1.5194967985153198

iterator 1900, D_Loss:1.0446189641952515, G_Loss:1.5582350492477417

iterator 2000, D_Loss:1.1071858406066895, G_Loss:1.470002293586731

iterator 2100, D_Loss:1.0592724084854126, G_Loss:1.43075692653656

iterator 2200, D_Loss:1.1067700386047363, G_Loss:1.3913092613220215

iterator 2300, D_Loss:1.163151502609253, G_Loss:1.2633501291275024

iterator 2400, D_Loss:1.1871747970581055, G_Loss:1.3934791088104248

iterator 2500, D_Loss:1.1693400144577026, G_Loss:1.3139170408248901

iterator 2600, D_Loss:1.1426377296447754, G_Loss:1.4117228984832764

iterator 2700, D_Loss:1.1873849630355835, G_Loss:1.4435492753982544

iterator 2800, D_Loss:1.2921409606933594, G_Loss:1.2543115615844727

iterator 2900, D_Loss:1.145209550857544, G_Loss:1.45039963722229

iterator 3000, D_Loss:1.1562600135803223, G_Loss:1.3270862102508545

iterator 3100, D_Loss:1.2299724817276, G_Loss:1.3820279836654663

iterator 3200, D_Loss:1.1897950172424316, G_Loss:1.370955467224121

iterator 3300, D_Loss:1.2355575561523438, G_Loss:1.3872199058532715

iterator 3400, D_Loss:1.139065146446228, G_Loss:1.3242689371109009

iterator 3500, D_Loss:1.2345242500305176, G_Loss:1.3165324926376343

iterator 3600, D_Loss:1.1847045421600342, G_Loss:1.3459692001342773

iterator 3700, D_Loss:1.1527774333953857, G_Loss:1.3008778095245361

iterator 3800, D_Loss:1.2134997844696045, G_Loss:1.2753905057907104

iterator 3900, D_Loss:1.199906587600708, G_Loss:1.3686491250991821

iterator 4000, D_Loss:1.1133720874786377, G_Loss:1.227298617362976

iterator 4100, D_Loss:1.1553122997283936, G_Loss:1.205929160118103

iterator 4200, D_Loss:1.1965415477752686, G_Loss:1.3630166053771973

iterator 4300, D_Loss:1.2338590621948242, G_Loss:1.124477744102478

iterator 4400, D_Loss:1.2430442571640015, G_Loss:1.2397656440734863

iterator 4500, D_Loss:1.2320162057876587, G_Loss:1.2329909801483154

iterator 4600, D_Loss:1.161392092704773, G_Loss:1.2408442497253418

iterator 4700, D_Loss:1.1611366271972656, G_Loss:1.1816495656967163

iterator 4800, D_Loss:1.2159630060195923, G_Loss:1.471691608428955

iterator 4900, D_Loss:1.144793152809143, G_Loss:1.2733650207519531

iterator 5000, D_Loss:1.2125617265701294, G_Loss:1.197307825088501

-----------Epoch 1-----------
iterator 100, D_Loss:1.2882819175720215, G_Loss:1.2595059871673584

iterator 200, D_Loss:1.1249254941940308, G_Loss:1.4157053232192993

iterator 300, D_Loss:1.1007647514343262, G_Loss:1.1656297445297241

iterator 400, D_Loss:1.2054235935211182, G_Loss:1.2666133642196655

iterator 500, D_Loss:1.187167763710022, G_Loss:1.2249336242675781

iterator 600, D_Loss:1.2041512727737427, G_Loss:1.2255536317825317

iterator 700, D_Loss:1.1161352396011353, G_Loss:1.3736430406570435

iterator 800, D_Loss:1.0887254476547241, G_Loss:1.6281615495681763

iterator 900, D_Loss:1.1010181903839111, G_Loss:1.4802833795547485

iterator 1000, D_Loss:1.1337368488311768, G_Loss:1.276586651802063

iterator 1100, D_Loss:1.1818435192108154, G_Loss:1.3501396179199219

iterator 1200, D_Loss:1.1953235864639282, G_Loss:1.3970274925231934

iterator 1300, D_Loss:1.0892938375473022, G_Loss:1.5852558612823486

iterator 1400, D_Loss:1.1748743057250977, G_Loss:1.3468533754348755

iterator 1500, D_Loss:1.2735692262649536, G_Loss:1.5311198234558105

iterator 1600, D_Loss:1.0271203517913818, G_Loss:1.2288295030593872

iterator 1700, D_Loss:0.9900670051574707, G_Loss:1.3059152364730835

iterator 1800, D_Loss:1.0121018886566162, G_Loss:1.6345980167388916

iterator 1900, D_Loss:1.164815068244934, G_Loss:1.4333852529525757

iterator 2000, D_Loss:0.9243024587631226, G_Loss:1.6684718132019043

iterator 2100, D_Loss:0.9270128011703491, G_Loss:1.6503400802612305

iterator 2200, D_Loss:1.0754085779190063, G_Loss:1.5236239433288574

iterator 2300, D_Loss:1.0142738819122314, G_Loss:1.5480127334594727

iterator 2400, D_Loss:1.052263855934143, G_Loss:1.4104397296905518

iterator 2500, D_Loss:1.0164844989776611, G_Loss:1.486834168434143

iterator 2600, D_Loss:0.9488219022750854, G_Loss:1.562479019165039

iterator 2700, D_Loss:0.8669430017471313, G_Loss:1.5201175212860107

iterator 2800, D_Loss:1.028131127357483, G_Loss:1.3529924154281616

iterator 2900, D_Loss:0.8885089159011841, G_Loss:1.456127643585205

iterator 3000, D_Loss:1.006111741065979, G_Loss:1.815963625907898

iterator 3100, D_Loss:1.1369848251342773, G_Loss:1.3683977127075195

iterator 3200, D_Loss:1.1763033866882324, G_Loss:1.7600510120391846

iterator 3300, D_Loss:1.021217703819275, G_Loss:2.0005576610565186

iterator 3400, D_Loss:0.8029437065124512, G_Loss:1.7057993412017822

iterator 3500, D_Loss:1.038325548171997, G_Loss:1.7729156017303467

iterator 3600, D_Loss:1.117020845413208, G_Loss:1.6874301433563232

iterator 3700, D_Loss:1.0038539171218872, G_Loss:1.7287379503250122

iterator 3800, D_Loss:0.9268861413002014, G_Loss:1.6104503870010376

iterator 3900, D_Loss:0.9385356307029724, G_Loss:1.679975152015686

iterator 4000, D_Loss:0.7754700183868408, G_Loss:1.9971742630004883

iterator 4100, D_Loss:0.9931591153144836, G_Loss:1.9922691583633423

iterator 4200, D_Loss:1.2736650705337524, G_Loss:2.155427932739258

iterator 4300, D_Loss:0.8687870502471924, G_Loss:1.5517045259475708

iterator 4400, D_Loss:0.9318935871124268, G_Loss:1.857256293296814

iterator 4500, D_Loss:0.9415305852890015, G_Loss:1.7812522649765015

iterator 4600, D_Loss:0.7846519947052002, G_Loss:1.6426470279693604

iterator 4700, D_Loss:0.8389672040939331, G_Loss:2.1979877948760986

iterator 4800, D_Loss:1.011584758758545, G_Loss:1.5798027515411377

iterator 4900, D_Loss:0.8093568086624146, G_Loss:2.318892240524292

iterator 5000, D_Loss:0.997766375541687, G_Loss:1.4907482862472534

-----------Epoch 2-----------
iterator 100, D_Loss:0.8968349695205688, G_Loss:1.6755861043930054

iterator 200, D_Loss:0.8552258610725403, G_Loss:2.1407644748687744

iterator 300, D_Loss:0.7760157585144043, G_Loss:1.7954298257827759

iterator 400, D_Loss:0.8791303038597107, G_Loss:2.2324881553649902

iterator 500, D_Loss:0.8326750993728638, G_Loss:1.918014407157898

iterator 600, D_Loss:0.9141649007797241, G_Loss:1.7048417329788208

iterator 700, D_Loss:0.729084312915802, G_Loss:1.5351507663726807

iterator 800, D_Loss:0.7737038731575012, G_Loss:1.9718260765075684

iterator 900, D_Loss:0.79007488489151, G_Loss:2.1089324951171875

iterator 1000, D_Loss:0.7991170287132263, G_Loss:2.0203537940979004

iterator 1100, D_Loss:0.8461194634437561, G_Loss:2.282891273498535

iterator 1200, D_Loss:0.7745624780654907, G_Loss:2.5986907482147217

iterator 1300, D_Loss:0.9233523607254028, G_Loss:1.8947043418884277

iterator 1400, D_Loss:0.8708986043930054, G_Loss:2.4496419429779053

iterator 1500, D_Loss:1.6031570434570312, G_Loss:2.128521680831909

iterator 1600, D_Loss:1.315683126449585, G_Loss:1.3503961563110352

iterator 1700, D_Loss:0.9204088449478149, G_Loss:1.773282766342163

iterator 1800, D_Loss:1.1106901168823242, G_Loss:1.996996521949768

iterator 1900, D_Loss:1.0125315189361572, G_Loss:2.098480463027954

iterator 2000, D_Loss:0.9368279576301575, G_Loss:1.784019947052002

iterator 2100, D_Loss:0.8009026050567627, G_Loss:1.5213102102279663

iterator 2200, D_Loss:0.9341821670532227, G_Loss:1.833825945854187

iterator 2300, D_Loss:1.0376689434051514, G_Loss:2.3083250522613525

iterator 2400, D_Loss:0.8277547955513, G_Loss:1.9425116777420044

iterator 2500, D_Loss:0.7229904532432556, G_Loss:1.7924827337265015

iterator 2600, D_Loss:0.8441745042800903, G_Loss:1.9787473678588867

iterator 2700, D_Loss:0.8139016032218933, G_Loss:2.2442855834960938

iterator 2800, D_Loss:0.8393137454986572, G_Loss:1.9690301418304443

iterator 2900, D_Loss:0.73704594373703, G_Loss:2.645284414291382

iterator 3000, D_Loss:0.9112437963485718, G_Loss:2.0940868854522705

iterator 3100, D_Loss:0.860042154788971, G_Loss:1.9442691802978516

iterator 3200, D_Loss:0.7630500197410583, G_Loss:2.131917715072632

iterator 3300, D_Loss:0.7718154191970825, G_Loss:2.9553589820861816

iterator 3400, D_Loss:0.6771443486213684, G_Loss:2.269261598587036

iterator 3500, D_Loss:0.7272016406059265, G_Loss:2.4193878173828125

iterator 3600, D_Loss:0.6941991448402405, G_Loss:2.1995151042938232

iterator 3700, D_Loss:0.766380250453949, G_Loss:1.8536865711212158

iterator 3800, D_Loss:0.813071072101593, G_Loss:3.062427520751953

iterator 3900, D_Loss:0.7265974283218384, G_Loss:2.195188522338867

iterator 4000, D_Loss:0.7085738778114319, G_Loss:2.4294114112854004

iterator 4100, D_Loss:0.6933542490005493, G_Loss:2.48757266998291

iterator 4200, D_Loss:0.7852593064308167, G_Loss:2.605015754699707

iterator 4300, D_Loss:0.6974709033966064, G_Loss:2.4626517295837402

iterator 4400, D_Loss:0.6700173616409302, G_Loss:2.870635509490967

iterator 4500, D_Loss:0.7537347674369812, G_Loss:2.4332897663116455

iterator 4600, D_Loss:0.7247283458709717, G_Loss:2.458989143371582

iterator 4700, D_Loss:0.6938375234603882, G_Loss:3.0998804569244385

iterator 4800, D_Loss:0.6351510882377625, G_Loss:3.3446061611175537

iterator 4900, D_Loss:0.6585543155670166, G_Loss:3.0263662338256836

iterator 5000, D_Loss:0.7017260193824768, G_Loss:3.1651864051818848

-----------Epoch 3-----------
iterator 100, D_Loss:0.6586199402809143, G_Loss:3.148773670196533

iterator 200, D_Loss:0.7655977010726929, G_Loss:2.9611690044403076

iterator 300, D_Loss:0.6548623442649841, G_Loss:3.274121046066284

iterator 400, D_Loss:0.6160233616828918, G_Loss:3.748755931854248

iterator 500, D_Loss:0.7944421768188477, G_Loss:3.2505834102630615

iterator 600, D_Loss:0.6826326847076416, G_Loss:3.235327959060669

iterator 700, D_Loss:0.7429835796356201, G_Loss:2.81037974357605

iterator 800, D_Loss:0.6980798244476318, G_Loss:3.6384119987487793

iterator 900, D_Loss:0.6579189300537109, G_Loss:3.0266506671905518

iterator 1000, D_Loss:0.7420734167098999, G_Loss:4.460718631744385

iterator 1100, D_Loss:0.7551871538162231, G_Loss:2.556910753250122

iterator 1200, D_Loss:0.7421331405639648, G_Loss:3.7247543334960938

iterator 1300, D_Loss:0.6844491958618164, G_Loss:3.601351261138916

iterator 1400, D_Loss:0.6640921235084534, G_Loss:3.4707255363464355

iterator 1500, D_Loss:0.9025022983551025, G_Loss:3.0734751224517822

iterator 1600, D_Loss:0.605530321598053, G_Loss:3.1530163288116455

iterator 1700, D_Loss:0.592910647392273, G_Loss:3.312757968902588

iterator 1800, D_Loss:0.5956188440322876, G_Loss:3.380911111831665

iterator 1900, D_Loss:0.6038737297058105, G_Loss:3.846609115600586

iterator 2000, D_Loss:0.6152539849281311, G_Loss:3.4013607501983643

iterator 2100, D_Loss:0.7206805348396301, G_Loss:3.331082344055176

iterator 2200, D_Loss:0.7331733107566833, G_Loss:2.777848243713379

iterator 2300, D_Loss:0.615892231464386, G_Loss:3.6472408771514893

iterator 2400, D_Loss:0.6114906668663025, G_Loss:3.2956812381744385

iterator 2500, D_Loss:0.6201155185699463, G_Loss:4.212226390838623

iterator 2600, D_Loss:0.6731037497520447, G_Loss:3.134516716003418

iterator 2700, D_Loss:0.5715048909187317, G_Loss:3.437929391860962

iterator 2800, D_Loss:0.6163772940635681, G_Loss:4.205173492431641

iterator 2900, D_Loss:0.6020233035087585, G_Loss:3.6994268894195557

iterator 3000, D_Loss:0.5870380401611328, G_Loss:3.869539737701416

iterator 3100, D_Loss:0.6157993078231812, G_Loss:4.0390424728393555

iterator 3200, D_Loss:0.6561493277549744, G_Loss:3.815164089202881

iterator 3300, D_Loss:0.6035059094429016, G_Loss:3.2480556964874268

iterator 3400, D_Loss:0.6019620299339294, G_Loss:3.7446508407592773

iterator 3500, D_Loss:0.6356912851333618, G_Loss:4.419290542602539

iterator 3600, D_Loss:0.6887127161026001, G_Loss:4.398322105407715

iterator 3700, D_Loss:0.5992785692214966, G_Loss:3.6214945316314697

iterator 3800, D_Loss:0.6247733235359192, G_Loss:4.156332015991211

iterator 3900, D_Loss:0.5629231929779053, G_Loss:3.532942771911621

iterator 4000, D_Loss:0.5860154628753662, G_Loss:3.6258814334869385

iterator 4100, D_Loss:0.6325017213821411, G_Loss:3.8427257537841797

iterator 4200, D_Loss:0.6412266492843628, G_Loss:3.5215790271759033

iterator 4300, D_Loss:0.6339914798736572, G_Loss:4.168436527252197

iterator 4400, D_Loss:0.5857797265052795, G_Loss:4.283686637878418

iterator 4500, D_Loss:0.5406821966171265, G_Loss:4.737375259399414

iterator 4600, D_Loss:0.554914116859436, G_Loss:4.532005786895752

iterator 4700, D_Loss:0.6119678020477295, G_Loss:4.624491214752197

iterator 4800, D_Loss:0.6106430292129517, G_Loss:3.3338801860809326

iterator 4900, D_Loss:0.6068652868270874, G_Loss:3.6791434288024902

iterator 5000, D_Loss:0.6575771570205688, G_Loss:3.615257501602173

-----------Epoch 4-----------
iterator 100, D_Loss:0.7058987617492676, G_Loss:3.3856966495513916

iterator 200, D_Loss:0.6921065449714661, G_Loss:4.142153739929199

iterator 300, D_Loss:0.6260651350021362, G_Loss:3.576455593109131

iterator 400, D_Loss:0.577323853969574, G_Loss:3.429657220840454

iterator 500, D_Loss:0.5487421751022339, G_Loss:4.434762001037598

iterator 600, D_Loss:0.6347806453704834, G_Loss:3.5309197902679443

iterator 700, D_Loss:0.607733964920044, G_Loss:5.024233341217041

iterator 800, D_Loss:0.60758376121521, G_Loss:3.3959388732910156

iterator 900, D_Loss:0.6172109246253967, G_Loss:5.137470722198486

iterator 1000, D_Loss:0.6591978669166565, G_Loss:4.900857448577881

iterator 1100, D_Loss:0.5870434045791626, G_Loss:4.219908237457275

iterator 1200, D_Loss:0.6303619742393494, G_Loss:3.70232892036438

iterator 1300, D_Loss:0.5550599098205566, G_Loss:3.3427016735076904

iterator 1400, D_Loss:0.6328210830688477, G_Loss:4.1394147872924805

iterator 1500, D_Loss:0.681931734085083, G_Loss:3.901291847229004

iterator 1600, D_Loss:0.5977057218551636, G_Loss:4.3420634269714355

iterator 1700, D_Loss:0.6962544322013855, G_Loss:4.745576858520508

iterator 1800, D_Loss:0.5951889753341675, G_Loss:3.949463367462158

iterator 1900, D_Loss:0.522259533405304, G_Loss:5.237818717956543

iterator 2000, D_Loss:0.5644216537475586, G_Loss:5.449901103973389

iterator 2100, D_Loss:0.5654743313789368, G_Loss:4.155739784240723

iterator 2200, D_Loss:0.5997799038887024, G_Loss:3.7773828506469727

iterator 2300, D_Loss:0.49957340955734253, G_Loss:4.36341667175293

iterator 2400, D_Loss:0.6181782484054565, G_Loss:4.272126197814941

iterator 2500, D_Loss:0.7139005064964294, G_Loss:3.55936598777771

iterator 2600, D_Loss:0.5504698753356934, G_Loss:5.620200157165527

iterator 2700, D_Loss:0.6215691566467285, G_Loss:3.5804827213287354

iterator 2800, D_Loss:0.6400349140167236, G_Loss:4.402810096740723

iterator 2900, D_Loss:0.6187725067138672, G_Loss:3.8189244270324707

iterator 3000, D_Loss:0.5918952226638794, G_Loss:4.2281270027160645

iterator 3100, D_Loss:0.5969796180725098, G_Loss:3.4864072799682617

iterator 3200, D_Loss:0.6509891748428345, G_Loss:4.773782730102539

iterator 3300, D_Loss:0.5886503458023071, G_Loss:3.9746499061584473

iterator 3400, D_Loss:0.5695182085037231, G_Loss:4.772045612335205

iterator 3500, D_Loss:0.6300833821296692, G_Loss:5.295177459716797

iterator 3600, D_Loss:0.6097354292869568, G_Loss:4.581783294677734

iterator 3700, D_Loss:0.5715235471725464, G_Loss:4.4113287925720215

iterator 3800, D_Loss:0.5759274959564209, G_Loss:4.467926979064941

iterator 3900, D_Loss:0.589200496673584, G_Loss:4.598768711090088

iterator 4000, D_Loss:0.557246744632721, G_Loss:4.280100345611572

iterator 4100, D_Loss:0.5803249478340149, G_Loss:5.059812545776367

iterator 4200, D_Loss:0.6572796106338501, G_Loss:4.818109512329102

iterator 4300, D_Loss:0.5879992246627808, G_Loss:4.6686482429504395

iterator 4400, D_Loss:0.5840940475463867, G_Loss:5.641098499298096

iterator 4500, D_Loss:0.5964850783348083, G_Loss:4.67933988571167

iterator 4600, D_Loss:0.5330781936645508, G_Loss:3.78896427154541

iterator 4700, D_Loss:0.529758870601654, G_Loss:4.620217323303223

iterator 4800, D_Loss:0.5291938185691833, G_Loss:3.580448627471924

iterator 4900, D_Loss:0.5294078588485718, G_Loss:4.328956127166748

iterator 5000, D_Loss:0.6563321352005005, G_Loss:4.662154197692871

-----------Epoch 5-----------
iterator 100, D_Loss:0.6292357444763184, G_Loss:4.6401047706604

iterator 200, D_Loss:0.5839688777923584, G_Loss:4.748672008514404

iterator 300, D_Loss:0.539421558380127, G_Loss:3.859077215194702

iterator 400, D_Loss:0.5549407005310059, G_Loss:4.878080368041992

iterator 500, D_Loss:0.5094723105430603, G_Loss:4.046299457550049

iterator 600, D_Loss:0.6554344296455383, G_Loss:4.770423889160156

iterator 700, D_Loss:0.5886098742485046, G_Loss:5.730044841766357

iterator 800, D_Loss:0.6108064651489258, G_Loss:4.057560443878174

iterator 900, D_Loss:0.5806632041931152, G_Loss:4.760858058929443

iterator 1000, D_Loss:0.6499152779579163, G_Loss:4.222293376922607

iterator 1100, D_Loss:0.6278428435325623, G_Loss:4.060266971588135

iterator 1200, D_Loss:0.6241546273231506, G_Loss:3.962378740310669

iterator 1300, D_Loss:0.6021265983581543, G_Loss:4.225099563598633

iterator 1400, D_Loss:0.5872469544410706, G_Loss:4.797674179077148

iterator 1500, D_Loss:0.6367018818855286, G_Loss:3.740886688232422

iterator 1600, D_Loss:0.5885770916938782, G_Loss:5.599214553833008

iterator 1700, D_Loss:0.5903578400611877, G_Loss:4.7649126052856445

iterator 1800, D_Loss:0.6053118705749512, G_Loss:4.535813331604004

iterator 1900, D_Loss:0.620213508605957, G_Loss:4.6627607345581055

iterator 2000, D_Loss:0.5424740314483643, G_Loss:4.313577175140381

iterator 2100, D_Loss:0.5466086268424988, G_Loss:4.637119770050049

iterator 2200, D_Loss:0.5832524299621582, G_Loss:4.829046726226807

iterator 2300, D_Loss:0.5517886281013489, G_Loss:4.478236675262451

iterator 2400, D_Loss:0.5706719160079956, G_Loss:4.877193450927734

iterator 2500, D_Loss:0.5708362460136414, G_Loss:5.809587478637695

iterator 2600, D_Loss:0.5471932291984558, G_Loss:6.198629379272461

iterator 2700, D_Loss:0.5693348050117493, G_Loss:4.566575527191162

iterator 2800, D_Loss:0.5955055952072144, G_Loss:4.288225173950195

iterator 2900, D_Loss:0.5876396298408508, G_Loss:5.383193492889404

iterator 3000, D_Loss:0.5901662111282349, G_Loss:6.055125713348389

iterator 3100, D_Loss:0.5420998930931091, G_Loss:3.585057497024536

iterator 3200, D_Loss:0.6516227722167969, G_Loss:4.236172676086426

iterator 3300, D_Loss:0.6224358677864075, G_Loss:4.76253080368042

iterator 3400, D_Loss:0.533954381942749, G_Loss:3.9591610431671143

iterator 3500, D_Loss:0.6117548942565918, G_Loss:4.472836017608643

iterator 3600, D_Loss:0.5964028239250183, G_Loss:5.297503471374512

iterator 3700, D_Loss:0.5942820906639099, G_Loss:3.920963764190674

iterator 3800, D_Loss:0.5886952877044678, G_Loss:4.376479625701904

iterator 3900, D_Loss:0.6069193482398987, G_Loss:3.7962279319763184

iterator 4000, D_Loss:0.5612750053405762, G_Loss:5.322874546051025

iterator 4100, D_Loss:0.6042256355285645, G_Loss:6.245818614959717

iterator 4200, D_Loss:0.6495987176895142, G_Loss:4.476938724517822

iterator 4300, D_Loss:0.5933409333229065, G_Loss:4.368345737457275

iterator 4400, D_Loss:0.6253303289413452, G_Loss:4.305787563323975

iterator 4500, D_Loss:0.63116854429245, G_Loss:5.911637306213379

iterator 4600, D_Loss:0.5565518736839294, G_Loss:5.033477306365967

iterator 4700, D_Loss:0.5432016849517822, G_Loss:4.192114353179932

iterator 4800, D_Loss:0.5776615738868713, G_Loss:4.065367221832275

iterator 4900, D_Loss:0.5795220136642456, G_Loss:4.488648414611816

iterator 5000, D_Loss:0.6316226124763489, G_Loss:6.284027099609375

-----------Epoch 6-----------
iterator 100, D_Loss:0.5964139699935913, G_Loss:4.595508575439453

iterator 200, D_Loss:0.5782296657562256, G_Loss:5.0404438972473145

iterator 300, D_Loss:0.560736358165741, G_Loss:4.093864440917969

iterator 400, D_Loss:0.5807946920394897, G_Loss:4.586398601531982

iterator 500, D_Loss:0.5375822186470032, G_Loss:3.9429149627685547

iterator 600, D_Loss:0.551606297492981, G_Loss:4.96558141708374

iterator 700, D_Loss:0.5931186676025391, G_Loss:4.474241256713867

iterator 800, D_Loss:0.6005949378013611, G_Loss:5.07102632522583

iterator 900, D_Loss:0.5410538911819458, G_Loss:4.433661937713623

iterator 1000, D_Loss:0.6219887733459473, G_Loss:3.7211029529571533

iterator 1100, D_Loss:0.5751094818115234, G_Loss:4.125603675842285

iterator 1200, D_Loss:0.620527446269989, G_Loss:4.117025852203369

iterator 1300, D_Loss:0.49893686175346375, G_Loss:6.386995315551758

iterator 1400, D_Loss:0.568100094795227, G_Loss:4.268399715423584

iterator 1500, D_Loss:0.5887992978096008, G_Loss:5.972527980804443

iterator 1600, D_Loss:0.606972336769104, G_Loss:4.0888752937316895

iterator 1700, D_Loss:0.5111803412437439, G_Loss:5.117656707763672

iterator 1800, D_Loss:0.5343006253242493, G_Loss:4.336853981018066

iterator 1900, D_Loss:0.5494176745414734, G_Loss:4.010119438171387

iterator 2000, D_Loss:0.5148541927337646, G_Loss:4.356778144836426

iterator 2100, D_Loss:0.5489687919616699, G_Loss:3.675811290740967

iterator 2200, D_Loss:0.5904856324195862, G_Loss:5.661291599273682

iterator 2300, D_Loss:0.5190111994743347, G_Loss:3.6545777320861816

iterator 2400, D_Loss:0.5829784274101257, G_Loss:4.767393112182617

iterator 2500, D_Loss:0.6291663646697998, G_Loss:3.8058040142059326

iterator 2600, D_Loss:0.5176553726196289, G_Loss:4.608519554138184

iterator 2700, D_Loss:0.5322628021240234, G_Loss:4.142317771911621

iterator 2800, D_Loss:0.6053661704063416, G_Loss:4.529842376708984

iterator 2900, D_Loss:0.5456767678260803, G_Loss:4.487295150756836

iterator 3000, D_Loss:0.6456046104431152, G_Loss:6.468050479888916

iterator 3100, D_Loss:0.6244364976882935, G_Loss:4.300151348114014

iterator 3200, D_Loss:0.5899857878684998, G_Loss:5.111830234527588

iterator 3300, D_Loss:0.5538609623908997, G_Loss:4.146895408630371

iterator 3400, D_Loss:0.5273569822311401, G_Loss:5.276925563812256

iterator 3500, D_Loss:0.5555600523948669, G_Loss:3.791229009628296

iterator 3600, D_Loss:0.5267287492752075, G_Loss:4.846692085266113

iterator 3700, D_Loss:0.5648433566093445, G_Loss:4.130655765533447

iterator 3800, D_Loss:0.5783830881118774, G_Loss:4.15293550491333

iterator 3900, D_Loss:0.5448722243309021, G_Loss:4.065964698791504

iterator 4000, D_Loss:0.5501226782798767, G_Loss:4.109950542449951

iterator 4100, D_Loss:0.577668309211731, G_Loss:5.326354503631592

iterator 4200, D_Loss:0.5980256795883179, G_Loss:4.888913631439209

iterator 4300, D_Loss:0.6058526635169983, G_Loss:4.9891180992126465

iterator 4400, D_Loss:0.5778608918190002, G_Loss:5.4489312171936035

iterator 4500, D_Loss:0.6182779669761658, G_Loss:3.811800956726074

iterator 4600, D_Loss:0.6298767924308777, G_Loss:4.538607597351074

iterator 4700, D_Loss:0.5591699481010437, G_Loss:3.6896400451660156

iterator 4800, D_Loss:0.5489858984947205, G_Loss:3.9314146041870117

iterator 4900, D_Loss:0.5250307321548462, G_Loss:6.432435989379883

iterator 5000, D_Loss:0.5913721323013306, G_Loss:3.855574369430542

-----------Epoch 7-----------
iterator 100, D_Loss:0.5516230463981628, G_Loss:4.1158342361450195

iterator 200, D_Loss:0.5875207781791687, G_Loss:3.701383113861084

iterator 300, D_Loss:0.5115652084350586, G_Loss:3.959608554840088

iterator 400, D_Loss:0.5558416843414307, G_Loss:4.6248674392700195

iterator 500, D_Loss:0.5669481754302979, G_Loss:5.19063138961792

iterator 600, D_Loss:0.6061222553253174, G_Loss:6.756305694580078

iterator 700, D_Loss:0.6113497018814087, G_Loss:4.751572132110596

iterator 800, D_Loss:0.5635545253753662, G_Loss:4.307201385498047

iterator 900, D_Loss:0.5548095703125, G_Loss:4.846227645874023

iterator 1000, D_Loss:0.5699974298477173, G_Loss:4.903938293457031

iterator 1100, D_Loss:0.578777015209198, G_Loss:3.967338800430298

iterator 1200, D_Loss:0.6004652976989746, G_Loss:4.740630626678467

iterator 1300, D_Loss:0.5301005244255066, G_Loss:4.234928607940674

iterator 1400, D_Loss:0.5769359469413757, G_Loss:4.704901218414307

iterator 1500, D_Loss:0.5483619570732117, G_Loss:3.7031078338623047

iterator 1600, D_Loss:0.6228960156440735, G_Loss:5.425443172454834

iterator 1700, D_Loss:0.5738158226013184, G_Loss:4.4323225021362305

iterator 1800, D_Loss:0.5663370490074158, G_Loss:4.527139186859131

iterator 1900, D_Loss:0.5107566714286804, G_Loss:4.102419376373291

iterator 2000, D_Loss:0.5340227484703064, G_Loss:3.858914852142334

iterator 2100, D_Loss:0.5205870270729065, G_Loss:3.8714241981506348

iterator 2200, D_Loss:0.5454590320587158, G_Loss:4.668123245239258

iterator 2300, D_Loss:0.6191734671592712, G_Loss:5.497548580169678

iterator 2400, D_Loss:0.5079048871994019, G_Loss:4.088011741638184

iterator 2500, D_Loss:0.6450330018997192, G_Loss:5.909039497375488

iterator 2600, D_Loss:0.5446650981903076, G_Loss:5.910667896270752

iterator 2700, D_Loss:0.5602099299430847, G_Loss:4.388682842254639

iterator 2800, D_Loss:0.590075671672821, G_Loss:4.407707214355469

iterator 2900, D_Loss:0.5325729846954346, G_Loss:5.468916893005371

iterator 3000, D_Loss:0.5538250803947449, G_Loss:4.7322211265563965

iterator 3100, D_Loss:0.5673770904541016, G_Loss:4.386977195739746

iterator 3200, D_Loss:0.5618171691894531, G_Loss:4.442347526550293

iterator 3300, D_Loss:0.5075639486312866, G_Loss:4.757843971252441

iterator 3400, D_Loss:0.5363196730613708, G_Loss:4.04969596862793

iterator 3500, D_Loss:0.6938318014144897, G_Loss:4.2393317222595215

iterator 3600, D_Loss:0.9733389616012573, G_Loss:3.0375688076019287

iterator 3700, D_Loss:1.083954095840454, G_Loss:1.6645572185516357

iterator 3800, D_Loss:1.279175877571106, G_Loss:1.6760815382003784

iterator 3900, D_Loss:1.1685105562210083, G_Loss:1.711453914642334

iterator 4000, D_Loss:1.1916487216949463, G_Loss:1.8005578517913818

iterator 4100, D_Loss:1.3344120979309082, G_Loss:1.5522860288619995

iterator 4200, D_Loss:1.1853991746902466, G_Loss:1.7345679998397827

iterator 4300, D_Loss:1.0981097221374512, G_Loss:1.375024437904358

iterator 4400, D_Loss:1.1456663608551025, G_Loss:1.6644631624221802

iterator 4500, D_Loss:1.2202434539794922, G_Loss:1.7649507522583008

iterator 4600, D_Loss:1.1355403661727905, G_Loss:1.7615268230438232

iterator 4700, D_Loss:1.0341633558273315, G_Loss:1.468141794204712

iterator 4800, D_Loss:0.9649295210838318, G_Loss:1.6207644939422607

iterator 4900, D_Loss:0.9021056890487671, G_Loss:1.8335347175598145

iterator 5000, D_Loss:1.0962145328521729, G_Loss:1.8408180475234985

-----------Epoch 8-----------
iterator 100, D_Loss:0.9120234847068787, G_Loss:1.4141279458999634

iterator 200, D_Loss:1.247894287109375, G_Loss:1.634455680847168

iterator 300, D_Loss:0.9930254220962524, G_Loss:1.8047020435333252

iterator 400, D_Loss:1.0454742908477783, G_Loss:1.6067075729370117

iterator 500, D_Loss:1.1329489946365356, G_Loss:2.3872880935668945

iterator 600, D_Loss:1.129354476928711, G_Loss:1.4752435684204102

iterator 700, D_Loss:1.1941041946411133, G_Loss:1.5682240724563599

iterator 800, D_Loss:0.9204400181770325, G_Loss:2.2668864727020264

iterator 900, D_Loss:0.9003430604934692, G_Loss:1.7758623361587524

iterator 1000, D_Loss:1.364823579788208, G_Loss:1.9455875158309937

iterator 1100, D_Loss:0.8949620723724365, G_Loss:2.2531566619873047

iterator 1200, D_Loss:0.901349663734436, G_Loss:1.8793584108352661

iterator 1300, D_Loss:1.0499954223632812, G_Loss:1.782057285308838

iterator 1400, D_Loss:1.0818171501159668, G_Loss:1.9826481342315674

iterator 1500, D_Loss:1.1083531379699707, G_Loss:2.3569729328155518

iterator 1600, D_Loss:0.9643745422363281, G_Loss:1.854409098625183

iterator 1700, D_Loss:0.879162073135376, G_Loss:2.1665432453155518

iterator 1800, D_Loss:0.8090418577194214, G_Loss:1.8970474004745483

iterator 1900, D_Loss:1.1132804155349731, G_Loss:2.078397035598755

iterator 2000, D_Loss:0.750184178352356, G_Loss:2.0820775032043457

iterator 2100, D_Loss:0.9134690761566162, G_Loss:1.9548628330230713

iterator 2200, D_Loss:1.1219168901443481, G_Loss:2.0856235027313232

iterator 2300, D_Loss:0.9348150491714478, G_Loss:2.5009121894836426

iterator 2400, D_Loss:0.742605984210968, G_Loss:1.8433793783187866

iterator 2500, D_Loss:0.8058798313140869, G_Loss:1.8633546829223633

iterator 2600, D_Loss:0.9057598114013672, G_Loss:2.1731159687042236

iterator 2700, D_Loss:0.8440796136856079, G_Loss:1.7441465854644775

iterator 2800, D_Loss:0.8323166370391846, G_Loss:3.2510769367218018

iterator 2900, D_Loss:0.7659288644790649, G_Loss:2.2552566528320312

iterator 3000, D_Loss:1.0828930139541626, G_Loss:2.2215888500213623

iterator 3100, D_Loss:1.0694735050201416, G_Loss:1.984384298324585

iterator 3200, D_Loss:0.9350252747535706, G_Loss:1.9479799270629883

iterator 3300, D_Loss:0.9674313068389893, G_Loss:2.1221437454223633

iterator 3400, D_Loss:0.8195756673812866, G_Loss:1.8451076745986938

iterator 3500, D_Loss:0.704970121383667, G_Loss:2.789914846420288

iterator 3600, D_Loss:0.8710448741912842, G_Loss:1.6797457933425903

iterator 3700, D_Loss:0.9138216972351074, G_Loss:2.7179346084594727

iterator 3800, D_Loss:0.9305161237716675, G_Loss:1.9234552383422852

iterator 3900, D_Loss:0.9281824827194214, G_Loss:2.519439697265625

iterator 4000, D_Loss:0.8414030075073242, G_Loss:2.5433290004730225

iterator 4100, D_Loss:0.7083355784416199, G_Loss:2.1061248779296875

iterator 4200, D_Loss:0.8690788745880127, G_Loss:2.0541317462921143

iterator 4300, D_Loss:0.8174514770507812, G_Loss:1.7231084108352661

iterator 4400, D_Loss:0.6101496815681458, G_Loss:2.121715545654297

iterator 4500, D_Loss:0.9426023364067078, G_Loss:1.8276022672653198

iterator 4600, D_Loss:0.8052655458450317, G_Loss:2.02775502204895

iterator 4700, D_Loss:0.6883943676948547, G_Loss:1.7529734373092651

iterator 4800, D_Loss:0.8231096863746643, G_Loss:2.648590326309204

iterator 4900, D_Loss:0.6869886517524719, G_Loss:2.4503819942474365

iterator 5000, D_Loss:0.8150550723075867, G_Loss:1.8949205875396729

-----------Epoch 9-----------
iterator 100, D_Loss:0.8323850035667419, G_Loss:2.731975555419922

iterator 200, D_Loss:0.9243096113204956, G_Loss:1.6651310920715332

iterator 300, D_Loss:0.7269774675369263, G_Loss:2.2461764812469482

iterator 400, D_Loss:0.8890794515609741, G_Loss:3.474817991256714

iterator 500, D_Loss:1.0541008710861206, G_Loss:3.0667452812194824

iterator 600, D_Loss:0.9447507262229919, G_Loss:1.8639990091323853

iterator 700, D_Loss:1.0473591089248657, G_Loss:2.2370283603668213

iterator 800, D_Loss:0.6970736980438232, G_Loss:2.2319936752319336

iterator 900, D_Loss:0.7218869924545288, G_Loss:3.3848166465759277

iterator 1000, D_Loss:1.2265822887420654, G_Loss:2.3629984855651855

iterator 1100, D_Loss:0.8471633791923523, G_Loss:2.1665709018707275

iterator 1200, D_Loss:0.7186813354492188, G_Loss:2.165555715560913

iterator 1300, D_Loss:0.8303639888763428, G_Loss:2.2297778129577637

iterator 1400, D_Loss:0.8568708300590515, G_Loss:2.372840404510498

iterator 1500, D_Loss:0.8212748765945435, G_Loss:3.5546669960021973

iterator 1600, D_Loss:0.8749253749847412, G_Loss:3.135051965713501

iterator 1700, D_Loss:0.7478878498077393, G_Loss:1.9726823568344116

iterator 1800, D_Loss:0.6893938183784485, G_Loss:2.2594151496887207

iterator 1900, D_Loss:1.0240119695663452, G_Loss:2.806994915008545

iterator 2000, D_Loss:0.7226405739784241, G_Loss:1.8427363634109497

iterator 2100, D_Loss:0.7047987580299377, G_Loss:2.6907529830932617

iterator 2200, D_Loss:0.853424072265625, G_Loss:2.4027280807495117

iterator 2300, D_Loss:0.6718754172325134, G_Loss:2.4598140716552734

iterator 2400, D_Loss:0.7167588472366333, G_Loss:2.599008560180664

iterator 2500, D_Loss:0.8264762759208679, G_Loss:2.388899564743042

iterator 2600, D_Loss:0.7336540818214417, G_Loss:2.1662142276763916

iterator 2700, D_Loss:0.8521712422370911, G_Loss:2.3085250854492188

iterator 2800, D_Loss:0.7424963116645813, G_Loss:2.107560873031616

iterator 2900, D_Loss:0.6420044898986816, G_Loss:2.3790488243103027

iterator 3000, D_Loss:1.1565366983413696, G_Loss:2.6927590370178223

iterator 3100, D_Loss:1.017634630203247, G_Loss:2.493114948272705

iterator 3200, D_Loss:1.0111944675445557, G_Loss:2.2090137004852295

iterator 3300, D_Loss:0.925956666469574, G_Loss:2.3166005611419678

iterator 3400, D_Loss:0.8064719438552856, G_Loss:2.0066256523132324

iterator 3500, D_Loss:0.849453330039978, G_Loss:4.255794048309326

iterator 3600, D_Loss:0.8245646953582764, G_Loss:1.9955588579177856

iterator 3700, D_Loss:1.061859130859375, G_Loss:2.275602102279663

iterator 3800, D_Loss:0.7613618969917297, G_Loss:2.4218881130218506

iterator 3900, D_Loss:0.7081420421600342, G_Loss:4.032309532165527

iterator 4000, D_Loss:0.8760047554969788, G_Loss:2.486034870147705

iterator 4100, D_Loss:0.7822685241699219, G_Loss:2.6088006496429443

iterator 4200, D_Loss:0.7995920181274414, G_Loss:3.2668023109436035

iterator 4300, D_Loss:0.887042760848999, G_Loss:2.9134271144866943

iterator 4400, D_Loss:0.7185719609260559, G_Loss:2.9441699981689453

iterator 4500, D_Loss:0.7997034788131714, G_Loss:2.0692524909973145

iterator 4600, D_Loss:0.7781132459640503, G_Loss:1.9874683618545532

iterator 4700, D_Loss:0.7335039973258972, G_Loss:1.9247822761535645

iterator 4800, D_Loss:0.7529193758964539, G_Loss:2.1171085834503174

iterator 4900, D_Loss:0.862144947052002, G_Loss:2.061068296432495

iterator 5000, D_Loss:0.7771267890930176, G_Loss:2.2656660079956055

train row : 30148
sample row: 30148
LGAN_generator(
  (LSTM): LSTMCell(600, 300)
  (fc00): Linear(in_features=400, out_features=1, bias=True)
  (fc01): Linear(in_features=1, out_features=400, bias=True)
  (fe0): Linear(in_features=300, out_features=400, bias=True)
  (fc10): Linear(in_features=400, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=400, bias=True)
  (fe1): Linear(in_features=300, out_features=400, bias=True)
  (fc20): Linear(in_features=400, out_features=1, bias=True)
  (fc21): Linear(in_features=1, out_features=400, bias=True)
  (fe2): Linear(in_features=300, out_features=400, bias=True)
  (fc30): Linear(in_features=400, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=400, bias=True)
  (fe3): Linear(in_features=300, out_features=400, bias=True)
  (fc40): Linear(in_features=400, out_features=1, bias=True)
  (fc41): Linear(in_features=1, out_features=400, bias=True)
  (fe4): Linear(in_features=300, out_features=400, bias=True)
  (fc50): Linear(in_features=400, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=400, bias=True)
  (fe5): Linear(in_features=300, out_features=400, bias=True)
  (fc60): Linear(in_features=400, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=400, bias=True)
  (fe6): Linear(in_features=300, out_features=400, bias=True)
  (fc70): Linear(in_features=400, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=400, bias=True)
  (fe7): Linear(in_features=300, out_features=400, bias=True)
  (fc80): Linear(in_features=400, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=400, bias=True)
  (fe8): Linear(in_features=300, out_features=400, bias=True)
  (fc90): Linear(in_features=400, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=400, bias=True)
  (fe9): Linear(in_features=300, out_features=400, bias=True)
  (fc100): Linear(in_features=400, out_features=1, bias=True)
  (fc101): Linear(in_features=1, out_features=400, bias=True)
  (fe10): Linear(in_features=300, out_features=400, bias=True)
  (fc110): Linear(in_features=400, out_features=1, bias=True)
  (fc111): Linear(in_features=1, out_features=400, bias=True)
  (fe11): Linear(in_features=300, out_features=400, bias=True)
  (fc120): Linear(in_features=400, out_features=1, bias=True)
  (fc121): Linear(in_features=1, out_features=400, bias=True)
  (fe12): Linear(in_features=300, out_features=400, bias=True)
  (fc130): Linear(in_features=400, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=400, bias=True)
  (fe13): Linear(in_features=300, out_features=400, bias=True)
  (fc140): Linear(in_features=400, out_features=2, bias=True)
  (fc141): Linear(in_features=2, out_features=400, bias=True)
  (fe14): Linear(in_features=300, out_features=400, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=105, out_features=500, bias=True)
  (inputbn): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=500, out_features=500, bias=True)
  (bn0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=500, out_features=1, bias=True)
)
(0, False, 105)
-----------Epoch 0-----------
iterator 100, D_Loss:1.1298596858978271, G_Loss:1.1317583322525024

iterator 200, D_Loss:1.125724196434021, G_Loss:1.3828871250152588

iterator 300, D_Loss:1.0929441452026367, G_Loss:1.609609842300415

iterator 400, D_Loss:1.0673043727874756, G_Loss:1.6114202737808228

iterator 500, D_Loss:1.1032315492630005, G_Loss:1.6099216938018799

iterator 600, D_Loss:1.2330715656280518, G_Loss:1.5437796115875244

iterator 700, D_Loss:1.1207647323608398, G_Loss:1.6070361137390137

iterator 800, D_Loss:1.1431971788406372, G_Loss:1.52448570728302

iterator 900, D_Loss:1.0824328660964966, G_Loss:1.574639081954956

iterator 1000, D_Loss:1.07602059841156, G_Loss:1.655524730682373

iterator 1100, D_Loss:0.8915539979934692, G_Loss:1.8144357204437256

iterator 1200, D_Loss:1.3415720462799072, G_Loss:1.514033317565918

iterator 1300, D_Loss:1.0485244989395142, G_Loss:1.7091162204742432

iterator 1400, D_Loss:0.8907511830329895, G_Loss:1.7312575578689575

iterator 1500, D_Loss:0.8828761577606201, G_Loss:1.9872527122497559

iterator 1600, D_Loss:1.260828971862793, G_Loss:1.6228930950164795

iterator 1700, D_Loss:1.0169227123260498, G_Loss:1.8463599681854248

iterator 1800, D_Loss:1.0503597259521484, G_Loss:1.741391658782959

iterator 1900, D_Loss:1.0227901935577393, G_Loss:1.8033568859100342

iterator 2000, D_Loss:0.8382455706596375, G_Loss:2.523186206817627

iterator 2100, D_Loss:0.9786938428878784, G_Loss:1.837675929069519

iterator 2200, D_Loss:0.7316778898239136, G_Loss:2.9003140926361084

iterator 2300, D_Loss:0.6772726774215698, G_Loss:3.398623466491699

iterator 2400, D_Loss:0.6520179510116577, G_Loss:3.6758975982666016

iterator 2500, D_Loss:0.5926684141159058, G_Loss:3.747955799102783

iterator 2600, D_Loss:0.5132920145988464, G_Loss:4.322286605834961

iterator 2700, D_Loss:0.6313309073448181, G_Loss:3.924013376235962

iterator 2800, D_Loss:0.5311582684516907, G_Loss:4.521754741668701

iterator 2900, D_Loss:0.5294744372367859, G_Loss:5.236579895019531

iterator 3000, D_Loss:0.4989687204360962, G_Loss:5.331151485443115

iterator 3100, D_Loss:0.535456657409668, G_Loss:3.013582229614258

iterator 3200, D_Loss:0.6007815599441528, G_Loss:4.184600830078125

iterator 3300, D_Loss:0.5987250804901123, G_Loss:5.35246467590332

iterator 3400, D_Loss:0.7063504457473755, G_Loss:4.63670015335083

iterator 3500, D_Loss:0.6124606132507324, G_Loss:4.096170902252197

iterator 3600, D_Loss:0.5730659365653992, G_Loss:5.341185569763184

iterator 3700, D_Loss:0.5759177207946777, G_Loss:4.483247756958008

iterator 3800, D_Loss:0.5905301570892334, G_Loss:3.984816074371338

iterator 3900, D_Loss:0.5262791514396667, G_Loss:5.557081699371338

iterator 4000, D_Loss:0.6954282522201538, G_Loss:3.9691548347473145

iterator 4100, D_Loss:0.6992560625076294, G_Loss:3.6014187335968018

iterator 4200, D_Loss:0.6090728640556335, G_Loss:3.712029457092285

iterator 4300, D_Loss:0.5465646982192993, G_Loss:4.963423728942871

iterator 4400, D_Loss:0.5323579907417297, G_Loss:4.490108013153076

iterator 4500, D_Loss:0.5979065895080566, G_Loss:4.747557163238525

iterator 4600, D_Loss:0.5668745040893555, G_Loss:6.915035724639893

iterator 4700, D_Loss:0.5221105217933655, G_Loss:4.232659339904785

iterator 4800, D_Loss:0.6027712225914001, G_Loss:4.46506404876709

iterator 4900, D_Loss:0.5677037835121155, G_Loss:4.520140647888184

iterator 5000, D_Loss:0.5268815755844116, G_Loss:4.423125267028809

-----------Epoch 1-----------
iterator 100, D_Loss:0.4999762177467346, G_Loss:4.961012363433838

iterator 200, D_Loss:0.5298649072647095, G_Loss:7.570892810821533

iterator 300, D_Loss:0.606543242931366, G_Loss:4.9615068435668945

iterator 400, D_Loss:0.4999442398548126, G_Loss:4.630222320556641

iterator 500, D_Loss:0.5543868541717529, G_Loss:4.827326774597168

iterator 600, D_Loss:0.489352822303772, G_Loss:4.601378917694092

iterator 700, D_Loss:0.5461476445198059, G_Loss:6.766587257385254

iterator 800, D_Loss:0.5741897821426392, G_Loss:5.372837543487549

iterator 900, D_Loss:0.5181249380111694, G_Loss:5.017491340637207

iterator 1000, D_Loss:0.536576509475708, G_Loss:3.5757243633270264

iterator 1100, D_Loss:0.5222672820091248, G_Loss:4.544618129730225

iterator 1200, D_Loss:0.5424239635467529, G_Loss:5.007525444030762

iterator 1300, D_Loss:0.5692802667617798, G_Loss:4.861517906188965

iterator 1400, D_Loss:0.5222992897033691, G_Loss:6.279677867889404

iterator 1500, D_Loss:0.48665082454681396, G_Loss:6.4888834953308105

iterator 1600, D_Loss:0.5027284622192383, G_Loss:4.6977219581604

iterator 1700, D_Loss:0.5223094820976257, G_Loss:5.904483795166016

iterator 1800, D_Loss:0.5407567620277405, G_Loss:3.7463631629943848

iterator 1900, D_Loss:0.5210254192352295, G_Loss:4.495025157928467

iterator 2000, D_Loss:0.5519576072692871, G_Loss:5.769052505493164

iterator 2100, D_Loss:0.4896402657032013, G_Loss:6.23227071762085

iterator 2200, D_Loss:0.5143839716911316, G_Loss:4.21514368057251

iterator 2300, D_Loss:0.5018792748451233, G_Loss:4.809609889984131

iterator 2400, D_Loss:0.5012020468711853, G_Loss:4.399765968322754

iterator 2500, D_Loss:0.4919641315937042, G_Loss:4.129024505615234

iterator 2600, D_Loss:0.480106383562088, G_Loss:5.4030303955078125

iterator 2700, D_Loss:0.534990131855011, G_Loss:4.765571117401123

iterator 2800, D_Loss:0.525372326374054, G_Loss:4.717362880706787

iterator 2900, D_Loss:0.5053287148475647, G_Loss:6.011183261871338

iterator 3000, D_Loss:0.49917757511138916, G_Loss:6.69675350189209

iterator 3100, D_Loss:0.4749090373516083, G_Loss:4.903501987457275

iterator 3200, D_Loss:0.5196569561958313, G_Loss:4.45693302154541

iterator 3300, D_Loss:0.4909130930900574, G_Loss:6.910236835479736

iterator 3400, D_Loss:0.5114864706993103, G_Loss:6.86781644821167

iterator 3500, D_Loss:0.4671703577041626, G_Loss:4.9288649559021

iterator 3600, D_Loss:0.4684825539588928, G_Loss:6.366888046264648

iterator 3700, D_Loss:0.4725528359413147, G_Loss:5.872681617736816

iterator 3800, D_Loss:0.5151320695877075, G_Loss:4.352718830108643

iterator 3900, D_Loss:0.476683109998703, G_Loss:6.096573829650879

iterator 4000, D_Loss:0.551464855670929, G_Loss:5.626997947692871

iterator 4100, D_Loss:0.48901692032814026, G_Loss:5.746872901916504

iterator 4200, D_Loss:0.4954582452774048, G_Loss:5.519731044769287

iterator 4300, D_Loss:0.5014021396636963, G_Loss:5.835603713989258

iterator 4400, D_Loss:0.4700395166873932, G_Loss:5.681238651275635

iterator 4500, D_Loss:0.5241492986679077, G_Loss:5.546445369720459

iterator 4600, D_Loss:0.44619399309158325, G_Loss:5.296162128448486

iterator 4700, D_Loss:0.4855304956436157, G_Loss:5.513829708099365

iterator 4800, D_Loss:0.4977816045284271, G_Loss:5.35106086730957

iterator 4900, D_Loss:0.48963260650634766, G_Loss:5.1372833251953125

iterator 5000, D_Loss:0.466844379901886, G_Loss:5.6768975257873535

-----------Epoch 2-----------
iterator 100, D_Loss:0.4936078190803528, G_Loss:5.527116775512695

iterator 200, D_Loss:0.4910879135131836, G_Loss:6.724056720733643

iterator 300, D_Loss:0.4720059335231781, G_Loss:5.282593250274658

iterator 400, D_Loss:0.49436938762664795, G_Loss:5.071955680847168

iterator 500, D_Loss:0.4818461239337921, G_Loss:5.001339912414551

iterator 600, D_Loss:0.4916699230670929, G_Loss:8.573800086975098

iterator 700, D_Loss:0.5026745796203613, G_Loss:5.152670383453369

iterator 800, D_Loss:0.5059900283813477, G_Loss:6.0416717529296875

iterator 900, D_Loss:0.527228593826294, G_Loss:5.808745384216309

iterator 1000, D_Loss:0.4872695803642273, G_Loss:5.807648658752441

iterator 1100, D_Loss:0.4963585436344147, G_Loss:5.675830841064453

iterator 1200, D_Loss:0.49604684114456177, G_Loss:5.918774604797363

iterator 1300, D_Loss:0.4833992123603821, G_Loss:5.515212059020996

iterator 1400, D_Loss:0.4878169298171997, G_Loss:5.456081390380859

iterator 1500, D_Loss:0.4949699938297272, G_Loss:4.249738693237305

iterator 1600, D_Loss:0.4872085154056549, G_Loss:6.330254077911377

iterator 1700, D_Loss:0.47558438777923584, G_Loss:5.5990705490112305

iterator 1800, D_Loss:0.45488107204437256, G_Loss:6.713005542755127

iterator 1900, D_Loss:0.4843585789203644, G_Loss:5.0834503173828125

iterator 2000, D_Loss:0.4825187921524048, G_Loss:4.826026439666748

iterator 2100, D_Loss:0.4678756594657898, G_Loss:6.51632022857666

iterator 2200, D_Loss:0.46973589062690735, G_Loss:7.023509502410889

iterator 2300, D_Loss:0.4669426679611206, G_Loss:6.910036087036133

iterator 2400, D_Loss:0.47482040524482727, G_Loss:7.419150352478027

iterator 2500, D_Loss:0.4776886999607086, G_Loss:5.32442569732666

iterator 2600, D_Loss:0.5079072117805481, G_Loss:5.7792768478393555

iterator 2700, D_Loss:0.4873366355895996, G_Loss:5.982624053955078

iterator 2800, D_Loss:0.4848325252532959, G_Loss:4.797154903411865

iterator 2900, D_Loss:0.4947566092014313, G_Loss:5.0951924324035645

iterator 3000, D_Loss:0.48544251918792725, G_Loss:5.197288990020752

iterator 3100, D_Loss:0.45992934703826904, G_Loss:10.610496520996094

iterator 3200, D_Loss:0.47045692801475525, G_Loss:5.6832122802734375

iterator 3300, D_Loss:0.4653733968734741, G_Loss:5.84148645401001

iterator 3400, D_Loss:0.473273903131485, G_Loss:9.312660217285156

iterator 3500, D_Loss:0.4578448235988617, G_Loss:6.418740749359131

iterator 3600, D_Loss:0.5022836923599243, G_Loss:5.78561544418335

iterator 3700, D_Loss:0.48875242471694946, G_Loss:5.972023010253906

iterator 3800, D_Loss:0.47708380222320557, G_Loss:6.082448959350586

iterator 3900, D_Loss:0.47937265038490295, G_Loss:5.898581027984619

iterator 4000, D_Loss:0.528449535369873, G_Loss:5.824702262878418

iterator 4100, D_Loss:0.47017934918403625, G_Loss:5.2720627784729

iterator 4200, D_Loss:0.46549996733665466, G_Loss:6.042450904846191

iterator 4300, D_Loss:0.4790838658809662, G_Loss:5.818601608276367

iterator 4400, D_Loss:0.4942736327648163, G_Loss:5.659501075744629

iterator 4500, D_Loss:0.4918231666088104, G_Loss:5.012797832489014

iterator 4600, D_Loss:0.49542370438575745, G_Loss:5.8379225730896

iterator 4700, D_Loss:0.4846029579639435, G_Loss:6.685725212097168

iterator 4800, D_Loss:0.4719535708427429, G_Loss:4.650296211242676

iterator 4900, D_Loss:0.4649643898010254, G_Loss:5.665637016296387

iterator 5000, D_Loss:0.4890115261077881, G_Loss:6.801609039306641

-----------Epoch 3-----------
iterator 100, D_Loss:0.474752813577652, G_Loss:7.284712314605713

iterator 200, D_Loss:0.46805450320243835, G_Loss:5.898280620574951

iterator 300, D_Loss:0.47501102089881897, G_Loss:6.751237869262695

iterator 400, D_Loss:0.47058048844337463, G_Loss:5.871045112609863

iterator 500, D_Loss:0.47878479957580566, G_Loss:6.169506072998047

iterator 600, D_Loss:0.4610303044319153, G_Loss:10.745845794677734

iterator 700, D_Loss:0.5013336539268494, G_Loss:8.791626930236816

iterator 800, D_Loss:0.5127395987510681, G_Loss:10.437444686889648

iterator 900, D_Loss:0.470601350069046, G_Loss:8.359560012817383

iterator 1000, D_Loss:0.45139938592910767, G_Loss:6.873293876647949

iterator 1100, D_Loss:0.471631795167923, G_Loss:6.188226699829102

iterator 1200, D_Loss:0.4823182225227356, G_Loss:6.522290229797363

iterator 1300, D_Loss:0.46086424589157104, G_Loss:5.500964164733887

iterator 1400, D_Loss:0.4571665823459625, G_Loss:5.474559783935547

iterator 1500, D_Loss:0.46627482771873474, G_Loss:6.569611072540283

iterator 1600, D_Loss:0.4937629699707031, G_Loss:4.401571273803711

iterator 1700, D_Loss:0.4707866609096527, G_Loss:6.20867919921875

iterator 1800, D_Loss:0.48490920662879944, G_Loss:5.058891773223877

iterator 1900, D_Loss:0.5025652647018433, G_Loss:6.208846092224121

iterator 2000, D_Loss:0.48682495951652527, G_Loss:5.44256591796875

iterator 2100, D_Loss:0.47933462262153625, G_Loss:6.282792568206787

iterator 2200, D_Loss:0.4713309407234192, G_Loss:7.076177597045898

iterator 2300, D_Loss:0.45605266094207764, G_Loss:6.717000961303711

iterator 2400, D_Loss:0.45806142687797546, G_Loss:5.836409091949463

iterator 2500, D_Loss:0.48273634910583496, G_Loss:6.5000457763671875

iterator 2600, D_Loss:0.46729642152786255, G_Loss:6.756820201873779

iterator 2700, D_Loss:0.4767867624759674, G_Loss:6.570478916168213

iterator 2800, D_Loss:0.4817463159561157, G_Loss:5.8298869132995605

iterator 2900, D_Loss:0.4783681631088257, G_Loss:9.523469924926758

iterator 3000, D_Loss:0.43586161732673645, G_Loss:6.9437479972839355

iterator 3100, D_Loss:0.4635885953903198, G_Loss:7.047177791595459

iterator 3200, D_Loss:0.4889793395996094, G_Loss:8.415395736694336

iterator 3300, D_Loss:0.4478292763233185, G_Loss:6.818997859954834

iterator 3400, D_Loss:0.45446473360061646, G_Loss:7.116195201873779

iterator 3500, D_Loss:0.4696418046951294, G_Loss:8.588411331176758

iterator 3600, D_Loss:0.4750468134880066, G_Loss:6.5134429931640625

iterator 3700, D_Loss:0.45884811878204346, G_Loss:7.4806084632873535

iterator 3800, D_Loss:0.45043519139289856, G_Loss:7.214756965637207

iterator 3900, D_Loss:0.44657081365585327, G_Loss:6.767246723175049

iterator 4000, D_Loss:0.48362016677856445, G_Loss:6.806156635284424

iterator 4100, D_Loss:0.4470052719116211, G_Loss:6.9416890144348145

iterator 4200, D_Loss:0.46417921781539917, G_Loss:6.472544193267822

iterator 4300, D_Loss:0.501281201839447, G_Loss:8.585914611816406

iterator 4400, D_Loss:0.47296667098999023, G_Loss:7.394326686859131

iterator 4500, D_Loss:0.46161678433418274, G_Loss:6.6983962059021

iterator 4600, D_Loss:0.4605957269668579, G_Loss:6.259687423706055

iterator 4700, D_Loss:0.46304085850715637, G_Loss:6.916863918304443

iterator 4800, D_Loss:0.48385775089263916, G_Loss:6.219456195831299

iterator 4900, D_Loss:0.46664848923683167, G_Loss:6.657590389251709

iterator 5000, D_Loss:0.45996323227882385, G_Loss:7.074763298034668

-----------Epoch 4-----------
iterator 100, D_Loss:0.462796151638031, G_Loss:5.950671672821045

iterator 200, D_Loss:0.4752887785434723, G_Loss:5.400544166564941

iterator 300, D_Loss:0.4697267711162567, G_Loss:5.027749061584473

iterator 400, D_Loss:0.4715571105480194, G_Loss:5.474565505981445

iterator 500, D_Loss:0.471108615398407, G_Loss:5.0682878494262695

iterator 600, D_Loss:0.4529208540916443, G_Loss:5.990562915802002

iterator 700, D_Loss:0.4708620607852936, G_Loss:6.482589244842529

iterator 800, D_Loss:0.49221116304397583, G_Loss:5.925410270690918

iterator 900, D_Loss:0.45180776715278625, G_Loss:5.42685604095459

iterator 1000, D_Loss:0.47350946068763733, G_Loss:5.899234771728516

iterator 1100, D_Loss:0.4938091039657593, G_Loss:5.478830337524414

iterator 1200, D_Loss:0.49422457814216614, G_Loss:5.553554534912109

iterator 1300, D_Loss:0.48468148708343506, G_Loss:5.734958648681641

iterator 1400, D_Loss:0.47431859374046326, G_Loss:5.614323139190674

iterator 1500, D_Loss:0.4608675241470337, G_Loss:5.216953277587891

iterator 1600, D_Loss:0.4578604996204376, G_Loss:6.403547286987305

iterator 1700, D_Loss:0.48805585503578186, G_Loss:8.150835037231445

iterator 1800, D_Loss:0.43899065256118774, G_Loss:5.285182952880859

iterator 1900, D_Loss:0.46784549951553345, G_Loss:5.908545970916748

iterator 2000, D_Loss:0.464995414018631, G_Loss:6.464966773986816

iterator 2100, D_Loss:0.46387359499931335, G_Loss:7.989993095397949

iterator 2200, D_Loss:0.4696335792541504, G_Loss:6.378309726715088

iterator 2300, D_Loss:0.4307444989681244, G_Loss:5.651674747467041

iterator 2400, D_Loss:0.4749484956264496, G_Loss:8.231677055358887

iterator 2500, D_Loss:0.5013473629951477, G_Loss:6.296352386474609

iterator 2600, D_Loss:0.45474377274513245, G_Loss:6.8719282150268555

iterator 2700, D_Loss:0.4884811341762543, G_Loss:6.562948703765869

iterator 2800, D_Loss:0.4882277548313141, G_Loss:8.344709396362305

iterator 2900, D_Loss:0.48287373781204224, G_Loss:6.299595832824707

iterator 3000, D_Loss:0.4848453104496002, G_Loss:5.8258466720581055

iterator 3100, D_Loss:0.4520084857940674, G_Loss:6.273674011230469

iterator 3200, D_Loss:0.47239863872528076, G_Loss:7.435764789581299

iterator 3300, D_Loss:0.4650915265083313, G_Loss:7.441837787628174

iterator 3400, D_Loss:0.46443477272987366, G_Loss:6.732312202453613

iterator 3500, D_Loss:0.48932188749313354, G_Loss:7.068739414215088

iterator 3600, D_Loss:0.46196600794792175, G_Loss:6.403371810913086

iterator 3700, D_Loss:0.46985673904418945, G_Loss:5.33027458190918

iterator 3800, D_Loss:0.4526679217815399, G_Loss:8.063958168029785

iterator 3900, D_Loss:0.4567301869392395, G_Loss:10.339242935180664

iterator 4000, D_Loss:0.5039669275283813, G_Loss:6.662672996520996

iterator 4100, D_Loss:0.4518775939941406, G_Loss:6.402804374694824

iterator 4200, D_Loss:0.4614400565624237, G_Loss:8.260753631591797

iterator 4300, D_Loss:0.4614102244377136, G_Loss:7.8494954109191895

iterator 4400, D_Loss:0.4614431858062744, G_Loss:7.438655376434326

iterator 4500, D_Loss:0.4796942174434662, G_Loss:6.665711402893066

iterator 4600, D_Loss:0.4533476233482361, G_Loss:7.9846110343933105

iterator 4700, D_Loss:0.45752647519111633, G_Loss:7.153769493103027

iterator 4800, D_Loss:0.44872555136680603, G_Loss:7.523481845855713

iterator 4900, D_Loss:0.46944719552993774, G_Loss:7.404706954956055

iterator 5000, D_Loss:0.5187966227531433, G_Loss:7.55588436126709

-----------Epoch 5-----------
iterator 100, D_Loss:0.45633819699287415, G_Loss:6.826312065124512

iterator 200, D_Loss:0.474720299243927, G_Loss:6.727954387664795

iterator 300, D_Loss:0.4456773102283478, G_Loss:8.97878646850586

iterator 400, D_Loss:0.4640820324420929, G_Loss:7.733834266662598

iterator 500, D_Loss:0.4569288194179535, G_Loss:7.598953723907471

iterator 600, D_Loss:0.4662171006202698, G_Loss:7.133326530456543

iterator 700, D_Loss:0.4824848771095276, G_Loss:6.841977119445801

iterator 800, D_Loss:0.4751160740852356, G_Loss:7.538505554199219

iterator 900, D_Loss:0.47462350130081177, G_Loss:7.923610687255859

iterator 1000, D_Loss:0.47386598587036133, G_Loss:7.4336137771606445

iterator 1100, D_Loss:0.46533340215682983, G_Loss:7.220061302185059

iterator 1200, D_Loss:0.4429238736629486, G_Loss:9.356447219848633

iterator 1300, D_Loss:0.4812198579311371, G_Loss:7.527772426605225

iterator 1400, D_Loss:0.4361332952976227, G_Loss:7.137718200683594

iterator 1500, D_Loss:0.44836387038230896, G_Loss:7.933880805969238

iterator 1600, D_Loss:0.4644542336463928, G_Loss:8.167159080505371

iterator 1700, D_Loss:0.45471861958503723, G_Loss:9.235149383544922

iterator 1800, D_Loss:0.45192214846611023, G_Loss:8.872344970703125

iterator 1900, D_Loss:0.45317381620407104, G_Loss:10.654043197631836

iterator 2000, D_Loss:0.4515921175479889, G_Loss:10.617716789245605

iterator 2100, D_Loss:0.4388160705566406, G_Loss:9.899801254272461

iterator 2200, D_Loss:0.45752015709877014, G_Loss:10.070845603942871

iterator 2300, D_Loss:0.46377015113830566, G_Loss:9.787830352783203

iterator 2400, D_Loss:0.45707228779792786, G_Loss:9.987419128417969

iterator 2500, D_Loss:0.4665523171424866, G_Loss:9.41762924194336

iterator 2600, D_Loss:0.46846598386764526, G_Loss:9.332862854003906

iterator 2700, D_Loss:0.4597269296646118, G_Loss:9.674256324768066

iterator 2800, D_Loss:0.4555675983428955, G_Loss:8.6815185546875

iterator 2900, D_Loss:0.459502249956131, G_Loss:9.615914344787598

iterator 3000, D_Loss:0.4592154324054718, G_Loss:9.281915664672852

iterator 3100, D_Loss:0.4218320846557617, G_Loss:10.791098594665527

iterator 3200, D_Loss:0.46145737171173096, G_Loss:8.64474105834961

iterator 3300, D_Loss:0.451556921005249, G_Loss:7.077002048492432

iterator 3400, D_Loss:0.4641721844673157, G_Loss:7.970769882202148

iterator 3500, D_Loss:0.4481748938560486, G_Loss:7.949219226837158

iterator 3600, D_Loss:0.45018285512924194, G_Loss:8.029356002807617

iterator 3700, D_Loss:0.4840683043003082, G_Loss:7.09334135055542

iterator 3800, D_Loss:0.4708179831504822, G_Loss:7.572093963623047

iterator 3900, D_Loss:0.44818443059921265, G_Loss:5.930126190185547

iterator 4000, D_Loss:0.48566460609436035, G_Loss:7.20893669128418

iterator 4100, D_Loss:0.46121978759765625, G_Loss:9.142757415771484

iterator 4200, D_Loss:0.46994495391845703, G_Loss:8.09918212890625

iterator 4300, D_Loss:0.4704337418079376, G_Loss:7.715088367462158

iterator 4400, D_Loss:0.5004467368125916, G_Loss:15.469608306884766

iterator 4500, D_Loss:0.4364057779312134, G_Loss:11.85641860961914

iterator 4600, D_Loss:0.45861390233039856, G_Loss:13.483406066894531

iterator 4700, D_Loss:0.44291311502456665, G_Loss:10.945977210998535

iterator 4800, D_Loss:0.48507294058799744, G_Loss:10.70254135131836

iterator 4900, D_Loss:0.45311760902404785, G_Loss:14.289053916931152

iterator 5000, D_Loss:0.45511019229888916, G_Loss:9.741360664367676

-----------Epoch 6-----------
iterator 100, D_Loss:0.47771981358528137, G_Loss:8.191896438598633

iterator 200, D_Loss:0.45886772871017456, G_Loss:7.712785720825195

iterator 300, D_Loss:0.4962308406829834, G_Loss:11.728063583374023

iterator 400, D_Loss:0.4703878164291382, G_Loss:6.038391590118408

iterator 500, D_Loss:0.47641614079475403, G_Loss:7.276463031768799

iterator 600, D_Loss:0.43934935331344604, G_Loss:7.257354259490967

iterator 700, D_Loss:0.47351300716400146, G_Loss:7.325491428375244

iterator 800, D_Loss:0.5023403167724609, G_Loss:8.365565299987793

iterator 900, D_Loss:0.47911882400512695, G_Loss:12.609349250793457

iterator 1000, D_Loss:0.4713241457939148, G_Loss:8.310239791870117

iterator 1100, D_Loss:0.4988970160484314, G_Loss:6.7846455574035645

iterator 1200, D_Loss:0.46778976917266846, G_Loss:7.8734049797058105

iterator 1300, D_Loss:0.4738300144672394, G_Loss:7.216376304626465

iterator 1400, D_Loss:0.46647733449935913, G_Loss:8.557181358337402

iterator 1500, D_Loss:0.4581485688686371, G_Loss:7.048611640930176

iterator 1600, D_Loss:0.447341650724411, G_Loss:8.403632164001465

iterator 1700, D_Loss:0.45793354511260986, G_Loss:8.522967338562012

iterator 1800, D_Loss:0.4494028389453888, G_Loss:7.628172874450684

iterator 1900, D_Loss:0.4839971959590912, G_Loss:7.17647647857666

iterator 2000, D_Loss:0.4627239406108856, G_Loss:7.639566898345947

iterator 2100, D_Loss:0.4658677279949188, G_Loss:6.639807224273682

iterator 2200, D_Loss:0.44868984818458557, G_Loss:7.118653774261475

iterator 2300, D_Loss:0.452073335647583, G_Loss:7.8139848709106445

iterator 2400, D_Loss:0.46674883365631104, G_Loss:6.678576469421387

iterator 2500, D_Loss:0.46373251080513, G_Loss:8.047791481018066

iterator 2600, D_Loss:0.4334453046321869, G_Loss:7.559672832489014

iterator 2700, D_Loss:0.43711817264556885, G_Loss:7.307278633117676

iterator 2800, D_Loss:0.44851550459861755, G_Loss:6.640657424926758

iterator 2900, D_Loss:0.4691565930843353, G_Loss:7.65549898147583

iterator 3000, D_Loss:0.4674879014492035, G_Loss:6.275658130645752

iterator 3100, D_Loss:0.44990959763526917, G_Loss:5.789296627044678

iterator 3200, D_Loss:0.45544466376304626, G_Loss:7.086699485778809

iterator 3300, D_Loss:0.4584614336490631, G_Loss:7.512794494628906

iterator 3400, D_Loss:0.4475920498371124, G_Loss:10.135324478149414

iterator 3500, D_Loss:0.46059632301330566, G_Loss:10.519271850585938

iterator 3600, D_Loss:0.46323174238204956, G_Loss:12.767250061035156

iterator 3700, D_Loss:0.4681217670440674, G_Loss:9.426840782165527

iterator 3800, D_Loss:0.44577330350875854, G_Loss:7.917257785797119

iterator 3900, D_Loss:0.4472968876361847, G_Loss:8.015395164489746

iterator 4000, D_Loss:0.4504106044769287, G_Loss:7.821855068206787

iterator 4100, D_Loss:0.45127496123313904, G_Loss:7.01856803894043

iterator 4200, D_Loss:0.4629512131214142, G_Loss:6.644619941711426

iterator 4300, D_Loss:0.4921283721923828, G_Loss:5.741792678833008

iterator 4400, D_Loss:0.4533064067363739, G_Loss:7.518060207366943

iterator 4500, D_Loss:0.5042400360107422, G_Loss:6.6772685050964355

iterator 4600, D_Loss:0.47532376646995544, G_Loss:7.229334831237793

iterator 4700, D_Loss:0.4689806401729584, G_Loss:11.493099212646484

iterator 4800, D_Loss:0.4762328267097473, G_Loss:6.6129631996154785

iterator 4900, D_Loss:0.4922275245189667, G_Loss:7.8567633628845215

iterator 5000, D_Loss:0.46200668811798096, G_Loss:7.226914882659912

-----------Epoch 7-----------
iterator 100, D_Loss:0.46316009759902954, G_Loss:7.462062358856201

iterator 200, D_Loss:0.47488945722579956, G_Loss:6.463469505310059

iterator 300, D_Loss:0.48105013370513916, G_Loss:6.701431751251221

iterator 400, D_Loss:0.4878824055194855, G_Loss:6.707883834838867

iterator 500, D_Loss:0.4646565020084381, G_Loss:5.867679119110107

iterator 600, D_Loss:0.4624587893486023, G_Loss:6.787664413452148

iterator 700, D_Loss:0.4899604618549347, G_Loss:6.290133953094482

iterator 800, D_Loss:0.49716299772262573, G_Loss:6.1874895095825195

iterator 900, D_Loss:0.4913855493068695, G_Loss:4.995177745819092

iterator 1000, D_Loss:0.44802969694137573, G_Loss:6.152923583984375

iterator 1100, D_Loss:0.4708443582057953, G_Loss:7.897409439086914

iterator 1200, D_Loss:0.4389980733394623, G_Loss:6.399231910705566

iterator 1300, D_Loss:0.4710266888141632, G_Loss:6.690410614013672

iterator 1400, D_Loss:0.45606809854507446, G_Loss:11.859798431396484

iterator 1500, D_Loss:0.4583248496055603, G_Loss:6.698767185211182

iterator 1600, D_Loss:0.455233633518219, G_Loss:7.060538291931152

iterator 1700, D_Loss:0.48292773962020874, G_Loss:6.345280647277832

iterator 1800, D_Loss:0.4740718603134155, G_Loss:6.546735763549805

iterator 1900, D_Loss:0.46403035521507263, G_Loss:6.593260288238525

iterator 2000, D_Loss:0.4569229781627655, G_Loss:6.987039566040039

iterator 2100, D_Loss:0.45767420530319214, G_Loss:8.73051929473877

iterator 2200, D_Loss:0.4679623544216156, G_Loss:7.721957206726074

iterator 2300, D_Loss:0.44433096051216125, G_Loss:6.808755397796631

iterator 2400, D_Loss:0.4551019072532654, G_Loss:6.44685173034668

iterator 2500, D_Loss:0.4830118417739868, G_Loss:9.654824256896973

iterator 2600, D_Loss:0.4481560289859772, G_Loss:7.680508613586426

iterator 2700, D_Loss:0.4646032452583313, G_Loss:8.121284484863281

iterator 2800, D_Loss:0.4725514054298401, G_Loss:7.2396416664123535

iterator 2900, D_Loss:0.453504741191864, G_Loss:8.597809791564941

iterator 3000, D_Loss:0.4324808716773987, G_Loss:8.011331558227539

iterator 3100, D_Loss:0.49129632115364075, G_Loss:7.736161708831787

iterator 3200, D_Loss:0.49117690324783325, G_Loss:7.620887756347656

iterator 3300, D_Loss:0.47118574380874634, G_Loss:8.052767753601074

iterator 3400, D_Loss:0.46299314498901367, G_Loss:7.33549690246582

iterator 3500, D_Loss:0.47298869490623474, G_Loss:8.205406188964844

iterator 3600, D_Loss:0.4643518328666687, G_Loss:7.337527275085449

iterator 3700, D_Loss:0.4644787013530731, G_Loss:12.555026054382324

iterator 3800, D_Loss:0.4665970206260681, G_Loss:6.97914457321167

iterator 3900, D_Loss:0.45785531401634216, G_Loss:7.778449058532715

iterator 4000, D_Loss:0.46967580914497375, G_Loss:8.384302139282227

iterator 4100, D_Loss:0.46423205733299255, G_Loss:7.793583393096924

iterator 4200, D_Loss:0.43927228450775146, G_Loss:7.008485794067383

iterator 4300, D_Loss:0.4837743043899536, G_Loss:7.51181697845459

iterator 4400, D_Loss:0.479953795671463, G_Loss:6.278106689453125

iterator 4500, D_Loss:0.46449607610702515, G_Loss:5.702353000640869

iterator 4600, D_Loss:0.46391215920448303, G_Loss:6.303281307220459

iterator 4700, D_Loss:0.47644999623298645, G_Loss:7.592845916748047

iterator 4800, D_Loss:0.48261183500289917, G_Loss:8.759880065917969

iterator 4900, D_Loss:0.487737238407135, G_Loss:6.923252105712891

iterator 5000, D_Loss:0.4817022979259491, G_Loss:6.332007884979248

-----------Epoch 8-----------
iterator 100, D_Loss:0.4513455331325531, G_Loss:7.235605239868164

iterator 200, D_Loss:0.4581746459007263, G_Loss:7.66375732421875

iterator 300, D_Loss:0.48277944326400757, G_Loss:5.937870502471924

iterator 400, D_Loss:0.46312591433525085, G_Loss:6.756402015686035

iterator 500, D_Loss:0.45769742131233215, G_Loss:6.121865749359131

iterator 600, D_Loss:0.44942378997802734, G_Loss:6.821821212768555

iterator 700, D_Loss:0.49128788709640503, G_Loss:9.173440933227539

iterator 800, D_Loss:0.4853557348251343, G_Loss:7.728926658630371

iterator 900, D_Loss:0.4744613766670227, G_Loss:8.35164737701416

iterator 1000, D_Loss:0.43922653794288635, G_Loss:7.699254512786865

iterator 1100, D_Loss:0.4650992751121521, G_Loss:6.732763290405273

iterator 1200, D_Loss:0.4585694670677185, G_Loss:6.584641933441162

iterator 1300, D_Loss:0.4496711790561676, G_Loss:6.002318859100342

iterator 1400, D_Loss:0.45722973346710205, G_Loss:6.3359694480896

iterator 1500, D_Loss:0.4542946219444275, G_Loss:7.105199813842773

iterator 1600, D_Loss:0.4533476233482361, G_Loss:7.106800079345703

iterator 1700, D_Loss:0.46319180727005005, G_Loss:6.300357818603516

iterator 1800, D_Loss:0.46613550186157227, G_Loss:7.560669422149658

iterator 1900, D_Loss:0.44851189851760864, G_Loss:8.178601264953613

iterator 2000, D_Loss:0.45812076330184937, G_Loss:8.091706275939941

iterator 2100, D_Loss:0.4686838388442993, G_Loss:6.049443244934082

iterator 2200, D_Loss:0.4752555787563324, G_Loss:9.307808876037598

iterator 2300, D_Loss:0.4373532235622406, G_Loss:7.9579877853393555

iterator 2400, D_Loss:0.5017473101615906, G_Loss:6.18344783782959

iterator 2500, D_Loss:0.4751362204551697, G_Loss:6.456554889678955

iterator 2600, D_Loss:0.4550059735774994, G_Loss:7.452599048614502

iterator 2700, D_Loss:0.49388059973716736, G_Loss:6.671493053436279

iterator 2800, D_Loss:0.46764200925827026, G_Loss:10.484137535095215

iterator 2900, D_Loss:0.4464481472969055, G_Loss:9.52385425567627

iterator 3000, D_Loss:0.453750878572464, G_Loss:9.083724975585938

iterator 3100, D_Loss:0.44281959533691406, G_Loss:8.473740577697754

iterator 3200, D_Loss:0.4525437653064728, G_Loss:7.239168167114258

iterator 3300, D_Loss:0.4677232801914215, G_Loss:13.908123970031738

iterator 3400, D_Loss:0.47675374150276184, G_Loss:7.395445346832275

iterator 3500, D_Loss:0.4420602321624756, G_Loss:7.794867515563965

iterator 3600, D_Loss:0.4590880870819092, G_Loss:7.246591091156006

iterator 3700, D_Loss:0.4617539346218109, G_Loss:6.60725736618042

iterator 3800, D_Loss:0.4628373384475708, G_Loss:7.252770900726318

iterator 3900, D_Loss:0.46630334854125977, G_Loss:6.347704887390137

iterator 4000, D_Loss:0.48167097568511963, G_Loss:9.603033065795898

iterator 4100, D_Loss:0.47301095724105835, G_Loss:6.297755241394043

iterator 4200, D_Loss:0.4650174081325531, G_Loss:6.119927883148193

iterator 4300, D_Loss:0.49077364802360535, G_Loss:6.70388650894165

iterator 4400, D_Loss:0.4721652865409851, G_Loss:7.424761772155762

iterator 4500, D_Loss:0.4752753674983978, G_Loss:6.509912490844727

iterator 4600, D_Loss:0.4643125832080841, G_Loss:7.131959438323975

iterator 4700, D_Loss:0.4478131830692291, G_Loss:7.460817337036133

iterator 4800, D_Loss:0.4744609594345093, G_Loss:6.636875152587891

iterator 4900, D_Loss:0.5031145215034485, G_Loss:6.504467964172363

iterator 5000, D_Loss:0.44788122177124023, G_Loss:6.779139995574951

-----------Epoch 9-----------
iterator 100, D_Loss:0.4532838761806488, G_Loss:7.171737194061279

iterator 200, D_Loss:0.4812532961368561, G_Loss:7.013446807861328

iterator 300, D_Loss:0.49640384316444397, G_Loss:6.732748031616211

iterator 400, D_Loss:0.46598169207572937, G_Loss:5.730815887451172

iterator 500, D_Loss:0.48626619577407837, G_Loss:5.465507984161377

iterator 600, D_Loss:0.4960377812385559, G_Loss:6.514555931091309

iterator 700, D_Loss:0.4862545430660248, G_Loss:6.691501617431641

iterator 800, D_Loss:0.49570903182029724, G_Loss:11.073278427124023

iterator 900, D_Loss:0.4615478813648224, G_Loss:7.715368270874023

iterator 1000, D_Loss:0.4454732835292816, G_Loss:7.029879093170166

iterator 1100, D_Loss:0.459455281496048, G_Loss:7.211393356323242

iterator 1200, D_Loss:0.4553613066673279, G_Loss:7.746036052703857

iterator 1300, D_Loss:0.4556286931037903, G_Loss:7.068690299987793

iterator 1400, D_Loss:0.4487761855125427, G_Loss:9.732446670532227

iterator 1500, D_Loss:0.46530014276504517, G_Loss:7.221238613128662

iterator 1600, D_Loss:0.4820593595504761, G_Loss:9.016419410705566

iterator 1700, D_Loss:0.4616706371307373, G_Loss:7.916370868682861

iterator 1800, D_Loss:0.4552907943725586, G_Loss:8.007667541503906

iterator 1900, D_Loss:0.4596706032752991, G_Loss:9.045610427856445

iterator 2000, D_Loss:0.4561542570590973, G_Loss:8.11086654663086

iterator 2100, D_Loss:0.4295935034751892, G_Loss:7.449139595031738

iterator 2200, D_Loss:0.46527424454689026, G_Loss:7.55826997756958

iterator 2300, D_Loss:0.4559108018875122, G_Loss:7.905359268188477

iterator 2400, D_Loss:0.4605928957462311, G_Loss:9.44533920288086

iterator 2500, D_Loss:0.4588004946708679, G_Loss:7.19619083404541

iterator 2600, D_Loss:0.4439070522785187, G_Loss:8.126797676086426

iterator 2700, D_Loss:0.45756757259368896, G_Loss:13.868210792541504

iterator 2800, D_Loss:0.48288458585739136, G_Loss:8.032849311828613

iterator 2900, D_Loss:0.46342360973358154, G_Loss:7.644874572753906

iterator 3000, D_Loss:0.4594409763813019, G_Loss:5.794046878814697

iterator 3100, D_Loss:0.4908619821071625, G_Loss:7.819139003753662

iterator 3200, D_Loss:0.4777769446372986, G_Loss:7.960984706878662

iterator 3300, D_Loss:0.47794297337532043, G_Loss:7.880391597747803

iterator 3400, D_Loss:0.4549332559108734, G_Loss:7.601973533630371

iterator 3500, D_Loss:0.44832539558410645, G_Loss:6.957698822021484

iterator 3600, D_Loss:0.4709949791431427, G_Loss:6.500216484069824

iterator 3700, D_Loss:0.45404571294784546, G_Loss:7.098401069641113

iterator 3800, D_Loss:0.47981512546539307, G_Loss:6.767544269561768

iterator 3900, D_Loss:0.46105849742889404, G_Loss:9.055909156799316

iterator 4000, D_Loss:0.4703890383243561, G_Loss:7.688660144805908

iterator 4100, D_Loss:0.45026201009750366, G_Loss:7.284997940063477

iterator 4200, D_Loss:0.4698982536792755, G_Loss:7.094194412231445

iterator 4300, D_Loss:0.48851603269577026, G_Loss:7.658705234527588

iterator 4400, D_Loss:0.44434255361557007, G_Loss:7.7268829345703125

iterator 4500, D_Loss:0.4554126560688019, G_Loss:7.94460916519165

iterator 4600, D_Loss:0.4709208309650421, G_Loss:8.08993911743164

iterator 4700, D_Loss:0.4684109687805176, G_Loss:7.958527088165283

iterator 4800, D_Loss:0.4528629183769226, G_Loss:7.737123966217041

iterator 4900, D_Loss:0.48060888051986694, G_Loss:8.018529891967773

iterator 5000, D_Loss:0.47080835700035095, G_Loss:6.892743110656738

LGAN_generator(
  (LSTM): LSTMCell(300, 500)
  (fc00): Linear(in_features=200, out_features=1, bias=True)
  (fc01): Linear(in_features=1, out_features=200, bias=True)
  (fe0): Linear(in_features=500, out_features=200, bias=True)
  (fc10): Linear(in_features=200, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=200, bias=True)
  (fe1): Linear(in_features=500, out_features=200, bias=True)
  (fc20): Linear(in_features=200, out_features=1, bias=True)
  (fc21): Linear(in_features=1, out_features=200, bias=True)
  (fe2): Linear(in_features=500, out_features=200, bias=True)
  (fc30): Linear(in_features=200, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=200, bias=True)
  (fe3): Linear(in_features=500, out_features=200, bias=True)
  (fc40): Linear(in_features=200, out_features=1, bias=True)
  (fc41): Linear(in_features=1, out_features=200, bias=True)
  (fe4): Linear(in_features=500, out_features=200, bias=True)
  (fc50): Linear(in_features=200, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=200, bias=True)
  (fe5): Linear(in_features=500, out_features=200, bias=True)
  (fc60): Linear(in_features=200, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=200, bias=True)
  (fe6): Linear(in_features=500, out_features=200, bias=True)
  (fc70): Linear(in_features=200, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=200, bias=True)
  (fe7): Linear(in_features=500, out_features=200, bias=True)
  (fc80): Linear(in_features=200, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=200, bias=True)
  (fe8): Linear(in_features=500, out_features=200, bias=True)
  (fc90): Linear(in_features=200, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=200, bias=True)
  (fe9): Linear(in_features=500, out_features=200, bias=True)
  (fc100): Linear(in_features=200, out_features=1, bias=True)
  (fc101): Linear(in_features=1, out_features=200, bias=True)
  (fe10): Linear(in_features=500, out_features=200, bias=True)
  (fc110): Linear(in_features=200, out_features=1, bias=True)
  (fc111): Linear(in_features=1, out_features=200, bias=True)
  (fe11): Linear(in_features=500, out_features=200, bias=True)
  (fc120): Linear(in_features=200, out_features=1, bias=True)
  (fc121): Linear(in_features=1, out_features=200, bias=True)
  (fe12): Linear(in_features=500, out_features=200, bias=True)
  (fc130): Linear(in_features=200, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=200, bias=True)
  (fe13): Linear(in_features=500, out_features=200, bias=True)
  (fc140): Linear(in_features=200, out_features=2, bias=True)
  (fc141): Linear(in_features=2, out_features=200, bias=True)
  (fe14): Linear(in_features=500, out_features=200, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=105, out_features=400, bias=True)
  (inputbn): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=400, out_features=400, bias=True)
  (bn0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=400, out_features=1, bias=True)
)
(0, False, 105)
-----------Epoch 0-----------
iterator 100, D_Loss:1.1696010828018188, G_Loss:1.1108039617538452

iterator 200, D_Loss:1.0814521312713623, G_Loss:1.3593579530715942

iterator 300, D_Loss:0.9893138408660889, G_Loss:1.6323835849761963

iterator 400, D_Loss:1.164695143699646, G_Loss:1.3091609477996826

iterator 500, D_Loss:0.9948514103889465, G_Loss:1.7086907625198364

iterator 600, D_Loss:0.9121914505958557, G_Loss:1.8619744777679443

iterator 700, D_Loss:0.8612135648727417, G_Loss:2.1712005138397217

iterator 800, D_Loss:0.7558732032775879, G_Loss:2.44014310836792

iterator 900, D_Loss:0.6876122951507568, G_Loss:2.6347768306732178

iterator 1000, D_Loss:0.6614030003547668, G_Loss:2.9590611457824707

iterator 1100, D_Loss:0.6315286159515381, G_Loss:3.2478222846984863

iterator 1200, D_Loss:0.8158115148544312, G_Loss:2.0866305828094482

iterator 1300, D_Loss:0.8898124694824219, G_Loss:3.3074400424957275

iterator 1400, D_Loss:0.7196863889694214, G_Loss:3.453038215637207

iterator 1500, D_Loss:0.8303543925285339, G_Loss:2.0464162826538086

iterator 1600, D_Loss:0.8822243213653564, G_Loss:2.2699790000915527

iterator 1700, D_Loss:0.7435475587844849, G_Loss:2.748274087905884

iterator 1800, D_Loss:0.9453254342079163, G_Loss:2.369913339614868

iterator 1900, D_Loss:0.9161862730979919, G_Loss:2.3948445320129395

iterator 2000, D_Loss:0.8410894870758057, G_Loss:2.004582405090332

iterator 2100, D_Loss:0.734046220779419, G_Loss:2.445967197418213

iterator 2200, D_Loss:0.698065996170044, G_Loss:2.7911486625671387

iterator 2300, D_Loss:0.7937513589859009, G_Loss:2.8634305000305176

iterator 2400, D_Loss:0.7376758456230164, G_Loss:2.963151693344116

iterator 2500, D_Loss:0.6721345782279968, G_Loss:3.348557472229004

iterator 2600, D_Loss:1.1716418266296387, G_Loss:3.3769447803497314

iterator 2700, D_Loss:0.7884411811828613, G_Loss:3.157136917114258

iterator 2800, D_Loss:0.6711446642875671, G_Loss:3.223135232925415

iterator 2900, D_Loss:0.7232693433761597, G_Loss:2.995237350463867

iterator 3000, D_Loss:0.6225764155387878, G_Loss:3.303194522857666

iterator 3100, D_Loss:0.6081045269966125, G_Loss:3.6758885383605957

iterator 3200, D_Loss:0.6248186826705933, G_Loss:3.3633720874786377

iterator 3300, D_Loss:0.6549403071403503, G_Loss:3.2477848529815674

iterator 3400, D_Loss:0.6267117261886597, G_Loss:4.257719039916992

iterator 3500, D_Loss:1.018684983253479, G_Loss:2.1904447078704834

iterator 3600, D_Loss:1.010136365890503, G_Loss:2.16925048828125

iterator 3700, D_Loss:0.8032450675964355, G_Loss:3.127354383468628

iterator 3800, D_Loss:0.9746842384338379, G_Loss:2.1596837043762207

iterator 3900, D_Loss:0.9693063497543335, G_Loss:1.9817510843276978

iterator 4000, D_Loss:0.90388023853302, G_Loss:1.9954839944839478

iterator 4100, D_Loss:0.9732513427734375, G_Loss:2.370785713195801

iterator 4200, D_Loss:0.8640307784080505, G_Loss:2.4765472412109375

iterator 4300, D_Loss:0.8783667683601379, G_Loss:2.500731945037842

iterator 4400, D_Loss:0.9609557390213013, G_Loss:2.0528128147125244

iterator 4500, D_Loss:1.1871705055236816, G_Loss:1.7736575603485107

iterator 4600, D_Loss:1.0931501388549805, G_Loss:1.94657564163208

iterator 4700, D_Loss:0.8882954120635986, G_Loss:2.054823398590088

iterator 4800, D_Loss:1.054975986480713, G_Loss:2.056185722351074

iterator 4900, D_Loss:1.2594693899154663, G_Loss:1.8990180492401123

iterator 5000, D_Loss:1.068233847618103, G_Loss:1.7853890657424927

-----------Epoch 1-----------
iterator 100, D_Loss:1.2711583375930786, G_Loss:1.6975736618041992

iterator 200, D_Loss:1.1393375396728516, G_Loss:2.0130462646484375

iterator 300, D_Loss:1.1380904912948608, G_Loss:2.1333181858062744

iterator 400, D_Loss:1.0476323366165161, G_Loss:1.589359998703003

iterator 500, D_Loss:1.1464793682098389, G_Loss:1.8028508424758911

iterator 600, D_Loss:1.0513932704925537, G_Loss:1.7098352909088135

iterator 700, D_Loss:1.078310489654541, G_Loss:1.6176540851593018

iterator 800, D_Loss:1.0617258548736572, G_Loss:1.6775319576263428

iterator 900, D_Loss:1.1507456302642822, G_Loss:1.7220747470855713

iterator 1000, D_Loss:1.1334956884384155, G_Loss:1.6519509553909302

iterator 1100, D_Loss:1.099605679512024, G_Loss:1.697631597518921

iterator 1200, D_Loss:1.16927969455719, G_Loss:1.6113102436065674

iterator 1300, D_Loss:1.2076301574707031, G_Loss:1.7938436269760132

iterator 1400, D_Loss:1.0018093585968018, G_Loss:1.5466161966323853

iterator 1500, D_Loss:1.2246291637420654, G_Loss:1.5916012525558472

iterator 1600, D_Loss:1.0951883792877197, G_Loss:1.7009129524230957

iterator 1700, D_Loss:1.068686604499817, G_Loss:1.4954341650009155

iterator 1800, D_Loss:0.9958826303482056, G_Loss:1.4539715051651

iterator 1900, D_Loss:1.0789761543273926, G_Loss:1.659724473953247

iterator 2000, D_Loss:1.0615808963775635, G_Loss:1.5671759843826294

iterator 2100, D_Loss:1.164581060409546, G_Loss:1.6243016719818115

iterator 2200, D_Loss:1.2785518169403076, G_Loss:1.5778650045394897

iterator 2300, D_Loss:1.004030704498291, G_Loss:1.4645646810531616

iterator 2400, D_Loss:1.407920479774475, G_Loss:1.6406952142715454

iterator 2500, D_Loss:1.2149111032485962, G_Loss:1.654457926750183

iterator 2600, D_Loss:1.1579288244247437, G_Loss:1.435085654258728

iterator 2700, D_Loss:1.1598942279815674, G_Loss:1.5042704343795776

iterator 2800, D_Loss:1.0342308282852173, G_Loss:1.3732848167419434

iterator 2900, D_Loss:1.1948193311691284, G_Loss:1.6368540525436401

iterator 3000, D_Loss:1.125673770904541, G_Loss:1.219936728477478

iterator 3100, D_Loss:1.24934720993042, G_Loss:1.0072978734970093

iterator 3200, D_Loss:1.303553819656372, G_Loss:1.4089555740356445

iterator 3300, D_Loss:1.1981122493743896, G_Loss:1.4116947650909424

iterator 3400, D_Loss:1.3161399364471436, G_Loss:1.4222162961959839

iterator 3500, D_Loss:1.2277644872665405, G_Loss:1.3636337518692017

iterator 3600, D_Loss:1.2451283931732178, G_Loss:1.2172605991363525

iterator 3700, D_Loss:1.2693095207214355, G_Loss:1.0841668844223022

iterator 3800, D_Loss:1.1299903392791748, G_Loss:1.3713029623031616

iterator 3900, D_Loss:1.3077914714813232, G_Loss:1.3156344890594482

iterator 4000, D_Loss:1.0895131826400757, G_Loss:1.2781286239624023

iterator 4100, D_Loss:1.2697322368621826, G_Loss:1.3206840753555298

iterator 4200, D_Loss:1.2791377305984497, G_Loss:1.3224841356277466

iterator 4300, D_Loss:1.1189619302749634, G_Loss:1.0580253601074219

iterator 4400, D_Loss:1.2318994998931885, G_Loss:1.3272995948791504

iterator 4500, D_Loss:1.3196942806243896, G_Loss:1.406526803970337

iterator 4600, D_Loss:1.2396444082260132, G_Loss:1.2573761940002441

iterator 4700, D_Loss:1.2743663787841797, G_Loss:1.181113600730896

iterator 4800, D_Loss:1.2753939628601074, G_Loss:1.3024132251739502

iterator 4900, D_Loss:1.3058465719223022, G_Loss:1.3541123867034912

iterator 5000, D_Loss:1.178269386291504, G_Loss:1.2206209897994995

-----------Epoch 2-----------
iterator 100, D_Loss:1.5463640689849854, G_Loss:1.2435640096664429

iterator 200, D_Loss:1.0637027025222778, G_Loss:1.3660427331924438

iterator 300, D_Loss:1.2630436420440674, G_Loss:1.223226547241211

iterator 400, D_Loss:1.2627837657928467, G_Loss:1.2849663496017456

iterator 500, D_Loss:1.2221719026565552, G_Loss:1.2382210493087769

iterator 600, D_Loss:1.2648744583129883, G_Loss:1.1693456172943115

iterator 700, D_Loss:1.2454607486724854, G_Loss:1.2269012928009033

iterator 800, D_Loss:1.257408618927002, G_Loss:1.147086501121521

iterator 900, D_Loss:1.225677251815796, G_Loss:1.2552675008773804

iterator 1000, D_Loss:1.2290011644363403, G_Loss:1.0804994106292725

iterator 1100, D_Loss:1.215882658958435, G_Loss:1.1957628726959229

iterator 1200, D_Loss:1.2943644523620605, G_Loss:1.1853718757629395

iterator 1300, D_Loss:1.3436393737792969, G_Loss:1.5284152030944824

iterator 1400, D_Loss:1.1087640523910522, G_Loss:1.2745641469955444

iterator 1500, D_Loss:1.3184025287628174, G_Loss:1.1623269319534302

iterator 1600, D_Loss:1.255611538887024, G_Loss:1.1987347602844238

iterator 1700, D_Loss:1.0280108451843262, G_Loss:1.189482569694519

iterator 1800, D_Loss:1.2554255723953247, G_Loss:1.2361341714859009

iterator 1900, D_Loss:1.2507941722869873, G_Loss:1.1435188055038452

iterator 2000, D_Loss:1.0155203342437744, G_Loss:1.3014559745788574

iterator 2100, D_Loss:1.1250090599060059, G_Loss:1.1756267547607422

iterator 2200, D_Loss:1.2038986682891846, G_Loss:1.2251158952713013

iterator 2300, D_Loss:1.191253423690796, G_Loss:1.2978510856628418

iterator 2400, D_Loss:1.4418694972991943, G_Loss:1.3821346759796143

iterator 2500, D_Loss:1.2388780117034912, G_Loss:1.2627544403076172

iterator 2600, D_Loss:1.2383179664611816, G_Loss:1.2685527801513672

iterator 2700, D_Loss:1.303135871887207, G_Loss:1.1187254190444946

iterator 2800, D_Loss:1.1061625480651855, G_Loss:1.2357176542282104

iterator 2900, D_Loss:1.2410218715667725, G_Loss:1.215964913368225

iterator 3000, D_Loss:1.2434401512145996, G_Loss:1.6565227508544922

iterator 3100, D_Loss:1.369534969329834, G_Loss:1.3611748218536377

iterator 3200, D_Loss:1.2921863794326782, G_Loss:1.152185082435608

iterator 3300, D_Loss:1.2178263664245605, G_Loss:1.203168511390686

iterator 3400, D_Loss:1.2660613059997559, G_Loss:1.2941161394119263

iterator 3500, D_Loss:1.2277541160583496, G_Loss:1.0785102844238281

iterator 3600, D_Loss:1.356205701828003, G_Loss:1.1254065036773682

iterator 3700, D_Loss:1.230670690536499, G_Loss:1.2532910108566284

iterator 3800, D_Loss:1.2184669971466064, G_Loss:1.269516110420227

iterator 3900, D_Loss:1.1832571029663086, G_Loss:1.1682394742965698

iterator 4000, D_Loss:1.1496312618255615, G_Loss:1.2748512029647827

iterator 4100, D_Loss:1.2854191064834595, G_Loss:1.1300989389419556

iterator 4200, D_Loss:1.2788474559783936, G_Loss:1.1730114221572876

iterator 4300, D_Loss:1.3401013612747192, G_Loss:1.2375837564468384

iterator 4400, D_Loss:1.1875784397125244, G_Loss:1.2173057794570923

iterator 4500, D_Loss:1.4590928554534912, G_Loss:1.2754714488983154

iterator 4600, D_Loss:1.363757848739624, G_Loss:1.1499669551849365

iterator 4700, D_Loss:1.2469159364700317, G_Loss:1.1387622356414795

iterator 4800, D_Loss:1.1508029699325562, G_Loss:1.2022079229354858

iterator 4900, D_Loss:1.3766331672668457, G_Loss:1.1332956552505493

iterator 5000, D_Loss:1.3850038051605225, G_Loss:1.203419804573059

-----------Epoch 3-----------
iterator 100, D_Loss:1.3637917041778564, G_Loss:1.0377488136291504

iterator 200, D_Loss:1.2207298278808594, G_Loss:1.1209821701049805

iterator 300, D_Loss:1.317122459411621, G_Loss:1.1715364456176758

iterator 400, D_Loss:1.2977734804153442, G_Loss:1.1831001043319702

iterator 500, D_Loss:1.3071624040603638, G_Loss:1.0463372468948364

iterator 600, D_Loss:1.1555914878845215, G_Loss:1.115376591682434

iterator 700, D_Loss:1.2248609066009521, G_Loss:1.149364709854126

iterator 800, D_Loss:1.3669867515563965, G_Loss:1.1305290460586548

iterator 900, D_Loss:1.304896593093872, G_Loss:1.230723261833191

iterator 1000, D_Loss:1.2638299465179443, G_Loss:1.1075077056884766

iterator 1100, D_Loss:1.3016551733016968, G_Loss:1.1349694728851318

iterator 1200, D_Loss:1.3223650455474854, G_Loss:1.0483402013778687

iterator 1300, D_Loss:1.288649559020996, G_Loss:1.1334950923919678

iterator 1400, D_Loss:1.2816517353057861, G_Loss:1.1398255825042725

iterator 1500, D_Loss:1.207837462425232, G_Loss:1.1408380270004272

iterator 1600, D_Loss:1.3082998991012573, G_Loss:0.9565390348434448

iterator 1700, D_Loss:1.2738471031188965, G_Loss:1.09146249294281

iterator 1800, D_Loss:1.2715165615081787, G_Loss:0.9723778367042542

iterator 1900, D_Loss:1.1316030025482178, G_Loss:1.0844780206680298

iterator 2000, D_Loss:1.1143245697021484, G_Loss:1.1759424209594727

iterator 2100, D_Loss:1.2962226867675781, G_Loss:1.0485153198242188

iterator 2200, D_Loss:1.286872148513794, G_Loss:1.0756707191467285

iterator 2300, D_Loss:1.1370749473571777, G_Loss:1.1026486158370972

iterator 2400, D_Loss:1.161577582359314, G_Loss:1.0525459051132202

iterator 2500, D_Loss:1.2399928569793701, G_Loss:1.1925420761108398

iterator 2600, D_Loss:1.2805403470993042, G_Loss:1.1442480087280273

iterator 2700, D_Loss:1.1290180683135986, G_Loss:1.118845820426941

iterator 2800, D_Loss:1.1978179216384888, G_Loss:1.0649518966674805

iterator 2900, D_Loss:1.3100857734680176, G_Loss:1.029932975769043

iterator 3000, D_Loss:1.2627015113830566, G_Loss:1.0426214933395386

iterator 3100, D_Loss:1.3595552444458008, G_Loss:1.1251919269561768

iterator 3200, D_Loss:1.3225512504577637, G_Loss:1.1524041891098022

iterator 3300, D_Loss:1.2784134149551392, G_Loss:1.1525774002075195

iterator 3400, D_Loss:1.2606154680252075, G_Loss:1.1111886501312256

iterator 3500, D_Loss:1.4074225425720215, G_Loss:1.2871909141540527

iterator 3600, D_Loss:1.324963092803955, G_Loss:1.0848957300186157

iterator 3700, D_Loss:1.2567646503448486, G_Loss:1.1324352025985718

iterator 3800, D_Loss:1.2274221181869507, G_Loss:1.2281931638717651

iterator 3900, D_Loss:1.2492947578430176, G_Loss:1.1205333471298218

iterator 4000, D_Loss:1.0143275260925293, G_Loss:1.3286653757095337

iterator 4100, D_Loss:1.2771317958831787, G_Loss:1.08773672580719

iterator 4200, D_Loss:1.308518886566162, G_Loss:1.0949418544769287

iterator 4300, D_Loss:1.1572831869125366, G_Loss:1.1778717041015625

iterator 4400, D_Loss:1.3596489429473877, G_Loss:1.0811023712158203

iterator 4500, D_Loss:1.2770781517028809, G_Loss:1.808030128479004

iterator 4600, D_Loss:1.277604579925537, G_Loss:1.1702337265014648

iterator 4700, D_Loss:1.1537922620773315, G_Loss:1.1176003217697144

iterator 4800, D_Loss:1.2411091327667236, G_Loss:1.4308536052703857

iterator 4900, D_Loss:1.240722894668579, G_Loss:1.0683192014694214

iterator 5000, D_Loss:1.1223000288009644, G_Loss:1.1636462211608887

-----------Epoch 4-----------
iterator 100, D_Loss:1.4183850288391113, G_Loss:1.1894885301589966

iterator 200, D_Loss:1.2832952737808228, G_Loss:1.1003907918930054

iterator 300, D_Loss:1.309204339981079, G_Loss:1.0912877321243286

iterator 400, D_Loss:1.4446221590042114, G_Loss:1.0682522058486938

iterator 500, D_Loss:1.3139684200286865, G_Loss:1.0225309133529663

iterator 600, D_Loss:1.1721234321594238, G_Loss:1.1780043840408325

iterator 700, D_Loss:1.2696483135223389, G_Loss:1.0582265853881836

iterator 800, D_Loss:1.3411226272583008, G_Loss:1.1339213848114014

iterator 900, D_Loss:1.3449050188064575, G_Loss:1.0465519428253174

iterator 1000, D_Loss:1.3129637241363525, G_Loss:1.0999281406402588

iterator 1100, D_Loss:1.3246049880981445, G_Loss:0.9695443511009216

iterator 1200, D_Loss:1.2509756088256836, G_Loss:1.0949143171310425

iterator 1300, D_Loss:1.3060096502304077, G_Loss:0.9675455689430237

iterator 1400, D_Loss:1.2632222175598145, G_Loss:0.9978139400482178

iterator 1500, D_Loss:1.4064064025878906, G_Loss:1.1003763675689697

iterator 1600, D_Loss:1.331370234489441, G_Loss:1.1613919734954834

iterator 1700, D_Loss:1.187549114227295, G_Loss:1.0576759576797485

iterator 1800, D_Loss:1.3280009031295776, G_Loss:1.1116389036178589

iterator 1900, D_Loss:1.202216625213623, G_Loss:1.0864301919937134

iterator 2000, D_Loss:1.2134053707122803, G_Loss:1.0246930122375488

iterator 2100, D_Loss:1.2858037948608398, G_Loss:1.0175445079803467

iterator 2200, D_Loss:1.3335270881652832, G_Loss:0.989133358001709

iterator 2300, D_Loss:1.268132209777832, G_Loss:1.069993495941162

iterator 2400, D_Loss:1.461561679840088, G_Loss:1.0502694845199585

iterator 2500, D_Loss:1.280177116394043, G_Loss:1.2058005332946777

iterator 2600, D_Loss:1.2611805200576782, G_Loss:0.9776676893234253

iterator 2700, D_Loss:1.3540186882019043, G_Loss:0.9675936698913574

iterator 2800, D_Loss:1.2435446977615356, G_Loss:1.2102528810501099

iterator 2900, D_Loss:1.321146011352539, G_Loss:1.1081434488296509

iterator 3000, D_Loss:1.2997372150421143, G_Loss:1.0698707103729248

iterator 3100, D_Loss:1.3848589658737183, G_Loss:1.0355125665664673

iterator 3200, D_Loss:1.4275822639465332, G_Loss:1.0367648601531982

iterator 3300, D_Loss:1.2229182720184326, G_Loss:0.9931266903877258

iterator 3400, D_Loss:1.326017141342163, G_Loss:0.9052683711051941

iterator 3500, D_Loss:1.343189001083374, G_Loss:1.030448317527771

iterator 3600, D_Loss:1.2444682121276855, G_Loss:1.2884917259216309

iterator 3700, D_Loss:1.2355108261108398, G_Loss:1.1082408428192139

iterator 3800, D_Loss:1.1661105155944824, G_Loss:1.0678622722625732

iterator 3900, D_Loss:1.3535794019699097, G_Loss:1.1671475172042847

iterator 4000, D_Loss:1.2299292087554932, G_Loss:1.1978455781936646

iterator 4100, D_Loss:1.3363045454025269, G_Loss:1.1082019805908203

iterator 4200, D_Loss:1.2927186489105225, G_Loss:1.0716673135757446

iterator 4300, D_Loss:1.2499780654907227, G_Loss:1.0984867811203003

iterator 4400, D_Loss:1.2655019760131836, G_Loss:0.978500247001648

iterator 4500, D_Loss:1.2230870723724365, G_Loss:1.070142149925232

iterator 4600, D_Loss:1.3043155670166016, G_Loss:1.2238818407058716

iterator 4700, D_Loss:1.3131418228149414, G_Loss:1.0417943000793457

iterator 4800, D_Loss:1.366809606552124, G_Loss:1.1192337274551392

iterator 4900, D_Loss:1.3641084432601929, G_Loss:1.0749461650848389

iterator 5000, D_Loss:1.2879400253295898, G_Loss:1.100436806678772

-----------Epoch 5-----------
iterator 100, D_Loss:1.2614328861236572, G_Loss:1.0130106210708618

iterator 200, D_Loss:1.243532419204712, G_Loss:0.9877303838729858

iterator 300, D_Loss:1.3586673736572266, G_Loss:0.9162008166313171

iterator 400, D_Loss:1.3875418901443481, G_Loss:0.8656492829322815

iterator 500, D_Loss:1.3597593307495117, G_Loss:1.0572528839111328

iterator 600, D_Loss:1.3239580392837524, G_Loss:0.9907819032669067

iterator 700, D_Loss:1.3096967935562134, G_Loss:1.0874638557434082

iterator 800, D_Loss:1.3221476078033447, G_Loss:0.9424706697463989

iterator 900, D_Loss:1.3398866653442383, G_Loss:0.9661520719528198

iterator 1000, D_Loss:1.3542321920394897, G_Loss:1.0514949560165405

iterator 1100, D_Loss:1.2940683364868164, G_Loss:1.0358513593673706

iterator 1200, D_Loss:1.3478829860687256, G_Loss:1.0811039209365845

iterator 1300, D_Loss:1.2755986452102661, G_Loss:1.0354903936386108

iterator 1400, D_Loss:1.2208929061889648, G_Loss:0.9508983492851257

iterator 1500, D_Loss:1.2920918464660645, G_Loss:0.9927249550819397

iterator 1600, D_Loss:1.2886383533477783, G_Loss:0.9670097231864929

iterator 1700, D_Loss:1.17881178855896, G_Loss:1.0371348857879639

iterator 1800, D_Loss:1.2970376014709473, G_Loss:0.9503821134567261

iterator 1900, D_Loss:1.3043146133422852, G_Loss:1.0785988569259644

iterator 2000, D_Loss:1.3036226034164429, G_Loss:0.9781515598297119

iterator 2100, D_Loss:1.2993297576904297, G_Loss:1.0418683290481567

iterator 2200, D_Loss:1.3035818338394165, G_Loss:1.1139239072799683

iterator 2300, D_Loss:1.2831575870513916, G_Loss:1.0514264106750488

iterator 2400, D_Loss:1.3217597007751465, G_Loss:1.0367199182510376

iterator 2500, D_Loss:1.2373847961425781, G_Loss:1.0841445922851562

iterator 2600, D_Loss:1.3934844732284546, G_Loss:0.9535254836082458

iterator 2700, D_Loss:1.3364694118499756, G_Loss:1.0791202783584595

iterator 2800, D_Loss:1.3335068225860596, G_Loss:1.0954927206039429

iterator 2900, D_Loss:1.3471503257751465, G_Loss:1.0397748947143555

iterator 3000, D_Loss:1.2381608486175537, G_Loss:1.0674182176589966

iterator 3100, D_Loss:1.3328006267547607, G_Loss:1.0651599168777466

iterator 3200, D_Loss:1.351179599761963, G_Loss:0.995219349861145

iterator 3300, D_Loss:1.3032987117767334, G_Loss:1.0000975131988525

iterator 3400, D_Loss:1.3344765901565552, G_Loss:0.9943280816078186

iterator 3500, D_Loss:1.346283197402954, G_Loss:0.9406143426895142

iterator 3600, D_Loss:1.3594938516616821, G_Loss:1.0362836122512817

iterator 3700, D_Loss:1.3852328062057495, G_Loss:0.9897467494010925

iterator 3800, D_Loss:1.3240721225738525, G_Loss:1.020999550819397

iterator 3900, D_Loss:1.3611247539520264, G_Loss:1.0109117031097412

iterator 4000, D_Loss:1.3225014209747314, G_Loss:1.180761694908142

iterator 4100, D_Loss:1.2588725090026855, G_Loss:0.9516630172729492

iterator 4200, D_Loss:1.3099722862243652, G_Loss:1.0472080707550049

iterator 4300, D_Loss:1.292924404144287, G_Loss:1.009729027748108

iterator 4400, D_Loss:1.3348772525787354, G_Loss:0.9866201877593994

iterator 4500, D_Loss:1.3483290672302246, G_Loss:0.9784612655639648

iterator 4600, D_Loss:1.3016411066055298, G_Loss:1.1443794965744019

iterator 4700, D_Loss:1.2416843175888062, G_Loss:1.0130515098571777

iterator 4800, D_Loss:1.360756278038025, G_Loss:1.021947979927063

iterator 4900, D_Loss:1.3139790296554565, G_Loss:0.9489464163780212

iterator 5000, D_Loss:1.325911045074463, G_Loss:1.060230016708374

-----------Epoch 6-----------
iterator 100, D_Loss:1.3236594200134277, G_Loss:0.9693432450294495

iterator 200, D_Loss:1.258509874343872, G_Loss:0.9931995868682861

iterator 300, D_Loss:1.3048162460327148, G_Loss:0.9959729313850403

iterator 400, D_Loss:1.2960541248321533, G_Loss:1.0883969068527222

iterator 500, D_Loss:1.322776198387146, G_Loss:0.9496815800666809

iterator 600, D_Loss:1.3138494491577148, G_Loss:1.005810260772705

iterator 700, D_Loss:1.3136601448059082, G_Loss:0.976095974445343

iterator 800, D_Loss:1.3329339027404785, G_Loss:1.0184623003005981

iterator 900, D_Loss:1.266258955001831, G_Loss:0.9620140790939331

iterator 1000, D_Loss:1.273743748664856, G_Loss:1.0175434350967407

iterator 1100, D_Loss:1.2939751148223877, G_Loss:0.9921872019767761

iterator 1200, D_Loss:1.3204841613769531, G_Loss:1.0119444131851196

iterator 1300, D_Loss:1.322417974472046, G_Loss:1.0956734418869019

iterator 1400, D_Loss:1.2503104209899902, G_Loss:1.0585410594940186

iterator 1500, D_Loss:1.2562326192855835, G_Loss:1.068120002746582

iterator 1600, D_Loss:1.3201618194580078, G_Loss:1.045684576034546

iterator 1700, D_Loss:1.2644786834716797, G_Loss:0.9907172918319702

iterator 1800, D_Loss:1.287205696105957, G_Loss:1.0034990310668945

iterator 1900, D_Loss:1.3069558143615723, G_Loss:1.031091332435608

iterator 2000, D_Loss:1.2499911785125732, G_Loss:1.0751066207885742

iterator 2100, D_Loss:1.2726850509643555, G_Loss:0.9873855710029602

iterator 2200, D_Loss:1.2549066543579102, G_Loss:1.2433466911315918

iterator 2300, D_Loss:1.3033490180969238, G_Loss:1.0274969339370728

iterator 2400, D_Loss:1.3301531076431274, G_Loss:0.9484914541244507

iterator 2500, D_Loss:1.3000965118408203, G_Loss:1.043214201927185

iterator 2600, D_Loss:1.3707480430603027, G_Loss:0.8686530590057373

iterator 2700, D_Loss:1.3186951875686646, G_Loss:1.071223497390747

iterator 2800, D_Loss:1.3478798866271973, G_Loss:1.0158499479293823

iterator 2900, D_Loss:1.3056590557098389, G_Loss:1.0448122024536133

iterator 3000, D_Loss:1.3654193878173828, G_Loss:0.9818746447563171

iterator 3100, D_Loss:1.3497447967529297, G_Loss:1.0847792625427246

iterator 3200, D_Loss:1.366579532623291, G_Loss:1.0309596061706543

iterator 3300, D_Loss:1.3204617500305176, G_Loss:1.0794190168380737

iterator 3400, D_Loss:1.3360034227371216, G_Loss:1.1029856204986572

iterator 3500, D_Loss:1.342803955078125, G_Loss:1.0426918268203735

iterator 3600, D_Loss:1.33137845993042, G_Loss:1.1082288026809692

iterator 3700, D_Loss:1.3559517860412598, G_Loss:0.9991271495819092

iterator 3800, D_Loss:1.231273889541626, G_Loss:0.999903678894043

iterator 3900, D_Loss:1.3569958209991455, G_Loss:1.198352575302124

iterator 4000, D_Loss:1.300499677658081, G_Loss:0.9743865728378296

iterator 4100, D_Loss:1.4037055969238281, G_Loss:1.0164707899093628

iterator 4200, D_Loss:1.1943862438201904, G_Loss:1.1996715068817139

iterator 4300, D_Loss:1.2826669216156006, G_Loss:1.0396981239318848

iterator 4400, D_Loss:1.275530457496643, G_Loss:1.0541839599609375

iterator 4500, D_Loss:1.3006484508514404, G_Loss:1.0184974670410156

iterator 4600, D_Loss:1.3293663263320923, G_Loss:1.1426904201507568

iterator 4700, D_Loss:1.3536396026611328, G_Loss:0.9365442395210266

iterator 4800, D_Loss:1.4734644889831543, G_Loss:1.099293828010559

iterator 4900, D_Loss:1.379629135131836, G_Loss:0.9416449666023254

iterator 5000, D_Loss:1.3021328449249268, G_Loss:0.9860581159591675

-----------Epoch 7-----------
iterator 100, D_Loss:1.4199421405792236, G_Loss:1.0731227397918701

iterator 200, D_Loss:1.3720338344573975, G_Loss:1.0061312913894653

iterator 300, D_Loss:1.3017334938049316, G_Loss:1.01963210105896

iterator 400, D_Loss:1.321458339691162, G_Loss:1.0812574625015259

iterator 500, D_Loss:1.392941951751709, G_Loss:1.1131452322006226

iterator 600, D_Loss:1.252192497253418, G_Loss:1.115697979927063

iterator 700, D_Loss:1.3464645147323608, G_Loss:0.9639874696731567

iterator 800, D_Loss:1.3038599491119385, G_Loss:1.0039311647415161

iterator 900, D_Loss:1.3343119621276855, G_Loss:1.1405706405639648

iterator 1000, D_Loss:1.2086353302001953, G_Loss:1.1223260164260864

iterator 1100, D_Loss:1.3440735340118408, G_Loss:1.0360491275787354

iterator 1200, D_Loss:1.2780587673187256, G_Loss:1.0081559419631958

iterator 1300, D_Loss:1.3294832706451416, G_Loss:0.9859293699264526

iterator 1400, D_Loss:1.19399893283844, G_Loss:1.0104833841323853

iterator 1500, D_Loss:1.3074510097503662, G_Loss:1.0596789121627808

iterator 1600, D_Loss:1.3161594867706299, G_Loss:1.024247169494629

iterator 1700, D_Loss:1.2623958587646484, G_Loss:1.0418701171875

iterator 1800, D_Loss:1.2461109161376953, G_Loss:1.0520356893539429

iterator 1900, D_Loss:1.1610429286956787, G_Loss:1.038182020187378

iterator 2000, D_Loss:1.258509874343872, G_Loss:1.0594019889831543

iterator 2100, D_Loss:1.3170875310897827, G_Loss:0.9709010720252991

iterator 2200, D_Loss:1.3290958404541016, G_Loss:1.111432433128357

iterator 2300, D_Loss:1.292188286781311, G_Loss:0.981040894985199

iterator 2400, D_Loss:1.403109073638916, G_Loss:0.9481417536735535

iterator 2500, D_Loss:1.275481939315796, G_Loss:1.0881906747817993

iterator 2600, D_Loss:1.3429808616638184, G_Loss:1.0153913497924805

iterator 2700, D_Loss:1.304518699645996, G_Loss:1.0281270742416382

iterator 2800, D_Loss:1.3549652099609375, G_Loss:1.194804072380066

iterator 2900, D_Loss:1.273468255996704, G_Loss:1.0289674997329712

iterator 3000, D_Loss:1.3460650444030762, G_Loss:1.000276803970337

iterator 3100, D_Loss:1.2942657470703125, G_Loss:1.0565667152404785

iterator 3200, D_Loss:1.364903211593628, G_Loss:0.8691642880439758

iterator 3300, D_Loss:1.254101276397705, G_Loss:1.027188777923584

iterator 3400, D_Loss:1.326401948928833, G_Loss:1.073870062828064

iterator 3500, D_Loss:1.2767821550369263, G_Loss:1.0738160610198975

iterator 3600, D_Loss:1.346006155014038, G_Loss:1.0115673542022705

iterator 3700, D_Loss:1.3536882400512695, G_Loss:1.025997281074524

iterator 3800, D_Loss:1.2858580350875854, G_Loss:1.003375768661499

iterator 3900, D_Loss:1.3041009902954102, G_Loss:0.9777432084083557

iterator 4000, D_Loss:1.25217604637146, G_Loss:1.0449928045272827

iterator 4100, D_Loss:1.2914668321609497, G_Loss:1.1933703422546387

iterator 4200, D_Loss:1.2099356651306152, G_Loss:1.1711549758911133

iterator 4300, D_Loss:1.4105746746063232, G_Loss:0.9953615069389343

iterator 4400, D_Loss:1.3097705841064453, G_Loss:0.9881511926651001

iterator 4500, D_Loss:1.299431324005127, G_Loss:1.0077290534973145

iterator 4600, D_Loss:1.389693260192871, G_Loss:1.075810432434082

iterator 4700, D_Loss:1.3440145254135132, G_Loss:0.9743406772613525

iterator 4800, D_Loss:1.3459807634353638, G_Loss:1.1246763467788696

iterator 4900, D_Loss:1.3354912996292114, G_Loss:0.9400056600570679

iterator 5000, D_Loss:1.3001129627227783, G_Loss:1.024611234664917

-----------Epoch 8-----------
iterator 100, D_Loss:1.3798680305480957, G_Loss:1.0013575553894043

iterator 200, D_Loss:1.335471749305725, G_Loss:1.0298335552215576

iterator 300, D_Loss:1.3823902606964111, G_Loss:0.965046763420105

iterator 400, D_Loss:1.331152319908142, G_Loss:1.0413039922714233

iterator 500, D_Loss:1.3343632221221924, G_Loss:1.0235260725021362

iterator 600, D_Loss:1.2635352611541748, G_Loss:0.9830997586250305

iterator 700, D_Loss:1.2794711589813232, G_Loss:0.9669961333274841

iterator 800, D_Loss:1.3267838954925537, G_Loss:1.0507886409759521

iterator 900, D_Loss:1.3239150047302246, G_Loss:0.9438744783401489

iterator 1000, D_Loss:1.3184127807617188, G_Loss:1.1544506549835205

iterator 1100, D_Loss:1.3213087320327759, G_Loss:1.0644903182983398

iterator 1200, D_Loss:1.2817692756652832, G_Loss:0.9344117641448975

iterator 1300, D_Loss:1.1914910078048706, G_Loss:1.0782965421676636

iterator 1400, D_Loss:1.336432933807373, G_Loss:0.9789283871650696

iterator 1500, D_Loss:1.3445181846618652, G_Loss:0.9316152334213257

iterator 1600, D_Loss:1.2870006561279297, G_Loss:1.1267176866531372

iterator 1700, D_Loss:1.353227138519287, G_Loss:1.1511948108673096

iterator 1800, D_Loss:1.3333797454833984, G_Loss:0.9618954658508301

iterator 1900, D_Loss:1.2980564832687378, G_Loss:0.9971739053726196

iterator 2000, D_Loss:1.3022838830947876, G_Loss:1.0489490032196045

iterator 2100, D_Loss:1.2608375549316406, G_Loss:0.9801106452941895

iterator 2200, D_Loss:1.2520865201950073, G_Loss:1.0142449140548706

iterator 2300, D_Loss:1.2972662448883057, G_Loss:0.9769177436828613

iterator 2400, D_Loss:1.4505641460418701, G_Loss:0.9627193212509155

iterator 2500, D_Loss:1.2970004081726074, G_Loss:1.0032604932785034

iterator 2600, D_Loss:1.3191670179367065, G_Loss:0.9235947132110596

iterator 2700, D_Loss:1.3267021179199219, G_Loss:0.9680096507072449

iterator 2800, D_Loss:1.3578500747680664, G_Loss:1.0562931299209595

iterator 2900, D_Loss:1.3439366817474365, G_Loss:0.9932947754859924

iterator 3000, D_Loss:1.3599389791488647, G_Loss:0.9386630058288574

iterator 3100, D_Loss:1.3438262939453125, G_Loss:1.0463145971298218

iterator 3200, D_Loss:1.3413947820663452, G_Loss:0.9942253828048706

iterator 3300, D_Loss:1.2905728816986084, G_Loss:1.3907357454299927

iterator 3400, D_Loss:1.2878687381744385, G_Loss:1.0041629076004028

iterator 3500, D_Loss:1.2813729047775269, G_Loss:1.0338653326034546

iterator 3600, D_Loss:1.3174899816513062, G_Loss:1.1067781448364258

iterator 3700, D_Loss:1.339646577835083, G_Loss:1.0569628477096558

iterator 3800, D_Loss:1.333219289779663, G_Loss:1.0270969867706299

iterator 3900, D_Loss:1.4375585317611694, G_Loss:0.8942523002624512

iterator 4000, D_Loss:1.307422161102295, G_Loss:1.006042242050171

iterator 4100, D_Loss:1.3943912982940674, G_Loss:0.9441558122634888

iterator 4200, D_Loss:1.263354778289795, G_Loss:0.9314368963241577

iterator 4300, D_Loss:1.3693180084228516, G_Loss:1.0134700536727905

iterator 4400, D_Loss:1.3088518381118774, G_Loss:1.0316622257232666

iterator 4500, D_Loss:1.3336501121520996, G_Loss:1.014750361442566

iterator 4600, D_Loss:1.3378515243530273, G_Loss:1.0244632959365845

iterator 4700, D_Loss:1.2788022756576538, G_Loss:1.0669490098953247

iterator 4800, D_Loss:1.322772741317749, G_Loss:0.962718665599823

iterator 4900, D_Loss:1.2857105731964111, G_Loss:1.1773529052734375

iterator 5000, D_Loss:1.3337976932525635, G_Loss:1.0335328578948975

-----------Epoch 9-----------
iterator 100, D_Loss:1.39457106590271, G_Loss:1.0292524099349976

iterator 200, D_Loss:1.2999565601348877, G_Loss:0.9834386110305786

iterator 300, D_Loss:1.2958850860595703, G_Loss:0.9568151235580444

iterator 400, D_Loss:1.2876362800598145, G_Loss:0.9935178160667419

iterator 500, D_Loss:1.3668460845947266, G_Loss:0.855704128742218

iterator 600, D_Loss:1.364915132522583, G_Loss:1.090371012687683

iterator 700, D_Loss:1.2406682968139648, G_Loss:1.0210543870925903

iterator 800, D_Loss:1.3212145566940308, G_Loss:0.8818850517272949

iterator 900, D_Loss:1.2377889156341553, G_Loss:1.0085537433624268

iterator 1000, D_Loss:1.2828614711761475, G_Loss:0.9857614040374756

iterator 1100, D_Loss:1.317733645439148, G_Loss:1.0092748403549194

iterator 1200, D_Loss:1.3111872673034668, G_Loss:1.0253379344940186

iterator 1300, D_Loss:1.231214165687561, G_Loss:1.0532983541488647

iterator 1400, D_Loss:1.2145569324493408, G_Loss:1.0550730228424072

iterator 1500, D_Loss:1.2919498682022095, G_Loss:1.0042792558670044

iterator 1600, D_Loss:1.2926907539367676, G_Loss:1.1076678037643433

iterator 1700, D_Loss:1.260940432548523, G_Loss:0.9803339838981628

iterator 1800, D_Loss:1.3106704950332642, G_Loss:0.9291850328445435

iterator 1900, D_Loss:1.355123519897461, G_Loss:1.0578219890594482

iterator 2000, D_Loss:1.2143855094909668, G_Loss:1.06559157371521

iterator 2100, D_Loss:1.2356891632080078, G_Loss:1.1131407022476196

iterator 2200, D_Loss:1.2442312240600586, G_Loss:1.2054513692855835

iterator 2300, D_Loss:1.3296399116516113, G_Loss:0.9370349645614624

iterator 2400, D_Loss:1.3269842863082886, G_Loss:1.0592737197875977

iterator 2500, D_Loss:1.2992855310440063, G_Loss:0.9965047240257263

iterator 2600, D_Loss:1.2839953899383545, G_Loss:1.0017337799072266

iterator 2700, D_Loss:1.442124605178833, G_Loss:0.9731667637825012

iterator 2800, D_Loss:1.348854422569275, G_Loss:1.0167988538742065

iterator 2900, D_Loss:1.3379814624786377, G_Loss:1.0699446201324463

iterator 3000, D_Loss:1.3660476207733154, G_Loss:0.9929304122924805

iterator 3100, D_Loss:1.305511474609375, G_Loss:0.9792870283126831

iterator 3200, D_Loss:1.3261947631835938, G_Loss:1.045853614807129

iterator 3300, D_Loss:1.2714353799819946, G_Loss:1.0404295921325684

iterator 3400, D_Loss:1.3393983840942383, G_Loss:1.0376883745193481

iterator 3500, D_Loss:1.335516095161438, G_Loss:0.9351078271865845

iterator 3600, D_Loss:1.3158620595932007, G_Loss:0.9779484272003174

iterator 3700, D_Loss:1.3214449882507324, G_Loss:0.9858696460723877

iterator 3800, D_Loss:1.2392723560333252, G_Loss:1.0556232929229736

iterator 3900, D_Loss:1.427597165107727, G_Loss:1.1462498903274536

iterator 4000, D_Loss:1.323381781578064, G_Loss:0.9303856492042542

iterator 4100, D_Loss:1.3114309310913086, G_Loss:0.9366976618766785

iterator 4200, D_Loss:1.1965603828430176, G_Loss:1.019208312034607

iterator 4300, D_Loss:1.3578760623931885, G_Loss:0.9980551600456238

iterator 4400, D_Loss:1.3335070610046387, G_Loss:1.042798399925232

iterator 4500, D_Loss:1.3346195220947266, G_Loss:1.0228196382522583

iterator 4600, D_Loss:1.3089081048965454, G_Loss:0.9174579381942749

iterator 4700, D_Loss:1.3565183877944946, G_Loss:0.9816635847091675

iterator 4800, D_Loss:1.4245498180389404, G_Loss:0.9627478718757629

iterator 4900, D_Loss:1.3307911157608032, G_Loss:0.9707801342010498

iterator 5000, D_Loss:1.327939510345459, G_Loss:0.9362632632255554

train row : 30148
sample row: 30148
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [192,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [193,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [194,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [195,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [196,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [197,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [198,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [199,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [96,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [97,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [98,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [99,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [100,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [101,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [102,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [103,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [104,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [105,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [106,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [107,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [108,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [109,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [110,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [111,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [112,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [113,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [114,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [115,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [116,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [117,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [118,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [119,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [120,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [121,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [122,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [123,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [124,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [125,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [126,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [127,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [64,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [65,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [66,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [67,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [68,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [69,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [70,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [71,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [72,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [73,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [74,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [75,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [76,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [77,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [78,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [79,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [80,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [81,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [82,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [83,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [84,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [85,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [86,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [87,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [88,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [89,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [90,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [91,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [92,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [93,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [94,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [95,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [128,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [129,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [130,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [131,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [132,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [133,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [134,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [135,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [136,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [137,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [138,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [139,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [140,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [141,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [142,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [143,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [144,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [145,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [146,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [147,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [148,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [149,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [150,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [151,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [152,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [153,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [154,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [155,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [156,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [157,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [158,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [159,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [0,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [1,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [2,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [3,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [4,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [5,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [6,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [7,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [8,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [9,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [10,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [11,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [12,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [13,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [14,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [15,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [16,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [17,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [18,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [19,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [20,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [21,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [22,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [23,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [24,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [25,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [26,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [27,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [28,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [29,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [30,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [31,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [160,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [161,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [162,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [163,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [164,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [165,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [166,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [167,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [168,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [169,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [170,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [171,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [172,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [173,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [174,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [175,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [176,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [177,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [178,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [179,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [180,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [181,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [182,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [183,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [184,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [185,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [186,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [187,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [188,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [189,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [190,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [191,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [32,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [33,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [34,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [35,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [36,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [37,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [38,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [39,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [40,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [41,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [42,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [43,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [44,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [45,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [46,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [47,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [48,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [49,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [50,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [51,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [52,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [53,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [54,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [55,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [56,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [57,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [58,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [59,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [60,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [61,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [62,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [63,0,0] Assertion `input >= 0. && input <= 1.` failed.
LGAN_generator(
  (LSTM): LSTMCell(150, 300)
  (fc00): Linear(in_features=100, out_features=1, bias=True)
  (fc01): Linear(in_features=1, out_features=100, bias=True)
  (fe0): Linear(in_features=300, out_features=100, bias=True)
  (fc10): Linear(in_features=100, out_features=1, bias=True)
  (fc11): Linear(in_features=1, out_features=100, bias=True)
  (fe1): Linear(in_features=300, out_features=100, bias=True)
  (fc20): Linear(in_features=100, out_features=1, bias=True)
  (fc21): Linear(in_features=1, out_features=100, bias=True)
  (fe2): Linear(in_features=300, out_features=100, bias=True)
  (fc30): Linear(in_features=100, out_features=1, bias=True)
  (fc31): Linear(in_features=1, out_features=100, bias=True)
  (fe3): Linear(in_features=300, out_features=100, bias=True)
  (fc40): Linear(in_features=100, out_features=1, bias=True)
  (fc41): Linear(in_features=1, out_features=100, bias=True)
  (fe4): Linear(in_features=300, out_features=100, bias=True)
  (fc50): Linear(in_features=100, out_features=1, bias=True)
  (fc51): Linear(in_features=1, out_features=100, bias=True)
  (fe5): Linear(in_features=300, out_features=100, bias=True)
  (fc60): Linear(in_features=100, out_features=1, bias=True)
  (fc61): Linear(in_features=1, out_features=100, bias=True)
  (fe6): Linear(in_features=300, out_features=100, bias=True)
  (fc70): Linear(in_features=100, out_features=1, bias=True)
  (fc71): Linear(in_features=1, out_features=100, bias=True)
  (fe7): Linear(in_features=300, out_features=100, bias=True)
  (fc80): Linear(in_features=100, out_features=1, bias=True)
  (fc81): Linear(in_features=1, out_features=100, bias=True)
  (fe8): Linear(in_features=300, out_features=100, bias=True)
  (fc90): Linear(in_features=100, out_features=1, bias=True)
  (fc91): Linear(in_features=1, out_features=100, bias=True)
  (fe9): Linear(in_features=300, out_features=100, bias=True)
  (fc100): Linear(in_features=100, out_features=1, bias=True)
  (fc101): Linear(in_features=1, out_features=100, bias=True)
  (fe10): Linear(in_features=300, out_features=100, bias=True)
  (fc110): Linear(in_features=100, out_features=1, bias=True)
  (fc111): Linear(in_features=1, out_features=100, bias=True)
  (fe11): Linear(in_features=300, out_features=100, bias=True)
  (fc120): Linear(in_features=100, out_features=1, bias=True)
  (fc121): Linear(in_features=1, out_features=100, bias=True)
  (fe12): Linear(in_features=300, out_features=100, bias=True)
  (fc130): Linear(in_features=100, out_features=1, bias=True)
  (fc131): Linear(in_features=1, out_features=100, bias=True)
  (fe13): Linear(in_features=300, out_features=100, bias=True)
  (fc140): Linear(in_features=100, out_features=1, bias=True)
  (fc141): Linear(in_features=1, out_features=100, bias=True)
  (fe14): Linear(in_features=300, out_features=100, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=15, out_features=400, bias=True)
  (inputbn): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=400, out_features=400, bias=True)
  (bn0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=400, bias=True)
  (bn1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=400, out_features=400, bias=True)
  (bn2): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=400, out_features=400, bias=True)
  (bn3): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc4): Linear(in_features=400, out_features=400, bias=True)
  (bn4): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=400, out_features=1, bias=True)
)
(0, False, 15)
-----------Epoch 0-----------
iterator 100, D_Loss:1.407658338546753, G_Loss:0.9061575531959534

iterator 200, D_Loss:1.3925923109054565, G_Loss:0.8556593060493469

iterator 300, D_Loss:1.3674614429473877, G_Loss:0.8824944496154785

iterator 400, D_Loss:1.209012746810913, G_Loss:1.1137590408325195

iterator 500, D_Loss:0.809677243232727, G_Loss:2.1812212467193604

iterator 600, D_Loss:0.6254240274429321, G_Loss:2.4164137840270996

iterator 700, D_Loss:0.4786587953567505, G_Loss:4.126074314117432

iterator 800, D_Loss:0.48454663157463074, G_Loss:4.7530035972595215

iterator 900, D_Loss:0.45504456758499146, G_Loss:4.720859527587891

iterator 1000, D_Loss:0.4914625883102417, G_Loss:4.971147060394287

iterator 1100, D_Loss:0.4861619770526886, G_Loss:3.026562452316284

iterator 1200, D_Loss:0.4541749656200409, G_Loss:4.767279624938965

iterator 1300, D_Loss:0.4298523962497711, G_Loss:6.2606916427612305

iterator 1400, D_Loss:0.45842453837394714, G_Loss:6.010235786437988

iterator 1500, D_Loss:0.44138965010643005, G_Loss:6.010301113128662

iterator 1600, D_Loss:0.44221383333206177, G_Loss:6.892449378967285

iterator 1700, D_Loss:0.42772549390792847, G_Loss:6.827883243560791

iterator 1800, D_Loss:0.4385547339916229, G_Loss:6.562029838562012

iterator 1900, D_Loss:0.4442201256752014, G_Loss:6.307757377624512

iterator 2000, D_Loss:0.4247872531414032, G_Loss:7.031256675720215

iterator 2100, D_Loss:0.475475937128067, G_Loss:5.397170543670654

iterator 2200, D_Loss:0.493990421295166, G_Loss:4.768529891967773

iterator 2300, D_Loss:0.46837931871414185, G_Loss:7.360490798950195

iterator 2400, D_Loss:0.4409068822860718, G_Loss:7.9770355224609375

iterator 2500, D_Loss:0.4220361113548279, G_Loss:7.576290130615234

iterator 2600, D_Loss:0.42453429102897644, G_Loss:8.207080841064453

iterator 2700, D_Loss:0.4403354823589325, G_Loss:7.802893161773682

iterator 2800, D_Loss:0.42010369896888733, G_Loss:7.940158843994141

iterator 2900, D_Loss:0.43143436312675476, G_Loss:7.975705146789551

iterator 3000, D_Loss:0.43106794357299805, G_Loss:8.000288963317871

iterator 3100, D_Loss:0.43361395597457886, G_Loss:9.294830322265625

iterator 3200, D_Loss:0.4381142258644104, G_Loss:8.707315444946289

iterator 3300, D_Loss:0.43294471502304077, G_Loss:8.851910591125488

iterator 3400, D_Loss:0.4365633428096771, G_Loss:9.059983253479004

iterator 3500, D_Loss:0.40301206707954407, G_Loss:8.863432884216309

iterator 3600, D_Loss:0.4318696856498718, G_Loss:8.979610443115234

iterator 3700, D_Loss:0.4312148094177246, G_Loss:8.764825820922852

iterator 3800, D_Loss:0.4212754964828491, G_Loss:9.528820991516113

iterator 3900, D_Loss:0.4201275408267975, G_Loss:9.198406219482422

iterator 4000, D_Loss:0.4195402264595032, G_Loss:9.572044372558594

iterator 4100, D_Loss:0.4166243374347687, G_Loss:9.583487510681152

iterator 4200, D_Loss:0.42289093136787415, G_Loss:9.312131881713867

iterator 4300, D_Loss:0.40358084440231323, G_Loss:9.454217910766602

Process Process-26:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 141, in thread_run
    V_Train(search, path, sample_it, gen, dis, config["n_epochs"], param["lr"], train_it, param["z_dim"], dataset, col_type, sample_times,itertimes = 100, steps_per_epoch = config["steps_per_epoch"],GPU=GPU,KL=KL)
  File "/home/youran/Daisy/Daisy/synthesizer/train.py", line 113, in V_Train
    D_Loss2 = F.binary_cross_entropy(y_fake, fake_label)
  File "/usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/8.3.0-10.1.243/openmpi/3.1.4/pytorch/1.4.0-python-3.7.4/lib/python3.7/site-packages/torch/nn/functional.py", line 2077, in binary_cross_entropy
    input, target, weight, reduction_enum)
RuntimeError: reduce failed to synchronize: cudaErrorAssert: device-side assert triggered
LGAN_generator(
  (LSTM): LSTMCell(1000, 100)
  (fc00): Linear(in_features=600, out_features=1, bias=True)
  (fc01): Linear(in_features=1, out_features=600, bias=True)
  (fe0): Linear(in_features=100, out_features=600, bias=True)
  (fc10): Linear(in_features=600, out_features=1, bias=True)
  (fc11): Linear(in_features=1, out_features=600, bias=True)
  (fe1): Linear(in_features=100, out_features=600, bias=True)
  (fc20): Linear(in_features=600, out_features=1, bias=True)
  (fc21): Linear(in_features=1, out_features=600, bias=True)
  (fe2): Linear(in_features=100, out_features=600, bias=True)
  (fc30): Linear(in_features=600, out_features=1, bias=True)
  (fc31): Linear(in_features=1, out_features=600, bias=True)
  (fe3): Linear(in_features=100, out_features=600, bias=True)
  (fc40): Linear(in_features=600, out_features=1, bias=True)
  (fc41): Linear(in_features=1, out_features=600, bias=True)
  (fe4): Linear(in_features=100, out_features=600, bias=True)
  (fc50): Linear(in_features=600, out_features=1, bias=True)
  (fc51): Linear(in_features=1, out_features=600, bias=True)
  (fe5): Linear(in_features=100, out_features=600, bias=True)
  (fc60): Linear(in_features=600, out_features=1, bias=True)
  (fc61): Linear(in_features=1, out_features=600, bias=True)
  (fe6): Linear(in_features=100, out_features=600, bias=True)
  (fc70): Linear(in_features=600, out_features=1, bias=True)
  (fc71): Linear(in_features=1, out_features=600, bias=True)
  (fe7): Linear(in_features=100, out_features=600, bias=True)
  (fc80): Linear(in_features=600, out_features=1, bias=True)
  (fc81): Linear(in_features=1, out_features=600, bias=True)
  (fe8): Linear(in_features=100, out_features=600, bias=True)
  (fc90): Linear(in_features=600, out_features=1, bias=True)
  (fc91): Linear(in_features=1, out_features=600, bias=True)
  (fe9): Linear(in_features=100, out_features=600, bias=True)
  (fc100): Linear(in_features=600, out_features=1, bias=True)
  (fc101): Linear(in_features=1, out_features=600, bias=True)
  (fe10): Linear(in_features=100, out_features=600, bias=True)
  (fc110): Linear(in_features=600, out_features=1, bias=True)
  (fc111): Linear(in_features=1, out_features=600, bias=True)
  (fe11): Linear(in_features=100, out_features=600, bias=True)
  (fc120): Linear(in_features=600, out_features=1, bias=True)
  (fc121): Linear(in_features=1, out_features=600, bias=True)
  (fe12): Linear(in_features=100, out_features=600, bias=True)
  (fc130): Linear(in_features=600, out_features=1, bias=True)
  (fc131): Linear(in_features=1, out_features=600, bias=True)
  (fe13): Linear(in_features=100, out_features=600, bias=True)
  (fc140): Linear(in_features=600, out_features=1, bias=True)
  (fc141): Linear(in_features=1, out_features=600, bias=True)
  (fe14): Linear(in_features=100, out_features=600, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=15, out_features=200, bias=True)
  (inputbn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (bn0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=200, out_features=200, bias=True)
  (bn1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=200, out_features=200, bias=True)
  (bn2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=200, out_features=200, bias=True)
  (bn3): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=200, out_features=1, bias=True)
)
(0, False, 15)
-----------Epoch 0-----------
iterator 100, D_Loss:1.368037223815918, G_Loss:0.8585326671600342

iterator 200, D_Loss:1.3884608745574951, G_Loss:0.8830236196517944

iterator 300, D_Loss:1.3747339248657227, G_Loss:0.8485937714576721

iterator 400, D_Loss:1.3689887523651123, G_Loss:0.8400560617446899

iterator 500, D_Loss:1.3135483264923096, G_Loss:1.0186848640441895

iterator 600, D_Loss:1.2342784404754639, G_Loss:1.1061224937438965

iterator 700, D_Loss:1.0706238746643066, G_Loss:1.6008729934692383

iterator 800, D_Loss:0.8099450469017029, G_Loss:1.992730736732483

iterator 900, D_Loss:0.666321873664856, G_Loss:2.4928665161132812

iterator 1000, D_Loss:0.5720834136009216, G_Loss:2.759326457977295

iterator 1100, D_Loss:0.5875908732414246, G_Loss:2.920351028442383

iterator 1200, D_Loss:0.5058190822601318, G_Loss:5.0027360916137695

iterator 1300, D_Loss:0.5294687151908875, G_Loss:3.370730400085449

iterator 1400, D_Loss:0.5024233460426331, G_Loss:4.294538974761963

iterator 1500, D_Loss:0.49027785658836365, G_Loss:3.7038040161132812

iterator 1600, D_Loss:0.44235020875930786, G_Loss:5.104130268096924

iterator 1700, D_Loss:0.4619256556034088, G_Loss:5.248673915863037

iterator 1800, D_Loss:0.5168349742889404, G_Loss:5.6699957847595215

iterator 1900, D_Loss:0.48432695865631104, G_Loss:4.059140682220459

iterator 2000, D_Loss:0.4842512607574463, G_Loss:5.338353157043457

iterator 2100, D_Loss:0.49786290526390076, G_Loss:5.694127082824707

iterator 2200, D_Loss:0.4816562235355377, G_Loss:5.80827522277832

iterator 2300, D_Loss:0.4379744827747345, G_Loss:6.206789970397949

iterator 2400, D_Loss:0.4398382306098938, G_Loss:6.005886077880859

iterator 2500, D_Loss:0.4638456106185913, G_Loss:5.632716655731201

iterator 2600, D_Loss:0.44695693254470825, G_Loss:6.274924278259277

iterator 2700, D_Loss:0.4487687349319458, G_Loss:7.229438304901123

iterator 2800, D_Loss:0.45082035660743713, G_Loss:7.5043439865112305

iterator 2900, D_Loss:0.4417632818222046, G_Loss:7.048853874206543

iterator 3000, D_Loss:0.4355928897857666, G_Loss:7.63253116607666

iterator 3100, D_Loss:0.46177178621292114, G_Loss:5.130321502685547

iterator 3200, D_Loss:0.43465545773506165, G_Loss:6.2727131843566895

iterator 3300, D_Loss:0.43593406677246094, G_Loss:7.0307183265686035

iterator 3400, D_Loss:0.43209829926490784, G_Loss:7.071831226348877

iterator 3500, D_Loss:0.4417143166065216, G_Loss:7.4396281242370605

iterator 3600, D_Loss:0.4516945481300354, G_Loss:7.360584259033203

iterator 3700, D_Loss:0.44567257165908813, G_Loss:6.117557525634766

iterator 3800, D_Loss:0.43703779578208923, G_Loss:6.516679286956787

iterator 3900, D_Loss:0.4516882300376892, G_Loss:6.6768999099731445

iterator 4000, D_Loss:0.4506659209728241, G_Loss:7.071657657623291

iterator 4100, D_Loss:0.5209842920303345, G_Loss:8.100618362426758

iterator 4200, D_Loss:0.41190075874328613, G_Loss:8.810653686523438

iterator 4300, D_Loss:0.4312945604324341, G_Loss:8.646605491638184

iterator 4400, D_Loss:0.4394421875476837, G_Loss:7.936567306518555

iterator 4500, D_Loss:0.45138150453567505, G_Loss:8.994976043701172

iterator 4600, D_Loss:0.505775511264801, G_Loss:8.37482738494873

iterator 4700, D_Loss:0.5016533732414246, G_Loss:9.68186092376709

iterator 4800, D_Loss:0.4490373432636261, G_Loss:9.270009994506836

iterator 4900, D_Loss:0.4203867018222809, G_Loss:10.062174797058105

iterator 5000, D_Loss:0.4096144735813141, G_Loss:10.47450065612793

-----------Epoch 1-----------
iterator 100, D_Loss:0.5104190111160278, G_Loss:9.54604721069336

iterator 200, D_Loss:0.4455660581588745, G_Loss:9.808362007141113

iterator 300, D_Loss:0.4329453706741333, G_Loss:10.062747955322266

iterator 400, D_Loss:0.46230751276016235, G_Loss:8.027259826660156

iterator 500, D_Loss:0.4491342306137085, G_Loss:7.481567859649658

iterator 600, D_Loss:0.4498109817504883, G_Loss:8.772459030151367

iterator 700, D_Loss:0.41847294569015503, G_Loss:6.658371448516846

iterator 800, D_Loss:0.4397960603237152, G_Loss:9.135544776916504

iterator 900, D_Loss:0.42424556612968445, G_Loss:8.917213439941406

iterator 1000, D_Loss:0.43849143385887146, G_Loss:6.849118709564209

iterator 1100, D_Loss:0.4234626591205597, G_Loss:9.141926765441895

iterator 1200, D_Loss:0.4598330557346344, G_Loss:8.66907024383545

iterator 1300, D_Loss:0.44661587476730347, G_Loss:7.737024307250977

iterator 1400, D_Loss:0.45065054297447205, G_Loss:9.208856582641602

iterator 1500, D_Loss:0.4337605834007263, G_Loss:8.581866264343262

iterator 1600, D_Loss:0.44431987404823303, G_Loss:9.585792541503906

iterator 1700, D_Loss:0.44265255331993103, G_Loss:9.192063331604004

iterator 1800, D_Loss:0.4104795455932617, G_Loss:9.888461112976074

iterator 1900, D_Loss:0.42334070801734924, G_Loss:9.533666610717773

iterator 2000, D_Loss:0.3993525207042694, G_Loss:10.499317169189453

iterator 2100, D_Loss:0.41782307624816895, G_Loss:9.424498558044434

iterator 2200, D_Loss:0.4275354743003845, G_Loss:10.67347526550293

iterator 2300, D_Loss:0.4499818980693817, G_Loss:10.598304748535156

iterator 2400, D_Loss:0.422811359167099, G_Loss:11.588460922241211

iterator 2500, D_Loss:0.41750532388687134, G_Loss:10.472190856933594

iterator 2600, D_Loss:0.4077175259590149, G_Loss:11.450433731079102

iterator 2700, D_Loss:0.43568310141563416, G_Loss:10.406030654907227

iterator 2800, D_Loss:0.4097534120082855, G_Loss:10.739815711975098

iterator 2900, D_Loss:0.4405960142612457, G_Loss:10.575788497924805

iterator 3000, D_Loss:0.4315201938152313, G_Loss:11.753466606140137

iterator 3100, D_Loss:0.4399593770503998, G_Loss:10.745800018310547

iterator 3200, D_Loss:0.4147453308105469, G_Loss:10.32779312133789

iterator 3300, D_Loss:0.3994399905204773, G_Loss:10.340401649475098

iterator 3400, D_Loss:0.4150872230529785, G_Loss:11.178838729858398

iterator 3500, D_Loss:0.4020981192588806, G_Loss:11.836535453796387

iterator 3600, D_Loss:0.39716222882270813, G_Loss:11.82629108428955

iterator 3700, D_Loss:0.4465790092945099, G_Loss:11.736907005310059

iterator 3800, D_Loss:0.44748252630233765, G_Loss:11.397590637207031

iterator 3900, D_Loss:0.41576752066612244, G_Loss:11.398001670837402

iterator 4000, D_Loss:0.45214298367500305, G_Loss:12.212864875793457

iterator 4100, D_Loss:0.42739054560661316, G_Loss:13.463656425476074

iterator 4200, D_Loss:0.4558444321155548, G_Loss:12.000919342041016

iterator 4300, D_Loss:0.38748621940612793, G_Loss:10.524291038513184

iterator 4400, D_Loss:0.42003709077835083, G_Loss:11.356675148010254

iterator 4500, D_Loss:0.439834862947464, G_Loss:12.323864936828613

iterator 4600, D_Loss:0.41790133714675903, G_Loss:11.066988945007324

iterator 4700, D_Loss:0.42559847235679626, G_Loss:12.108135223388672

iterator 4800, D_Loss:0.4333370625972748, G_Loss:11.007370948791504

iterator 4900, D_Loss:0.40691667795181274, G_Loss:11.629576683044434

iterator 5000, D_Loss:0.4242827892303467, G_Loss:11.877140998840332

-----------Epoch 2-----------
iterator 100, D_Loss:0.4174721837043762, G_Loss:8.09494400024414

iterator 200, D_Loss:0.43260911107063293, G_Loss:11.169118881225586

iterator 300, D_Loss:0.42554253339767456, G_Loss:10.286293983459473

iterator 400, D_Loss:0.4297146201133728, G_Loss:12.033982276916504

iterator 500, D_Loss:0.40829998254776, G_Loss:12.000251770019531

iterator 600, D_Loss:0.41863778233528137, G_Loss:12.201403617858887

iterator 700, D_Loss:0.4276106357574463, G_Loss:11.301366806030273

iterator 800, D_Loss:0.42432427406311035, G_Loss:11.149663925170898

iterator 900, D_Loss:0.4474206566810608, G_Loss:13.960639953613281

iterator 1000, D_Loss:0.3975352644920349, G_Loss:11.320121765136719

iterator 1100, D_Loss:0.3989127278327942, G_Loss:13.395105361938477

iterator 1200, D_Loss:0.40804171562194824, G_Loss:12.125785827636719

iterator 1300, D_Loss:0.42277881503105164, G_Loss:12.504999160766602

iterator 1400, D_Loss:0.4269981384277344, G_Loss:11.257872581481934

iterator 1500, D_Loss:0.4366767406463623, G_Loss:12.278063774108887

iterator 1600, D_Loss:0.4247613847255707, G_Loss:11.876106262207031

iterator 1700, D_Loss:0.3904995918273926, G_Loss:13.767949104309082

iterator 1800, D_Loss:0.44367414712905884, G_Loss:12.1636323928833

iterator 1900, D_Loss:0.40054643154144287, G_Loss:13.851863861083984

iterator 2000, D_Loss:0.44054344296455383, G_Loss:11.83275032043457

iterator 2100, D_Loss:0.45023152232170105, G_Loss:13.298449516296387

iterator 2200, D_Loss:0.4244384467601776, G_Loss:12.094128608703613

iterator 2300, D_Loss:0.44457322359085083, G_Loss:14.947391510009766

iterator 2400, D_Loss:0.40976670384407043, G_Loss:13.58532428741455

iterator 2500, D_Loss:0.4229973256587982, G_Loss:12.871367454528809

iterator 2600, D_Loss:0.4187472462654114, G_Loss:14.930943489074707

iterator 2700, D_Loss:0.4192521572113037, G_Loss:15.177740097045898

iterator 2800, D_Loss:0.4288169741630554, G_Loss:15.495838165283203

iterator 2900, D_Loss:0.42844101786613464, G_Loss:14.674520492553711

iterator 3000, D_Loss:0.4268573522567749, G_Loss:13.459349632263184

iterator 3100, D_Loss:0.388208270072937, G_Loss:13.330506324768066

iterator 3200, D_Loss:0.436514288187027, G_Loss:11.07927131652832

iterator 3300, D_Loss:0.4281003475189209, G_Loss:10.183119773864746

iterator 3400, D_Loss:0.43129467964172363, G_Loss:13.06759262084961

iterator 3500, D_Loss:0.4264329969882965, G_Loss:13.791546821594238

iterator 3600, D_Loss:0.43543022871017456, G_Loss:15.213295936584473

iterator 3700, D_Loss:0.41347697377204895, G_Loss:12.945072174072266

iterator 3800, D_Loss:0.4288182258605957, G_Loss:12.063406944274902

iterator 3900, D_Loss:0.38054391741752625, G_Loss:12.4918851852417

iterator 4000, D_Loss:0.41930344700813293, G_Loss:12.069046974182129

iterator 4100, D_Loss:0.4162576198577881, G_Loss:10.787374496459961

iterator 4200, D_Loss:0.40022075176239014, G_Loss:12.206334114074707

iterator 4300, D_Loss:0.4017139971256256, G_Loss:14.049205780029297

iterator 4400, D_Loss:0.4352530241012573, G_Loss:10.038546562194824

iterator 4500, D_Loss:0.4500674307346344, G_Loss:12.085182189941406

iterator 4600, D_Loss:0.4451856017112732, G_Loss:13.648078918457031

iterator 4700, D_Loss:0.4405614733695984, G_Loss:11.47848892211914

iterator 4800, D_Loss:0.41299405694007874, G_Loss:11.78670883178711

iterator 4900, D_Loss:0.4397389590740204, G_Loss:12.312470436096191

iterator 5000, D_Loss:0.4411175549030304, G_Loss:13.432602882385254

-----------Epoch 3-----------
iterator 100, D_Loss:0.4342972934246063, G_Loss:12.486899375915527

iterator 200, D_Loss:0.43585848808288574, G_Loss:13.074945449829102

iterator 300, D_Loss:0.4000106751918793, G_Loss:11.680744171142578

iterator 400, D_Loss:0.4197101294994354, G_Loss:17.431100845336914

iterator 500, D_Loss:0.4307977557182312, G_Loss:15.131753921508789

iterator 600, D_Loss:0.4023057520389557, G_Loss:14.603803634643555

iterator 700, D_Loss:0.42928582429885864, G_Loss:13.392375946044922

iterator 800, D_Loss:0.4179956614971161, G_Loss:14.100946426391602

iterator 900, D_Loss:0.43649405241012573, G_Loss:13.142024040222168

iterator 1000, D_Loss:0.41528433561325073, G_Loss:11.386103630065918

iterator 1100, D_Loss:0.41919034719467163, G_Loss:14.342325210571289

iterator 1200, D_Loss:0.42810654640197754, G_Loss:14.635981559753418

iterator 1300, D_Loss:0.4208407998085022, G_Loss:13.836065292358398

iterator 1400, D_Loss:0.4244498014450073, G_Loss:12.76685905456543

iterator 1500, D_Loss:0.44659385085105896, G_Loss:13.000919342041016

iterator 1600, D_Loss:0.439723938703537, G_Loss:13.380197525024414

iterator 1700, D_Loss:0.4318433105945587, G_Loss:13.668946266174316

iterator 1800, D_Loss:0.4226153790950775, G_Loss:14.00757122039795

iterator 1900, D_Loss:0.40132537484169006, G_Loss:13.061389923095703

iterator 2000, D_Loss:0.41494908928871155, G_Loss:14.360273361206055

iterator 2100, D_Loss:0.43999019265174866, G_Loss:11.419391632080078

iterator 2200, D_Loss:0.4289497435092926, G_Loss:15.125907897949219

iterator 2300, D_Loss:0.41909345984458923, G_Loss:15.841756820678711

iterator 2400, D_Loss:0.43048131465911865, G_Loss:14.659564971923828

iterator 2500, D_Loss:0.4257454574108124, G_Loss:16.484771728515625

iterator 2600, D_Loss:0.45170846581459045, G_Loss:15.15993881225586

iterator 2700, D_Loss:0.4326954483985901, G_Loss:15.439617156982422

iterator 2800, D_Loss:0.3940105438232422, G_Loss:12.607237815856934

iterator 2900, D_Loss:0.46660110354423523, G_Loss:13.675389289855957

iterator 3000, D_Loss:0.432235449552536, G_Loss:15.895821571350098

iterator 3100, D_Loss:0.43657511472702026, G_Loss:16.6684513092041

iterator 3200, D_Loss:0.41914957761764526, G_Loss:14.111189842224121

iterator 3300, D_Loss:0.41629505157470703, G_Loss:15.649704933166504

iterator 3400, D_Loss:0.439405620098114, G_Loss:14.218945503234863

iterator 3500, D_Loss:0.4186869263648987, G_Loss:14.255422592163086

iterator 3600, D_Loss:0.4221580922603607, G_Loss:13.9832763671875

iterator 3700, D_Loss:0.42425844073295593, G_Loss:14.273659706115723

iterator 3800, D_Loss:0.41748395562171936, G_Loss:11.786162376403809

iterator 3900, D_Loss:0.4128647446632385, G_Loss:14.339077949523926

iterator 4000, D_Loss:0.3835609257221222, G_Loss:15.910552978515625

iterator 4100, D_Loss:0.42028942704200745, G_Loss:15.987701416015625

iterator 4200, D_Loss:0.455038845539093, G_Loss:15.172551155090332

iterator 4300, D_Loss:0.4170777201652527, G_Loss:14.262630462646484

iterator 4400, D_Loss:0.4350840151309967, G_Loss:15.070286750793457

iterator 4500, D_Loss:0.4044569134712219, G_Loss:12.995733261108398

iterator 4600, D_Loss:0.4367317259311676, G_Loss:13.87887954711914

iterator 4700, D_Loss:0.42822492122650146, G_Loss:14.221657752990723

iterator 4800, D_Loss:0.3986590802669525, G_Loss:14.386170387268066

iterator 4900, D_Loss:0.43382972478866577, G_Loss:14.676252365112305

iterator 5000, D_Loss:0.42028385400772095, G_Loss:14.406030654907227

-----------Epoch 4-----------
iterator 100, D_Loss:0.402077317237854, G_Loss:14.22591781616211

iterator 200, D_Loss:0.43338316679000854, G_Loss:13.686928749084473

iterator 300, D_Loss:0.4109094738960266, G_Loss:14.558338165283203

iterator 400, D_Loss:0.42796996235847473, G_Loss:14.266674041748047

iterator 500, D_Loss:0.4396494925022125, G_Loss:13.035200119018555

iterator 600, D_Loss:0.40364158153533936, G_Loss:14.129558563232422

iterator 700, D_Loss:0.41705262660980225, G_Loss:13.757519721984863

iterator 800, D_Loss:0.44769951701164246, G_Loss:12.134786605834961

iterator 900, D_Loss:0.4416935443878174, G_Loss:12.219250679016113

iterator 1000, D_Loss:0.403845876455307, G_Loss:10.398350715637207

iterator 1100, D_Loss:0.4287067651748657, G_Loss:13.187657356262207

iterator 1200, D_Loss:0.42102521657943726, G_Loss:13.127331733703613

iterator 1300, D_Loss:0.4407847225666046, G_Loss:13.143200874328613

iterator 1400, D_Loss:0.4141707420349121, G_Loss:13.871129989624023

iterator 1500, D_Loss:0.434977650642395, G_Loss:12.338910102844238

iterator 1600, D_Loss:0.43519723415374756, G_Loss:12.585214614868164

iterator 1700, D_Loss:0.43700993061065674, G_Loss:8.824935913085938

iterator 1800, D_Loss:0.4118269979953766, G_Loss:13.093189239501953

iterator 1900, D_Loss:0.42425599694252014, G_Loss:11.511033058166504

iterator 2000, D_Loss:0.4070330858230591, G_Loss:15.017926216125488

iterator 2100, D_Loss:0.4023604094982147, G_Loss:11.587115287780762

iterator 2200, D_Loss:0.4064457416534424, G_Loss:14.109665870666504

iterator 2300, D_Loss:0.41510453820228577, G_Loss:16.02328109741211

iterator 2400, D_Loss:0.41448137164115906, G_Loss:12.137394905090332

iterator 2500, D_Loss:0.44096797704696655, G_Loss:13.713147163391113

iterator 2600, D_Loss:0.41356852650642395, G_Loss:13.116859436035156

iterator 2700, D_Loss:0.443725049495697, G_Loss:13.423593521118164

iterator 2800, D_Loss:0.40589639544487, G_Loss:13.093666076660156

iterator 2900, D_Loss:0.43038487434387207, G_Loss:13.927543640136719

iterator 3000, D_Loss:0.42297762632369995, G_Loss:12.455370903015137

iterator 3100, D_Loss:0.4302956759929657, G_Loss:11.917728424072266

iterator 3200, D_Loss:0.3898571729660034, G_Loss:14.535362243652344

iterator 3300, D_Loss:0.40251094102859497, G_Loss:13.568180084228516

iterator 3400, D_Loss:0.4018838703632355, G_Loss:11.732571601867676

iterator 3500, D_Loss:0.45329055190086365, G_Loss:13.675576210021973

iterator 3600, D_Loss:0.4209326207637787, G_Loss:12.618555068969727

iterator 3700, D_Loss:0.4441946744918823, G_Loss:14.564913749694824

iterator 3800, D_Loss:0.43043771386146545, G_Loss:14.481165885925293

iterator 3900, D_Loss:0.46288108825683594, G_Loss:11.706932067871094

iterator 4000, D_Loss:0.40185901522636414, G_Loss:12.703643798828125

iterator 4100, D_Loss:0.4259340465068817, G_Loss:11.719574928283691

iterator 4200, D_Loss:0.409790962934494, G_Loss:14.56545639038086

iterator 4300, D_Loss:0.4171261787414551, G_Loss:13.26355266571045

iterator 4400, D_Loss:0.4324065148830414, G_Loss:13.066956520080566

iterator 4500, D_Loss:0.4168819785118103, G_Loss:12.614023208618164

iterator 4600, D_Loss:0.4071348309516907, G_Loss:13.68366813659668

iterator 4700, D_Loss:0.4139047861099243, G_Loss:12.918134689331055

iterator 4800, D_Loss:0.42116352915763855, G_Loss:14.202615737915039

iterator 4900, D_Loss:0.42616090178489685, G_Loss:11.842947006225586

iterator 5000, D_Loss:0.3973110020160675, G_Loss:14.365734100341797

-----------Epoch 5-----------
iterator 100, D_Loss:0.41322049498558044, G_Loss:15.168146133422852

iterator 200, D_Loss:0.40143904089927673, G_Loss:12.998435974121094

iterator 300, D_Loss:0.42986199259757996, G_Loss:14.908971786499023

iterator 400, D_Loss:0.4255765378475189, G_Loss:13.294525146484375

iterator 500, D_Loss:0.42459386587142944, G_Loss:14.632660865783691

iterator 600, D_Loss:0.44399696588516235, G_Loss:14.85456657409668

iterator 700, D_Loss:0.4380488991737366, G_Loss:13.777621269226074

iterator 800, D_Loss:0.4275290071964264, G_Loss:13.683633804321289

iterator 900, D_Loss:0.42359471321105957, G_Loss:14.454254150390625

iterator 1000, D_Loss:0.43273526430130005, G_Loss:13.298284530639648

iterator 1100, D_Loss:0.44500967860221863, G_Loss:13.64859390258789

iterator 1200, D_Loss:0.42532843351364136, G_Loss:13.086461067199707

iterator 1300, D_Loss:0.4486278295516968, G_Loss:13.396279335021973

iterator 1400, D_Loss:0.4288073778152466, G_Loss:13.091513633728027

iterator 1500, D_Loss:0.425489604473114, G_Loss:12.984114646911621

iterator 1600, D_Loss:0.4131997525691986, G_Loss:13.650443077087402

iterator 1700, D_Loss:0.43027061223983765, G_Loss:11.815511703491211

iterator 1800, D_Loss:0.4404994547367096, G_Loss:12.9326171875

iterator 1900, D_Loss:0.415459543466568, G_Loss:13.969568252563477

iterator 2000, D_Loss:0.4105236828327179, G_Loss:14.290452003479004

iterator 2100, D_Loss:0.442310631275177, G_Loss:13.006196022033691

iterator 2200, D_Loss:0.42264342308044434, G_Loss:13.137343406677246

iterator 2300, D_Loss:0.4367188811302185, G_Loss:13.833674430847168

iterator 2400, D_Loss:0.4054306447505951, G_Loss:13.684024810791016

iterator 2500, D_Loss:0.41673967242240906, G_Loss:12.27224349975586

iterator 2600, D_Loss:0.4055725336074829, G_Loss:12.940505027770996

iterator 2700, D_Loss:0.41710707545280457, G_Loss:14.511929512023926

iterator 2800, D_Loss:0.4330218434333801, G_Loss:13.098084449768066

iterator 2900, D_Loss:0.44404083490371704, G_Loss:12.324145317077637

iterator 3000, D_Loss:0.4481986165046692, G_Loss:13.609565734863281

iterator 3100, D_Loss:0.4389916956424713, G_Loss:12.894278526306152

iterator 3200, D_Loss:0.4302770495414734, G_Loss:12.502969741821289

iterator 3300, D_Loss:0.4251302182674408, G_Loss:13.007177352905273

iterator 3400, D_Loss:0.43394580483436584, G_Loss:13.472084045410156

iterator 3500, D_Loss:0.4271330237388611, G_Loss:14.935907363891602

iterator 3600, D_Loss:0.42995449900627136, G_Loss:12.418057441711426

iterator 3700, D_Loss:0.41718700528144836, G_Loss:13.076870918273926

iterator 3800, D_Loss:0.40173494815826416, G_Loss:14.139286041259766

iterator 3900, D_Loss:0.42067739367485046, G_Loss:13.528912544250488

iterator 4000, D_Loss:0.42130595445632935, G_Loss:13.40987777709961

iterator 4100, D_Loss:0.40653669834136963, G_Loss:12.812983512878418

iterator 4200, D_Loss:0.4186307191848755, G_Loss:14.117511749267578

iterator 4300, D_Loss:0.42386505007743835, G_Loss:13.121931076049805

iterator 4400, D_Loss:0.42081418633461, G_Loss:13.170284271240234

iterator 4500, D_Loss:0.43527716398239136, G_Loss:12.776429176330566

iterator 4600, D_Loss:0.41753053665161133, G_Loss:14.258267402648926

iterator 4700, D_Loss:0.4193441867828369, G_Loss:13.287611961364746

iterator 4800, D_Loss:0.44486942887306213, G_Loss:13.703636169433594

iterator 4900, D_Loss:0.4330615997314453, G_Loss:14.26099967956543

iterator 5000, D_Loss:0.402679443359375, G_Loss:13.106534004211426

-----------Epoch 6-----------
iterator 100, D_Loss:0.42222148180007935, G_Loss:13.34985637664795

iterator 200, D_Loss:0.39695602655410767, G_Loss:14.88615608215332

iterator 300, D_Loss:0.45853525400161743, G_Loss:12.944035530090332

iterator 400, D_Loss:0.4257713556289673, G_Loss:14.142892837524414

iterator 500, D_Loss:0.4236586391925812, G_Loss:14.685140609741211

iterator 600, D_Loss:0.4048234224319458, G_Loss:13.676401138305664

iterator 700, D_Loss:0.4249506890773773, G_Loss:13.450350761413574

iterator 800, D_Loss:0.42683058977127075, G_Loss:13.803308486938477

iterator 900, D_Loss:0.4258287847042084, G_Loss:10.393399238586426

iterator 1000, D_Loss:0.4009373188018799, G_Loss:12.389111518859863

iterator 1100, D_Loss:0.4291161000728607, G_Loss:11.727652549743652

iterator 1200, D_Loss:0.42139390110969543, G_Loss:11.833812713623047

iterator 1300, D_Loss:0.3960879445075989, G_Loss:11.912762641906738

iterator 1400, D_Loss:0.43149760365486145, G_Loss:9.871976852416992

iterator 1500, D_Loss:0.42956316471099854, G_Loss:12.205974578857422

iterator 1600, D_Loss:0.43670448660850525, G_Loss:11.838776588439941

iterator 1700, D_Loss:0.3943983018398285, G_Loss:12.831457138061523

iterator 1800, D_Loss:0.39719054102897644, G_Loss:12.56860065460205

iterator 1900, D_Loss:0.4415893256664276, G_Loss:14.089759826660156

iterator 2000, D_Loss:0.43353214859962463, G_Loss:13.034817695617676

iterator 2100, D_Loss:0.4248647391796112, G_Loss:12.700346946716309

iterator 2200, D_Loss:0.43608975410461426, G_Loss:13.407248497009277

iterator 2300, D_Loss:0.4353366494178772, G_Loss:11.656896591186523

iterator 2400, D_Loss:0.4074864983558655, G_Loss:12.738858222961426

iterator 2500, D_Loss:0.4011184573173523, G_Loss:13.817840576171875

iterator 2600, D_Loss:0.40670907497406006, G_Loss:14.154265403747559

iterator 2700, D_Loss:0.3955610394477844, G_Loss:11.903502464294434

iterator 2800, D_Loss:0.4304068386554718, G_Loss:12.202481269836426

iterator 2900, D_Loss:0.424323171377182, G_Loss:13.091761589050293

iterator 3000, D_Loss:0.41751179099082947, G_Loss:12.9473876953125

iterator 3100, D_Loss:0.39288872480392456, G_Loss:13.363465309143066

iterator 3200, D_Loss:0.43328577280044556, G_Loss:12.795156478881836

iterator 3300, D_Loss:0.4138643741607666, G_Loss:13.680377006530762

iterator 3400, D_Loss:0.4294050335884094, G_Loss:13.616128921508789

iterator 3500, D_Loss:0.4059251546859741, G_Loss:14.76612663269043

iterator 3600, D_Loss:0.4405834376811981, G_Loss:14.987346649169922

iterator 3700, D_Loss:0.4064646065235138, G_Loss:14.813093185424805

iterator 3800, D_Loss:0.4171105623245239, G_Loss:10.759578704833984

iterator 3900, D_Loss:0.43408456444740295, G_Loss:14.710217475891113

iterator 4000, D_Loss:0.4009245038032532, G_Loss:15.990490913391113

iterator 4100, D_Loss:0.4169456362724304, G_Loss:14.248129844665527

iterator 4200, D_Loss:0.39704498648643494, G_Loss:13.810068130493164

iterator 4300, D_Loss:0.41576942801475525, G_Loss:14.19226360321045

iterator 4400, D_Loss:0.42676663398742676, G_Loss:15.229792594909668

iterator 4500, D_Loss:0.4225783944129944, G_Loss:13.49445915222168

iterator 4600, D_Loss:0.44996121525764465, G_Loss:13.410806655883789

iterator 4700, D_Loss:0.4311794340610504, G_Loss:13.620087623596191

iterator 4800, D_Loss:0.41980165243148804, G_Loss:13.337464332580566

iterator 4900, D_Loss:0.4626840054988861, G_Loss:13.575345039367676

iterator 5000, D_Loss:0.4192562401294708, G_Loss:13.637446403503418

-----------Epoch 7-----------
iterator 100, D_Loss:0.42860284447669983, G_Loss:14.997064590454102

iterator 200, D_Loss:0.40905290842056274, G_Loss:12.024707794189453

iterator 300, D_Loss:0.4052901268005371, G_Loss:13.798266410827637

iterator 400, D_Loss:0.40348777174949646, G_Loss:13.655035018920898

iterator 500, D_Loss:0.4168805181980133, G_Loss:12.405335426330566

iterator 600, D_Loss:0.43110930919647217, G_Loss:12.409687042236328

iterator 700, D_Loss:0.4483873248100281, G_Loss:13.667350769042969

iterator 800, D_Loss:0.4275577962398529, G_Loss:10.581162452697754

iterator 900, D_Loss:0.4216564893722534, G_Loss:11.847977638244629

iterator 1000, D_Loss:0.42193248867988586, G_Loss:11.312212944030762

iterator 1100, D_Loss:0.4376737177371979, G_Loss:13.299566268920898

iterator 1200, D_Loss:0.4566437005996704, G_Loss:12.76606559753418

iterator 1300, D_Loss:0.42182788252830505, G_Loss:12.046597480773926

iterator 1400, D_Loss:0.4160836935043335, G_Loss:13.020898818969727

iterator 1500, D_Loss:0.4125306010246277, G_Loss:13.48451042175293

iterator 1600, D_Loss:0.4155794084072113, G_Loss:13.649251937866211

iterator 1700, D_Loss:0.41604018211364746, G_Loss:13.207602500915527

iterator 1800, D_Loss:0.42034992575645447, G_Loss:13.052330017089844

iterator 1900, D_Loss:0.4268389046192169, G_Loss:13.167935371398926

iterator 2000, D_Loss:0.40563639998435974, G_Loss:12.317651748657227

iterator 2100, D_Loss:0.41043412685394287, G_Loss:12.7020845413208

iterator 2200, D_Loss:0.4448045492172241, G_Loss:12.806526184082031

iterator 2300, D_Loss:0.427481085062027, G_Loss:13.903977394104004

iterator 2400, D_Loss:0.44201332330703735, G_Loss:13.567095756530762

iterator 2500, D_Loss:0.4223172962665558, G_Loss:13.547107696533203

iterator 2600, D_Loss:0.42180168628692627, G_Loss:13.556962966918945

iterator 2700, D_Loss:0.4183695912361145, G_Loss:13.346529960632324

iterator 2800, D_Loss:0.4279997646808624, G_Loss:13.120266914367676

iterator 2900, D_Loss:0.4001549780368805, G_Loss:13.737781524658203

iterator 3000, D_Loss:0.4174578785896301, G_Loss:13.294301986694336

iterator 3100, D_Loss:0.4276193678379059, G_Loss:11.21504020690918

iterator 3200, D_Loss:0.4278634786605835, G_Loss:13.132031440734863

iterator 3300, D_Loss:0.4114135205745697, G_Loss:14.278070449829102

iterator 3400, D_Loss:0.39709314703941345, G_Loss:13.806915283203125

iterator 3500, D_Loss:0.4318637251853943, G_Loss:13.40645980834961

iterator 3600, D_Loss:0.4316243827342987, G_Loss:13.303701400756836

iterator 3700, D_Loss:0.44898033142089844, G_Loss:13.428841590881348

iterator 3800, D_Loss:0.4205171763896942, G_Loss:12.992792129516602

iterator 3900, D_Loss:0.45342782139778137, G_Loss:13.797098159790039

iterator 4000, D_Loss:0.4359680414199829, G_Loss:12.511870384216309

iterator 4100, D_Loss:0.4204712510108948, G_Loss:12.330765724182129

iterator 4200, D_Loss:0.4399281144142151, G_Loss:12.988759994506836

iterator 4300, D_Loss:0.4432799220085144, G_Loss:13.364677429199219

iterator 4400, D_Loss:0.4681287407875061, G_Loss:13.491442680358887

iterator 4500, D_Loss:0.4111235737800598, G_Loss:12.450204849243164

iterator 4600, D_Loss:0.42403194308280945, G_Loss:14.037271499633789

iterator 4700, D_Loss:0.4267544150352478, G_Loss:14.814732551574707

iterator 4800, D_Loss:0.4332854449748993, G_Loss:14.561984062194824

iterator 4900, D_Loss:0.46350860595703125, G_Loss:16.062108993530273

iterator 5000, D_Loss:0.4132433533668518, G_Loss:13.373601913452148

-----------Epoch 8-----------
iterator 100, D_Loss:0.44116201996803284, G_Loss:14.454916000366211

iterator 200, D_Loss:0.421673446893692, G_Loss:13.145055770874023

iterator 300, D_Loss:0.41610822081565857, G_Loss:14.58984088897705

iterator 400, D_Loss:0.413125216960907, G_Loss:13.539084434509277

iterator 500, D_Loss:0.45259061455726624, G_Loss:14.23641586303711

iterator 600, D_Loss:0.4200793504714966, G_Loss:14.500102996826172

iterator 700, D_Loss:0.4211762845516205, G_Loss:13.516596794128418

iterator 800, D_Loss:0.42659130692481995, G_Loss:14.415799140930176

iterator 900, D_Loss:0.44212764501571655, G_Loss:14.375775337219238

iterator 1000, D_Loss:0.4190123379230499, G_Loss:14.140302658081055

iterator 1100, D_Loss:0.39334404468536377, G_Loss:14.856863021850586

iterator 1200, D_Loss:0.4521557688713074, G_Loss:13.134840965270996

iterator 1300, D_Loss:0.4415871500968933, G_Loss:14.59050178527832

iterator 1400, D_Loss:0.40485644340515137, G_Loss:13.365373611450195

iterator 1500, D_Loss:0.4157586395740509, G_Loss:13.310995101928711

iterator 1600, D_Loss:0.4234059453010559, G_Loss:13.672551155090332

iterator 1700, D_Loss:0.4386196732521057, G_Loss:13.294524192810059

iterator 1800, D_Loss:0.41068676114082336, G_Loss:13.159740447998047

iterator 1900, D_Loss:0.41594693064689636, G_Loss:11.684545516967773

iterator 2000, D_Loss:0.42200836539268494, G_Loss:13.072715759277344

iterator 2100, D_Loss:0.40352553129196167, G_Loss:14.065227508544922

iterator 2200, D_Loss:0.4417732357978821, G_Loss:14.055171966552734

iterator 2300, D_Loss:0.43553468585014343, G_Loss:13.74278450012207

iterator 2400, D_Loss:0.4244450330734253, G_Loss:12.174055099487305

iterator 2500, D_Loss:0.43996331095695496, G_Loss:13.249493598937988

iterator 2600, D_Loss:0.40405890345573425, G_Loss:13.068160057067871

iterator 2700, D_Loss:0.4081759452819824, G_Loss:13.707162857055664

iterator 2800, D_Loss:0.4275181293487549, G_Loss:12.52291488647461

iterator 2900, D_Loss:0.4328976273536682, G_Loss:12.610300064086914

iterator 3000, D_Loss:0.4109593629837036, G_Loss:13.543179512023926

iterator 3100, D_Loss:0.41429755091667175, G_Loss:14.341458320617676

iterator 3200, D_Loss:0.4184933304786682, G_Loss:13.38501262664795

iterator 3300, D_Loss:0.42077410221099854, G_Loss:11.725049018859863

iterator 3400, D_Loss:0.41560497879981995, G_Loss:14.42630386352539

iterator 3500, D_Loss:0.42117932438850403, G_Loss:12.993325233459473

iterator 3600, D_Loss:0.4282075762748718, G_Loss:13.101018905639648

iterator 3700, D_Loss:0.4249337613582611, G_Loss:13.248700141906738

iterator 3800, D_Loss:0.4259132742881775, G_Loss:13.273104667663574

iterator 3900, D_Loss:0.40435463190078735, G_Loss:14.475141525268555

iterator 4000, D_Loss:0.44186970591545105, G_Loss:13.188057899475098

iterator 4100, D_Loss:0.4339342415332794, G_Loss:14.740955352783203

iterator 4200, D_Loss:0.42371469736099243, G_Loss:13.742332458496094

iterator 4300, D_Loss:0.4121575355529785, G_Loss:13.573731422424316

iterator 4400, D_Loss:0.42707568407058716, G_Loss:13.772408485412598

iterator 4500, D_Loss:0.427861750125885, G_Loss:13.744546890258789

iterator 4600, D_Loss:0.4281662404537201, G_Loss:12.687664985656738

iterator 4700, D_Loss:0.43334537744522095, G_Loss:13.485895156860352

iterator 4800, D_Loss:0.3942098319530487, G_Loss:14.190434455871582

iterator 4900, D_Loss:0.42409810423851013, G_Loss:13.13449478149414

iterator 5000, D_Loss:0.44688233733177185, G_Loss:13.2859525680542

-----------Epoch 9-----------
iterator 100, D_Loss:0.4086681604385376, G_Loss:13.016570091247559

iterator 200, D_Loss:0.42173442244529724, G_Loss:13.3720121383667

iterator 300, D_Loss:0.3993840217590332, G_Loss:13.215483665466309

iterator 400, D_Loss:0.4090505540370941, G_Loss:12.223433494567871

iterator 500, D_Loss:0.41423293948173523, G_Loss:13.737220764160156

iterator 600, D_Loss:0.43249809741973877, G_Loss:13.395427703857422

iterator 700, D_Loss:0.4178500473499298, G_Loss:11.802953720092773

iterator 800, D_Loss:0.4045345187187195, G_Loss:12.258045196533203

iterator 900, D_Loss:0.4479425847530365, G_Loss:12.043830871582031

iterator 1000, D_Loss:0.4164273738861084, G_Loss:11.766778945922852

iterator 1100, D_Loss:0.4233741760253906, G_Loss:11.89019775390625

iterator 1200, D_Loss:0.421293705701828, G_Loss:13.015819549560547

iterator 1300, D_Loss:0.4202057123184204, G_Loss:12.850293159484863

iterator 1400, D_Loss:0.42019563913345337, G_Loss:12.522789001464844

iterator 1500, D_Loss:0.435565710067749, G_Loss:13.061814308166504

iterator 1600, D_Loss:0.42829644680023193, G_Loss:13.266471862792969

iterator 1700, D_Loss:0.418129563331604, G_Loss:12.359841346740723

iterator 1800, D_Loss:0.4392140507698059, G_Loss:13.0097017288208

iterator 1900, D_Loss:0.41959062218666077, G_Loss:12.991935729980469

iterator 2000, D_Loss:0.4298698902130127, G_Loss:13.889782905578613

iterator 2100, D_Loss:0.41965585947036743, G_Loss:12.612517356872559

iterator 2200, D_Loss:0.4070253074169159, G_Loss:13.455881118774414

iterator 2300, D_Loss:0.42649754881858826, G_Loss:13.153908729553223

iterator 2400, D_Loss:0.42051753401756287, G_Loss:14.643885612487793

iterator 2500, D_Loss:0.4184914529323578, G_Loss:13.902002334594727

iterator 2600, D_Loss:0.41558197140693665, G_Loss:13.045917510986328

iterator 2700, D_Loss:0.44820213317871094, G_Loss:13.003935813903809

iterator 2800, D_Loss:0.4155727028846741, G_Loss:13.019617080688477

iterator 2900, D_Loss:0.4367307424545288, G_Loss:13.175065994262695

iterator 3000, D_Loss:0.44163110852241516, G_Loss:13.126006126403809

iterator 3100, D_Loss:0.4438975155353546, G_Loss:13.933637619018555

iterator 3200, D_Loss:0.41523832082748413, G_Loss:13.200664520263672

iterator 3300, D_Loss:0.4217921197414398, G_Loss:11.743260383605957

iterator 3400, D_Loss:0.39811083674430847, G_Loss:13.166080474853516

iterator 3500, D_Loss:0.41806313395500183, G_Loss:13.2216157913208

iterator 3600, D_Loss:0.4495188593864441, G_Loss:12.758544921875

iterator 3700, D_Loss:0.45076876878738403, G_Loss:12.687134742736816

iterator 3800, D_Loss:0.4359358251094818, G_Loss:12.771286964416504

iterator 3900, D_Loss:0.412427693605423, G_Loss:13.303017616271973

iterator 4000, D_Loss:0.4189673066139221, G_Loss:13.523101806640625

iterator 4100, D_Loss:0.4147365391254425, G_Loss:11.120870590209961

iterator 4200, D_Loss:0.4375109374523163, G_Loss:12.159585952758789

iterator 4300, D_Loss:0.4339941143989563, G_Loss:12.590997695922852

iterator 4400, D_Loss:0.4547383189201355, G_Loss:11.302238464355469

iterator 4500, D_Loss:0.43286222219467163, G_Loss:11.936559677124023

iterator 4600, D_Loss:0.40468829870224, G_Loss:12.70467758178711

iterator 4700, D_Loss:0.4124066233634949, G_Loss:11.841314315795898

iterator 4800, D_Loss:0.4222384989261627, G_Loss:12.380809783935547

iterator 4900, D_Loss:0.41390541195869446, G_Loss:12.99641227722168

iterator 5000, D_Loss:0.44967958331108093, G_Loss:13.137469291687012

train row : 30148
sample row: 30148
LGAN_generator(
  (LSTM): LSTMCell(202, 100)
  (gmfc00): Linear(in_features=100, out_features=1, bias=True)
  (gmfc01): Linear(in_features=100, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=100, bias=True)
  (gmfe00): Linear(in_features=100, out_features=100, bias=True)
  (gmfe01): Linear(in_features=100, out_features=100, bias=True)
  (fc10): Linear(in_features=100, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=100, bias=True)
  (fe1): Linear(in_features=100, out_features=100, bias=True)
  (gmfc20): Linear(in_features=100, out_features=1, bias=True)
  (gmfc21): Linear(in_features=100, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=100, bias=True)
  (gmfe20): Linear(in_features=100, out_features=100, bias=True)
  (gmfe21): Linear(in_features=100, out_features=100, bias=True)
  (fc30): Linear(in_features=100, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=100, bias=True)
  (fe3): Linear(in_features=100, out_features=100, bias=True)
  (gmfc40): Linear(in_features=100, out_features=1, bias=True)
  (gmfc41): Linear(in_features=100, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=100, bias=True)
  (gmfe40): Linear(in_features=100, out_features=100, bias=True)
  (gmfe41): Linear(in_features=100, out_features=100, bias=True)
  (fc50): Linear(in_features=100, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=100, bias=True)
  (fe5): Linear(in_features=100, out_features=100, bias=True)
  (fc60): Linear(in_features=100, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=100, bias=True)
  (fe6): Linear(in_features=100, out_features=100, bias=True)
  (fc70): Linear(in_features=100, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=100, bias=True)
  (fe7): Linear(in_features=100, out_features=100, bias=True)
  (fc80): Linear(in_features=100, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=100, bias=True)
  (fe8): Linear(in_features=100, out_features=100, bias=True)
  (fc90): Linear(in_features=100, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=100, bias=True)
  (fe9): Linear(in_features=100, out_features=100, bias=True)
  (gmfc100): Linear(in_features=100, out_features=1, bias=True)
  (gmfc101): Linear(in_features=100, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=100, bias=True)
  (gmfe100): Linear(in_features=100, out_features=100, bias=True)
  (gmfe101): Linear(in_features=100, out_features=100, bias=True)
  (gmfc110): Linear(in_features=100, out_features=1, bias=True)
  (gmfc111): Linear(in_features=100, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=100, bias=True)
  (gmfe110): Linear(in_features=100, out_features=100, bias=True)
  (gmfe111): Linear(in_features=100, out_features=100, bias=True)
  (gmfc120): Linear(in_features=100, out_features=1, bias=True)
  (gmfc121): Linear(in_features=100, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=100, bias=True)
  (gmfe120): Linear(in_features=100, out_features=100, bias=True)
  (gmfe121): Linear(in_features=100, out_features=100, bias=True)
  (fc130): Linear(in_features=100, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=100, bias=True)
  (fe13): Linear(in_features=100, out_features=100, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=400, bias=True)
  (inputbn): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=400, out_features=400, bias=True)
  (bn0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=400, bias=True)
  (bn1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=400, out_features=1, bias=True)
)
(2, True, 133)
(30148, 2)
-----------Epoch 0-----------
iterator 0, D_Loss:1.4998921155929565, G_Loss:9.134544372558594

iterator 100, D_Loss:1.409359335899353, G_Loss:1.485408067703247

iterator 200, D_Loss:1.3903086185455322, G_Loss:1.2419464588165283

iterator 300, D_Loss:1.3953330516815186, G_Loss:1.2791506052017212

iterator 400, D_Loss:1.2894377708435059, G_Loss:1.1701233386993408

iterator 500, D_Loss:1.2524757385253906, G_Loss:1.1684097051620483

iterator 600, D_Loss:1.2875193357467651, G_Loss:1.1723421812057495

iterator 700, D_Loss:1.2102805376052856, G_Loss:1.2291690111160278

iterator 800, D_Loss:1.0875556468963623, G_Loss:1.222678542137146

iterator 900, D_Loss:1.0925172567367554, G_Loss:1.2480220794677734

iterator 1000, D_Loss:1.2189937829971313, G_Loss:1.2208088636398315

iterator 1100, D_Loss:1.2713289260864258, G_Loss:1.1316237449645996

iterator 1200, D_Loss:1.44374418258667, G_Loss:1.3557677268981934

iterator 1300, D_Loss:1.1615872383117676, G_Loss:1.356635332107544

iterator 1400, D_Loss:1.1666377782821655, G_Loss:1.2830816507339478

iterator 1500, D_Loss:1.154680848121643, G_Loss:1.2643553018569946

iterator 1600, D_Loss:1.1838383674621582, G_Loss:1.4563301801681519

iterator 1700, D_Loss:1.0997730493545532, G_Loss:1.6749552488327026

iterator 1800, D_Loss:1.1121127605438232, G_Loss:0.9617875814437866

iterator 1900, D_Loss:0.9054813385009766, G_Loss:1.4607982635498047

iterator 2000, D_Loss:0.7816050052642822, G_Loss:1.752794623374939

iterator 2100, D_Loss:0.734879732131958, G_Loss:2.1874499320983887

iterator 2200, D_Loss:0.9362339377403259, G_Loss:1.686110258102417

iterator 2300, D_Loss:1.133629322052002, G_Loss:1.6088069677352905

iterator 2400, D_Loss:0.8965221643447876, G_Loss:2.0327510833740234

iterator 2500, D_Loss:1.039339303970337, G_Loss:1.734262466430664

iterator 2600, D_Loss:1.1042617559432983, G_Loss:1.3250597715377808

iterator 2700, D_Loss:1.2058300971984863, G_Loss:1.494665265083313

iterator 2800, D_Loss:1.1836539506912231, G_Loss:1.277671456336975

iterator 2900, D_Loss:1.1442292928695679, G_Loss:1.7966434955596924

iterator 3000, D_Loss:1.056563138961792, G_Loss:1.7884724140167236

iterator 3100, D_Loss:0.9029781818389893, G_Loss:1.4164496660232544

iterator 3200, D_Loss:0.8922984600067139, G_Loss:1.4038430452346802

iterator 3300, D_Loss:0.9759690165519714, G_Loss:1.7300721406936646

iterator 3400, D_Loss:0.891896665096283, G_Loss:1.3856594562530518

iterator 3500, D_Loss:1.318474531173706, G_Loss:1.7263497114181519

iterator 3600, D_Loss:0.8657513856887817, G_Loss:2.0288848876953125

iterator 3700, D_Loss:1.067182183265686, G_Loss:1.5050543546676636

iterator 3800, D_Loss:1.0091853141784668, G_Loss:2.2111852169036865

iterator 3900, D_Loss:1.0702909231185913, G_Loss:1.374267816543579

iterator 4000, D_Loss:0.8742831945419312, G_Loss:2.0208256244659424

iterator 4100, D_Loss:0.9279746413230896, G_Loss:1.8722641468048096

iterator 4200, D_Loss:0.7234719395637512, G_Loss:1.7932112216949463

iterator 4300, D_Loss:0.9537841081619263, G_Loss:2.121274471282959

iterator 4400, D_Loss:1.1729816198349, G_Loss:1.8888561725616455

iterator 4500, D_Loss:0.8783502578735352, G_Loss:2.582735776901245

iterator 4600, D_Loss:0.8795302510261536, G_Loss:2.067119598388672

iterator 4700, D_Loss:0.9461803436279297, G_Loss:1.8529841899871826

iterator 4800, D_Loss:0.7684147953987122, G_Loss:2.434920072555542

iterator 4900, D_Loss:0.8179079294204712, G_Loss:2.2986996173858643

-----------Epoch 1-----------
iterator 0, D_Loss:1.564327597618103, G_Loss:1.9683135747909546

iterator 100, D_Loss:0.8269081115722656, G_Loss:2.4998128414154053

iterator 200, D_Loss:0.944514811038971, G_Loss:2.821126937866211

iterator 300, D_Loss:0.7858748435974121, G_Loss:1.9268076419830322

iterator 400, D_Loss:0.7084549069404602, G_Loss:2.5437583923339844

iterator 500, D_Loss:0.9362743496894836, G_Loss:2.7890725135803223

iterator 600, D_Loss:1.1602919101715088, G_Loss:1.6305303573608398

iterator 700, D_Loss:0.6894816160202026, G_Loss:2.8561551570892334

iterator 800, D_Loss:0.8126168251037598, G_Loss:2.143404722213745

iterator 900, D_Loss:1.1822950839996338, G_Loss:2.50443434715271

iterator 1000, D_Loss:0.6854175329208374, G_Loss:1.9361568689346313

iterator 1100, D_Loss:0.8879806995391846, G_Loss:2.101524591445923

iterator 1200, D_Loss:0.862057626247406, G_Loss:2.14399790763855

iterator 1300, D_Loss:1.1307501792907715, G_Loss:2.3736813068389893

iterator 1400, D_Loss:0.7819879055023193, G_Loss:2.1407723426818848

iterator 1500, D_Loss:0.6494385004043579, G_Loss:2.55281138420105

iterator 1600, D_Loss:0.8947235345840454, G_Loss:2.067619800567627

iterator 1700, D_Loss:0.7503417134284973, G_Loss:2.2591781616210938

iterator 1800, D_Loss:0.8480797410011292, G_Loss:2.994161605834961

iterator 1900, D_Loss:0.6723048686981201, G_Loss:2.568598508834839

iterator 2000, D_Loss:1.1300429105758667, G_Loss:2.305722951889038

iterator 2100, D_Loss:0.7313611507415771, G_Loss:2.6997478008270264

iterator 2200, D_Loss:1.024711012840271, G_Loss:2.4805121421813965

iterator 2300, D_Loss:1.4242736101150513, G_Loss:2.7282137870788574

iterator 2400, D_Loss:0.8282831907272339, G_Loss:2.2614591121673584

iterator 2500, D_Loss:0.8741999864578247, G_Loss:2.0954787731170654

iterator 2600, D_Loss:0.90941321849823, G_Loss:2.065305709838867

iterator 2700, D_Loss:0.8564728498458862, G_Loss:2.175323486328125

iterator 2800, D_Loss:0.7650608420372009, G_Loss:2.1346018314361572

iterator 2900, D_Loss:0.7983663082122803, G_Loss:2.054739475250244

iterator 3000, D_Loss:0.8732949495315552, G_Loss:1.7682074308395386

iterator 3100, D_Loss:0.9990430474281311, G_Loss:2.1294009685516357

iterator 3200, D_Loss:0.9742456674575806, G_Loss:2.4573328495025635

iterator 3300, D_Loss:0.7892885804176331, G_Loss:2.7392008304595947

iterator 3400, D_Loss:1.0417604446411133, G_Loss:1.9174166917800903

iterator 3500, D_Loss:1.0047979354858398, G_Loss:1.9108390808105469

iterator 3600, D_Loss:0.7528640627861023, G_Loss:1.5998212099075317

iterator 3700, D_Loss:0.7314901947975159, G_Loss:2.00553560256958

iterator 3800, D_Loss:0.9035105109214783, G_Loss:2.454418420791626

iterator 3900, D_Loss:0.8847106695175171, G_Loss:2.2900428771972656

iterator 4000, D_Loss:0.7171404361724854, G_Loss:2.1776723861694336

iterator 4100, D_Loss:0.8553277254104614, G_Loss:3.185776472091675

iterator 4200, D_Loss:0.712070107460022, G_Loss:2.7103021144866943

iterator 4300, D_Loss:0.6954017877578735, G_Loss:2.526005744934082

iterator 4400, D_Loss:0.8610613346099854, G_Loss:3.168694019317627

iterator 4500, D_Loss:1.2003248929977417, G_Loss:1.9404851198196411

iterator 4600, D_Loss:0.761934220790863, G_Loss:2.421942949295044

iterator 4700, D_Loss:0.7343606948852539, G_Loss:2.2995986938476562

iterator 4800, D_Loss:0.9160935878753662, G_Loss:2.2354118824005127

iterator 4900, D_Loss:0.65739506483078, G_Loss:2.3151142597198486

-----------Epoch 2-----------
iterator 0, D_Loss:0.7430291175842285, G_Loss:2.3660552501678467

iterator 100, D_Loss:0.6709414124488831, G_Loss:2.9639883041381836

iterator 200, D_Loss:0.9058268070220947, G_Loss:1.6998682022094727

iterator 300, D_Loss:0.9247521162033081, G_Loss:1.285704493522644

iterator 400, D_Loss:1.0568081140518188, G_Loss:3.3454818725585938

iterator 500, D_Loss:1.1720584630966187, G_Loss:1.7724933624267578

iterator 600, D_Loss:0.9386593699455261, G_Loss:2.8189873695373535

iterator 700, D_Loss:0.9476816058158875, G_Loss:2.1262574195861816

iterator 800, D_Loss:0.7806098461151123, G_Loss:2.3159103393554688

iterator 900, D_Loss:0.9579522609710693, G_Loss:2.766779899597168

iterator 1000, D_Loss:0.6679986715316772, G_Loss:2.2861204147338867

iterator 1100, D_Loss:0.6555581092834473, G_Loss:2.8521783351898193

iterator 1200, D_Loss:0.7966803312301636, G_Loss:2.3709592819213867

iterator 1300, D_Loss:0.6704312562942505, G_Loss:2.1150588989257812

iterator 1400, D_Loss:0.9992128610610962, G_Loss:2.0543010234832764

iterator 1500, D_Loss:0.7390815019607544, G_Loss:2.1172988414764404

iterator 1600, D_Loss:0.7860351800918579, G_Loss:2.291311025619507

iterator 1700, D_Loss:0.8944332599639893, G_Loss:2.823666572570801

iterator 1800, D_Loss:0.9472671747207642, G_Loss:2.3743748664855957

iterator 1900, D_Loss:0.805633544921875, G_Loss:1.9514307975769043

iterator 2000, D_Loss:0.9162259101867676, G_Loss:2.0021700859069824

iterator 2100, D_Loss:0.8304886817932129, G_Loss:3.229243516921997

iterator 2200, D_Loss:0.9316402673721313, G_Loss:1.640764832496643

iterator 2300, D_Loss:0.6062819957733154, G_Loss:2.506503105163574

iterator 2400, D_Loss:0.9127486348152161, G_Loss:2.7934248447418213

iterator 2500, D_Loss:0.696873664855957, G_Loss:2.7126805782318115

iterator 2600, D_Loss:0.7126500606536865, G_Loss:2.311514139175415

iterator 2700, D_Loss:0.8567065000534058, G_Loss:2.679516553878784

iterator 2800, D_Loss:0.7853440046310425, G_Loss:1.8460376262664795

iterator 2900, D_Loss:0.9058294296264648, G_Loss:2.7744147777557373

iterator 3000, D_Loss:0.759665846824646, G_Loss:2.7402896881103516

iterator 3100, D_Loss:0.7605038285255432, G_Loss:2.4368367195129395

iterator 3200, D_Loss:0.754411518573761, G_Loss:2.214226484298706

iterator 3300, D_Loss:0.8695998191833496, G_Loss:2.532276153564453

iterator 3400, D_Loss:0.7932225465774536, G_Loss:2.2833099365234375

iterator 3500, D_Loss:0.739075779914856, G_Loss:2.9745032787323

iterator 3600, D_Loss:1.0936222076416016, G_Loss:2.254127025604248

iterator 3700, D_Loss:0.769904375076294, G_Loss:1.727709174156189

iterator 3800, D_Loss:0.6476982831954956, G_Loss:2.8211557865142822

iterator 3900, D_Loss:1.0478311777114868, G_Loss:2.7668161392211914

iterator 4000, D_Loss:0.6271114945411682, G_Loss:3.142592191696167

iterator 4100, D_Loss:1.0025826692581177, G_Loss:4.316617965698242

iterator 4200, D_Loss:0.6667898893356323, G_Loss:2.944105386734009

iterator 4300, D_Loss:0.6586082577705383, G_Loss:3.272350311279297

iterator 4400, D_Loss:0.7108492255210876, G_Loss:3.6745336055755615

iterator 4500, D_Loss:0.7929995656013489, G_Loss:2.332033395767212

iterator 4600, D_Loss:0.6684110760688782, G_Loss:3.0821142196655273

iterator 4700, D_Loss:1.1581612825393677, G_Loss:2.155315637588501

iterator 4800, D_Loss:0.7078554630279541, G_Loss:2.890496015548706

iterator 4900, D_Loss:0.7726316452026367, G_Loss:2.9039621353149414

-----------Epoch 3-----------
iterator 0, D_Loss:0.7646039724349976, G_Loss:2.483283519744873

iterator 100, D_Loss:1.0089439153671265, G_Loss:1.7761425971984863

iterator 200, D_Loss:0.6676641702651978, G_Loss:2.3414785861968994

iterator 300, D_Loss:0.8974753618240356, G_Loss:2.853231430053711

iterator 400, D_Loss:1.0031379461288452, G_Loss:2.2626640796661377

iterator 500, D_Loss:0.8486760854721069, G_Loss:1.7093207836151123

iterator 600, D_Loss:0.7617941498756409, G_Loss:2.7762644290924072

iterator 700, D_Loss:0.7221070528030396, G_Loss:2.5734381675720215

iterator 800, D_Loss:0.7168698310852051, G_Loss:2.37762713432312

iterator 900, D_Loss:0.7309613227844238, G_Loss:3.8084492683410645

iterator 1000, D_Loss:0.7084606289863586, G_Loss:2.7169933319091797

iterator 1100, D_Loss:0.7335076928138733, G_Loss:2.520082950592041

iterator 1200, D_Loss:0.9600694179534912, G_Loss:2.3000152111053467

iterator 1300, D_Loss:0.7729086875915527, G_Loss:2.970539093017578

iterator 1400, D_Loss:0.8318091630935669, G_Loss:1.6540966033935547

iterator 1500, D_Loss:0.6668697595596313, G_Loss:2.870166301727295

iterator 1600, D_Loss:0.6555855870246887, G_Loss:2.7938485145568848

iterator 1700, D_Loss:0.8011928796768188, G_Loss:2.0379652976989746

iterator 1800, D_Loss:0.6916713118553162, G_Loss:2.88948392868042

iterator 1900, D_Loss:0.6215667724609375, G_Loss:2.995208978652954

iterator 2000, D_Loss:0.7803364992141724, G_Loss:3.380450963973999

iterator 2100, D_Loss:0.6519426703453064, G_Loss:3.1308176517486572

iterator 2200, D_Loss:0.6310098767280579, G_Loss:2.9768848419189453

iterator 2300, D_Loss:0.5898144245147705, G_Loss:2.949373722076416

iterator 2400, D_Loss:0.5745934844017029, G_Loss:3.7513904571533203

iterator 2500, D_Loss:0.693644642829895, G_Loss:3.6864497661590576

iterator 2600, D_Loss:0.6026374101638794, G_Loss:3.0056023597717285

iterator 2700, D_Loss:0.575867772102356, G_Loss:3.5847866535186768

iterator 2800, D_Loss:0.5528626441955566, G_Loss:3.274798631668091

iterator 2900, D_Loss:0.5906232595443726, G_Loss:3.5013909339904785

iterator 3000, D_Loss:0.5543181300163269, G_Loss:3.1568174362182617

iterator 3100, D_Loss:0.620972752571106, G_Loss:3.1007370948791504

iterator 3200, D_Loss:0.6175631284713745, G_Loss:4.245770454406738

iterator 3300, D_Loss:0.5354803800582886, G_Loss:3.6782641410827637

iterator 3400, D_Loss:0.6092475056648254, G_Loss:3.6577694416046143

iterator 3500, D_Loss:0.5678118467330933, G_Loss:3.381051540374756

iterator 3600, D_Loss:0.5588176250457764, G_Loss:3.336050510406494

iterator 3700, D_Loss:0.5441696047782898, G_Loss:4.358449459075928

iterator 3800, D_Loss:0.8233985900878906, G_Loss:2.300628662109375

iterator 3900, D_Loss:0.5514344573020935, G_Loss:4.094347953796387

iterator 4000, D_Loss:0.6898595690727234, G_Loss:3.9427733421325684

iterator 4100, D_Loss:0.7344000339508057, G_Loss:4.156798362731934

iterator 4200, D_Loss:0.5864781141281128, G_Loss:3.352750301361084

iterator 4300, D_Loss:0.7265368103981018, G_Loss:2.8461496829986572

iterator 4400, D_Loss:0.5698484182357788, G_Loss:3.9122018814086914

iterator 4500, D_Loss:0.561674952507019, G_Loss:4.043156147003174

iterator 4600, D_Loss:0.6062120795249939, G_Loss:3.6550588607788086

iterator 4700, D_Loss:0.6867398619651794, G_Loss:3.256333112716675

iterator 4800, D_Loss:0.6547720432281494, G_Loss:4.243302345275879

iterator 4900, D_Loss:0.619764506816864, G_Loss:3.4490582942962646

-----------Epoch 4-----------
iterator 0, D_Loss:0.8501706123352051, G_Loss:2.999809741973877

iterator 100, D_Loss:0.6798413991928101, G_Loss:3.162168025970459

iterator 200, D_Loss:0.7852568030357361, G_Loss:2.953252077102661

iterator 300, D_Loss:0.6315991878509521, G_Loss:3.645765542984009

iterator 400, D_Loss:0.7870815396308899, G_Loss:3.4394195079803467

iterator 500, D_Loss:0.801977813243866, G_Loss:3.2153282165527344

iterator 600, D_Loss:0.732117235660553, G_Loss:2.221080780029297

iterator 700, D_Loss:0.6159665584564209, G_Loss:3.6766884326934814

iterator 800, D_Loss:0.6536822319030762, G_Loss:2.3573873043060303

iterator 900, D_Loss:0.8080626726150513, G_Loss:3.001495122909546

iterator 1000, D_Loss:0.7265347242355347, G_Loss:2.5418009757995605

iterator 1100, D_Loss:0.5792645215988159, G_Loss:2.941333770751953

iterator 1200, D_Loss:0.629240870475769, G_Loss:3.0360238552093506

iterator 1300, D_Loss:1.0470905303955078, G_Loss:3.473306655883789

iterator 1400, D_Loss:0.7135064005851746, G_Loss:2.2227280139923096

iterator 1500, D_Loss:0.6613017320632935, G_Loss:2.3182806968688965

iterator 1600, D_Loss:0.5389438271522522, G_Loss:3.98048734664917

iterator 1700, D_Loss:0.6583980917930603, G_Loss:2.8767781257629395

iterator 1800, D_Loss:0.6207458972930908, G_Loss:2.959616184234619

iterator 1900, D_Loss:0.7931020259857178, G_Loss:2.137002468109131

iterator 2000, D_Loss:0.5977411866188049, G_Loss:4.051316261291504

iterator 2100, D_Loss:0.8387791514396667, G_Loss:2.502274513244629

iterator 2200, D_Loss:0.7256226539611816, G_Loss:2.88615083694458

iterator 2300, D_Loss:0.6445229649543762, G_Loss:3.3191123008728027

iterator 2400, D_Loss:0.6732004880905151, G_Loss:3.755593776702881

iterator 2500, D_Loss:0.7427704930305481, G_Loss:3.270615816116333

iterator 2600, D_Loss:0.6107947826385498, G_Loss:4.048083305358887

iterator 2700, D_Loss:0.7707127332687378, G_Loss:3.4438421726226807

iterator 2800, D_Loss:0.6787824034690857, G_Loss:3.463306427001953

iterator 2900, D_Loss:0.580909252166748, G_Loss:2.815471649169922

iterator 3000, D_Loss:0.800489068031311, G_Loss:2.287142753601074

iterator 3100, D_Loss:0.6542444229125977, G_Loss:3.7176103591918945

iterator 3200, D_Loss:0.9063478708267212, G_Loss:2.692925214767456

iterator 3300, D_Loss:0.7881182432174683, G_Loss:1.9628493785858154

iterator 3400, D_Loss:0.7020857334136963, G_Loss:2.17627215385437

iterator 3500, D_Loss:0.6630906462669373, G_Loss:3.4324581623077393

iterator 3600, D_Loss:0.5457462668418884, G_Loss:3.2789666652679443

iterator 3700, D_Loss:0.6912624835968018, G_Loss:2.569650411605835

iterator 3800, D_Loss:0.6740677952766418, G_Loss:3.2664403915405273

iterator 3900, D_Loss:0.6322706937789917, G_Loss:3.1794486045837402

iterator 4000, D_Loss:0.5280197858810425, G_Loss:2.884467363357544

iterator 4100, D_Loss:0.5981887578964233, G_Loss:3.7173728942871094

iterator 4200, D_Loss:0.6775984764099121, G_Loss:3.7633981704711914

iterator 4300, D_Loss:0.5751192569732666, G_Loss:3.4556314945220947

iterator 4400, D_Loss:0.854276180267334, G_Loss:3.7685728073120117

iterator 4500, D_Loss:0.8547970056533813, G_Loss:3.2950730323791504

iterator 4600, D_Loss:0.6106515526771545, G_Loss:2.5746166706085205

iterator 4700, D_Loss:0.5572993755340576, G_Loss:2.8902223110198975

iterator 4800, D_Loss:0.6540441513061523, G_Loss:2.680635929107666

iterator 4900, D_Loss:0.6769548654556274, G_Loss:3.5719246864318848

-----------Epoch 5-----------
iterator 0, D_Loss:0.6682506203651428, G_Loss:3.358039379119873

iterator 100, D_Loss:0.6104766726493835, G_Loss:3.634082794189453

iterator 200, D_Loss:0.8005685806274414, G_Loss:3.4141836166381836

iterator 300, D_Loss:0.7227483987808228, G_Loss:3.796712636947632

iterator 400, D_Loss:0.6783078908920288, G_Loss:3.677611827850342

iterator 500, D_Loss:0.6466032862663269, G_Loss:2.896482467651367

iterator 600, D_Loss:0.7244371175765991, G_Loss:3.7908527851104736

iterator 700, D_Loss:1.0128222703933716, G_Loss:2.836991310119629

iterator 800, D_Loss:0.6617531180381775, G_Loss:3.952697277069092

iterator 900, D_Loss:0.5661554932594299, G_Loss:4.291251182556152

iterator 1000, D_Loss:0.5502647757530212, G_Loss:3.8228750228881836

iterator 1100, D_Loss:0.7016922235488892, G_Loss:3.307776927947998

iterator 1200, D_Loss:0.599906861782074, G_Loss:3.2481915950775146

iterator 1300, D_Loss:0.5617852807044983, G_Loss:3.5024240016937256

iterator 1400, D_Loss:0.5519344210624695, G_Loss:3.0155253410339355

iterator 1500, D_Loss:0.5279926061630249, G_Loss:4.15691614151001

iterator 1600, D_Loss:0.5979761481285095, G_Loss:4.596035003662109

iterator 1700, D_Loss:0.5147419571876526, G_Loss:4.128139495849609

iterator 1800, D_Loss:0.6724572777748108, G_Loss:4.316493988037109

iterator 1900, D_Loss:0.5947644710540771, G_Loss:4.257076740264893

iterator 2000, D_Loss:0.5612010955810547, G_Loss:3.7749218940734863

iterator 2100, D_Loss:0.8426425457000732, G_Loss:3.939258098602295

iterator 2200, D_Loss:0.6142445206642151, G_Loss:3.579493284225464

iterator 2300, D_Loss:0.7221719026565552, G_Loss:4.15498161315918

iterator 2400, D_Loss:0.5806275606155396, G_Loss:4.114706993103027

iterator 2500, D_Loss:0.6185225248336792, G_Loss:3.4665627479553223

iterator 2600, D_Loss:1.1300854682922363, G_Loss:2.3757638931274414

iterator 2700, D_Loss:0.5882425904273987, G_Loss:3.922027826309204

iterator 2800, D_Loss:2.151334524154663, G_Loss:3.8236145973205566

iterator 2900, D_Loss:0.6523032188415527, G_Loss:4.109706878662109

iterator 3000, D_Loss:0.6166183352470398, G_Loss:4.23602819442749

iterator 3100, D_Loss:0.5755107998847961, G_Loss:3.7275266647338867

iterator 3200, D_Loss:0.584878146648407, G_Loss:2.6325719356536865

iterator 3300, D_Loss:0.7175400257110596, G_Loss:3.3475089073181152

iterator 3400, D_Loss:0.6267449855804443, G_Loss:3.7956557273864746

iterator 3500, D_Loss:0.7374523878097534, G_Loss:2.851963996887207

iterator 3600, D_Loss:0.6896842122077942, G_Loss:3.5049338340759277

iterator 3700, D_Loss:0.6884539127349854, G_Loss:3.2221484184265137

iterator 3800, D_Loss:0.5845280289649963, G_Loss:3.5458335876464844

iterator 3900, D_Loss:0.6085793375968933, G_Loss:2.5477101802825928

iterator 4000, D_Loss:0.6861796975135803, G_Loss:3.0907931327819824

iterator 4100, D_Loss:0.9835508465766907, G_Loss:4.568488597869873

iterator 4200, D_Loss:0.7480028867721558, G_Loss:4.175630569458008

iterator 4300, D_Loss:0.7784937620162964, G_Loss:3.3233814239501953

iterator 4400, D_Loss:0.6974876523017883, G_Loss:3.3296902179718018

iterator 4500, D_Loss:0.6406050324440002, G_Loss:3.6443777084350586

iterator 4600, D_Loss:0.6265222430229187, G_Loss:5.109049320220947

iterator 4700, D_Loss:0.5727761387825012, G_Loss:3.234508752822876

iterator 4800, D_Loss:0.5721433758735657, G_Loss:3.440096378326416

iterator 4900, D_Loss:0.5824024677276611, G_Loss:3.732069969177246

-----------Epoch 6-----------
iterator 0, D_Loss:0.6300441026687622, G_Loss:3.955533027648926

iterator 100, D_Loss:0.5341063737869263, G_Loss:4.818728446960449

iterator 200, D_Loss:0.7171609997749329, G_Loss:3.5467071533203125

iterator 300, D_Loss:0.6183651685714722, G_Loss:2.8616068363189697

iterator 400, D_Loss:0.6359859108924866, G_Loss:3.6713690757751465

iterator 500, D_Loss:0.7144229412078857, G_Loss:5.625515937805176

iterator 600, D_Loss:0.5592260360717773, G_Loss:3.295645236968994

iterator 700, D_Loss:0.7952114939689636, G_Loss:3.7772538661956787

iterator 800, D_Loss:0.5529585480690002, G_Loss:3.777519702911377

iterator 900, D_Loss:0.6340685486793518, G_Loss:3.424816846847534

iterator 1000, D_Loss:0.7773341536521912, G_Loss:3.3161144256591797

iterator 1100, D_Loss:0.7623963356018066, G_Loss:2.726929187774658

iterator 1200, D_Loss:0.7349485754966736, G_Loss:3.642427682876587

iterator 1300, D_Loss:0.6750558614730835, G_Loss:4.131901741027832

iterator 1400, D_Loss:0.6270767450332642, G_Loss:3.3011865615844727

iterator 1500, D_Loss:0.7397782206535339, G_Loss:2.580716848373413

iterator 1600, D_Loss:0.5795423984527588, G_Loss:2.7362043857574463

iterator 1700, D_Loss:0.5785984396934509, G_Loss:3.5534162521362305

iterator 1800, D_Loss:0.5483795404434204, G_Loss:2.425440788269043

iterator 1900, D_Loss:0.6177226305007935, G_Loss:3.041654586791992

iterator 2000, D_Loss:0.7058985829353333, G_Loss:4.676276206970215

iterator 2100, D_Loss:0.633509635925293, G_Loss:3.766347885131836

iterator 2200, D_Loss:0.6470604538917542, G_Loss:3.617888927459717

iterator 2300, D_Loss:0.6417374610900879, G_Loss:2.5586800575256348

iterator 2400, D_Loss:0.6468042731285095, G_Loss:3.6767306327819824

iterator 2500, D_Loss:0.651598334312439, G_Loss:5.256894588470459

iterator 2600, D_Loss:0.63112872838974, G_Loss:3.169468402862549

iterator 2700, D_Loss:0.7463803291320801, G_Loss:4.5706305503845215

iterator 2800, D_Loss:0.5838684439659119, G_Loss:2.5122807025909424

iterator 2900, D_Loss:0.7114607691764832, G_Loss:3.824584484100342

iterator 3000, D_Loss:0.8482331037521362, G_Loss:3.420642614364624

iterator 3100, D_Loss:0.5972083210945129, G_Loss:3.138942241668701

iterator 3200, D_Loss:0.6257770657539368, G_Loss:2.9910383224487305

iterator 3300, D_Loss:0.6354498267173767, G_Loss:3.5180020332336426

iterator 3400, D_Loss:0.6663883328437805, G_Loss:2.3445193767547607

iterator 3500, D_Loss:0.8691081404685974, G_Loss:3.7224481105804443

iterator 3600, D_Loss:0.6404486894607544, G_Loss:4.327514171600342

iterator 3700, D_Loss:0.853180468082428, G_Loss:3.839765787124634

iterator 3800, D_Loss:0.6244244575500488, G_Loss:3.6827800273895264

iterator 3900, D_Loss:0.6658716201782227, G_Loss:3.9235470294952393

iterator 4000, D_Loss:0.5363869667053223, G_Loss:2.9269754886627197

iterator 4100, D_Loss:0.6784329414367676, G_Loss:3.7636704444885254

iterator 4200, D_Loss:0.7390221953392029, G_Loss:2.88958477973938

iterator 4300, D_Loss:0.5950600504875183, G_Loss:3.248537540435791

iterator 4400, D_Loss:0.7360810041427612, G_Loss:2.2100791931152344

iterator 4500, D_Loss:0.5619277954101562, G_Loss:3.4749319553375244

iterator 4600, D_Loss:0.6106898784637451, G_Loss:4.067751407623291

iterator 4700, D_Loss:0.5850969552993774, G_Loss:3.717665672302246

iterator 4800, D_Loss:0.6290647983551025, G_Loss:3.229285717010498

iterator 4900, D_Loss:0.5624046921730042, G_Loss:4.400367259979248

-----------Epoch 7-----------
iterator 0, D_Loss:0.5352388024330139, G_Loss:3.641418933868408

iterator 100, D_Loss:0.629545271396637, G_Loss:3.5470330715179443

iterator 200, D_Loss:1.0201709270477295, G_Loss:3.674893856048584

iterator 300, D_Loss:0.6154433488845825, G_Loss:3.3013675212860107

iterator 400, D_Loss:0.520261287689209, G_Loss:5.321888446807861

iterator 500, D_Loss:0.5508384704589844, G_Loss:3.449434757232666

iterator 600, D_Loss:0.5959323644638062, G_Loss:2.269986391067505

iterator 700, D_Loss:0.8762792348861694, G_Loss:2.8103814125061035

iterator 800, D_Loss:0.6044352650642395, G_Loss:4.069388389587402

iterator 900, D_Loss:0.689909040927887, G_Loss:3.0201616287231445

iterator 1000, D_Loss:0.5988993048667908, G_Loss:3.1406502723693848

iterator 1100, D_Loss:0.5938498973846436, G_Loss:4.174259662628174

iterator 1200, D_Loss:0.6648536920547485, G_Loss:3.698296308517456

iterator 1300, D_Loss:0.6164549589157104, G_Loss:3.389493465423584

iterator 1400, D_Loss:0.6111359000205994, G_Loss:3.6323018074035645

iterator 1500, D_Loss:0.5580416917800903, G_Loss:2.8633816242218018

iterator 1600, D_Loss:0.5631106495857239, G_Loss:3.945833683013916

iterator 1700, D_Loss:0.6863195300102234, G_Loss:4.085363864898682

iterator 1800, D_Loss:0.8055617809295654, G_Loss:4.354567050933838

iterator 1900, D_Loss:0.8452693223953247, G_Loss:3.277869701385498

iterator 2000, D_Loss:0.5959682464599609, G_Loss:2.7757368087768555

iterator 2100, D_Loss:0.7000032067298889, G_Loss:3.267132043838501

iterator 2200, D_Loss:0.7598791718482971, G_Loss:3.8323278427124023

iterator 2300, D_Loss:0.5693966746330261, G_Loss:3.089717388153076

iterator 2400, D_Loss:0.6751391291618347, G_Loss:4.378634452819824

iterator 2500, D_Loss:0.5180101990699768, G_Loss:4.8710432052612305

iterator 2600, D_Loss:0.5803791284561157, G_Loss:3.193394899368286

iterator 2700, D_Loss:0.5591440796852112, G_Loss:3.4378387928009033

iterator 2800, D_Loss:1.008169174194336, G_Loss:4.036632061004639

iterator 2900, D_Loss:0.5415517091751099, G_Loss:4.095762729644775

iterator 3000, D_Loss:0.6444851756095886, G_Loss:3.2795052528381348

iterator 3100, D_Loss:0.642422616481781, G_Loss:3.9867351055145264

iterator 3200, D_Loss:0.7106467485427856, G_Loss:3.205368757247925

iterator 3300, D_Loss:0.9108095169067383, G_Loss:1.8462977409362793

iterator 3400, D_Loss:0.6768598556518555, G_Loss:3.9526352882385254

iterator 3500, D_Loss:0.6948102712631226, G_Loss:3.6578195095062256

iterator 3600, D_Loss:0.5483418107032776, G_Loss:2.9366490840911865

iterator 3700, D_Loss:0.7207349538803101, G_Loss:3.9317898750305176

iterator 3800, D_Loss:0.623844563961029, G_Loss:2.714364528656006

iterator 3900, D_Loss:0.747094452381134, G_Loss:3.814885139465332

iterator 4000, D_Loss:0.7248638868331909, G_Loss:3.3237667083740234

iterator 4100, D_Loss:0.6564937233924866, G_Loss:3.0111868381500244

iterator 4200, D_Loss:0.6576172113418579, G_Loss:3.7171828746795654

iterator 4300, D_Loss:0.506184995174408, G_Loss:6.356008052825928

iterator 4400, D_Loss:0.6646953821182251, G_Loss:4.7601799964904785

iterator 4500, D_Loss:0.6228441596031189, G_Loss:3.260460138320923

iterator 4600, D_Loss:0.799052357673645, G_Loss:2.477530002593994

iterator 4700, D_Loss:0.567611813545227, G_Loss:4.02288818359375

iterator 4800, D_Loss:0.6276956796646118, G_Loss:2.701822519302368

iterator 4900, D_Loss:0.7136070728302002, G_Loss:2.9088528156280518

-----------Epoch 8-----------
iterator 0, D_Loss:0.5688397884368896, G_Loss:4.694700717926025

iterator 100, D_Loss:0.5708706378936768, G_Loss:5.01517915725708

iterator 200, D_Loss:0.6261035203933716, G_Loss:3.7888436317443848

iterator 300, D_Loss:0.5975683927536011, G_Loss:4.104036331176758

iterator 400, D_Loss:0.5990960597991943, G_Loss:3.7136828899383545

iterator 500, D_Loss:0.5883364677429199, G_Loss:5.217971324920654

iterator 600, D_Loss:0.6124662160873413, G_Loss:3.3621621131896973

iterator 700, D_Loss:0.5568456649780273, G_Loss:3.444051742553711

iterator 800, D_Loss:0.5971817374229431, G_Loss:2.8936421871185303

iterator 900, D_Loss:0.5596505403518677, G_Loss:3.273543119430542

iterator 1000, D_Loss:0.4902106523513794, G_Loss:3.4915173053741455

iterator 1100, D_Loss:0.5599374771118164, G_Loss:4.153960704803467

iterator 1200, D_Loss:0.5530473589897156, G_Loss:4.764016151428223

iterator 1300, D_Loss:0.5403846502304077, G_Loss:4.574802875518799

iterator 1400, D_Loss:0.5361839532852173, G_Loss:4.5748138427734375

iterator 1500, D_Loss:0.5716233849525452, G_Loss:7.062155246734619

iterator 1600, D_Loss:0.7597521543502808, G_Loss:3.889226198196411

iterator 1700, D_Loss:0.5938287973403931, G_Loss:3.7354228496551514

iterator 1800, D_Loss:0.5500227808952332, G_Loss:5.734918594360352

iterator 1900, D_Loss:0.6618402004241943, G_Loss:3.3873634338378906

iterator 2000, D_Loss:0.6294216513633728, G_Loss:4.7605061531066895

iterator 2100, D_Loss:0.5906345844268799, G_Loss:3.5187270641326904

iterator 2200, D_Loss:0.6798236966133118, G_Loss:4.859020709991455

iterator 2300, D_Loss:0.6407129168510437, G_Loss:3.6530253887176514

iterator 2400, D_Loss:0.5497334003448486, G_Loss:3.7363696098327637

iterator 2500, D_Loss:0.6522761583328247, G_Loss:3.2466866970062256

iterator 2600, D_Loss:0.6071345210075378, G_Loss:3.5024936199188232

iterator 2700, D_Loss:0.7554969787597656, G_Loss:3.1668331623077393

iterator 2800, D_Loss:0.6059786081314087, G_Loss:3.430328130722046

iterator 2900, D_Loss:0.6342187523841858, G_Loss:3.42495059967041

iterator 3000, D_Loss:0.5794013142585754, G_Loss:2.796696186065674

iterator 3100, D_Loss:0.5784600377082825, G_Loss:3.97548508644104

iterator 3200, D_Loss:0.7265529632568359, G_Loss:3.594527244567871

iterator 3300, D_Loss:0.6272485256195068, G_Loss:4.082154273986816

iterator 3400, D_Loss:0.6497044563293457, G_Loss:2.584840774536133

iterator 3500, D_Loss:0.6071759462356567, G_Loss:3.818006992340088

iterator 3600, D_Loss:0.6200799942016602, G_Loss:3.0307810306549072

iterator 3700, D_Loss:0.7324392795562744, G_Loss:4.475677490234375

iterator 3800, D_Loss:0.5877084136009216, G_Loss:4.794116973876953

iterator 3900, D_Loss:0.6302051544189453, G_Loss:3.0414605140686035

iterator 4000, D_Loss:0.5307751297950745, G_Loss:4.353145122528076

iterator 4100, D_Loss:0.6565934419631958, G_Loss:3.32486891746521

iterator 4200, D_Loss:0.6306296586990356, G_Loss:4.02172327041626

iterator 4300, D_Loss:0.7381188869476318, G_Loss:4.706955432891846

iterator 4400, D_Loss:0.693063497543335, G_Loss:3.5440309047698975

iterator 4500, D_Loss:0.4929514527320862, G_Loss:3.634664535522461

iterator 4600, D_Loss:0.6286709904670715, G_Loss:5.431110858917236

iterator 4700, D_Loss:0.5476966500282288, G_Loss:2.2666993141174316

iterator 4800, D_Loss:0.7776029706001282, G_Loss:3.2455151081085205

iterator 4900, D_Loss:0.6632266640663147, G_Loss:5.247504234313965

-----------Epoch 9-----------
iterator 0, D_Loss:0.5558635592460632, G_Loss:4.08849573135376

iterator 100, D_Loss:0.621791422367096, G_Loss:4.178638458251953

iterator 200, D_Loss:0.6384754180908203, G_Loss:4.136667728424072

iterator 300, D_Loss:0.5935143828392029, G_Loss:5.0115275382995605

iterator 400, D_Loss:0.6669979691505432, G_Loss:3.193101644515991

iterator 500, D_Loss:0.5442096590995789, G_Loss:4.502832889556885

iterator 600, D_Loss:0.608241081237793, G_Loss:4.47782039642334

iterator 700, D_Loss:0.5159762501716614, G_Loss:3.551492929458618

iterator 800, D_Loss:0.6508503556251526, G_Loss:2.8984899520874023

iterator 900, D_Loss:0.6383354663848877, G_Loss:5.180991172790527

iterator 1000, D_Loss:0.5126152038574219, G_Loss:3.789013147354126

iterator 1100, D_Loss:0.5992062091827393, G_Loss:3.4507944583892822

iterator 1200, D_Loss:0.6523115634918213, G_Loss:2.9894158840179443

iterator 1300, D_Loss:0.5275317430496216, G_Loss:3.644090414047241

iterator 1400, D_Loss:0.5947813987731934, G_Loss:3.7098548412323

iterator 1500, D_Loss:0.9756358861923218, G_Loss:2.848564624786377

iterator 1600, D_Loss:0.7210940718650818, G_Loss:4.809439182281494

iterator 1700, D_Loss:0.50111985206604, G_Loss:4.146656036376953

iterator 1800, D_Loss:0.6715932488441467, G_Loss:3.878763437271118

iterator 1900, D_Loss:0.6345191597938538, G_Loss:4.228804111480713

iterator 2000, D_Loss:0.5570001006126404, G_Loss:3.013542652130127

iterator 2100, D_Loss:0.5596400499343872, G_Loss:4.979933738708496

iterator 2200, D_Loss:0.6687473654747009, G_Loss:2.7451205253601074

iterator 2300, D_Loss:0.5711236000061035, G_Loss:4.65493631362915

iterator 2400, D_Loss:0.544209897518158, G_Loss:4.758200645446777

iterator 2500, D_Loss:0.6512033939361572, G_Loss:5.4071221351623535

iterator 2600, D_Loss:0.5921787619590759, G_Loss:4.220507621765137

iterator 2700, D_Loss:0.6535770893096924, G_Loss:3.5321526527404785

iterator 2800, D_Loss:0.6479169130325317, G_Loss:3.1875557899475098

iterator 2900, D_Loss:0.6783827543258667, G_Loss:4.52471923828125

iterator 3000, D_Loss:0.6401115655899048, G_Loss:4.128245830535889

iterator 3100, D_Loss:0.5724263787269592, G_Loss:4.497429847717285

iterator 3200, D_Loss:0.6620994806289673, G_Loss:4.780112266540527

iterator 3300, D_Loss:0.6006863117218018, G_Loss:3.9060144424438477

iterator 3400, D_Loss:0.5581610202789307, G_Loss:4.857623100280762

iterator 3500, D_Loss:0.6169006824493408, G_Loss:3.810056686401367

iterator 3600, D_Loss:0.5127626657485962, G_Loss:4.362053871154785

iterator 3700, D_Loss:0.5292496681213379, G_Loss:6.108591079711914

iterator 3800, D_Loss:0.5747420787811279, G_Loss:3.992654800415039

iterator 3900, D_Loss:0.5987547039985657, G_Loss:4.549803256988525

iterator 4000, D_Loss:0.6258620023727417, G_Loss:5.043641567230225

iterator 4100, D_Loss:0.6571350693702698, G_Loss:4.182446479797363

iterator 4200, D_Loss:0.6444938778877258, G_Loss:5.293597221374512

iterator 4300, D_Loss:0.6432054042816162, G_Loss:4.512269973754883

iterator 4400, D_Loss:0.6892613768577576, G_Loss:5.598484039306641

iterator 4500, D_Loss:0.6714773178100586, G_Loss:6.1570539474487305

iterator 4600, D_Loss:0.7423223257064819, G_Loss:3.7973480224609375

iterator 4700, D_Loss:0.588128387928009, G_Loss:4.983647346496582

iterator 4800, D_Loss:0.581452488899231, G_Loss:4.051970958709717

iterator 4900, D_Loss:0.6082417368888855, G_Loss:3.6977415084838867

LGAN_generator(
  (LSTM): LSTMCell(802, 100)
  (gmfc00): Linear(in_features=600, out_features=1, bias=True)
  (gmfc01): Linear(in_features=600, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=600, bias=True)
  (gmfe00): Linear(in_features=100, out_features=600, bias=True)
  (gmfe01): Linear(in_features=100, out_features=600, bias=True)
  (fc10): Linear(in_features=600, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=600, bias=True)
  (fe1): Linear(in_features=100, out_features=600, bias=True)
  (gmfc20): Linear(in_features=600, out_features=1, bias=True)
  (gmfc21): Linear(in_features=600, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=600, bias=True)
  (gmfe20): Linear(in_features=100, out_features=600, bias=True)
  (gmfe21): Linear(in_features=100, out_features=600, bias=True)
  (fc30): Linear(in_features=600, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=600, bias=True)
  (fe3): Linear(in_features=100, out_features=600, bias=True)
  (gmfc40): Linear(in_features=600, out_features=1, bias=True)
  (gmfc41): Linear(in_features=600, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=600, bias=True)
  (gmfe40): Linear(in_features=100, out_features=600, bias=True)
  (gmfe41): Linear(in_features=100, out_features=600, bias=True)
  (fc50): Linear(in_features=600, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=600, bias=True)
  (fe5): Linear(in_features=100, out_features=600, bias=True)
  (fc60): Linear(in_features=600, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=600, bias=True)
  (fe6): Linear(in_features=100, out_features=600, bias=True)
  (fc70): Linear(in_features=600, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=600, bias=True)
  (fe7): Linear(in_features=100, out_features=600, bias=True)
  (fc80): Linear(in_features=600, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=600, bias=True)
  (fe8): Linear(in_features=100, out_features=600, bias=True)
  (fc90): Linear(in_features=600, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=600, bias=True)
  (fe9): Linear(in_features=100, out_features=600, bias=True)
  (gmfc100): Linear(in_features=600, out_features=1, bias=True)
  (gmfc101): Linear(in_features=600, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=600, bias=True)
  (gmfe100): Linear(in_features=100, out_features=600, bias=True)
  (gmfe101): Linear(in_features=100, out_features=600, bias=True)
  (gmfc110): Linear(in_features=600, out_features=1, bias=True)
  (gmfc111): Linear(in_features=600, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=600, bias=True)
  (gmfe110): Linear(in_features=100, out_features=600, bias=True)
  (gmfe111): Linear(in_features=100, out_features=600, bias=True)
  (gmfc120): Linear(in_features=600, out_features=1, bias=True)
  (gmfc121): Linear(in_features=600, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=600, bias=True)
  (gmfe120): Linear(in_features=100, out_features=600, bias=True)
  (gmfe121): Linear(in_features=100, out_features=600, bias=True)
  (fc130): Linear(in_features=600, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=600, bias=True)
  (fe13): Linear(in_features=100, out_features=600, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=300, bias=True)
  (inputbn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=300, out_features=300, bias=True)
  (bn0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=300, out_features=300, bias=True)
  (bn1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=300, out_features=300, bias=True)
  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=300, out_features=300, bias=True)
  (bn3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=300, out_features=1, bias=True)
)
(2, True, 133)
(30148, 2)
-----------Epoch 0-----------
iterator 0, D_Loss:1.4657888412475586, G_Loss:7.12030029296875

iterator 100, D_Loss:1.392624855041504, G_Loss:1.951562762260437

iterator 200, D_Loss:1.3843724727630615, G_Loss:1.277904987335205

iterator 300, D_Loss:1.3578293323516846, G_Loss:1.417487621307373

iterator 400, D_Loss:1.3769490718841553, G_Loss:1.2176544666290283

iterator 500, D_Loss:1.37530517578125, G_Loss:1.511939287185669

iterator 600, D_Loss:1.3888349533081055, G_Loss:1.127305507659912

iterator 700, D_Loss:1.3869723081588745, G_Loss:1.0713077783584595

iterator 800, D_Loss:1.3725825548171997, G_Loss:1.0280275344848633

iterator 900, D_Loss:1.3721791505813599, G_Loss:0.9799321293830872

iterator 1000, D_Loss:1.3782191276550293, G_Loss:0.987372636795044

iterator 1100, D_Loss:1.3788470029830933, G_Loss:0.9592309594154358

iterator 1200, D_Loss:1.3659255504608154, G_Loss:0.9240982532501221

iterator 1300, D_Loss:1.3656915426254272, G_Loss:0.9660015106201172

iterator 1400, D_Loss:1.3667962551116943, G_Loss:0.9636735320091248

iterator 1500, D_Loss:1.351200819015503, G_Loss:0.956829309463501

iterator 1600, D_Loss:1.2670409679412842, G_Loss:1.0396381616592407

iterator 1700, D_Loss:1.3509812355041504, G_Loss:0.9626889228820801

iterator 1800, D_Loss:1.3985354900360107, G_Loss:0.9626254439353943

iterator 1900, D_Loss:1.3589835166931152, G_Loss:0.9728245735168457

iterator 2000, D_Loss:1.3051552772521973, G_Loss:1.0157787799835205

iterator 2100, D_Loss:1.2111027240753174, G_Loss:1.1980215311050415

iterator 2200, D_Loss:1.2286624908447266, G_Loss:1.1452940702438354

iterator 2300, D_Loss:1.2515950202941895, G_Loss:1.1500225067138672

iterator 2400, D_Loss:1.260311245918274, G_Loss:1.034749150276184

iterator 2500, D_Loss:1.136782169342041, G_Loss:1.196098804473877

iterator 2600, D_Loss:1.2927063703536987, G_Loss:1.0401158332824707

iterator 2700, D_Loss:1.2986794710159302, G_Loss:0.8005927801132202

iterator 2800, D_Loss:1.2803664207458496, G_Loss:1.1206413507461548

iterator 2900, D_Loss:1.1408177614212036, G_Loss:1.3940939903259277

iterator 3000, D_Loss:0.9928367733955383, G_Loss:1.4684245586395264

iterator 3100, D_Loss:1.0378872156143188, G_Loss:1.3061872720718384

iterator 3200, D_Loss:0.9001696705818176, G_Loss:1.656292200088501

iterator 3300, D_Loss:0.8741981387138367, G_Loss:1.9945220947265625

iterator 3400, D_Loss:0.7824349403381348, G_Loss:1.8635361194610596

iterator 3500, D_Loss:0.8609619140625, G_Loss:1.8885188102722168

iterator 3600, D_Loss:0.7014633417129517, G_Loss:2.031491279602051

iterator 3700, D_Loss:0.6578007340431213, G_Loss:2.417261838912964

iterator 3800, D_Loss:0.6386584639549255, G_Loss:2.5293922424316406

iterator 3900, D_Loss:0.664061963558197, G_Loss:2.493013381958008

iterator 4000, D_Loss:0.6137237548828125, G_Loss:1.5195374488830566

iterator 4100, D_Loss:0.6067952513694763, G_Loss:2.771073341369629

iterator 4200, D_Loss:0.5426672101020813, G_Loss:3.1294732093811035

iterator 4300, D_Loss:0.6052505970001221, G_Loss:3.2764739990234375

iterator 4400, D_Loss:0.5748006701469421, G_Loss:2.8689236640930176

iterator 4500, D_Loss:0.5589873194694519, G_Loss:3.28912353515625

iterator 4600, D_Loss:0.6537257432937622, G_Loss:2.7001967430114746

iterator 4700, D_Loss:0.5250949263572693, G_Loss:3.4649572372436523

iterator 4800, D_Loss:0.5154513716697693, G_Loss:2.59281849861145

iterator 4900, D_Loss:0.6266751885414124, G_Loss:3.137594699859619

-----------Epoch 1-----------
iterator 0, D_Loss:0.6270133256912231, G_Loss:2.946995735168457

iterator 100, D_Loss:0.5662429928779602, G_Loss:3.842039108276367

iterator 200, D_Loss:0.5789241790771484, G_Loss:3.605010986328125

iterator 300, D_Loss:0.49656081199645996, G_Loss:3.7062830924987793

iterator 400, D_Loss:0.5395446419715881, G_Loss:3.9841806888580322

iterator 500, D_Loss:0.5018351674079895, G_Loss:3.499976634979248

iterator 600, D_Loss:0.49107232689857483, G_Loss:4.21047306060791

iterator 700, D_Loss:0.5552513599395752, G_Loss:4.1772942543029785

iterator 800, D_Loss:0.5016677379608154, G_Loss:4.5781779289245605

iterator 900, D_Loss:0.4868606626987457, G_Loss:4.529023170471191

iterator 1000, D_Loss:0.4961296617984772, G_Loss:4.112688064575195

iterator 1100, D_Loss:3.299696922302246, G_Loss:4.2986555099487305

iterator 1200, D_Loss:0.4990738332271576, G_Loss:2.5333428382873535

iterator 1300, D_Loss:0.46429216861724854, G_Loss:4.049506664276123

iterator 1400, D_Loss:0.4720021188259125, G_Loss:3.9496383666992188

iterator 1500, D_Loss:0.4551030993461609, G_Loss:4.009446144104004

iterator 1600, D_Loss:0.4960005581378937, G_Loss:4.468612194061279

iterator 1700, D_Loss:0.47970888018608093, G_Loss:3.8956923484802246

iterator 1800, D_Loss:0.4758537709712982, G_Loss:5.026632785797119

iterator 1900, D_Loss:0.5338574647903442, G_Loss:4.943888187408447

iterator 2000, D_Loss:0.4608026444911957, G_Loss:4.267723083496094

iterator 2100, D_Loss:0.4919266104698181, G_Loss:5.083550453186035

iterator 2200, D_Loss:0.4469172954559326, G_Loss:4.410289764404297

iterator 2300, D_Loss:0.43649202585220337, G_Loss:4.174466609954834

iterator 2400, D_Loss:0.5266387462615967, G_Loss:4.756142616271973

iterator 2500, D_Loss:0.4456523358821869, G_Loss:4.974764347076416

iterator 2600, D_Loss:0.4620991051197052, G_Loss:4.466317653656006

iterator 2700, D_Loss:0.47497376799583435, G_Loss:5.3794121742248535

iterator 2800, D_Loss:0.4781167805194855, G_Loss:4.792633533477783

iterator 2900, D_Loss:0.46358194947242737, G_Loss:5.221365451812744

iterator 3000, D_Loss:0.49698448181152344, G_Loss:5.515043258666992

iterator 3100, D_Loss:0.4853571057319641, G_Loss:3.6078174114227295

iterator 3200, D_Loss:0.4818243086338043, G_Loss:4.3398542404174805

iterator 3300, D_Loss:0.4418559968471527, G_Loss:5.88559627532959

iterator 3400, D_Loss:0.4654460549354553, G_Loss:3.526831865310669

iterator 3500, D_Loss:0.45653441548347473, G_Loss:5.083337783813477

iterator 3600, D_Loss:0.4707055985927582, G_Loss:5.2846999168396

iterator 3700, D_Loss:0.4456462860107422, G_Loss:5.166579246520996

iterator 3800, D_Loss:0.473056435585022, G_Loss:6.472467422485352

iterator 3900, D_Loss:0.601557731628418, G_Loss:4.273026943206787

iterator 4000, D_Loss:0.521145224571228, G_Loss:3.548985481262207

iterator 4100, D_Loss:0.4509050250053406, G_Loss:5.016117095947266

iterator 4200, D_Loss:0.48418673872947693, G_Loss:2.9306693077087402

iterator 4300, D_Loss:0.4589618742465973, G_Loss:4.753561019897461

iterator 4400, D_Loss:2.2191479206085205, G_Loss:5.2404069900512695

iterator 4500, D_Loss:0.469211220741272, G_Loss:3.9360556602478027

iterator 4600, D_Loss:1.840718388557434, G_Loss:4.089204788208008

iterator 4700, D_Loss:0.7192291617393494, G_Loss:3.185265302658081

iterator 4800, D_Loss:0.4305032789707184, G_Loss:5.945788860321045

iterator 4900, D_Loss:0.46700653433799744, G_Loss:5.854120254516602

-----------Epoch 2-----------
iterator 0, D_Loss:0.6020920872688293, G_Loss:3.331906318664551

iterator 100, D_Loss:0.46082788705825806, G_Loss:4.777838230133057

iterator 200, D_Loss:0.4981329143047333, G_Loss:5.536219120025635

iterator 300, D_Loss:0.4892479181289673, G_Loss:3.3099753856658936

iterator 400, D_Loss:0.4657582640647888, G_Loss:3.8103504180908203

iterator 500, D_Loss:0.601533055305481, G_Loss:4.921372890472412

iterator 600, D_Loss:0.4742739498615265, G_Loss:5.507978439331055

iterator 700, D_Loss:0.5107767581939697, G_Loss:5.014749526977539

iterator 800, D_Loss:0.4892643094062805, G_Loss:4.589541912078857

iterator 900, D_Loss:0.46522587537765503, G_Loss:4.446685791015625

iterator 1000, D_Loss:0.7898119688034058, G_Loss:2.2108936309814453

iterator 1100, D_Loss:0.7075531482696533, G_Loss:3.3717987537384033

iterator 1200, D_Loss:1.0685182809829712, G_Loss:1.6185414791107178

iterator 1300, D_Loss:0.9374282360076904, G_Loss:2.823589563369751

iterator 1400, D_Loss:0.652522087097168, G_Loss:2.9283313751220703

iterator 1500, D_Loss:0.8433946371078491, G_Loss:2.871769428253174

iterator 1600, D_Loss:0.6254624724388123, G_Loss:2.3971786499023438

iterator 1700, D_Loss:0.5319797992706299, G_Loss:3.6255950927734375

iterator 1800, D_Loss:0.4940548837184906, G_Loss:4.026552677154541

iterator 1900, D_Loss:0.5724450349807739, G_Loss:3.6780338287353516

iterator 2000, D_Loss:0.4899219870567322, G_Loss:4.480717182159424

iterator 2100, D_Loss:0.47414630651474, G_Loss:3.5205166339874268

iterator 2200, D_Loss:0.524530827999115, G_Loss:4.13741397857666

iterator 2300, D_Loss:0.46481725573539734, G_Loss:4.035813808441162

iterator 2400, D_Loss:0.5061005353927612, G_Loss:4.582345962524414

iterator 2500, D_Loss:0.5017027258872986, G_Loss:4.400943279266357

iterator 2600, D_Loss:0.46145379543304443, G_Loss:4.738499164581299

iterator 2700, D_Loss:0.45441028475761414, G_Loss:5.33819055557251

iterator 2800, D_Loss:0.4606119394302368, G_Loss:4.925719261169434

iterator 2900, D_Loss:0.46803247928619385, G_Loss:4.789885997772217

iterator 3000, D_Loss:0.44843921065330505, G_Loss:3.9784023761749268

iterator 3100, D_Loss:0.44705861806869507, G_Loss:4.073736667633057

iterator 3200, D_Loss:0.47193780541419983, G_Loss:3.735830068588257

iterator 3300, D_Loss:0.49415189027786255, G_Loss:3.8197672367095947

iterator 3400, D_Loss:0.5064069032669067, G_Loss:4.91189432144165

iterator 3500, D_Loss:0.5166800618171692, G_Loss:4.494467735290527

iterator 3600, D_Loss:0.4571366012096405, G_Loss:4.655435562133789

iterator 3700, D_Loss:0.4507473111152649, G_Loss:5.753377437591553

iterator 3800, D_Loss:0.4458475708961487, G_Loss:4.499069690704346

iterator 3900, D_Loss:0.46414491534233093, G_Loss:5.127549171447754

iterator 4000, D_Loss:0.4789291322231293, G_Loss:4.626906394958496

iterator 4100, D_Loss:0.4536999464035034, G_Loss:4.763454914093018

iterator 4200, D_Loss:0.4652615785598755, G_Loss:4.566882133483887

iterator 4300, D_Loss:0.4627939760684967, G_Loss:4.670577526092529

iterator 4400, D_Loss:0.4991287291049957, G_Loss:6.3809967041015625

iterator 4500, D_Loss:0.49284490942955017, G_Loss:4.8761115074157715

iterator 4600, D_Loss:0.46618762612342834, G_Loss:4.7897162437438965

iterator 4700, D_Loss:0.47903841733932495, G_Loss:5.052493572235107

iterator 4800, D_Loss:0.4745194613933563, G_Loss:4.888182163238525

iterator 4900, D_Loss:0.46089357137680054, G_Loss:5.984096527099609

-----------Epoch 3-----------
iterator 0, D_Loss:0.456215500831604, G_Loss:5.796724796295166

iterator 100, D_Loss:0.45983755588531494, G_Loss:5.643868923187256

iterator 200, D_Loss:0.45899927616119385, G_Loss:3.959282398223877

iterator 300, D_Loss:0.4678753912448883, G_Loss:5.526682376861572

iterator 400, D_Loss:1.2404437065124512, G_Loss:3.1882686614990234

iterator 500, D_Loss:0.7349194288253784, G_Loss:4.824388027191162

iterator 600, D_Loss:0.602645218372345, G_Loss:4.393802642822266

iterator 700, D_Loss:0.6247106790542603, G_Loss:3.938225269317627

iterator 800, D_Loss:0.7705131769180298, G_Loss:1.2474918365478516

iterator 900, D_Loss:0.6636635065078735, G_Loss:4.576364040374756

iterator 1000, D_Loss:0.8640137314796448, G_Loss:1.1237595081329346

iterator 1100, D_Loss:0.6723226308822632, G_Loss:3.6127207279205322

iterator 1200, D_Loss:0.5953394770622253, G_Loss:3.3472700119018555

iterator 1300, D_Loss:0.68553626537323, G_Loss:1.8171266317367554

iterator 1400, D_Loss:1.756220817565918, G_Loss:3.04934024810791

iterator 1500, D_Loss:0.7151113152503967, G_Loss:2.88633131980896

iterator 1600, D_Loss:1.0402201414108276, G_Loss:2.6454408168792725

iterator 1700, D_Loss:0.6408169269561768, G_Loss:2.510714054107666

iterator 1800, D_Loss:0.6700719594955444, G_Loss:3.072967290878296

iterator 1900, D_Loss:0.5980693101882935, G_Loss:2.54002046585083

iterator 2000, D_Loss:0.6246387958526611, G_Loss:1.6760565042495728

iterator 2100, D_Loss:0.6527407765388489, G_Loss:4.134942054748535

iterator 2200, D_Loss:0.5221391916275024, G_Loss:4.906473636627197

iterator 2300, D_Loss:0.5931902527809143, G_Loss:2.6522533893585205

iterator 2400, D_Loss:0.8019438982009888, G_Loss:3.3748421669006348

iterator 2500, D_Loss:0.6385400295257568, G_Loss:1.868540644645691

iterator 2600, D_Loss:0.7988909482955933, G_Loss:3.9255788326263428

iterator 2700, D_Loss:0.7655755281448364, G_Loss:1.862027645111084

iterator 2800, D_Loss:0.7182942032814026, G_Loss:1.452927827835083

iterator 2900, D_Loss:1.071265697479248, G_Loss:1.24362313747406

iterator 3000, D_Loss:0.5828523635864258, G_Loss:3.5839006900787354

iterator 3100, D_Loss:0.6836921572685242, G_Loss:4.1562933921813965

iterator 3200, D_Loss:0.9125159978866577, G_Loss:1.1683621406555176

iterator 3300, D_Loss:0.5768164396286011, G_Loss:3.1157219409942627

iterator 3400, D_Loss:1.05843186378479, G_Loss:2.682008981704712

iterator 3500, D_Loss:0.517419159412384, G_Loss:4.984283447265625

iterator 3600, D_Loss:0.8363063335418701, G_Loss:2.2113196849823

iterator 3700, D_Loss:0.4798029959201813, G_Loss:2.9453046321868896

iterator 3800, D_Loss:0.5436331033706665, G_Loss:3.886625289916992

iterator 3900, D_Loss:0.5221522450447083, G_Loss:4.923865795135498

iterator 4000, D_Loss:0.6961209774017334, G_Loss:3.2252583503723145

iterator 4100, D_Loss:0.5078340172767639, G_Loss:3.7489304542541504

iterator 4200, D_Loss:0.5334507822990417, G_Loss:3.322345018386841

iterator 4300, D_Loss:0.5117411017417908, G_Loss:4.256878852844238

iterator 4400, D_Loss:0.71104896068573, G_Loss:4.440896511077881

iterator 4500, D_Loss:0.544455885887146, G_Loss:2.6835951805114746

iterator 4600, D_Loss:0.6780300140380859, G_Loss:3.4669501781463623

iterator 4700, D_Loss:0.5709706544876099, G_Loss:4.208522319793701

iterator 4800, D_Loss:0.9246377348899841, G_Loss:4.319480895996094

iterator 4900, D_Loss:0.4915477931499481, G_Loss:5.553478240966797

-----------Epoch 4-----------
iterator 0, D_Loss:0.8860629200935364, G_Loss:2.6555418968200684

iterator 100, D_Loss:2.6465866565704346, G_Loss:2.7083919048309326

iterator 200, D_Loss:0.8626440763473511, G_Loss:2.9673972129821777

iterator 300, D_Loss:0.8359100222587585, G_Loss:3.4853012561798096

iterator 400, D_Loss:0.4650135040283203, G_Loss:3.5939085483551025

iterator 500, D_Loss:0.724261999130249, G_Loss:4.2795538902282715

iterator 600, D_Loss:0.5015287399291992, G_Loss:4.10656213760376

iterator 700, D_Loss:0.6186287999153137, G_Loss:1.6906507015228271

iterator 800, D_Loss:0.5338606834411621, G_Loss:2.741023540496826

iterator 900, D_Loss:0.5254834294319153, G_Loss:4.044432163238525

iterator 1000, D_Loss:0.7122164964675903, G_Loss:2.1328465938568115

iterator 1100, D_Loss:0.4879409670829773, G_Loss:3.5908091068267822

iterator 1200, D_Loss:0.562482476234436, G_Loss:3.2340638637542725

iterator 1300, D_Loss:0.5291110277175903, G_Loss:3.1123204231262207

iterator 1400, D_Loss:0.4909222722053528, G_Loss:3.162703514099121

iterator 1500, D_Loss:1.0363693237304688, G_Loss:5.13131046295166

iterator 1600, D_Loss:0.726061224937439, G_Loss:2.248081684112549

iterator 1700, D_Loss:2.026531457901001, G_Loss:4.753997325897217

iterator 1800, D_Loss:0.5039641857147217, G_Loss:2.9110143184661865

iterator 1900, D_Loss:0.6401383876800537, G_Loss:1.8430213928222656

iterator 2000, D_Loss:0.7966095209121704, G_Loss:4.748226642608643

iterator 2100, D_Loss:0.48723357915878296, G_Loss:4.580048561096191

iterator 2200, D_Loss:0.5276880264282227, G_Loss:3.764399766921997

iterator 2300, D_Loss:0.6768080592155457, G_Loss:1.9898133277893066

iterator 2400, D_Loss:0.5960099101066589, G_Loss:4.15372896194458

iterator 2500, D_Loss:0.4933968186378479, G_Loss:1.7706698179244995

iterator 2600, D_Loss:0.5548567771911621, G_Loss:1.7660269737243652

iterator 2700, D_Loss:0.4705767333507538, G_Loss:3.686012029647827

iterator 2800, D_Loss:0.7903697490692139, G_Loss:2.941581964492798

iterator 2900, D_Loss:1.1794342994689941, G_Loss:1.484255313873291

iterator 3000, D_Loss:0.6066057682037354, G_Loss:3.281841993331909

iterator 3100, D_Loss:0.9751189351081848, G_Loss:3.6369216442108154

iterator 3200, D_Loss:0.523517906665802, G_Loss:4.422982215881348

iterator 3300, D_Loss:0.6524242758750916, G_Loss:2.176170825958252

iterator 3400, D_Loss:0.6821032166481018, G_Loss:1.8018944263458252

iterator 3500, D_Loss:0.7160378694534302, G_Loss:2.7772583961486816

iterator 3600, D_Loss:0.6996755003929138, G_Loss:4.37572717666626

iterator 3700, D_Loss:0.7740222811698914, G_Loss:3.3795948028564453

iterator 3800, D_Loss:0.6993721127510071, G_Loss:2.8913803100585938

iterator 3900, D_Loss:0.554802656173706, G_Loss:5.637456893920898

iterator 4000, D_Loss:0.8135923147201538, G_Loss:4.486239433288574

iterator 4100, D_Loss:0.5696917176246643, G_Loss:2.414090633392334

iterator 4200, D_Loss:0.7825680375099182, G_Loss:2.7063984870910645

iterator 4300, D_Loss:0.5879578590393066, G_Loss:2.3582634925842285

iterator 4400, D_Loss:0.8624926805496216, G_Loss:5.1249098777771

iterator 4500, D_Loss:0.4796486496925354, G_Loss:7.231185436248779

iterator 4600, D_Loss:0.5138238668441772, G_Loss:5.272317886352539

iterator 4700, D_Loss:0.5644141435623169, G_Loss:2.497438907623291

iterator 4800, D_Loss:0.5536980628967285, G_Loss:3.8545589447021484

iterator 4900, D_Loss:0.6827329993247986, G_Loss:5.909269332885742

-----------Epoch 5-----------
iterator 0, D_Loss:0.6027038097381592, G_Loss:3.7017102241516113

iterator 100, D_Loss:0.5042443871498108, G_Loss:5.5603814125061035

iterator 200, D_Loss:0.7560681104660034, G_Loss:2.177978038787842

iterator 300, D_Loss:0.728701651096344, G_Loss:2.017172336578369

iterator 400, D_Loss:0.45746859908103943, G_Loss:5.862398147583008

iterator 500, D_Loss:0.495484322309494, G_Loss:7.726926803588867

iterator 600, D_Loss:0.5109392404556274, G_Loss:5.715354919433594

iterator 700, D_Loss:0.44908833503723145, G_Loss:5.523827075958252

iterator 800, D_Loss:0.6238723993301392, G_Loss:4.30288553237915

iterator 900, D_Loss:0.5495105981826782, G_Loss:4.957531929016113

iterator 1000, D_Loss:0.5944775342941284, G_Loss:6.822124004364014

iterator 1100, D_Loss:1.021498441696167, G_Loss:1.3568503856658936

iterator 1200, D_Loss:0.46163371205329895, G_Loss:4.322495460510254

iterator 1300, D_Loss:0.5186949968338013, G_Loss:3.2695393562316895

iterator 1400, D_Loss:0.7391014099121094, G_Loss:3.894796371459961

iterator 1500, D_Loss:0.5109243988990784, G_Loss:4.7397356033325195

iterator 1600, D_Loss:0.4440709352493286, G_Loss:4.025437355041504

iterator 1700, D_Loss:0.4477464258670807, G_Loss:6.788741588592529

iterator 1800, D_Loss:0.5215916633605957, G_Loss:4.949534893035889

iterator 1900, D_Loss:0.8569339513778687, G_Loss:3.619823694229126

iterator 2000, D_Loss:0.4557951092720032, G_Loss:4.907289505004883

iterator 2100, D_Loss:0.7118526697158813, G_Loss:5.09759521484375

iterator 2200, D_Loss:0.47948625683784485, G_Loss:6.833236217498779

iterator 2300, D_Loss:0.47513729333877563, G_Loss:6.794302940368652

iterator 2400, D_Loss:0.47858554124832153, G_Loss:3.508371114730835

iterator 2500, D_Loss:0.5459232330322266, G_Loss:5.129339218139648

iterator 2600, D_Loss:0.47268879413604736, G_Loss:1.8311803340911865

iterator 2700, D_Loss:0.5821411609649658, G_Loss:4.443795204162598

iterator 2800, D_Loss:0.5338575839996338, G_Loss:3.8890204429626465

iterator 2900, D_Loss:0.7288618087768555, G_Loss:3.505171537399292

iterator 3000, D_Loss:0.5701342225074768, G_Loss:2.9283242225646973

iterator 3100, D_Loss:0.45794677734375, G_Loss:5.082837104797363

iterator 3200, D_Loss:0.695188581943512, G_Loss:4.07501745223999

iterator 3300, D_Loss:0.5118063688278198, G_Loss:5.534773826599121

iterator 3400, D_Loss:0.4941869080066681, G_Loss:5.2676520347595215

iterator 3500, D_Loss:0.4401145577430725, G_Loss:5.742501735687256

iterator 3600, D_Loss:0.457820326089859, G_Loss:7.731294631958008

iterator 3700, D_Loss:0.4614217281341553, G_Loss:3.7606401443481445

iterator 3800, D_Loss:0.45333462953567505, G_Loss:5.119194507598877

iterator 3900, D_Loss:0.49995067715644836, G_Loss:3.6028313636779785

iterator 4000, D_Loss:0.4936921298503876, G_Loss:3.813424587249756

iterator 4100, D_Loss:0.6087884306907654, G_Loss:3.2384023666381836

iterator 4200, D_Loss:0.5062340497970581, G_Loss:6.8485212326049805

iterator 4300, D_Loss:0.443454772233963, G_Loss:5.903095245361328

iterator 4400, D_Loss:2.361295461654663, G_Loss:2.0641329288482666

iterator 4500, D_Loss:0.4487648904323578, G_Loss:5.911643981933594

iterator 4600, D_Loss:0.4739730954170227, G_Loss:5.184533596038818

iterator 4700, D_Loss:0.48665115237236023, G_Loss:3.742237091064453

iterator 4800, D_Loss:0.43986332416534424, G_Loss:5.37830114364624

iterator 4900, D_Loss:0.4546681046485901, G_Loss:5.468587875366211

-----------Epoch 6-----------
iterator 0, D_Loss:0.4671480655670166, G_Loss:5.308368682861328

iterator 100, D_Loss:0.5151607990264893, G_Loss:7.9219279289245605

iterator 200, D_Loss:0.5598123073577881, G_Loss:5.452793121337891

iterator 300, D_Loss:0.7420921921730042, G_Loss:3.2790119647979736

iterator 400, D_Loss:0.4052596986293793, G_Loss:3.554990768432617

iterator 500, D_Loss:0.44658172130584717, G_Loss:8.282289505004883

iterator 600, D_Loss:0.509727418422699, G_Loss:7.389105796813965

iterator 700, D_Loss:0.4574154019355774, G_Loss:4.362349987030029

iterator 800, D_Loss:0.43056443333625793, G_Loss:4.180293560028076

iterator 900, D_Loss:0.556584358215332, G_Loss:1.8081223964691162

iterator 1000, D_Loss:0.432024747133255, G_Loss:4.5626301765441895

iterator 1100, D_Loss:0.4479914605617523, G_Loss:7.404607772827148

iterator 1200, D_Loss:0.4711945056915283, G_Loss:3.405447483062744

iterator 1300, D_Loss:0.6467279195785522, G_Loss:4.567490577697754

iterator 1400, D_Loss:0.4600670039653778, G_Loss:6.152202606201172

iterator 1500, D_Loss:0.7073662281036377, G_Loss:8.800066947937012

iterator 1600, D_Loss:0.8435088992118835, G_Loss:6.160830497741699

iterator 1700, D_Loss:0.5031483173370361, G_Loss:6.664886474609375

iterator 1800, D_Loss:0.4376318156719208, G_Loss:4.867065906524658

iterator 1900, D_Loss:0.5685023665428162, G_Loss:3.267103433609009

iterator 2000, D_Loss:1.01687753200531, G_Loss:4.1909966468811035

iterator 2100, D_Loss:0.4238941967487335, G_Loss:6.349338054656982

iterator 2200, D_Loss:0.4817538559436798, G_Loss:7.522790908813477

iterator 2300, D_Loss:0.5254828929901123, G_Loss:4.432741641998291

iterator 2400, D_Loss:0.4859914481639862, G_Loss:4.753340244293213

iterator 2500, D_Loss:0.5788030028343201, G_Loss:4.85031795501709

iterator 2600, D_Loss:0.4467584490776062, G_Loss:9.671772003173828

iterator 2700, D_Loss:0.4121713638305664, G_Loss:6.050956726074219

iterator 2800, D_Loss:0.9731289744377136, G_Loss:3.649353504180908

iterator 2900, D_Loss:0.5486526489257812, G_Loss:4.421117305755615

iterator 3000, D_Loss:0.4700351357460022, G_Loss:2.2148568630218506

iterator 3100, D_Loss:0.5088645219802856, G_Loss:6.892643928527832

iterator 3200, D_Loss:0.4271719455718994, G_Loss:5.494583606719971

iterator 3300, D_Loss:0.5484937429428101, G_Loss:6.30470085144043

iterator 3400, D_Loss:0.44574809074401855, G_Loss:4.146006107330322

iterator 3500, D_Loss:1.0515484809875488, G_Loss:4.942431926727295

iterator 3600, D_Loss:0.46767139434814453, G_Loss:5.896967887878418

iterator 3700, D_Loss:0.4779626131057739, G_Loss:6.085763454437256

iterator 3800, D_Loss:0.9081180691719055, G_Loss:6.689819812774658

iterator 3900, D_Loss:0.4950622022151947, G_Loss:6.058742046356201

iterator 4000, D_Loss:0.4787796437740326, G_Loss:5.134225368499756

iterator 4100, D_Loss:0.4296775758266449, G_Loss:5.691267013549805

iterator 4200, D_Loss:0.4362666606903076, G_Loss:6.731191635131836

iterator 4300, D_Loss:0.43926724791526794, G_Loss:5.903860569000244

iterator 4400, D_Loss:0.7328946590423584, G_Loss:3.089599609375

iterator 4500, D_Loss:0.48981520533561707, G_Loss:4.365841388702393

iterator 4600, D_Loss:0.4459018409252167, G_Loss:5.5113091468811035

iterator 4700, D_Loss:0.473466157913208, G_Loss:7.440881252288818

iterator 4800, D_Loss:0.41772717237472534, G_Loss:7.433532238006592

iterator 4900, D_Loss:0.6506040096282959, G_Loss:6.81687068939209

-----------Epoch 7-----------
iterator 0, D_Loss:0.4870327413082123, G_Loss:4.137582302093506

iterator 100, D_Loss:0.44342315196990967, G_Loss:4.677089691162109

iterator 200, D_Loss:0.6964265704154968, G_Loss:5.199735164642334

iterator 300, D_Loss:0.4741505980491638, G_Loss:3.6083576679229736

iterator 400, D_Loss:0.42143797874450684, G_Loss:4.723936080932617

iterator 500, D_Loss:0.43678367137908936, G_Loss:6.931635856628418

iterator 600, D_Loss:0.4309394657611847, G_Loss:4.753415107727051

iterator 700, D_Loss:0.45349252223968506, G_Loss:3.4032366275787354

iterator 800, D_Loss:0.4309079051017761, G_Loss:7.967931747436523

iterator 900, D_Loss:0.45018795132637024, G_Loss:8.955381393432617

iterator 1000, D_Loss:0.45318982005119324, G_Loss:7.474234104156494

iterator 1100, D_Loss:0.44779011607170105, G_Loss:5.723814010620117

iterator 1200, D_Loss:0.4557083547115326, G_Loss:7.3890275955200195

iterator 1300, D_Loss:0.4198269546031952, G_Loss:8.89418888092041

iterator 1400, D_Loss:0.44546830654144287, G_Loss:6.8295722007751465

iterator 1500, D_Loss:0.46709293127059937, G_Loss:7.3097710609436035

iterator 1600, D_Loss:0.4608471989631653, G_Loss:5.068515777587891

iterator 1700, D_Loss:0.5344616174697876, G_Loss:4.756092548370361

iterator 1800, D_Loss:0.4524630904197693, G_Loss:2.09108567237854

iterator 1900, D_Loss:0.4470267593860626, G_Loss:7.265007495880127

iterator 2000, D_Loss:0.4427335262298584, G_Loss:6.186528205871582

iterator 2100, D_Loss:0.42041754722595215, G_Loss:7.46706485748291

iterator 2200, D_Loss:0.4273165166378021, G_Loss:9.455211639404297

iterator 2300, D_Loss:0.6743258833885193, G_Loss:7.1486124992370605

iterator 2400, D_Loss:1.015039086341858, G_Loss:4.106086730957031

iterator 2500, D_Loss:0.4362811744213104, G_Loss:9.246827125549316

iterator 2600, D_Loss:0.43028131127357483, G_Loss:8.157340049743652

iterator 2700, D_Loss:0.6625832915306091, G_Loss:6.303642272949219

iterator 2800, D_Loss:0.5097994208335876, G_Loss:2.3566136360168457

iterator 2900, D_Loss:0.5034622550010681, G_Loss:3.601700782775879

iterator 3000, D_Loss:0.4468875527381897, G_Loss:10.749960899353027

iterator 3100, D_Loss:0.48339754343032837, G_Loss:6.896270275115967

iterator 3200, D_Loss:0.4450054168701172, G_Loss:8.290440559387207

iterator 3300, D_Loss:0.4641357958316803, G_Loss:8.107342720031738

iterator 3400, D_Loss:0.8557502627372742, G_Loss:6.683887481689453

iterator 3500, D_Loss:0.6458940505981445, G_Loss:7.0575737953186035

iterator 3600, D_Loss:0.4533083140850067, G_Loss:5.786825656890869

iterator 3700, D_Loss:0.48151877522468567, G_Loss:7.773857116699219

iterator 3800, D_Loss:0.4813072085380554, G_Loss:2.467535972595215

iterator 3900, D_Loss:0.42532867193222046, G_Loss:6.808608055114746

iterator 4000, D_Loss:0.4351001977920532, G_Loss:4.988669395446777

iterator 4100, D_Loss:0.4400380849838257, G_Loss:7.081754207611084

iterator 4200, D_Loss:0.46330663561820984, G_Loss:6.408834457397461

iterator 4300, D_Loss:0.47285526990890503, G_Loss:8.096439361572266

iterator 4400, D_Loss:0.41632747650146484, G_Loss:8.481807708740234

iterator 4500, D_Loss:0.40845105051994324, G_Loss:6.088900089263916

iterator 4600, D_Loss:0.4480980336666107, G_Loss:9.214601516723633

iterator 4700, D_Loss:0.4375411868095398, G_Loss:3.874396800994873

iterator 4800, D_Loss:0.43973684310913086, G_Loss:7.488316059112549

iterator 4900, D_Loss:0.43544164299964905, G_Loss:7.90401029586792

-----------Epoch 8-----------
iterator 0, D_Loss:0.42751726508140564, G_Loss:9.04429817199707

iterator 100, D_Loss:0.43077611923217773, G_Loss:7.109058380126953

iterator 200, D_Loss:0.4541298747062683, G_Loss:7.966304779052734

iterator 300, D_Loss:0.4102053940296173, G_Loss:4.527921676635742

iterator 400, D_Loss:0.469244122505188, G_Loss:7.0764665603637695

iterator 500, D_Loss:0.44695478677749634, G_Loss:4.744358539581299

iterator 600, D_Loss:0.43398189544677734, G_Loss:9.909465789794922

iterator 700, D_Loss:0.42230215668678284, G_Loss:7.784069061279297

iterator 800, D_Loss:0.5659990906715393, G_Loss:5.2583465576171875

iterator 900, D_Loss:0.46126142144203186, G_Loss:4.939842700958252

iterator 1000, D_Loss:0.45705583691596985, G_Loss:4.721652984619141

iterator 1100, D_Loss:0.464599609375, G_Loss:8.51887035369873

iterator 1200, D_Loss:0.4416355788707733, G_Loss:8.200098991394043

iterator 1300, D_Loss:0.4478067457675934, G_Loss:8.625494003295898

iterator 1400, D_Loss:0.44299161434173584, G_Loss:5.179480075836182

iterator 1500, D_Loss:0.4300583600997925, G_Loss:7.960178375244141

iterator 1600, D_Loss:0.451943576335907, G_Loss:6.300934791564941

iterator 1700, D_Loss:0.4478640556335449, G_Loss:4.980066299438477

iterator 1800, D_Loss:0.42713674902915955, G_Loss:7.629355430603027

iterator 1900, D_Loss:0.46582555770874023, G_Loss:7.054590702056885

iterator 2000, D_Loss:0.4351295232772827, G_Loss:7.837095260620117

iterator 2100, D_Loss:0.41502514481544495, G_Loss:8.744033813476562

iterator 2200, D_Loss:0.4335179328918457, G_Loss:9.116354942321777

iterator 2300, D_Loss:0.43697959184646606, G_Loss:9.419047355651855

iterator 2400, D_Loss:0.4362489581108093, G_Loss:10.16202449798584

iterator 2500, D_Loss:0.41541287302970886, G_Loss:7.342837333679199

iterator 2600, D_Loss:0.42768654227256775, G_Loss:7.691972732543945

iterator 2700, D_Loss:0.4365023672580719, G_Loss:7.018216133117676

iterator 2800, D_Loss:0.4498887062072754, G_Loss:6.903261661529541

iterator 2900, D_Loss:0.4464159607887268, G_Loss:8.289732933044434

iterator 3000, D_Loss:0.45191526412963867, G_Loss:4.14003324508667

iterator 3100, D_Loss:0.4255392253398895, G_Loss:7.6423726081848145

iterator 3200, D_Loss:0.42636287212371826, G_Loss:7.913483142852783

iterator 3300, D_Loss:0.6165387630462646, G_Loss:5.22849178314209

iterator 3400, D_Loss:0.4508553743362427, G_Loss:8.057003021240234

iterator 3500, D_Loss:0.4189797639846802, G_Loss:7.431308269500732

iterator 3600, D_Loss:0.4391547441482544, G_Loss:9.235458374023438

iterator 3700, D_Loss:0.43952783942222595, G_Loss:10.128406524658203

iterator 3800, D_Loss:0.43635886907577515, G_Loss:7.6013593673706055

iterator 3900, D_Loss:0.42350953817367554, G_Loss:8.539399147033691

iterator 4000, D_Loss:0.43120959401130676, G_Loss:5.374558925628662

iterator 4100, D_Loss:0.43768879771232605, G_Loss:9.973691940307617

iterator 4200, D_Loss:0.42821499705314636, G_Loss:11.452872276306152

iterator 4300, D_Loss:0.437968373298645, G_Loss:6.527570724487305

iterator 4400, D_Loss:0.44170746207237244, G_Loss:3.2574846744537354

iterator 4500, D_Loss:0.4481082856655121, G_Loss:7.040696144104004

iterator 4600, D_Loss:0.43472617864608765, G_Loss:7.187127590179443

iterator 4700, D_Loss:0.4295073449611664, G_Loss:8.412069320678711

iterator 4800, D_Loss:0.4623250961303711, G_Loss:9.997652053833008

iterator 4900, D_Loss:0.41947072744369507, G_Loss:8.867646217346191

-----------Epoch 9-----------
iterator 0, D_Loss:0.4458256959915161, G_Loss:8.484209060668945

iterator 100, D_Loss:0.45199012756347656, G_Loss:10.292343139648438

iterator 200, D_Loss:0.43710798025131226, G_Loss:7.655457496643066

iterator 300, D_Loss:0.4207282066345215, G_Loss:8.495904922485352

iterator 400, D_Loss:0.45922955870628357, G_Loss:10.132940292358398

iterator 500, D_Loss:0.4561310112476349, G_Loss:8.76827335357666

iterator 600, D_Loss:0.45318156480789185, G_Loss:10.2642183303833

iterator 700, D_Loss:0.7423684000968933, G_Loss:6.67403507232666

iterator 800, D_Loss:0.4510728120803833, G_Loss:7.811263561248779

iterator 900, D_Loss:0.4360436797142029, G_Loss:5.325614929199219

iterator 1000, D_Loss:0.4279025197029114, G_Loss:6.4467291831970215

iterator 1100, D_Loss:0.42832663655281067, G_Loss:9.070550918579102

iterator 1200, D_Loss:0.43923428654670715, G_Loss:10.08565616607666

iterator 1300, D_Loss:0.4255712032318115, G_Loss:7.634702205657959

iterator 1400, D_Loss:0.41648849844932556, G_Loss:6.171386241912842

iterator 1500, D_Loss:0.4376833438873291, G_Loss:5.655876636505127

iterator 1600, D_Loss:0.4342246949672699, G_Loss:9.66187572479248

iterator 1700, D_Loss:0.41486841440200806, G_Loss:9.2010498046875

iterator 1800, D_Loss:0.42473867535591125, G_Loss:8.38769817352295

iterator 1900, D_Loss:0.42851486802101135, G_Loss:12.737251281738281

iterator 2000, D_Loss:0.46138593554496765, G_Loss:8.492790222167969

iterator 2100, D_Loss:0.47012853622436523, G_Loss:10.937657356262207

iterator 2200, D_Loss:0.4276851713657379, G_Loss:9.154593467712402

iterator 2300, D_Loss:0.45924630761146545, G_Loss:7.867923259735107

iterator 2400, D_Loss:0.44624063372612, G_Loss:4.392826557159424

iterator 2500, D_Loss:0.4753039479255676, G_Loss:10.921418190002441

iterator 2600, D_Loss:0.4726024568080902, G_Loss:8.75674057006836

iterator 2700, D_Loss:0.4431883990764618, G_Loss:11.049464225769043

iterator 2800, D_Loss:0.4291720390319824, G_Loss:11.882162094116211

iterator 2900, D_Loss:0.43925753235816956, G_Loss:9.59040355682373

iterator 3000, D_Loss:0.4257012605667114, G_Loss:6.111385345458984

iterator 3100, D_Loss:0.43122434616088867, G_Loss:8.998510360717773

iterator 3200, D_Loss:0.4308842122554779, G_Loss:7.544191837310791

iterator 3300, D_Loss:0.4431900978088379, G_Loss:11.60434341430664

iterator 3400, D_Loss:0.4431792199611664, G_Loss:11.043607711791992

iterator 3500, D_Loss:0.4442455470561981, G_Loss:9.650312423706055

iterator 3600, D_Loss:0.4285954535007477, G_Loss:10.008044242858887

iterator 3700, D_Loss:0.4335249364376068, G_Loss:9.549797058105469

iterator 3800, D_Loss:0.6592245697975159, G_Loss:9.764511108398438

iterator 3900, D_Loss:0.4523562490940094, G_Loss:13.417974472045898

iterator 4000, D_Loss:0.4406764507293701, G_Loss:7.835693836212158

iterator 4100, D_Loss:0.46460258960723877, G_Loss:10.72875690460205

iterator 4200, D_Loss:0.4195150136947632, G_Loss:13.441269874572754

iterator 4300, D_Loss:0.4237767457962036, G_Loss:10.564905166625977

iterator 4400, D_Loss:0.4369838833808899, G_Loss:9.413338661193848

iterator 4500, D_Loss:0.4362218976020813, G_Loss:9.843819618225098

iterator 4600, D_Loss:0.42485296726226807, G_Loss:8.33187198638916

iterator 4700, D_Loss:0.417384535074234, G_Loss:11.703882217407227

iterator 4800, D_Loss:0.43102720379829407, G_Loss:10.739595413208008

iterator 4900, D_Loss:0.45123663544654846, G_Loss:11.569450378417969

train row : 30148
sample row: 30148
LGAN_generator(
  (LSTM): LSTMCell(652, 200)
  (gmfc00): Linear(in_features=600, out_features=1, bias=True)
  (gmfc01): Linear(in_features=600, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=600, bias=True)
  (gmfe00): Linear(in_features=200, out_features=600, bias=True)
  (gmfe01): Linear(in_features=200, out_features=600, bias=True)
  (fc10): Linear(in_features=600, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=600, bias=True)
  (fe1): Linear(in_features=200, out_features=600, bias=True)
  (gmfc20): Linear(in_features=600, out_features=1, bias=True)
  (gmfc21): Linear(in_features=600, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=600, bias=True)
  (gmfe20): Linear(in_features=200, out_features=600, bias=True)
  (gmfe21): Linear(in_features=200, out_features=600, bias=True)
  (fc30): Linear(in_features=600, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=600, bias=True)
  (fe3): Linear(in_features=200, out_features=600, bias=True)
  (gmfc40): Linear(in_features=600, out_features=1, bias=True)
  (gmfc41): Linear(in_features=600, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=600, bias=True)
  (gmfe40): Linear(in_features=200, out_features=600, bias=True)
  (gmfe41): Linear(in_features=200, out_features=600, bias=True)
  (fc50): Linear(in_features=600, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=600, bias=True)
  (fe5): Linear(in_features=200, out_features=600, bias=True)
  (fc60): Linear(in_features=600, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=600, bias=True)
  (fe6): Linear(in_features=200, out_features=600, bias=True)
  (fc70): Linear(in_features=600, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=600, bias=True)
  (fe7): Linear(in_features=200, out_features=600, bias=True)
  (fc80): Linear(in_features=600, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=600, bias=True)
  (fe8): Linear(in_features=200, out_features=600, bias=True)
  (fc90): Linear(in_features=600, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=600, bias=True)
  (fe9): Linear(in_features=200, out_features=600, bias=True)
  (gmfc100): Linear(in_features=600, out_features=1, bias=True)
  (gmfc101): Linear(in_features=600, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=600, bias=True)
  (gmfe100): Linear(in_features=200, out_features=600, bias=True)
  (gmfe101): Linear(in_features=200, out_features=600, bias=True)
  (gmfc110): Linear(in_features=600, out_features=1, bias=True)
  (gmfc111): Linear(in_features=600, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=600, bias=True)
  (gmfe110): Linear(in_features=200, out_features=600, bias=True)
  (gmfe111): Linear(in_features=200, out_features=600, bias=True)
  (gmfc120): Linear(in_features=600, out_features=1, bias=True)
  (gmfc121): Linear(in_features=600, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=600, bias=True)
  (gmfe120): Linear(in_features=200, out_features=600, bias=True)
  (gmfe121): Linear(in_features=200, out_features=600, bias=True)
  (fc130): Linear(in_features=600, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=600, bias=True)
  (fe13): Linear(in_features=200, out_features=600, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=500, bias=True)
  (inputbn): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=500, out_features=500, bias=True)
  (bn0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=500, out_features=500, bias=True)
  (bn1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=500, out_features=1, bias=True)
)
-----------Epoch 0-----------
iterator 100, D_Loss:1.356835126876831, G_Loss:0.9878485798835754

iterator 200, D_Loss:1.2660452127456665, G_Loss:1.0866265296936035

iterator 300, D_Loss:1.2167447805404663, G_Loss:1.0826715230941772

iterator 400, D_Loss:1.132596731185913, G_Loss:1.303850769996643

iterator 500, D_Loss:1.0957056283950806, G_Loss:1.3631545305252075

iterator 600, D_Loss:0.9594318866729736, G_Loss:1.5937340259552002

iterator 700, D_Loss:0.9590399265289307, G_Loss:1.696718692779541

iterator 800, D_Loss:0.9399716854095459, G_Loss:2.04823637008667

iterator 900, D_Loss:1.0842711925506592, G_Loss:1.7077116966247559

iterator 1000, D_Loss:0.8662076592445374, G_Loss:1.9241955280303955

iterator 1100, D_Loss:0.7142676115036011, G_Loss:2.6061062812805176

iterator 1200, D_Loss:0.8519595861434937, G_Loss:3.578606605529785

iterator 1300, D_Loss:1.0724384784698486, G_Loss:1.9098607301712036

iterator 1400, D_Loss:0.8366881608963013, G_Loss:2.4090933799743652

iterator 1500, D_Loss:0.5622894167900085, G_Loss:3.284700632095337

iterator 1600, D_Loss:2.1817221641540527, G_Loss:2.856417417526245

iterator 1700, D_Loss:0.6625611186027527, G_Loss:3.0140275955200195

iterator 1800, D_Loss:0.6796542406082153, G_Loss:3.161835193634033

iterator 1900, D_Loss:0.8032479882240295, G_Loss:2.8683762550354004

iterator 2000, D_Loss:0.9782930016517639, G_Loss:2.4403653144836426

iterator 2100, D_Loss:0.7889189124107361, G_Loss:2.717759609222412

iterator 2200, D_Loss:0.8605647087097168, G_Loss:3.123152732849121

iterator 2300, D_Loss:0.7121449708938599, G_Loss:4.14455509185791

iterator 2400, D_Loss:0.7032236456871033, G_Loss:2.955477476119995

iterator 2500, D_Loss:0.7851305603981018, G_Loss:3.544952630996704

iterator 2600, D_Loss:0.9692738056182861, G_Loss:2.5334455966949463

iterator 2700, D_Loss:0.8495774269104004, G_Loss:3.117384433746338

iterator 2800, D_Loss:0.8048473596572876, G_Loss:2.3948402404785156

iterator 2900, D_Loss:0.8167225122451782, G_Loss:3.0583765506744385

iterator 3000, D_Loss:0.7231308221817017, G_Loss:3.3508639335632324

iterator 3100, D_Loss:0.6784529089927673, G_Loss:2.900007486343384

iterator 3200, D_Loss:0.6513032913208008, G_Loss:4.165456771850586

iterator 3300, D_Loss:0.6883499026298523, G_Loss:3.910102367401123

iterator 3400, D_Loss:0.925869345664978, G_Loss:2.142897367477417

iterator 3500, D_Loss:0.646696150302887, G_Loss:4.863018035888672

iterator 3600, D_Loss:0.5995311737060547, G_Loss:3.7349696159362793

iterator 3700, D_Loss:0.8958905339241028, G_Loss:2.917055130004883

iterator 3800, D_Loss:0.7887483239173889, G_Loss:2.337148427963257

iterator 3900, D_Loss:0.5643898248672485, G_Loss:4.276332855224609

iterator 4000, D_Loss:0.7042595744132996, G_Loss:4.122277736663818

iterator 4100, D_Loss:0.8428977727890015, G_Loss:2.4282636642456055

iterator 4200, D_Loss:0.9460131525993347, G_Loss:3.6629271507263184

iterator 4300, D_Loss:0.6878761649131775, G_Loss:3.325148820877075

iterator 4400, D_Loss:0.5904289484024048, G_Loss:3.3824384212493896

iterator 4500, D_Loss:0.6796335577964783, G_Loss:5.112331390380859

iterator 4600, D_Loss:0.6064505577087402, G_Loss:4.011682033538818

iterator 4700, D_Loss:0.5495415925979614, G_Loss:4.220343112945557

iterator 4800, D_Loss:0.6818745732307434, G_Loss:3.0245015621185303

iterator 4900, D_Loss:0.6121784448623657, G_Loss:3.543553590774536

iterator 5000, D_Loss:0.6051998138427734, G_Loss:3.4702463150024414

-----------Epoch 1-----------
iterator 100, D_Loss:0.8109321594238281, G_Loss:3.6037373542785645

iterator 200, D_Loss:0.6215171813964844, G_Loss:4.062656402587891

iterator 300, D_Loss:0.8355129957199097, G_Loss:3.9521901607513428

iterator 400, D_Loss:0.6955041289329529, G_Loss:3.4050424098968506

iterator 500, D_Loss:0.5711524486541748, G_Loss:4.174300193786621

iterator 600, D_Loss:0.786454975605011, G_Loss:3.5670347213745117

iterator 700, D_Loss:0.673069953918457, G_Loss:3.3115744590759277

iterator 800, D_Loss:0.5388835668563843, G_Loss:3.5319364070892334

iterator 900, D_Loss:0.6132753491401672, G_Loss:3.950545072555542

iterator 1000, D_Loss:0.6767365336418152, G_Loss:4.99044942855835

iterator 1100, D_Loss:0.5144379138946533, G_Loss:4.346614360809326

iterator 1200, D_Loss:0.7471207976341248, G_Loss:3.0729820728302

iterator 1300, D_Loss:0.9249242544174194, G_Loss:5.029528617858887

iterator 1400, D_Loss:0.682144284248352, G_Loss:4.012063026428223

iterator 1500, D_Loss:0.6414707899093628, G_Loss:4.28154182434082

iterator 1600, D_Loss:0.49645093083381653, G_Loss:6.760247230529785

iterator 1700, D_Loss:0.5276492238044739, G_Loss:3.478646755218506

iterator 1800, D_Loss:0.48573219776153564, G_Loss:4.433987140655518

iterator 1900, D_Loss:1.1811470985412598, G_Loss:5.890179634094238

iterator 2000, D_Loss:0.479120135307312, G_Loss:4.084271430969238

iterator 2100, D_Loss:0.46403518319129944, G_Loss:7.222933292388916

iterator 2200, D_Loss:0.4763525426387787, G_Loss:5.425204277038574

iterator 2300, D_Loss:0.7044572234153748, G_Loss:6.017258644104004

iterator 2400, D_Loss:0.531453013420105, G_Loss:4.972320556640625

iterator 2500, D_Loss:0.4786764979362488, G_Loss:5.418891906738281

iterator 2600, D_Loss:0.46867966651916504, G_Loss:4.620485305786133

iterator 2700, D_Loss:0.44642624258995056, G_Loss:6.040200233459473

iterator 2800, D_Loss:0.48887577652931213, G_Loss:6.511716842651367

iterator 2900, D_Loss:0.6354795098304749, G_Loss:6.429837226867676

iterator 3000, D_Loss:0.47829461097717285, G_Loss:6.545440673828125

iterator 3100, D_Loss:0.4413120448589325, G_Loss:6.330297470092773

iterator 3200, D_Loss:0.4630957841873169, G_Loss:5.880354881286621

iterator 3300, D_Loss:0.462775319814682, G_Loss:7.64990758895874

iterator 3400, D_Loss:0.45201969146728516, G_Loss:7.143913745880127

iterator 3500, D_Loss:0.49906396865844727, G_Loss:4.7373552322387695

iterator 3600, D_Loss:0.43475639820098877, G_Loss:7.034717559814453

iterator 3700, D_Loss:0.43083176016807556, G_Loss:5.607851505279541

iterator 3800, D_Loss:0.456445574760437, G_Loss:8.061698913574219

iterator 3900, D_Loss:0.4278428852558136, G_Loss:8.264338493347168

iterator 4000, D_Loss:0.4734536111354828, G_Loss:7.342304706573486

iterator 4100, D_Loss:0.4652986228466034, G_Loss:5.502139091491699

iterator 4200, D_Loss:0.446208655834198, G_Loss:7.153592586517334

iterator 4300, D_Loss:0.44637686014175415, G_Loss:9.204639434814453

iterator 4400, D_Loss:0.6189665198326111, G_Loss:7.449118614196777

iterator 4500, D_Loss:0.4972596764564514, G_Loss:6.532882213592529

iterator 4600, D_Loss:0.43971237540245056, G_Loss:7.476492881774902

iterator 4700, D_Loss:0.4479919672012329, G_Loss:8.275238037109375

iterator 4800, D_Loss:0.45736563205718994, G_Loss:11.326051712036133

iterator 4900, D_Loss:0.44249823689460754, G_Loss:6.649827003479004

iterator 5000, D_Loss:0.6206513047218323, G_Loss:9.023332595825195

-----------Epoch 2-----------
iterator 100, D_Loss:0.4514691233634949, G_Loss:9.750946044921875

iterator 200, D_Loss:0.4402124881744385, G_Loss:7.885232925415039

iterator 300, D_Loss:0.4388495683670044, G_Loss:9.3397798538208

iterator 400, D_Loss:0.45037999749183655, G_Loss:7.58117151260376

iterator 500, D_Loss:0.4301309883594513, G_Loss:10.195720672607422

iterator 600, D_Loss:0.4463222324848175, G_Loss:11.31027603149414

iterator 700, D_Loss:0.4981924891471863, G_Loss:10.346067428588867

iterator 800, D_Loss:0.44684380292892456, G_Loss:9.361832618713379

iterator 900, D_Loss:0.45941033959388733, G_Loss:9.068408966064453

iterator 1000, D_Loss:0.41963300108909607, G_Loss:9.796432495117188

iterator 1100, D_Loss:0.45663711428642273, G_Loss:10.149198532104492

iterator 1200, D_Loss:0.4396211802959442, G_Loss:8.438520431518555

iterator 1300, D_Loss:0.4437996745109558, G_Loss:7.008001327514648

iterator 1400, D_Loss:0.4604434669017792, G_Loss:8.606220245361328

iterator 1500, D_Loss:0.4735606014728546, G_Loss:6.227705001831055

iterator 1600, D_Loss:0.4448845386505127, G_Loss:9.048773765563965

iterator 1700, D_Loss:0.4688975214958191, G_Loss:8.323965072631836

iterator 1800, D_Loss:0.4280582368373871, G_Loss:9.598468780517578

iterator 1900, D_Loss:0.4432951509952545, G_Loss:10.512487411499023

iterator 2000, D_Loss:0.4357229769229889, G_Loss:7.6562113761901855

iterator 2100, D_Loss:0.43843916058540344, G_Loss:10.259542465209961

iterator 2200, D_Loss:0.43570059537887573, G_Loss:8.527052879333496

iterator 2300, D_Loss:0.4507009983062744, G_Loss:9.724591255187988

iterator 2400, D_Loss:0.42686474323272705, G_Loss:9.508402824401855

iterator 2500, D_Loss:0.4441131055355072, G_Loss:11.155492782592773

iterator 2600, D_Loss:0.46116116642951965, G_Loss:12.181867599487305

iterator 2700, D_Loss:0.5650527477264404, G_Loss:11.283990859985352

iterator 2800, D_Loss:0.4829646944999695, G_Loss:11.56928825378418

iterator 2900, D_Loss:0.5355625748634338, G_Loss:8.569055557250977

iterator 3000, D_Loss:0.44027072191238403, G_Loss:14.19041633605957

iterator 3100, D_Loss:0.4429086744785309, G_Loss:12.123275756835938

iterator 3200, D_Loss:0.422954261302948, G_Loss:14.386968612670898

iterator 3300, D_Loss:0.45046037435531616, G_Loss:14.654544830322266

iterator 3400, D_Loss:0.42320212721824646, G_Loss:15.768667221069336

iterator 3500, D_Loss:0.4335778057575226, G_Loss:10.504213333129883

iterator 3600, D_Loss:0.44534653425216675, G_Loss:16.53251838684082

iterator 3700, D_Loss:0.4445323646068573, G_Loss:16.239131927490234

iterator 3800, D_Loss:0.4468350112438202, G_Loss:15.574764251708984

iterator 3900, D_Loss:0.4641623795032501, G_Loss:14.760334014892578

iterator 4000, D_Loss:0.4611440598964691, G_Loss:14.388382911682129

iterator 4100, D_Loss:0.4160049557685852, G_Loss:15.549786567687988

iterator 4200, D_Loss:0.4305327534675598, G_Loss:15.899426460266113

iterator 4300, D_Loss:0.40899524092674255, G_Loss:15.149432182312012

iterator 4400, D_Loss:0.4199344515800476, G_Loss:13.906475067138672

iterator 4500, D_Loss:0.43505412340164185, G_Loss:15.700538635253906

iterator 4600, D_Loss:0.43945950269699097, G_Loss:13.906715393066406

iterator 4700, D_Loss:0.448801726102829, G_Loss:13.176229476928711

iterator 4800, D_Loss:0.4122990667819977, G_Loss:13.956482887268066

iterator 4900, D_Loss:0.4299072325229645, G_Loss:14.598549842834473

iterator 5000, D_Loss:0.44517505168914795, G_Loss:16.96186637878418

-----------Epoch 3-----------
iterator 100, D_Loss:0.4375045895576477, G_Loss:14.747408866882324

iterator 200, D_Loss:0.4257519841194153, G_Loss:15.094856262207031

iterator 300, D_Loss:0.42638251185417175, G_Loss:14.671846389770508

iterator 400, D_Loss:0.41591209173202515, G_Loss:16.606779098510742

iterator 500, D_Loss:0.4186955988407135, G_Loss:15.879851341247559

iterator 600, D_Loss:0.41726037859916687, G_Loss:16.35852813720703

iterator 700, D_Loss:0.4458654820919037, G_Loss:16.2293701171875

iterator 800, D_Loss:0.43739283084869385, G_Loss:14.411598205566406

iterator 900, D_Loss:0.4277539849281311, G_Loss:17.474740982055664

iterator 1000, D_Loss:0.4282037615776062, G_Loss:16.589866638183594

iterator 1100, D_Loss:0.42556390166282654, G_Loss:13.935600280761719

iterator 1200, D_Loss:0.4329591989517212, G_Loss:10.330894470214844

iterator 1300, D_Loss:0.4235721528530121, G_Loss:11.190838813781738

iterator 1400, D_Loss:0.4268244504928589, G_Loss:8.307870864868164

iterator 1500, D_Loss:0.44469109177589417, G_Loss:11.895416259765625

iterator 1600, D_Loss:0.4391230642795563, G_Loss:12.660401344299316

iterator 1700, D_Loss:0.43234118819236755, G_Loss:12.785874366760254

iterator 1800, D_Loss:0.502254843711853, G_Loss:9.259746551513672

iterator 1900, D_Loss:0.4821197986602783, G_Loss:9.100027084350586

iterator 2000, D_Loss:0.44068729877471924, G_Loss:10.294376373291016

iterator 2100, D_Loss:0.4326351583003998, G_Loss:15.987639427185059

iterator 2200, D_Loss:0.4351372718811035, G_Loss:10.539373397827148

iterator 2300, D_Loss:0.4405474364757538, G_Loss:10.851933479309082

iterator 2400, D_Loss:0.44058647751808167, G_Loss:11.665811538696289

iterator 2500, D_Loss:0.4465065002441406, G_Loss:12.297843933105469

iterator 2600, D_Loss:0.4722626209259033, G_Loss:5.940469264984131

iterator 2700, D_Loss:0.4280031621456146, G_Loss:9.290733337402344

iterator 2800, D_Loss:0.4806627333164215, G_Loss:10.636734962463379

iterator 2900, D_Loss:0.4623042047023773, G_Loss:7.317540168762207

iterator 3000, D_Loss:0.43687039613723755, G_Loss:8.051473617553711

iterator 3100, D_Loss:0.41756388545036316, G_Loss:9.719432830810547

iterator 3200, D_Loss:0.48504185676574707, G_Loss:7.805225849151611

iterator 3300, D_Loss:0.4579590857028961, G_Loss:10.07076644897461

iterator 3400, D_Loss:0.41389980912208557, G_Loss:11.695236206054688

iterator 3500, D_Loss:0.4487338066101074, G_Loss:8.260334968566895

iterator 3600, D_Loss:0.44746142625808716, G_Loss:11.415705680847168

iterator 3700, D_Loss:0.4317851960659027, G_Loss:9.278509140014648

iterator 3800, D_Loss:0.4249172806739807, G_Loss:11.51224422454834

iterator 3900, D_Loss:0.4228048026561737, G_Loss:11.429984092712402

iterator 4000, D_Loss:0.47409385442733765, G_Loss:9.81261157989502

iterator 4100, D_Loss:0.44327449798583984, G_Loss:6.744050025939941

iterator 4200, D_Loss:0.5089725255966187, G_Loss:9.832812309265137

iterator 4300, D_Loss:0.5900096893310547, G_Loss:5.300439357757568

iterator 4400, D_Loss:0.471915602684021, G_Loss:5.811805725097656

iterator 4500, D_Loss:0.44440630078315735, G_Loss:6.301632881164551

iterator 4600, D_Loss:0.4502141773700714, G_Loss:7.8432793617248535

iterator 4700, D_Loss:0.4534010589122772, G_Loss:8.253035545349121

iterator 4800, D_Loss:0.46553486585617065, G_Loss:8.295171737670898

iterator 4900, D_Loss:0.4957827031612396, G_Loss:8.174530982971191

iterator 5000, D_Loss:0.4670460820198059, G_Loss:9.226428031921387

-----------Epoch 4-----------
iterator 100, D_Loss:0.4393768608570099, G_Loss:10.727697372436523

iterator 200, D_Loss:0.4461904764175415, G_Loss:7.7345685958862305

iterator 300, D_Loss:0.44146475195884705, G_Loss:9.100493431091309

iterator 400, D_Loss:0.45016252994537354, G_Loss:10.088066101074219

iterator 500, D_Loss:0.4560732841491699, G_Loss:11.701866149902344

iterator 600, D_Loss:0.4567708969116211, G_Loss:7.315959453582764

iterator 700, D_Loss:0.43385809659957886, G_Loss:6.4078898429870605

iterator 800, D_Loss:0.5367956757545471, G_Loss:9.089496612548828

iterator 900, D_Loss:0.43874332308769226, G_Loss:8.272132873535156

iterator 1000, D_Loss:0.48119187355041504, G_Loss:6.173316478729248

iterator 1100, D_Loss:0.44629621505737305, G_Loss:11.649333953857422

iterator 1200, D_Loss:0.45589160919189453, G_Loss:8.547195434570312

iterator 1300, D_Loss:0.5016915798187256, G_Loss:8.09837532043457

iterator 1400, D_Loss:0.4576827883720398, G_Loss:6.329453468322754

iterator 1500, D_Loss:0.44005975127220154, G_Loss:10.473773002624512

iterator 1600, D_Loss:0.5146094560623169, G_Loss:6.395965099334717

iterator 1700, D_Loss:0.46394968032836914, G_Loss:11.649720191955566

iterator 1800, D_Loss:0.42196980118751526, G_Loss:10.806634902954102

iterator 1900, D_Loss:0.458204060792923, G_Loss:8.922072410583496

iterator 2000, D_Loss:0.45486414432525635, G_Loss:9.68455696105957

iterator 2100, D_Loss:0.46075958013534546, G_Loss:9.446063041687012

iterator 2200, D_Loss:0.4497792422771454, G_Loss:4.215063095092773

iterator 2300, D_Loss:0.45949652791023254, G_Loss:6.515029430389404

iterator 2400, D_Loss:0.6485182642936707, G_Loss:4.756535053253174

iterator 2500, D_Loss:0.5141661763191223, G_Loss:7.68931245803833

iterator 2600, D_Loss:0.4870421290397644, G_Loss:8.4302978515625

iterator 2700, D_Loss:0.48622092604637146, G_Loss:8.52600383758545

iterator 2800, D_Loss:0.6497167348861694, G_Loss:6.405786037445068

iterator 2900, D_Loss:0.46106454730033875, G_Loss:5.955801963806152

iterator 3000, D_Loss:0.667914628982544, G_Loss:9.042794227600098

iterator 3100, D_Loss:0.43850967288017273, G_Loss:7.368683815002441

iterator 3200, D_Loss:0.4528201222419739, G_Loss:3.832624673843384

iterator 3300, D_Loss:0.49186384677886963, G_Loss:7.185575008392334

iterator 3400, D_Loss:0.47484925389289856, G_Loss:7.319423675537109

iterator 3500, D_Loss:0.4683396518230438, G_Loss:7.900875568389893

iterator 3600, D_Loss:0.4789606034755707, G_Loss:4.538827896118164

iterator 3700, D_Loss:0.5198284983634949, G_Loss:9.889116287231445

iterator 3800, D_Loss:0.7311763763427734, G_Loss:5.948709011077881

iterator 3900, D_Loss:0.48650088906288147, G_Loss:10.92263126373291

iterator 4000, D_Loss:0.4389305114746094, G_Loss:9.698124885559082

iterator 4100, D_Loss:0.4277387857437134, G_Loss:8.322338104248047

iterator 4200, D_Loss:0.43342217803001404, G_Loss:10.266805648803711

iterator 4300, D_Loss:0.4364365041255951, G_Loss:11.85102367401123

iterator 4400, D_Loss:0.44989100098609924, G_Loss:5.40638542175293

iterator 4500, D_Loss:0.45182400941848755, G_Loss:7.706191539764404

iterator 4600, D_Loss:0.477781742811203, G_Loss:5.802737712860107

iterator 4700, D_Loss:0.4575812816619873, G_Loss:8.290006637573242

iterator 4800, D_Loss:0.43150001764297485, G_Loss:6.712472915649414

iterator 4900, D_Loss:0.5134457945823669, G_Loss:5.319297790527344

iterator 5000, D_Loss:0.5029433369636536, G_Loss:6.517696857452393

-----------Epoch 5-----------
iterator 100, D_Loss:0.48083174228668213, G_Loss:6.24215030670166

iterator 200, D_Loss:0.4748765826225281, G_Loss:7.371119022369385

iterator 300, D_Loss:0.5069028735160828, G_Loss:8.230963706970215

iterator 400, D_Loss:0.493124395608902, G_Loss:8.245919227600098

iterator 500, D_Loss:0.45323681831359863, G_Loss:13.30284309387207

iterator 600, D_Loss:0.4835493862628937, G_Loss:7.599693298339844

iterator 700, D_Loss:0.5021820068359375, G_Loss:10.328056335449219

iterator 800, D_Loss:0.45863282680511475, G_Loss:9.415238380432129

iterator 900, D_Loss:0.4620283842086792, G_Loss:6.749332427978516

iterator 1000, D_Loss:0.5079754590988159, G_Loss:6.218436241149902

iterator 1100, D_Loss:0.4736673831939697, G_Loss:8.382843971252441

iterator 1200, D_Loss:0.4357110261917114, G_Loss:6.691662788391113

iterator 1300, D_Loss:0.4663901627063751, G_Loss:9.228893280029297

iterator 1400, D_Loss:0.45816344022750854, G_Loss:7.266130447387695

iterator 1500, D_Loss:0.479993999004364, G_Loss:9.840936660766602

iterator 1600, D_Loss:0.45206204056739807, G_Loss:9.617020606994629

iterator 1700, D_Loss:0.46221923828125, G_Loss:11.636656761169434

iterator 1800, D_Loss:0.4747464656829834, G_Loss:7.664981842041016

iterator 1900, D_Loss:0.45655128359794617, G_Loss:8.213905334472656

iterator 2000, D_Loss:0.46080896258354187, G_Loss:9.804621696472168

iterator 2100, D_Loss:0.44002819061279297, G_Loss:8.395772933959961

iterator 2200, D_Loss:0.45967942476272583, G_Loss:7.293274402618408

iterator 2300, D_Loss:0.45213454961776733, G_Loss:7.320235252380371

iterator 2400, D_Loss:0.4534221589565277, G_Loss:9.146685600280762

iterator 2500, D_Loss:0.501556932926178, G_Loss:14.510505676269531

iterator 2600, D_Loss:0.4504068195819855, G_Loss:10.24701976776123

iterator 2700, D_Loss:0.458495169878006, G_Loss:9.048954010009766

iterator 2800, D_Loss:0.44046828150749207, G_Loss:9.522415161132812

iterator 2900, D_Loss:0.44783857464790344, G_Loss:8.274105072021484

iterator 3000, D_Loss:0.4644576907157898, G_Loss:10.692813873291016

iterator 3100, D_Loss:0.44182661175727844, G_Loss:7.353066921234131

iterator 3200, D_Loss:0.4549022316932678, G_Loss:14.818760871887207

iterator 3300, D_Loss:0.4673139750957489, G_Loss:12.931633949279785

iterator 3400, D_Loss:0.4424992799758911, G_Loss:15.845714569091797

iterator 3500, D_Loss:0.44036954641342163, G_Loss:11.640810012817383

iterator 3600, D_Loss:0.46579623222351074, G_Loss:10.044843673706055

iterator 3700, D_Loss:0.49025943875312805, G_Loss:8.594091415405273

iterator 3800, D_Loss:0.47682005167007446, G_Loss:7.020342826843262

iterator 3900, D_Loss:0.4932202696800232, G_Loss:8.947425842285156

iterator 4000, D_Loss:0.43202027678489685, G_Loss:8.27074146270752

iterator 4100, D_Loss:0.44588547945022583, G_Loss:8.535428047180176

iterator 4200, D_Loss:0.48714324831962585, G_Loss:13.042064666748047

iterator 4300, D_Loss:0.4380614757537842, G_Loss:9.469378471374512

iterator 4400, D_Loss:0.4500432014465332, G_Loss:8.9791841506958

iterator 4500, D_Loss:0.435781866312027, G_Loss:9.933907508850098

iterator 4600, D_Loss:0.43407249450683594, G_Loss:11.062944412231445

iterator 4700, D_Loss:0.4476579427719116, G_Loss:7.587906837463379

iterator 4800, D_Loss:0.43988701701164246, G_Loss:12.612529754638672

iterator 4900, D_Loss:0.4172039330005646, G_Loss:9.794293403625488

iterator 5000, D_Loss:0.43806222081184387, G_Loss:10.74216365814209

-----------Epoch 6-----------
iterator 100, D_Loss:0.4355878531932831, G_Loss:17.44223403930664

iterator 200, D_Loss:0.4316841661930084, G_Loss:12.902533531188965

iterator 300, D_Loss:0.4487881064414978, G_Loss:11.681801795959473

iterator 400, D_Loss:0.44480639696121216, G_Loss:13.153295516967773

iterator 500, D_Loss:0.42276281118392944, G_Loss:11.15824031829834

iterator 600, D_Loss:0.4204217791557312, G_Loss:13.221277236938477

iterator 700, D_Loss:0.4289269745349884, G_Loss:16.02472686767578

iterator 800, D_Loss:0.451930969953537, G_Loss:14.559137344360352

iterator 900, D_Loss:0.4431133270263672, G_Loss:14.119894981384277

iterator 1000, D_Loss:0.45495790243148804, G_Loss:10.008928298950195

iterator 1100, D_Loss:0.45130011439323425, G_Loss:13.277321815490723

iterator 1200, D_Loss:0.43896177411079407, G_Loss:10.977058410644531

iterator 1300, D_Loss:0.4412634074687958, G_Loss:11.676736831665039

iterator 1400, D_Loss:0.44762471318244934, G_Loss:10.302830696105957

iterator 1500, D_Loss:0.42608368396759033, G_Loss:13.458385467529297

iterator 1600, D_Loss:0.4296095073223114, G_Loss:8.75546932220459

iterator 1700, D_Loss:0.43156370520591736, G_Loss:11.892624855041504

iterator 1800, D_Loss:0.42965444922447205, G_Loss:10.490911483764648

iterator 1900, D_Loss:0.4857257902622223, G_Loss:14.155352592468262

iterator 2000, D_Loss:0.47794783115386963, G_Loss:6.642136573791504

iterator 2100, D_Loss:0.44776651263237, G_Loss:10.446808815002441

iterator 2200, D_Loss:0.4564604163169861, G_Loss:9.477090835571289

iterator 2300, D_Loss:0.4380844831466675, G_Loss:6.096330642700195

iterator 2400, D_Loss:0.464322030544281, G_Loss:8.983541488647461

iterator 2500, D_Loss:0.4453508257865906, G_Loss:12.428577423095703

iterator 2600, D_Loss:0.4153232276439667, G_Loss:8.446813583374023

iterator 2700, D_Loss:0.419600248336792, G_Loss:7.482114315032959

iterator 2800, D_Loss:0.44463658332824707, G_Loss:12.104734420776367

iterator 2900, D_Loss:0.5302615761756897, G_Loss:10.675175666809082

iterator 3000, D_Loss:0.4450286328792572, G_Loss:9.790255546569824

iterator 3100, D_Loss:0.41141849756240845, G_Loss:14.312613487243652

iterator 3200, D_Loss:0.43455761671066284, G_Loss:10.643113136291504

iterator 3300, D_Loss:0.43753787875175476, G_Loss:6.343719959259033

iterator 3400, D_Loss:0.4211859107017517, G_Loss:14.373083114624023

iterator 3500, D_Loss:0.43664753437042236, G_Loss:9.178491592407227

iterator 3600, D_Loss:0.4256887137889862, G_Loss:9.952913284301758

iterator 3700, D_Loss:0.5324205756187439, G_Loss:13.251879692077637

iterator 3800, D_Loss:0.46506378054618835, G_Loss:6.72031307220459

iterator 3900, D_Loss:0.48075249791145325, G_Loss:11.8264799118042

iterator 4000, D_Loss:0.4208989143371582, G_Loss:13.591788291931152

iterator 4100, D_Loss:0.42209944128990173, G_Loss:13.888776779174805

iterator 4200, D_Loss:0.47523266077041626, G_Loss:23.421110153198242

iterator 4300, D_Loss:0.4465182423591614, G_Loss:14.190694808959961

iterator 4400, D_Loss:0.45254915952682495, G_Loss:14.74138069152832

iterator 4500, D_Loss:0.44028475880622864, G_Loss:16.555130004882812

iterator 4600, D_Loss:0.4360623061656952, G_Loss:22.753494262695312

iterator 4700, D_Loss:0.4425124526023865, G_Loss:19.807098388671875

iterator 4800, D_Loss:0.4354170858860016, G_Loss:19.897506713867188

iterator 4900, D_Loss:0.4396798610687256, G_Loss:18.111684799194336

iterator 5000, D_Loss:0.4313720166683197, G_Loss:20.765531539916992

-----------Epoch 7-----------
iterator 100, D_Loss:0.4386384189128876, G_Loss:18.09541893005371

iterator 200, D_Loss:0.4396520256996155, G_Loss:17.2148494720459

iterator 300, D_Loss:0.43039223551750183, G_Loss:17.388248443603516

iterator 400, D_Loss:0.42095673084259033, G_Loss:16.684648513793945

iterator 500, D_Loss:0.41608890891075134, G_Loss:16.104108810424805

iterator 600, D_Loss:0.4276229441165924, G_Loss:17.03778839111328

iterator 700, D_Loss:0.4321011006832123, G_Loss:19.04859161376953

iterator 800, D_Loss:0.4383838176727295, G_Loss:16.39163589477539

iterator 900, D_Loss:0.4374590218067169, G_Loss:14.974818229675293

iterator 1000, D_Loss:0.41042348742485046, G_Loss:19.91155433654785

iterator 1100, D_Loss:0.4328751862049103, G_Loss:19.41413116455078

iterator 1200, D_Loss:0.4092424809932709, G_Loss:21.00782585144043

iterator 1300, D_Loss:0.4326571524143219, G_Loss:19.53482437133789

iterator 1400, D_Loss:0.41926631331443787, G_Loss:17.56629753112793

iterator 1500, D_Loss:0.42227497696876526, G_Loss:18.301332473754883

iterator 1600, D_Loss:0.4237612783908844, G_Loss:15.356527328491211

iterator 1700, D_Loss:0.43426236510276794, G_Loss:18.989212036132812

iterator 1800, D_Loss:0.4342390298843384, G_Loss:15.019821166992188

iterator 1900, D_Loss:0.4181952476501465, G_Loss:19.33531951904297

iterator 2000, D_Loss:0.4277743995189667, G_Loss:18.925458908081055

iterator 2100, D_Loss:0.43075186014175415, G_Loss:18.565683364868164

iterator 2200, D_Loss:0.434771865606308, G_Loss:16.300769805908203

iterator 2300, D_Loss:0.42774641513824463, G_Loss:25.502920150756836

iterator 2400, D_Loss:0.4138835370540619, G_Loss:17.86532211303711

iterator 2500, D_Loss:0.4485442638397217, G_Loss:18.91730308532715

iterator 2600, D_Loss:0.41941168904304504, G_Loss:19.737140655517578

iterator 2700, D_Loss:0.42269420623779297, G_Loss:21.612594604492188

iterator 2800, D_Loss:0.4359261095523834, G_Loss:20.940195083618164

iterator 2900, D_Loss:0.42566928267478943, G_Loss:18.903606414794922

iterator 3000, D_Loss:0.41028058528900146, G_Loss:23.67656707763672

iterator 3100, D_Loss:0.4534490704536438, G_Loss:23.85542869567871

iterator 3200, D_Loss:0.4301254153251648, G_Loss:21.970361709594727

iterator 3300, D_Loss:0.4293102025985718, G_Loss:19.766090393066406

iterator 3400, D_Loss:0.42514756321907043, G_Loss:21.13431739807129

iterator 3500, D_Loss:0.43296006321907043, G_Loss:16.862287521362305

iterator 3600, D_Loss:0.4338676929473877, G_Loss:19.55575180053711

iterator 3700, D_Loss:0.4175972640514374, G_Loss:21.068361282348633

iterator 3800, D_Loss:0.4190100133419037, G_Loss:18.76642417907715

iterator 3900, D_Loss:0.43648841977119446, G_Loss:20.88066291809082

iterator 4000, D_Loss:0.41316068172454834, G_Loss:18.387426376342773

iterator 4100, D_Loss:0.42428138852119446, G_Loss:20.976505279541016

iterator 4200, D_Loss:0.42260241508483887, G_Loss:19.477214813232422

iterator 4300, D_Loss:0.4250035583972931, G_Loss:21.309097290039062

iterator 4400, D_Loss:0.4371570348739624, G_Loss:20.442211151123047

iterator 4500, D_Loss:0.42166438698768616, G_Loss:20.705142974853516

iterator 4600, D_Loss:0.4208812713623047, G_Loss:20.69779396057129

iterator 4700, D_Loss:0.4480990767478943, G_Loss:17.597652435302734

iterator 4800, D_Loss:0.43156731128692627, G_Loss:21.171232223510742

iterator 4900, D_Loss:0.42859092354774475, G_Loss:18.98251724243164

iterator 5000, D_Loss:0.4320926070213318, G_Loss:22.69031524658203

-----------Epoch 8-----------
iterator 100, D_Loss:0.4043673872947693, G_Loss:20.711803436279297

iterator 200, D_Loss:0.4043716788291931, G_Loss:18.148845672607422

iterator 300, D_Loss:0.4357142448425293, G_Loss:20.32260513305664

iterator 400, D_Loss:0.4223390221595764, G_Loss:20.090290069580078

iterator 500, D_Loss:0.41739463806152344, G_Loss:20.172252655029297

iterator 600, D_Loss:0.4190136790275574, G_Loss:20.16209602355957

iterator 700, D_Loss:0.43153712153434753, G_Loss:20.52165985107422

iterator 800, D_Loss:0.42523258924484253, G_Loss:17.9108829498291

iterator 900, D_Loss:0.4301067888736725, G_Loss:19.03306007385254

iterator 1000, D_Loss:0.4079400599002838, G_Loss:18.08945083618164

iterator 1100, D_Loss:0.4201227128505707, G_Loss:18.836959838867188

iterator 1200, D_Loss:0.42395395040512085, G_Loss:19.734806060791016

iterator 1300, D_Loss:0.4038315415382385, G_Loss:19.72184181213379

iterator 1400, D_Loss:0.42340388894081116, G_Loss:16.284358978271484

iterator 1500, D_Loss:0.4244009852409363, G_Loss:22.20092010498047

iterator 1600, D_Loss:0.4223884344100952, G_Loss:17.346084594726562

iterator 1700, D_Loss:0.42869699001312256, G_Loss:19.77989959716797

iterator 1800, D_Loss:0.42577439546585083, G_Loss:18.14515495300293

iterator 1900, D_Loss:0.41134774684906006, G_Loss:20.565418243408203

iterator 2000, D_Loss:0.43090179562568665, G_Loss:19.80996322631836

iterator 2100, D_Loss:0.4224814474582672, G_Loss:18.865415573120117

iterator 2200, D_Loss:0.4403243064880371, G_Loss:19.003158569335938

iterator 2300, D_Loss:0.4077376127243042, G_Loss:22.32476806640625

iterator 2400, D_Loss:0.4330921471118927, G_Loss:19.90019416809082

iterator 2500, D_Loss:0.4365849196910858, G_Loss:20.45187759399414

iterator 2600, D_Loss:0.42188119888305664, G_Loss:19.801738739013672

iterator 2700, D_Loss:0.4390380084514618, G_Loss:21.331592559814453

iterator 2800, D_Loss:0.42905184626579285, G_Loss:19.628559112548828

iterator 2900, D_Loss:0.4168951213359833, G_Loss:16.42325210571289

iterator 3000, D_Loss:0.4199466407299042, G_Loss:20.48373031616211

iterator 3100, D_Loss:0.41933006048202515, G_Loss:18.62701416015625

iterator 3200, D_Loss:0.4256679117679596, G_Loss:20.319690704345703

iterator 3300, D_Loss:0.42476627230644226, G_Loss:23.703880310058594

iterator 3400, D_Loss:0.4344407021999359, G_Loss:20.61964225769043

iterator 3500, D_Loss:0.40700778365135193, G_Loss:18.48420524597168

iterator 3600, D_Loss:0.4155520498752594, G_Loss:18.50481605529785

iterator 3700, D_Loss:0.42476657032966614, G_Loss:19.847698211669922

iterator 3800, D_Loss:0.4269636571407318, G_Loss:16.969276428222656

iterator 3900, D_Loss:0.43337851762771606, G_Loss:19.782997131347656

iterator 4000, D_Loss:0.43711742758750916, G_Loss:19.638450622558594

iterator 4100, D_Loss:0.42818331718444824, G_Loss:19.017192840576172

iterator 4200, D_Loss:0.43026211857795715, G_Loss:17.891895294189453

iterator 4300, D_Loss:0.4122696816921234, G_Loss:16.65238380432129

iterator 4400, D_Loss:0.42145639657974243, G_Loss:17.721721649169922

iterator 4500, D_Loss:0.42711183428764343, G_Loss:21.705724716186523

iterator 4600, D_Loss:0.4170917272567749, G_Loss:18.70943832397461

iterator 4700, D_Loss:0.4112120568752289, G_Loss:19.77336311340332

iterator 4800, D_Loss:0.4290812015533447, G_Loss:21.58722686767578

iterator 4900, D_Loss:0.4412853419780731, G_Loss:15.757266998291016

iterator 5000, D_Loss:0.41237974166870117, G_Loss:22.178943634033203

-----------Epoch 9-----------
iterator 100, D_Loss:0.41885805130004883, G_Loss:18.619720458984375

iterator 200, D_Loss:0.4343506693840027, G_Loss:18.62900733947754

iterator 300, D_Loss:0.43147414922714233, G_Loss:19.220500946044922

iterator 400, D_Loss:0.41935545206069946, G_Loss:18.372453689575195

iterator 500, D_Loss:0.4242731034755707, G_Loss:20.012474060058594

iterator 600, D_Loss:0.4498058259487152, G_Loss:17.476123809814453

iterator 700, D_Loss:0.43238455057144165, G_Loss:18.824256896972656

iterator 800, D_Loss:0.442659854888916, G_Loss:15.556777000427246

iterator 900, D_Loss:0.426655113697052, G_Loss:17.434951782226562

iterator 1000, D_Loss:0.4093491733074188, G_Loss:16.32046890258789

iterator 1100, D_Loss:0.4255527853965759, G_Loss:18.96862030029297

iterator 1200, D_Loss:0.4277956485748291, G_Loss:19.140588760375977

iterator 1300, D_Loss:0.4273752272129059, G_Loss:20.04500389099121

iterator 1400, D_Loss:0.429279625415802, G_Loss:15.838882446289062

iterator 1500, D_Loss:0.43456560373306274, G_Loss:20.029409408569336

iterator 1600, D_Loss:0.44561564922332764, G_Loss:16.524169921875

iterator 1700, D_Loss:0.43793225288391113, G_Loss:18.834461212158203

iterator 1800, D_Loss:0.411893367767334, G_Loss:14.399989128112793

iterator 1900, D_Loss:0.4186840057373047, G_Loss:19.698471069335938

iterator 2000, D_Loss:0.42344459891319275, G_Loss:17.153493881225586

iterator 2100, D_Loss:0.40159156918525696, G_Loss:17.883817672729492

iterator 2200, D_Loss:0.43158388137817383, G_Loss:17.047176361083984

iterator 2300, D_Loss:0.4270479083061218, G_Loss:20.701801300048828

iterator 2400, D_Loss:0.4139520227909088, G_Loss:17.023359298706055

iterator 2500, D_Loss:0.4255850315093994, G_Loss:16.73116111755371

iterator 2600, D_Loss:0.41268137097358704, G_Loss:16.68062400817871

iterator 2700, D_Loss:0.4213222861289978, G_Loss:17.944257736206055

iterator 2800, D_Loss:0.42995843291282654, G_Loss:17.159740447998047

iterator 2900, D_Loss:0.4219122529029846, G_Loss:14.732316970825195

iterator 3000, D_Loss:0.4231922924518585, G_Loss:19.225025177001953

iterator 3100, D_Loss:0.4431670308113098, G_Loss:18.912017822265625

iterator 3200, D_Loss:0.4329395294189453, G_Loss:19.086597442626953

iterator 3300, D_Loss:0.44879400730133057, G_Loss:16.03529930114746

iterator 3400, D_Loss:0.4025719165802002, G_Loss:18.079723358154297

iterator 3500, D_Loss:0.42055952548980713, G_Loss:15.756858825683594

iterator 3600, D_Loss:0.4349312484264374, G_Loss:16.333314895629883

iterator 3700, D_Loss:0.4223932921886444, G_Loss:18.13237190246582

iterator 3800, D_Loss:0.42869260907173157, G_Loss:15.589088439941406

iterator 3900, D_Loss:0.42214110493659973, G_Loss:16.877193450927734

iterator 4000, D_Loss:0.4216592609882355, G_Loss:17.376394271850586

iterator 4100, D_Loss:0.4293294847011566, G_Loss:17.772960662841797

iterator 4200, D_Loss:0.44205403327941895, G_Loss:16.359085083007812

iterator 4300, D_Loss:0.4414522051811218, G_Loss:17.322851181030273

iterator 4400, D_Loss:0.4127890467643738, G_Loss:16.531131744384766

iterator 4500, D_Loss:0.4176519215106964, G_Loss:16.686561584472656

iterator 4600, D_Loss:0.4339023232460022, G_Loss:15.367532730102539

iterator 4700, D_Loss:0.43714776635169983, G_Loss:14.51159381866455

iterator 4800, D_Loss:0.4177221655845642, G_Loss:16.384984970092773

iterator 4900, D_Loss:0.4321354925632477, G_Loss:14.492478370666504

iterator 5000, D_Loss:0.4311208128929138, G_Loss:17.302989959716797

LGAN_generator(
  (LSTM): LSTMCell(702, 400)
  (gmfc00): Linear(in_features=300, out_features=1, bias=True)
  (gmfc01): Linear(in_features=300, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=300, bias=True)
  (gmfe00): Linear(in_features=400, out_features=300, bias=True)
  (gmfe01): Linear(in_features=400, out_features=300, bias=True)
  (fc10): Linear(in_features=300, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=300, bias=True)
  (fe1): Linear(in_features=400, out_features=300, bias=True)
  (gmfc20): Linear(in_features=300, out_features=1, bias=True)
  (gmfc21): Linear(in_features=300, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=300, bias=True)
  (gmfe20): Linear(in_features=400, out_features=300, bias=True)
  (gmfe21): Linear(in_features=400, out_features=300, bias=True)
  (fc30): Linear(in_features=300, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=300, bias=True)
  (fe3): Linear(in_features=400, out_features=300, bias=True)
  (gmfc40): Linear(in_features=300, out_features=1, bias=True)
  (gmfc41): Linear(in_features=300, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=300, bias=True)
  (gmfe40): Linear(in_features=400, out_features=300, bias=True)
  (gmfe41): Linear(in_features=400, out_features=300, bias=True)
  (fc50): Linear(in_features=300, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=300, bias=True)
  (fe5): Linear(in_features=400, out_features=300, bias=True)
  (fc60): Linear(in_features=300, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=300, bias=True)
  (fe6): Linear(in_features=400, out_features=300, bias=True)
  (fc70): Linear(in_features=300, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=300, bias=True)
  (fe7): Linear(in_features=400, out_features=300, bias=True)
  (fc80): Linear(in_features=300, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=300, bias=True)
  (fe8): Linear(in_features=400, out_features=300, bias=True)
  (fc90): Linear(in_features=300, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=300, bias=True)
  (fe9): Linear(in_features=400, out_features=300, bias=True)
  (gmfc100): Linear(in_features=300, out_features=1, bias=True)
  (gmfc101): Linear(in_features=300, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=300, bias=True)
  (gmfe100): Linear(in_features=400, out_features=300, bias=True)
  (gmfe101): Linear(in_features=400, out_features=300, bias=True)
  (gmfc110): Linear(in_features=300, out_features=1, bias=True)
  (gmfc111): Linear(in_features=300, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=300, bias=True)
  (gmfe110): Linear(in_features=400, out_features=300, bias=True)
  (gmfe111): Linear(in_features=400, out_features=300, bias=True)
  (gmfc120): Linear(in_features=300, out_features=1, bias=True)
  (gmfc121): Linear(in_features=300, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=300, bias=True)
  (gmfe120): Linear(in_features=400, out_features=300, bias=True)
  (gmfe121): Linear(in_features=400, out_features=300, bias=True)
  (fc130): Linear(in_features=300, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=300, bias=True)
  (fe13): Linear(in_features=400, out_features=300, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=100, bias=True)
  (inputbn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=100, out_features=100, bias=True)
  (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=100, out_features=1, bias=True)
)
-----------Epoch 0-----------
iterator 100, D_Loss:1.3872425556182861, G_Loss:1.1739200353622437

iterator 200, D_Loss:1.3666417598724365, G_Loss:1.0977286100387573

iterator 300, D_Loss:1.340977668762207, G_Loss:1.131043553352356

iterator 400, D_Loss:1.2556593418121338, G_Loss:1.3782347440719604

iterator 500, D_Loss:1.200455904006958, G_Loss:1.3636422157287598

iterator 600, D_Loss:1.026524305343628, G_Loss:1.4503397941589355

iterator 700, D_Loss:1.0870089530944824, G_Loss:1.8303706645965576

iterator 800, D_Loss:1.0810552835464478, G_Loss:1.5367045402526855

iterator 900, D_Loss:1.2690985202789307, G_Loss:1.6658918857574463

iterator 1000, D_Loss:1.030049204826355, G_Loss:1.7088303565979004

iterator 1100, D_Loss:1.1914503574371338, G_Loss:1.3320125341415405

iterator 1200, D_Loss:1.1708958148956299, G_Loss:1.640711784362793

iterator 1300, D_Loss:1.575451374053955, G_Loss:1.469072937965393

iterator 1400, D_Loss:1.573317050933838, G_Loss:1.332685947418213

iterator 1500, D_Loss:1.348336935043335, G_Loss:1.627272605895996

iterator 1600, D_Loss:1.0025670528411865, G_Loss:2.0645394325256348

iterator 1700, D_Loss:0.8575994968414307, G_Loss:2.9440643787384033

iterator 1800, D_Loss:0.6935005187988281, G_Loss:3.086158275604248

iterator 1900, D_Loss:0.6604742407798767, G_Loss:3.1780972480773926

iterator 2000, D_Loss:0.5934253334999084, G_Loss:4.311683654785156

iterator 2100, D_Loss:0.779348611831665, G_Loss:3.992494821548462

iterator 2200, D_Loss:0.5987917184829712, G_Loss:4.462995529174805

iterator 2300, D_Loss:0.5653102993965149, G_Loss:3.8987982273101807

iterator 2400, D_Loss:0.5386551022529602, G_Loss:4.554648399353027

iterator 2500, D_Loss:0.6440206170082092, G_Loss:4.976388454437256

iterator 2600, D_Loss:0.4809767007827759, G_Loss:5.7729692459106445

iterator 2700, D_Loss:0.5174745321273804, G_Loss:5.701931476593018

iterator 2800, D_Loss:0.6015008687973022, G_Loss:3.9622411727905273

iterator 2900, D_Loss:0.5415118336677551, G_Loss:6.426415920257568

iterator 3000, D_Loss:0.53429114818573, G_Loss:5.050149917602539

iterator 3100, D_Loss:0.5898396968841553, G_Loss:5.825408935546875

iterator 3200, D_Loss:0.7105181217193604, G_Loss:5.712029457092285

iterator 3300, D_Loss:0.5511965155601501, G_Loss:5.826730728149414

iterator 3400, D_Loss:0.5407832860946655, G_Loss:5.859805583953857

iterator 3500, D_Loss:0.497039794921875, G_Loss:6.135996341705322

iterator 3600, D_Loss:0.6243027448654175, G_Loss:5.685276985168457

iterator 3700, D_Loss:0.4960589110851288, G_Loss:8.010992050170898

iterator 3800, D_Loss:0.4763749837875366, G_Loss:7.996649265289307

iterator 3900, D_Loss:0.5161547660827637, G_Loss:7.652690887451172

iterator 4000, D_Loss:0.5859624743461609, G_Loss:10.145283699035645

iterator 4100, D_Loss:0.5222166180610657, G_Loss:7.947032928466797

iterator 4200, D_Loss:0.46534135937690735, G_Loss:8.372529029846191

iterator 4300, D_Loss:0.47915905714035034, G_Loss:8.494962692260742

iterator 4400, D_Loss:0.4941389858722687, G_Loss:9.257840156555176

iterator 4500, D_Loss:0.49562278389930725, G_Loss:9.96226692199707

iterator 4600, D_Loss:0.5520148277282715, G_Loss:8.567767143249512

iterator 4700, D_Loss:0.48205500841140747, G_Loss:10.167890548706055

iterator 4800, D_Loss:0.4701557755470276, G_Loss:8.95566177368164

iterator 4900, D_Loss:0.45224133133888245, G_Loss:8.157036781311035

iterator 5000, D_Loss:0.454531192779541, G_Loss:9.840274810791016

-----------Epoch 1-----------
iterator 100, D_Loss:0.464364618062973, G_Loss:10.218539237976074

iterator 200, D_Loss:0.5045557618141174, G_Loss:7.753842353820801

iterator 300, D_Loss:0.4651625454425812, G_Loss:9.928658485412598

iterator 400, D_Loss:0.48290106654167175, G_Loss:7.713168621063232

iterator 500, D_Loss:0.49157968163490295, G_Loss:12.81224250793457

iterator 600, D_Loss:0.46694740653038025, G_Loss:11.755290985107422

iterator 700, D_Loss:0.45145222544670105, G_Loss:11.888368606567383

iterator 800, D_Loss:0.464638352394104, G_Loss:9.75299072265625

iterator 900, D_Loss:0.45221078395843506, G_Loss:11.99306583404541

iterator 1000, D_Loss:0.4806578457355499, G_Loss:11.60049057006836

iterator 1100, D_Loss:0.43804046511650085, G_Loss:12.50377368927002

iterator 1200, D_Loss:0.46638715267181396, G_Loss:12.368280410766602

iterator 1300, D_Loss:0.448141872882843, G_Loss:13.69522476196289

iterator 1400, D_Loss:0.4582807719707489, G_Loss:13.973584175109863

iterator 1500, D_Loss:0.43875718116760254, G_Loss:14.926200866699219

iterator 1600, D_Loss:0.4518642723560333, G_Loss:10.989429473876953

iterator 1700, D_Loss:0.4528964161872864, G_Loss:11.563413619995117

iterator 1800, D_Loss:0.4127383232116699, G_Loss:14.159488677978516

iterator 1900, D_Loss:0.43841269612312317, G_Loss:13.404245376586914

iterator 2000, D_Loss:0.4137488603591919, G_Loss:13.426410675048828

iterator 2100, D_Loss:0.43786391615867615, G_Loss:13.815008163452148

iterator 2200, D_Loss:0.43325117230415344, G_Loss:12.422945022583008

iterator 2300, D_Loss:0.4573826789855957, G_Loss:13.006820678710938

iterator 2400, D_Loss:0.4315517246723175, G_Loss:12.8999662399292

iterator 2500, D_Loss:0.44234082102775574, G_Loss:14.234603881835938

iterator 2600, D_Loss:0.41392895579338074, G_Loss:15.56059741973877

iterator 2700, D_Loss:0.44359290599823, G_Loss:14.105918884277344

iterator 2800, D_Loss:0.4167540669441223, G_Loss:13.171831130981445

iterator 2900, D_Loss:0.4541921317577362, G_Loss:16.516395568847656

iterator 3000, D_Loss:0.4223780333995819, G_Loss:15.765052795410156

iterator 3100, D_Loss:0.4307438135147095, G_Loss:13.301785469055176

iterator 3200, D_Loss:0.419392466545105, G_Loss:12.25020694732666

iterator 3300, D_Loss:0.41896921396255493, G_Loss:11.5021333694458

iterator 3400, D_Loss:0.4216347634792328, G_Loss:12.394938468933105

iterator 3500, D_Loss:0.39861997961997986, G_Loss:13.990716934204102

iterator 3600, D_Loss:0.4039953649044037, G_Loss:14.99439811706543

iterator 3700, D_Loss:0.4133014380931854, G_Loss:12.637981414794922

iterator 3800, D_Loss:0.4470428228378296, G_Loss:19.121273040771484

iterator 3900, D_Loss:0.42050376534461975, G_Loss:13.287513732910156

iterator 4000, D_Loss:0.45871707797050476, G_Loss:15.539145469665527

iterator 4100, D_Loss:0.4549157917499542, G_Loss:11.635799407958984

iterator 4200, D_Loss:0.4621712565422058, G_Loss:14.103909492492676

iterator 4300, D_Loss:0.41484302282333374, G_Loss:16.12325096130371

iterator 4400, D_Loss:0.4235309660434723, G_Loss:14.977617263793945

iterator 4500, D_Loss:0.44084590673446655, G_Loss:13.70854377746582

iterator 4600, D_Loss:0.4291650354862213, G_Loss:15.776291847229004

iterator 4700, D_Loss:0.43746042251586914, G_Loss:14.14773941040039

iterator 4800, D_Loss:0.44064733386039734, G_Loss:15.36530876159668

iterator 4900, D_Loss:0.4128052294254303, G_Loss:12.88574504852295

iterator 5000, D_Loss:0.427086740732193, G_Loss:13.237004280090332

-----------Epoch 2-----------
iterator 100, D_Loss:0.4256497621536255, G_Loss:12.510808944702148

iterator 200, D_Loss:0.4322093427181244, G_Loss:12.866484642028809

iterator 300, D_Loss:0.42989563941955566, G_Loss:16.343189239501953

iterator 400, D_Loss:0.4438924193382263, G_Loss:13.198155403137207

iterator 500, D_Loss:0.40609243512153625, G_Loss:17.026832580566406

iterator 600, D_Loss:0.4238947927951813, G_Loss:13.883761405944824

iterator 700, D_Loss:0.4429289400577545, G_Loss:14.864986419677734

iterator 800, D_Loss:0.4276351034641266, G_Loss:13.895501136779785

iterator 900, D_Loss:0.4464738965034485, G_Loss:14.62869644165039

iterator 1000, D_Loss:0.4134667217731476, G_Loss:15.011286735534668

iterator 1100, D_Loss:0.406250923871994, G_Loss:16.243175506591797

iterator 1200, D_Loss:0.4156140089035034, G_Loss:14.24028491973877

iterator 1300, D_Loss:0.4330090582370758, G_Loss:14.653363227844238

iterator 1400, D_Loss:0.4341224730014801, G_Loss:16.416391372680664

iterator 1500, D_Loss:0.44410282373428345, G_Loss:15.223008155822754

iterator 1600, D_Loss:0.42488452792167664, G_Loss:12.469903945922852

iterator 1700, D_Loss:0.39392852783203125, G_Loss:17.188289642333984

iterator 1800, D_Loss:0.44688135385513306, G_Loss:15.359006881713867

iterator 1900, D_Loss:0.42087697982788086, G_Loss:14.63239860534668

iterator 2000, D_Loss:0.44177478551864624, G_Loss:21.30076789855957

iterator 2100, D_Loss:0.4524073302745819, G_Loss:18.660444259643555

iterator 2200, D_Loss:0.4303341805934906, G_Loss:18.95392608642578

iterator 2300, D_Loss:0.44417011737823486, G_Loss:19.051544189453125

iterator 2400, D_Loss:0.4139268100261688, G_Loss:18.970279693603516

iterator 2500, D_Loss:0.4467451572418213, G_Loss:20.75299835205078

iterator 2600, D_Loss:0.4269319474697113, G_Loss:20.711246490478516

iterator 2700, D_Loss:0.4193308651447296, G_Loss:21.27240753173828

iterator 2800, D_Loss:0.4302183985710144, G_Loss:18.97947883605957

iterator 2900, D_Loss:0.4373384714126587, G_Loss:22.787338256835938

iterator 3000, D_Loss:0.4244470000267029, G_Loss:21.970808029174805

iterator 3100, D_Loss:0.3870411515235901, G_Loss:18.31189727783203

iterator 3200, D_Loss:0.4444892406463623, G_Loss:21.20806121826172

iterator 3300, D_Loss:0.4359930455684662, G_Loss:19.103275299072266

iterator 3400, D_Loss:0.4518680274486542, G_Loss:17.91543197631836

iterator 3500, D_Loss:0.43328341841697693, G_Loss:18.54143714904785

iterator 3600, D_Loss:0.4402766823768616, G_Loss:18.12730598449707

iterator 3700, D_Loss:0.4414742588996887, G_Loss:12.625494003295898

iterator 3800, D_Loss:0.4278069734573364, G_Loss:18.301677703857422

iterator 3900, D_Loss:0.3835006654262543, G_Loss:18.21784019470215

iterator 4000, D_Loss:0.4304881989955902, G_Loss:19.146625518798828

iterator 4100, D_Loss:0.44326215982437134, G_Loss:13.798345565795898

iterator 4200, D_Loss:0.41403651237487793, G_Loss:20.491662979125977

iterator 4300, D_Loss:0.408094584941864, G_Loss:16.40856170654297

iterator 4400, D_Loss:0.4376153349876404, G_Loss:17.154659271240234

iterator 4500, D_Loss:0.44651639461517334, G_Loss:17.910465240478516

iterator 4600, D_Loss:0.44747915863990784, G_Loss:20.07482147216797

iterator 4700, D_Loss:0.457833856344223, G_Loss:20.792903900146484

iterator 4800, D_Loss:0.41360536217689514, G_Loss:18.070819854736328

iterator 4900, D_Loss:0.4427123963832855, G_Loss:16.3765869140625

iterator 5000, D_Loss:0.45011869072914124, G_Loss:15.909228324890137

-----------Epoch 3-----------
iterator 100, D_Loss:0.43685653805732727, G_Loss:16.26683807373047

iterator 200, D_Loss:0.45906099677085876, G_Loss:13.658504486083984

iterator 300, D_Loss:0.40467777848243713, G_Loss:15.958589553833008

iterator 400, D_Loss:0.4525530934333801, G_Loss:14.144865989685059

iterator 500, D_Loss:0.4347451329231262, G_Loss:19.720417022705078

iterator 600, D_Loss:0.39921069145202637, G_Loss:18.408191680908203

iterator 700, D_Loss:0.433707058429718, G_Loss:17.841144561767578

iterator 800, D_Loss:0.4216383397579193, G_Loss:17.585681915283203

iterator 900, D_Loss:0.4388859272003174, G_Loss:18.228879928588867

iterator 1000, D_Loss:0.41942673921585083, G_Loss:17.165775299072266

iterator 1100, D_Loss:0.42611056566238403, G_Loss:17.506738662719727

iterator 1200, D_Loss:0.4311334490776062, G_Loss:18.169612884521484

iterator 1300, D_Loss:0.4263971149921417, G_Loss:18.151775360107422

iterator 1400, D_Loss:0.43715333938598633, G_Loss:21.63931655883789

iterator 1500, D_Loss:0.4480465054512024, G_Loss:18.242029190063477

iterator 1600, D_Loss:0.44389593601226807, G_Loss:17.17551040649414

iterator 1700, D_Loss:0.4337802827358246, G_Loss:20.02486228942871

iterator 1800, D_Loss:0.42206287384033203, G_Loss:18.62545394897461

iterator 1900, D_Loss:0.4075061082839966, G_Loss:14.706123352050781

iterator 2000, D_Loss:0.4161841571331024, G_Loss:18.563758850097656

iterator 2100, D_Loss:0.5170484781265259, G_Loss:17.68159294128418

iterator 2200, D_Loss:0.4316973388195038, G_Loss:17.710132598876953

iterator 2300, D_Loss:0.4299887418746948, G_Loss:17.103666305541992

iterator 2400, D_Loss:0.4383472502231598, G_Loss:16.784225463867188

iterator 2500, D_Loss:0.4298698604106903, G_Loss:16.198566436767578

iterator 2600, D_Loss:0.4622577726840973, G_Loss:15.217117309570312

iterator 2700, D_Loss:0.4394412338733673, G_Loss:18.402400970458984

iterator 2800, D_Loss:0.4009295105934143, G_Loss:18.22801971435547

iterator 2900, D_Loss:0.43795761466026306, G_Loss:18.55013656616211

iterator 3000, D_Loss:0.43057355284690857, G_Loss:18.80374526977539

iterator 3100, D_Loss:0.44395309686660767, G_Loss:17.232250213623047

iterator 3200, D_Loss:0.4388113021850586, G_Loss:12.883638381958008

iterator 3300, D_Loss:0.4282468855381012, G_Loss:17.78244972229004

iterator 3400, D_Loss:0.4673633873462677, G_Loss:19.145296096801758

iterator 3500, D_Loss:0.4145372211933136, G_Loss:16.338096618652344

iterator 3600, D_Loss:0.4310324192047119, G_Loss:15.875106811523438

iterator 3700, D_Loss:0.43167898058891296, G_Loss:19.063743591308594

iterator 3800, D_Loss:0.43098366260528564, G_Loss:16.5322265625

iterator 3900, D_Loss:0.4145466387271881, G_Loss:15.302604675292969

iterator 4000, D_Loss:0.3951408565044403, G_Loss:18.65662384033203

iterator 4100, D_Loss:0.4310983121395111, G_Loss:16.163803100585938

iterator 4200, D_Loss:0.45414969325065613, G_Loss:19.481557846069336

iterator 4300, D_Loss:0.4154720902442932, G_Loss:19.697093963623047

iterator 4400, D_Loss:0.4409697353839874, G_Loss:19.543506622314453

iterator 4500, D_Loss:0.4058583080768585, G_Loss:20.949411392211914

iterator 4600, D_Loss:0.48851922154426575, G_Loss:20.56047821044922

iterator 4700, D_Loss:0.42966386675834656, G_Loss:17.118968963623047

iterator 4800, D_Loss:0.4013066291809082, G_Loss:20.739151000976562

iterator 4900, D_Loss:0.4422001242637634, G_Loss:17.011234283447266

iterator 5000, D_Loss:0.424248605966568, G_Loss:19.089527130126953

-----------Epoch 4-----------
iterator 100, D_Loss:0.4131831228733063, G_Loss:19.914627075195312

iterator 200, D_Loss:0.43461596965789795, G_Loss:16.700225830078125

iterator 300, D_Loss:0.4140869379043579, G_Loss:17.45095443725586

iterator 400, D_Loss:0.43465715646743774, G_Loss:18.77074432373047

iterator 500, D_Loss:0.4460231065750122, G_Loss:19.693702697753906

iterator 600, D_Loss:0.4090942442417145, G_Loss:22.887754440307617

iterator 700, D_Loss:0.418951153755188, G_Loss:20.225114822387695

iterator 800, D_Loss:0.4552158713340759, G_Loss:19.803489685058594

iterator 900, D_Loss:0.43470466136932373, G_Loss:18.203460693359375

iterator 1000, D_Loss:0.4051743745803833, G_Loss:17.45488929748535

iterator 1100, D_Loss:0.4291576147079468, G_Loss:17.168737411499023

iterator 1200, D_Loss:0.42356351017951965, G_Loss:17.654865264892578

iterator 1300, D_Loss:0.4404728412628174, G_Loss:20.16094207763672

iterator 1400, D_Loss:0.4395771622657776, G_Loss:18.23416519165039

iterator 1500, D_Loss:0.4378630518913269, G_Loss:18.703182220458984

iterator 1600, D_Loss:0.44691741466522217, G_Loss:16.785737991333008

iterator 1700, D_Loss:0.418422132730484, G_Loss:18.805076599121094

iterator 1800, D_Loss:0.4093650281429291, G_Loss:20.66773223876953

iterator 1900, D_Loss:0.423189640045166, G_Loss:16.835187911987305

iterator 2000, D_Loss:0.40478575229644775, G_Loss:21.140047073364258

iterator 2100, D_Loss:0.40606680512428284, G_Loss:22.932106018066406

iterator 2200, D_Loss:0.410634845495224, G_Loss:21.328845977783203

iterator 2300, D_Loss:0.4169933497905731, G_Loss:18.60504722595215

iterator 2400, D_Loss:0.42284175753593445, G_Loss:17.737548828125

iterator 2500, D_Loss:0.44781041145324707, G_Loss:21.602142333984375

iterator 2600, D_Loss:0.4125921428203583, G_Loss:18.7493896484375

iterator 2700, D_Loss:0.4449819028377533, G_Loss:21.394554138183594

iterator 2800, D_Loss:0.41436895728111267, G_Loss:21.38968849182129

iterator 2900, D_Loss:0.4344142973423004, G_Loss:23.251670837402344

iterator 3000, D_Loss:0.42198947072029114, G_Loss:22.674053192138672

iterator 3100, D_Loss:0.43635204434394836, G_Loss:23.544496536254883

iterator 3200, D_Loss:0.3897329866886139, G_Loss:22.558307647705078

iterator 3300, D_Loss:0.4068501591682434, G_Loss:22.41655731201172

iterator 3400, D_Loss:0.41786953806877136, G_Loss:17.760896682739258

iterator 3500, D_Loss:0.45303165912628174, G_Loss:21.071937561035156

iterator 3600, D_Loss:0.4222196042537689, G_Loss:18.064910888671875

iterator 3700, D_Loss:0.4495508372783661, G_Loss:20.76560401916504

iterator 3800, D_Loss:0.43048468232154846, G_Loss:19.211395263671875

iterator 3900, D_Loss:0.4647519886493683, G_Loss:20.584442138671875

iterator 4000, D_Loss:0.4137631952762604, G_Loss:21.94619369506836

iterator 4100, D_Loss:0.4281173348426819, G_Loss:14.844624519348145

iterator 4200, D_Loss:0.413154661655426, G_Loss:18.792327880859375

iterator 4300, D_Loss:0.41552796959877014, G_Loss:19.22488021850586

iterator 4400, D_Loss:0.43475937843322754, G_Loss:19.21752166748047

iterator 4500, D_Loss:0.42353618144989014, G_Loss:20.978984832763672

iterator 4600, D_Loss:0.41293027997016907, G_Loss:19.228130340576172

iterator 4700, D_Loss:0.4409324526786804, G_Loss:21.49571990966797

iterator 4800, D_Loss:0.4263540208339691, G_Loss:20.456512451171875

iterator 4900, D_Loss:0.4301608204841614, G_Loss:19.549646377563477

iterator 5000, D_Loss:0.399749755859375, G_Loss:21.354286193847656

-----------Epoch 5-----------
iterator 100, D_Loss:0.41870394349098206, G_Loss:21.078758239746094

iterator 200, D_Loss:0.4118904769420624, G_Loss:20.706764221191406

iterator 300, D_Loss:0.4329431653022766, G_Loss:22.114898681640625

iterator 400, D_Loss:0.4307801425457001, G_Loss:18.925533294677734

iterator 500, D_Loss:0.42453184723854065, G_Loss:21.256017684936523

iterator 600, D_Loss:0.4479127526283264, G_Loss:20.60027313232422

iterator 700, D_Loss:0.43740808963775635, G_Loss:23.42072868347168

iterator 800, D_Loss:0.43108636140823364, G_Loss:21.790206909179688

iterator 900, D_Loss:0.42156288027763367, G_Loss:21.39968490600586

iterator 1000, D_Loss:0.43907806277275085, G_Loss:16.87319564819336

iterator 1100, D_Loss:0.4479544758796692, G_Loss:17.457672119140625

iterator 1200, D_Loss:0.43336227536201477, G_Loss:16.895288467407227

iterator 1300, D_Loss:0.45801621675491333, G_Loss:16.046098709106445

iterator 1400, D_Loss:0.43079984188079834, G_Loss:19.413387298583984

iterator 1500, D_Loss:0.4279623031616211, G_Loss:17.108083724975586

iterator 1600, D_Loss:0.4344768226146698, G_Loss:13.685672760009766

iterator 1700, D_Loss:0.428606241941452, G_Loss:19.453336715698242

iterator 1800, D_Loss:0.44206559658050537, G_Loss:20.073436737060547

iterator 1900, D_Loss:0.4175306558609009, G_Loss:14.53494644165039

iterator 2000, D_Loss:0.41660118103027344, G_Loss:16.8944149017334

iterator 2100, D_Loss:0.4724407494068146, G_Loss:19.63153076171875

iterator 2200, D_Loss:0.42509958148002625, G_Loss:19.19864273071289

iterator 2300, D_Loss:0.43954014778137207, G_Loss:20.65765380859375

iterator 2400, D_Loss:0.4084806740283966, G_Loss:17.970054626464844

iterator 2500, D_Loss:0.4175571799278259, G_Loss:21.098575592041016

iterator 2600, D_Loss:0.4068934917449951, G_Loss:22.218059539794922

iterator 2700, D_Loss:0.4243881106376648, G_Loss:19.987716674804688

iterator 2800, D_Loss:0.44571295380592346, G_Loss:19.10312271118164

iterator 2900, D_Loss:0.4495505094528198, G_Loss:21.441421508789062

iterator 3000, D_Loss:0.4503946006298065, G_Loss:20.94771957397461

iterator 3100, D_Loss:0.43889641761779785, G_Loss:21.367074966430664

iterator 3200, D_Loss:0.43110930919647217, G_Loss:18.548627853393555

iterator 3300, D_Loss:0.42879346013069153, G_Loss:22.312829971313477

iterator 3400, D_Loss:0.43501514196395874, G_Loss:20.701284408569336

iterator 3500, D_Loss:0.43396270275115967, G_Loss:20.532501220703125

iterator 3600, D_Loss:0.4316273033618927, G_Loss:22.575050354003906

iterator 3700, D_Loss:0.4175706207752228, G_Loss:20.82468605041504

iterator 3800, D_Loss:0.4130171835422516, G_Loss:22.072113037109375

iterator 3900, D_Loss:0.42135462164878845, G_Loss:21.662111282348633

iterator 4000, D_Loss:0.4353986084461212, G_Loss:21.480430603027344

iterator 4100, D_Loss:0.4127971827983856, G_Loss:18.1092472076416

iterator 4200, D_Loss:0.42429524660110474, G_Loss:20.775726318359375

iterator 4300, D_Loss:0.4256603419780731, G_Loss:24.065092086791992

iterator 4400, D_Loss:0.42707088589668274, G_Loss:20.968534469604492

iterator 4500, D_Loss:0.4411926567554474, G_Loss:22.86138153076172

iterator 4600, D_Loss:0.4211345911026001, G_Loss:23.54651641845703

iterator 4700, D_Loss:0.41812583804130554, G_Loss:25.674190521240234

iterator 4800, D_Loss:0.44773420691490173, G_Loss:23.498031616210938

iterator 4900, D_Loss:0.4352988600730896, G_Loss:22.35403823852539

iterator 5000, D_Loss:0.40359756350517273, G_Loss:22.763025283813477

-----------Epoch 6-----------
iterator 100, D_Loss:0.4241108298301697, G_Loss:21.00267219543457

iterator 200, D_Loss:0.4013881981372833, G_Loss:19.917146682739258

iterator 300, D_Loss:0.4603325426578522, G_Loss:21.452255249023438

iterator 400, D_Loss:0.4290158152580261, G_Loss:20.47216796875

iterator 500, D_Loss:0.4232012927532196, G_Loss:22.728073120117188

iterator 600, D_Loss:0.41136547923088074, G_Loss:20.744749069213867

iterator 700, D_Loss:0.43317314982414246, G_Loss:20.86333656311035

iterator 800, D_Loss:0.4295404255390167, G_Loss:17.687328338623047

iterator 900, D_Loss:0.4298669099807739, G_Loss:19.561067581176758

iterator 1000, D_Loss:0.410896360874176, G_Loss:21.293397903442383

iterator 1100, D_Loss:0.45434752106666565, G_Loss:20.60894012451172

iterator 1200, D_Loss:0.4269111454486847, G_Loss:21.422975540161133

iterator 1300, D_Loss:0.39682838320732117, G_Loss:21.8991756439209

iterator 1400, D_Loss:0.44307053089141846, G_Loss:12.357152938842773

iterator 1500, D_Loss:0.4269036650657654, G_Loss:17.102384567260742

iterator 1600, D_Loss:0.44622933864593506, G_Loss:16.511642456054688

iterator 1700, D_Loss:0.3954687714576721, G_Loss:16.508459091186523

iterator 1800, D_Loss:0.40450233221054077, G_Loss:16.252031326293945

iterator 1900, D_Loss:0.4415625035762787, G_Loss:14.917285919189453

iterator 2000, D_Loss:0.43901270627975464, G_Loss:17.96819305419922

iterator 2100, D_Loss:0.44367048144340515, G_Loss:17.073974609375

iterator 2200, D_Loss:0.4412003457546234, G_Loss:16.68209457397461

iterator 2300, D_Loss:0.4386447072029114, G_Loss:18.50707244873047

iterator 2400, D_Loss:0.4134954512119293, G_Loss:20.25039291381836

iterator 2500, D_Loss:0.40356916189193726, G_Loss:20.31781768798828

iterator 2600, D_Loss:0.4077209532260895, G_Loss:20.17529296875

iterator 2700, D_Loss:0.3992598354816437, G_Loss:19.931917190551758

iterator 2800, D_Loss:0.4376335144042969, G_Loss:16.6921329498291

iterator 2900, D_Loss:0.4279594123363495, G_Loss:21.072572708129883

iterator 3000, D_Loss:0.4184969365596771, G_Loss:21.807575225830078

iterator 3100, D_Loss:0.3995738923549652, G_Loss:18.923187255859375

iterator 3200, D_Loss:0.43528762459754944, G_Loss:21.346893310546875

iterator 3300, D_Loss:0.4172866940498352, G_Loss:19.884307861328125

iterator 3400, D_Loss:0.43439003825187683, G_Loss:21.242116928100586

iterator 3500, D_Loss:0.4178314208984375, G_Loss:20.287622451782227

iterator 3600, D_Loss:0.4399036169052124, G_Loss:19.338687896728516

iterator 3700, D_Loss:0.4091905951499939, G_Loss:20.68779945373535

iterator 3800, D_Loss:0.4168390929698944, G_Loss:22.39848518371582

iterator 3900, D_Loss:0.43824639916419983, G_Loss:20.466672897338867

iterator 4000, D_Loss:0.40034762024879456, G_Loss:22.290794372558594

iterator 4100, D_Loss:0.423572838306427, G_Loss:15.395097732543945

iterator 4200, D_Loss:0.39989984035491943, G_Loss:21.140779495239258

iterator 4300, D_Loss:0.4275730550289154, G_Loss:21.401813507080078

iterator 4400, D_Loss:0.42908474802970886, G_Loss:20.0454044342041

iterator 4500, D_Loss:0.44603508710861206, G_Loss:21.78226089477539

iterator 4600, D_Loss:0.4570963680744171, G_Loss:20.45669174194336

iterator 4700, D_Loss:0.4339355528354645, G_Loss:22.390893936157227

iterator 4800, D_Loss:0.4231566786766052, G_Loss:21.750883102416992

iterator 4900, D_Loss:0.4671996533870697, G_Loss:20.983291625976562

iterator 5000, D_Loss:0.4214508831501007, G_Loss:21.491703033447266

-----------Epoch 7-----------
iterator 100, D_Loss:0.43578851222991943, G_Loss:21.1332950592041

iterator 200, D_Loss:0.4102683365345001, G_Loss:20.201997756958008

iterator 300, D_Loss:0.4106886088848114, G_Loss:20.93846893310547

iterator 400, D_Loss:0.4047733247280121, G_Loss:17.283859252929688

iterator 500, D_Loss:0.4234546720981598, G_Loss:19.736698150634766

iterator 600, D_Loss:0.4329129755496979, G_Loss:21.203716278076172

iterator 700, D_Loss:0.45397087931632996, G_Loss:22.521533966064453

iterator 800, D_Loss:0.43270638585090637, G_Loss:20.932035446166992

iterator 900, D_Loss:0.43179967999458313, G_Loss:20.231979370117188

iterator 1000, D_Loss:0.420369952917099, G_Loss:19.449220657348633

iterator 1100, D_Loss:0.4418772757053375, G_Loss:21.339805603027344

iterator 1200, D_Loss:0.4513677954673767, G_Loss:19.72347640991211

iterator 1300, D_Loss:0.421138197183609, G_Loss:21.049083709716797

iterator 1400, D_Loss:0.42877423763275146, G_Loss:15.667119979858398

iterator 1500, D_Loss:0.41664233803749084, G_Loss:19.85865020751953

iterator 1600, D_Loss:0.42306751012802124, G_Loss:15.481545448303223

iterator 1700, D_Loss:0.42312565445899963, G_Loss:21.514083862304688

iterator 1800, D_Loss:0.42411285638809204, G_Loss:19.74282455444336

iterator 1900, D_Loss:0.4298906922340393, G_Loss:17.708311080932617

iterator 2000, D_Loss:0.40506747364997864, G_Loss:20.404138565063477

iterator 2100, D_Loss:0.41349923610687256, G_Loss:23.499740600585938

iterator 2200, D_Loss:0.4514552354812622, G_Loss:20.788225173950195

iterator 2300, D_Loss:0.42814961075782776, G_Loss:20.091129302978516

iterator 2400, D_Loss:0.44003626704216003, G_Loss:23.05211067199707

iterator 2500, D_Loss:0.4339252710342407, G_Loss:22.766042709350586

iterator 2600, D_Loss:0.4220291078090668, G_Loss:23.005952835083008

iterator 2700, D_Loss:0.4233601689338684, G_Loss:21.500404357910156

iterator 2800, D_Loss:0.4319060146808624, G_Loss:19.503253936767578

iterator 2900, D_Loss:0.403090238571167, G_Loss:21.835277557373047

iterator 3000, D_Loss:0.4164864122867584, G_Loss:21.938236236572266

iterator 3100, D_Loss:0.4340701699256897, G_Loss:21.975547790527344

iterator 3200, D_Loss:0.4296641945838928, G_Loss:19.36665916442871

iterator 3300, D_Loss:0.41688936948776245, G_Loss:20.939998626708984

iterator 3400, D_Loss:0.40355637669563293, G_Loss:21.182756423950195

iterator 3500, D_Loss:0.4302295744419098, G_Loss:17.37584114074707

iterator 3600, D_Loss:0.4341004192829132, G_Loss:17.476171493530273

iterator 3700, D_Loss:0.460462361574173, G_Loss:23.16131019592285

iterator 3800, D_Loss:0.42133861780166626, G_Loss:22.47628402709961

iterator 3900, D_Loss:0.4634680449962616, G_Loss:20.178691864013672

iterator 4000, D_Loss:0.44203615188598633, G_Loss:19.160017013549805

iterator 4100, D_Loss:0.43740716576576233, G_Loss:17.892431259155273

iterator 4200, D_Loss:0.4436948597431183, G_Loss:25.164180755615234

iterator 4300, D_Loss:0.4435490369796753, G_Loss:23.468584060668945

iterator 4400, D_Loss:0.4658423662185669, G_Loss:22.706058502197266

iterator 4500, D_Loss:0.41214197874069214, G_Loss:25.055648803710938

iterator 4600, D_Loss:0.4288770854473114, G_Loss:23.851295471191406

iterator 4700, D_Loss:0.4274364411830902, G_Loss:19.47732162475586

iterator 4800, D_Loss:0.4351244270801544, G_Loss:22.793190002441406

iterator 4900, D_Loss:0.4641490578651428, G_Loss:20.22026252746582

iterator 5000, D_Loss:0.41630053520202637, G_Loss:18.530725479125977

-----------Epoch 8-----------
iterator 100, D_Loss:0.44605115056037903, G_Loss:22.28337860107422

iterator 200, D_Loss:0.42244672775268555, G_Loss:20.449068069458008

iterator 300, D_Loss:0.4185546338558197, G_Loss:22.26087188720703

iterator 400, D_Loss:0.41960409283638, G_Loss:20.88577651977539

iterator 500, D_Loss:0.4547722339630127, G_Loss:24.842266082763672

iterator 600, D_Loss:0.4199182093143463, G_Loss:24.341447830200195

iterator 700, D_Loss:0.42392417788505554, G_Loss:23.213876724243164

iterator 800, D_Loss:0.42773857712745667, G_Loss:21.409425735473633

iterator 900, D_Loss:0.4420946538448334, G_Loss:23.499059677124023

iterator 1000, D_Loss:0.4222885072231293, G_Loss:21.143108367919922

iterator 1100, D_Loss:0.3965429365634918, G_Loss:24.30439567565918

iterator 1200, D_Loss:0.4557812213897705, G_Loss:20.554271697998047

iterator 1300, D_Loss:0.4453093409538269, G_Loss:21.969608306884766

iterator 1400, D_Loss:0.41469433903694153, G_Loss:21.437946319580078

iterator 1500, D_Loss:0.4155837893486023, G_Loss:22.693622589111328

iterator 1600, D_Loss:0.42901328206062317, G_Loss:20.360443115234375

iterator 1700, D_Loss:0.4460000693798065, G_Loss:24.185836791992188

iterator 1800, D_Loss:0.4106386601924896, G_Loss:21.441129684448242

iterator 1900, D_Loss:0.42301130294799805, G_Loss:17.77399444580078

iterator 2000, D_Loss:0.42917948961257935, G_Loss:17.880325317382812

iterator 2100, D_Loss:0.42263761162757874, G_Loss:20.435606002807617

iterator 2200, D_Loss:0.4449998736381531, G_Loss:19.327627182006836

iterator 2300, D_Loss:0.4391171932220459, G_Loss:20.624422073364258

iterator 2400, D_Loss:0.42453518509864807, G_Loss:19.23831558227539

iterator 2500, D_Loss:0.44123995304107666, G_Loss:20.062824249267578

iterator 2600, D_Loss:0.4044244885444641, G_Loss:20.807266235351562

iterator 2700, D_Loss:0.41696277260780334, G_Loss:19.156539916992188

iterator 2800, D_Loss:0.427177369594574, G_Loss:16.357372283935547

iterator 2900, D_Loss:0.43573278188705444, G_Loss:20.33660125732422

iterator 3000, D_Loss:0.41179701685905457, G_Loss:19.46205711364746

iterator 3100, D_Loss:0.4164469242095947, G_Loss:19.560779571533203

iterator 3200, D_Loss:0.41933590173721313, G_Loss:18.641498565673828

iterator 3300, D_Loss:0.42554765939712524, G_Loss:20.37330436706543

iterator 3400, D_Loss:0.41984233260154724, G_Loss:19.070844650268555

iterator 3500, D_Loss:0.4212534427642822, G_Loss:20.214128494262695

iterator 3600, D_Loss:0.4324698746204376, G_Loss:19.370256423950195

iterator 3700, D_Loss:0.4401346743106842, G_Loss:22.01620101928711

iterator 3800, D_Loss:0.43367934226989746, G_Loss:21.21792221069336

iterator 3900, D_Loss:0.4055820405483246, G_Loss:19.95327377319336

iterator 4000, D_Loss:0.4506080150604248, G_Loss:20.727157592773438

iterator 4100, D_Loss:0.4415738582611084, G_Loss:16.5640926361084

iterator 4200, D_Loss:0.42648255825042725, G_Loss:20.318050384521484

iterator 4300, D_Loss:0.41256871819496155, G_Loss:22.004552841186523

iterator 4400, D_Loss:0.4283934533596039, G_Loss:19.222543716430664

iterator 4500, D_Loss:0.43429702520370483, G_Loss:21.698083877563477

iterator 4600, D_Loss:0.43531158566474915, G_Loss:20.68001937866211

iterator 4700, D_Loss:0.4380785822868347, G_Loss:19.713390350341797

iterator 4800, D_Loss:0.39791470766067505, G_Loss:21.734359741210938

iterator 4900, D_Loss:0.42728298902511597, G_Loss:20.118139266967773

iterator 5000, D_Loss:0.4469848573207855, G_Loss:15.54823112487793

-----------Epoch 9-----------
iterator 100, D_Loss:0.4071744978427887, G_Loss:17.90372085571289

iterator 200, D_Loss:0.42023375630378723, G_Loss:18.93088722229004

iterator 300, D_Loss:0.4022176265716553, G_Loss:18.633718490600586

iterator 400, D_Loss:0.4155855178833008, G_Loss:14.977999687194824

iterator 500, D_Loss:0.4121859073638916, G_Loss:14.115209579467773

iterator 600, D_Loss:0.43845731019973755, G_Loss:18.70511245727539

iterator 700, D_Loss:0.42104166746139526, G_Loss:15.852093696594238

iterator 800, D_Loss:0.40853050351142883, G_Loss:17.134183883666992

iterator 900, D_Loss:0.45396193861961365, G_Loss:17.234737396240234

iterator 1000, D_Loss:0.418672651052475, G_Loss:17.642690658569336

iterator 1100, D_Loss:0.429769903421402, G_Loss:16.765676498413086

iterator 1200, D_Loss:0.4225975573062897, G_Loss:19.751243591308594

iterator 1300, D_Loss:0.418907105922699, G_Loss:22.44373893737793

iterator 1400, D_Loss:0.42137542366981506, G_Loss:21.50074577331543

iterator 1500, D_Loss:0.43772268295288086, G_Loss:23.162202835083008

iterator 1600, D_Loss:0.43339860439300537, G_Loss:20.246322631835938

iterator 1700, D_Loss:0.42112410068511963, G_Loss:23.41363525390625

iterator 1800, D_Loss:0.4414881467819214, G_Loss:21.390735626220703

iterator 1900, D_Loss:0.42953434586524963, G_Loss:17.925872802734375

iterator 2000, D_Loss:0.42987364530563354, G_Loss:20.898517608642578

iterator 2100, D_Loss:0.4245850741863251, G_Loss:21.187421798706055

iterator 2200, D_Loss:0.4077775180339813, G_Loss:19.275392532348633

iterator 2300, D_Loss:0.4299124777317047, G_Loss:19.162525177001953

iterator 2400, D_Loss:0.42615869641304016, G_Loss:20.453048706054688

iterator 2500, D_Loss:0.452166885137558, G_Loss:20.74913215637207

iterator 2600, D_Loss:0.4164801836013794, G_Loss:22.118192672729492

iterator 2700, D_Loss:0.4477466642856598, G_Loss:20.519052505493164

iterator 2800, D_Loss:0.4157163202762604, G_Loss:19.788259506225586

iterator 2900, D_Loss:0.43737712502479553, G_Loss:19.159408569335938

iterator 3000, D_Loss:0.4513789415359497, G_Loss:22.12081527709961

iterator 3100, D_Loss:0.4467889666557312, G_Loss:19.845325469970703

iterator 3200, D_Loss:0.417010635137558, G_Loss:18.879486083984375

iterator 3300, D_Loss:0.42638686299324036, G_Loss:21.577287673950195

iterator 3400, D_Loss:0.40259596705436707, G_Loss:20.13225746154785

iterator 3500, D_Loss:0.42163169384002686, G_Loss:20.245262145996094

iterator 3600, D_Loss:0.44955015182495117, G_Loss:22.347393035888672

iterator 3700, D_Loss:0.45428574085235596, G_Loss:21.54547119140625

iterator 3800, D_Loss:0.436757355928421, G_Loss:23.57430648803711

iterator 3900, D_Loss:0.41842377185821533, G_Loss:22.94045639038086

iterator 4000, D_Loss:0.4220895767211914, G_Loss:20.910419464111328

iterator 4100, D_Loss:0.40999501943588257, G_Loss:17.600624084472656

iterator 4200, D_Loss:0.4389323890209198, G_Loss:22.820419311523438

iterator 4300, D_Loss:0.4356667101383209, G_Loss:22.757080078125

iterator 4400, D_Loss:0.45659172534942627, G_Loss:20.79401969909668

iterator 4500, D_Loss:0.43774160742759705, G_Loss:23.54163360595703

iterator 4600, D_Loss:0.4075908958911896, G_Loss:23.618064880371094

iterator 4700, D_Loss:0.41488662362098694, G_Loss:22.109638214111328

iterator 4800, D_Loss:0.42466971278190613, G_Loss:22.50499153137207

iterator 4900, D_Loss:0.4161965250968933, G_Loss:23.640642166137695

iterator 5000, D_Loss:0.452556312084198, G_Loss:19.953996658325195

train row : 30148
sample row: 30148
Process Process-16:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 69, in thread_run
    train_method = config["train_method"]
KeyError: 'train_method'
Process Process-17:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 69, in thread_run
    train_method = config["train_method"]
KeyError: 'train_method'
Process Process-15:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 69, in thread_run
    train_method = config["train_method"]
KeyError: 'train_method'
Process Process-19:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 69, in thread_run
    train_method = config["train_method"]
KeyError: 'train_method'
Process Process-18:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 69, in thread_run
    train_method = config["train_method"]
KeyError: 'train_method'
Process Process-21:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 69, in thread_run
    train_method = config["train_method"]
KeyError: 'train_method'
Process Process-20:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 69, in thread_run
    train_method = config["train_method"]
KeyError: 'train_method'
train row : 30148
sample row: 30148
LGAN_generator(
  (LSTM): LSTMCell(700, 400)
  (gmfc00): Linear(in_features=500, out_features=1, bias=True)
  (gmfc01): Linear(in_features=500, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=500, bias=True)
  (gmfe00): Linear(in_features=400, out_features=500, bias=True)
  (gmfe01): Linear(in_features=400, out_features=500, bias=True)
  (fc10): Linear(in_features=500, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=500, bias=True)
  (fe1): Linear(in_features=400, out_features=500, bias=True)
  (gmfc20): Linear(in_features=500, out_features=1, bias=True)
  (gmfc21): Linear(in_features=500, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=500, bias=True)
  (gmfe20): Linear(in_features=400, out_features=500, bias=True)
  (gmfe21): Linear(in_features=400, out_features=500, bias=True)
  (fc30): Linear(in_features=500, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=500, bias=True)
  (fe3): Linear(in_features=400, out_features=500, bias=True)
  (gmfc40): Linear(in_features=500, out_features=1, bias=True)
  (gmfc41): Linear(in_features=500, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=500, bias=True)
  (gmfe40): Linear(in_features=400, out_features=500, bias=True)
  (gmfe41): Linear(in_features=400, out_features=500, bias=True)
  (fc50): Linear(in_features=500, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=500, bias=True)
  (fe5): Linear(in_features=400, out_features=500, bias=True)
  (fc60): Linear(in_features=500, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=500, bias=True)
  (fe6): Linear(in_features=400, out_features=500, bias=True)
  (fc70): Linear(in_features=500, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=500, bias=True)
  (fe7): Linear(in_features=400, out_features=500, bias=True)
  (fc80): Linear(in_features=500, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=500, bias=True)
  (fe8): Linear(in_features=400, out_features=500, bias=True)
  (fc90): Linear(in_features=500, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=500, bias=True)
  (fe9): Linear(in_features=400, out_features=500, bias=True)
  (gmfc100): Linear(in_features=500, out_features=1, bias=True)
  (gmfc101): Linear(in_features=500, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=500, bias=True)
  (gmfe100): Linear(in_features=400, out_features=500, bias=True)
  (gmfe101): Linear(in_features=400, out_features=500, bias=True)
  (gmfc110): Linear(in_features=500, out_features=1, bias=True)
  (gmfc111): Linear(in_features=500, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=500, bias=True)
  (gmfe110): Linear(in_features=400, out_features=500, bias=True)
  (gmfe111): Linear(in_features=400, out_features=500, bias=True)
  (gmfc120): Linear(in_features=500, out_features=1, bias=True)
  (gmfc121): Linear(in_features=500, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=500, bias=True)
  (gmfe120): Linear(in_features=400, out_features=500, bias=True)
  (gmfe121): Linear(in_features=400, out_features=500, bias=True)
  (fc130): Linear(in_features=500, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=500, bias=True)
  (fe13): Linear(in_features=400, out_features=500, bias=True)
  (fc140): Linear(in_features=500, out_features=2, bias=True)
  (fc141): Linear(in_features=2, out_features=500, bias=True)
  (fe14): Linear(in_features=400, out_features=500, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=200, bias=True)
  (inputbn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (bn0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=200, out_features=200, bias=True)
  (bn1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=200, out_features=1, bias=True)
)
------ng : 0-------
generator loss: 0.005535027477890253
discriminator loss: -5.3960829973220825e-05
------ng : 100-------
generator loss: 0.001303342403843999
discriminator loss: -0.004709497559815645
------ng : 200-------
generator loss: 0.0016229819739237428
discriminator loss: -0.0030237105675041676
------ng : 300-------
generator loss: 0.001712887198664248
discriminator loss: -0.003133581019937992
------ng : 400-------
generator loss: 0.001117110368795693
discriminator loss: -0.004400741774588823
------ng : 500-------
generator loss: 0.00106537074316293
discriminator loss: -0.0024995203129947186
------ng : 600-------
generator loss: 0.001475928002037108
discriminator loss: -0.004699885845184326
------ng : 700-------
generator loss: -0.0018130707321688533
discriminator loss: -0.0035947347059845924
------ng : 800-------
generator loss: 0.001434922800399363
discriminator loss: -0.0031333379447460175
------ng : 900-------
generator loss: -0.0006533123669214547
discriminator loss: -0.003191870404407382
------ng : 1000-------
generator loss: -0.00017325158114545047
discriminator loss: -0.001962430775165558
------ng : 1100-------
generator loss: 0.0016838462324813008
discriminator loss: -0.0022103204391896725
------ng : 1200-------
generator loss: -0.001583543256856501
discriminator loss: -0.002140388125553727
------ng : 1300-------
generator loss: -0.0001513789320597425
discriminator loss: -0.001725536771118641
------ng : 1400-------
generator loss: 0.0006057259161025286
discriminator loss: -0.00371764344163239
------ng : 1500-------
generator loss: -0.0013020412297919393
discriminator loss: -0.002844763919711113
------ng : 1600-------
generator loss: -0.001738860853947699
discriminator loss: -0.00290110195055604
------ng : 1700-------
generator loss: 0.000251268211286515
discriminator loss: -0.003326107282191515
------ng : 1800-------
generator loss: 0.001686620875261724
discriminator loss: -0.002512523205950856
------ng : 1900-------
generator loss: 0.0007297114352695644
discriminator loss: -0.0014936996158212423
------ng : 2000-------
generator loss: 0.0015696316258981824
discriminator loss: -0.0017731919651851058
------ng : 2100-------
generator loss: 0.001312017673626542
discriminator loss: -0.0029305412899702787
------ng : 2200-------
generator loss: 0.00043963093776255846
discriminator loss: -0.0022371134255081415
------ng : 2300-------
generator loss: -0.00046217042836360633
discriminator loss: -0.003205497981980443
------ng : 2400-------
generator loss: 0.0007361277821473777
discriminator loss: -0.0025442959740757942
------ng : 2500-------
generator loss: 0.0017841820372268558
discriminator loss: -0.003042790340259671
------ng : 2600-------
generator loss: 0.0008861917303875089
discriminator loss: -0.002347268396988511
------ng : 2700-------
generator loss: -0.0009177133324556053
discriminator loss: -0.000672254478558898
------ng : 2800-------
generator loss: 0.0009569610701873899
discriminator loss: -0.0020484435372054577
------ng : 2900-------
generator loss: 0.0003719342057593167
discriminator loss: -0.0012506742496043444
------ng : 3000-------
generator loss: -0.0001996880309889093
discriminator loss: -0.0017974225338548422
------ng : 3100-------
generator loss: 2.7961771138507174e-06
discriminator loss: -0.0016218964010477066
------ng : 3200-------
generator loss: 5.576710100285709e-05
discriminator loss: -0.0021641443017870188
------ng : 3300-------
generator loss: 0.0010084972018375993
discriminator loss: -0.002308208728209138
------ng : 3400-------
generator loss: 0.0010867099044844508
discriminator loss: -0.002345165703445673
------ng : 3500-------
generator loss: 0.0006638298509642482
discriminator loss: -0.002870259340852499
------ng : 3600-------
generator loss: 0.0010794623522087932
discriminator loss: -0.002040859777480364
------ng : 3700-------
generator loss: -0.00042781958472914994
discriminator loss: -0.002277831546962261
------ng : 3800-------
generator loss: -0.0013583453837782145
discriminator loss: -0.0009450228535570204
------ng : 3900-------
generator loss: -0.0017948427703231573
discriminator loss: -0.0021342416293919086
------ng : 4000-------
generator loss: 0.0007223550928756595
discriminator loss: -0.0025619217194616795
------ng : 4100-------
generator loss: -0.0009029612992890179
discriminator loss: -0.0014457728248089552
------ng : 4200-------
generator loss: 0.0015525054186582565
discriminator loss: -0.001558844349347055
------ng : 4300-------
generator loss: -3.0750215955777094e-05
discriminator loss: -0.0032586667221039534
------ng : 4400-------
generator loss: 0.0016766103217378259
discriminator loss: -0.0016349123325198889
------ng : 4500-------
generator loss: -0.000908432702999562
discriminator loss: -0.001907175057567656
------ng : 4600-------
generator loss: 0.001311382045969367
discriminator loss: -0.001274107489734888
------ng : 4700-------
generator loss: 0.0011124665616080165
discriminator loss: -0.0016000984469428658
------ng : 4800-------
generator loss: -0.0012752005131915212
discriminator loss: -0.0026671565137803555
------ng : 4900-------
generator loss: 0.0011233827099204063
discriminator loss: -0.0023376375902444124
LGAN_generator(
  (LSTM): LSTMCell(900, 300)
  (gmfc00): Linear(in_features=500, out_features=1, bias=True)
  (gmfc01): Linear(in_features=500, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=500, bias=True)
  (gmfe00): Linear(in_features=300, out_features=500, bias=True)
  (gmfe01): Linear(in_features=300, out_features=500, bias=True)
  (fc10): Linear(in_features=500, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=500, bias=True)
  (fe1): Linear(in_features=300, out_features=500, bias=True)
  (gmfc20): Linear(in_features=500, out_features=1, bias=True)
  (gmfc21): Linear(in_features=500, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=500, bias=True)
  (gmfe20): Linear(in_features=300, out_features=500, bias=True)
  (gmfe21): Linear(in_features=300, out_features=500, bias=True)
  (fc30): Linear(in_features=500, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=500, bias=True)
  (fe3): Linear(in_features=300, out_features=500, bias=True)
  (gmfc40): Linear(in_features=500, out_features=1, bias=True)
  (gmfc41): Linear(in_features=500, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=500, bias=True)
  (gmfe40): Linear(in_features=300, out_features=500, bias=True)
  (gmfe41): Linear(in_features=300, out_features=500, bias=True)
  (fc50): Linear(in_features=500, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=500, bias=True)
  (fe5): Linear(in_features=300, out_features=500, bias=True)
  (fc60): Linear(in_features=500, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=500, bias=True)
  (fe6): Linear(in_features=300, out_features=500, bias=True)
  (fc70): Linear(in_features=500, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=500, bias=True)
  (fe7): Linear(in_features=300, out_features=500, bias=True)
  (fc80): Linear(in_features=500, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=500, bias=True)
  (fe8): Linear(in_features=300, out_features=500, bias=True)
  (fc90): Linear(in_features=500, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=500, bias=True)
  (fe9): Linear(in_features=300, out_features=500, bias=True)
  (gmfc100): Linear(in_features=500, out_features=1, bias=True)
  (gmfc101): Linear(in_features=500, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=500, bias=True)
  (gmfe100): Linear(in_features=300, out_features=500, bias=True)
  (gmfe101): Linear(in_features=300, out_features=500, bias=True)
  (gmfc110): Linear(in_features=500, out_features=1, bias=True)
  (gmfc111): Linear(in_features=500, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=500, bias=True)
  (gmfe110): Linear(in_features=300, out_features=500, bias=True)
  (gmfe111): Linear(in_features=300, out_features=500, bias=True)
  (gmfc120): Linear(in_features=500, out_features=1, bias=True)
  (gmfc121): Linear(in_features=500, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=500, bias=True)
  (gmfe120): Linear(in_features=300, out_features=500, bias=True)
  (gmfe121): Linear(in_features=300, out_features=500, bias=True)
  (fc130): Linear(in_features=500, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=500, bias=True)
  (fe13): Linear(in_features=300, out_features=500, bias=True)
  (fc140): Linear(in_features=500, out_features=2, bias=True)
  (fc141): Linear(in_features=2, out_features=500, bias=True)
  (fe14): Linear(in_features=300, out_features=500, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=500, bias=True)
  (inputbn): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=500, out_features=500, bias=True)
  (bn0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=500, out_features=1, bias=True)
)
------ng : 0-------
generator loss: 0.00942353904247284
discriminator loss: -0.0025028586387634277
------ng : 100-------
generator loss: 0.0009923866018652916
discriminator loss: -0.005469087511301041
------ng : 200-------
generator loss: -6.968384695937857e-05
discriminator loss: -0.004581722430884838
------ng : 300-------
generator loss: -0.0013751336373388767
discriminator loss: -0.007348770275712013
------ng : 400-------
generator loss: 0.0010739776771515608
discriminator loss: -0.007445155642926693
------ng : 500-------
generator loss: -0.001653956132940948
discriminator loss: -0.004774133209139109
------ng : 600-------
generator loss: -0.0017154797678813338
discriminator loss: -0.004894633311778307
------ng : 700-------
generator loss: -0.0008654711418785155
discriminator loss: -0.0062139080837368965
------ng : 800-------
generator loss: -0.0005118263652548194
discriminator loss: -0.005559183657169342
------ng : 900-------
generator loss: -0.002706758910790086
discriminator loss: -0.0046435752883553505
------ng : 1000-------
generator loss: -0.0009192013530991971
discriminator loss: -0.006705510895699263
------ng : 1100-------
generator loss: -0.0014284518547356129
discriminator loss: -0.007541620638221502
------ng : 1200-------
generator loss: -0.0018892626976594329
discriminator loss: -0.0043638646602630615
------ng : 1300-------
generator loss: 0.0005868850275874138
discriminator loss: -0.006168232765048742
------ng : 1400-------
generator loss: -0.0005286537925712764
discriminator loss: -0.004701875615864992
------ng : 1500-------
generator loss: 0.000659078941680491
discriminator loss: -0.005687725730240345
------ng : 1600-------
generator loss: 0.0005612678360193968
discriminator loss: -0.005981457885354757
------ng : 1700-------
generator loss: 0.0005740932538174093
discriminator loss: -0.0064346641302108765
------ng : 1800-------
generator loss: 0.00139428221154958
discriminator loss: -0.005184847861528397
------ng : 1900-------
generator loss: -0.0013480958295986056
discriminator loss: -0.006235996261239052
------ng : 2000-------
generator loss: -0.0013121638912707567
discriminator loss: -0.00579837616533041
------ng : 2100-------
generator loss: -0.0018170588882640004
discriminator loss: -0.005539568141102791
------ng : 2200-------
generator loss: -0.00029584229923784733
discriminator loss: -0.003997043240815401
------ng : 2300-------
generator loss: 0.0007622332195751369
discriminator loss: -0.004813484847545624
------ng : 2400-------
generator loss: -0.003209910588338971
discriminator loss: -0.00392910884693265
------ng : 2500-------
generator loss: -0.002543454524129629
discriminator loss: -0.004753445275127888
------ng : 2600-------
generator loss: -0.0013459405163303018
discriminator loss: -0.003424930851906538
------ng : 2700-------
generator loss: -0.0026819962076842785
discriminator loss: -0.004179776646196842
------ng : 2800-------
generator loss: -0.0031858577858656645
discriminator loss: -0.003243023296818137
------ng : 2900-------
generator loss: -0.0030296407639980316
discriminator loss: -0.004051460884511471
------ng : 3000-------
generator loss: -0.002157425507903099
discriminator loss: -0.004162285011261702
------ng : 3100-------
generator loss: -0.0006829557241871953
discriminator loss: -0.00288420170545578
------ng : 3200-------
generator loss: -0.0003027257916983217
discriminator loss: -0.004980715457350016
------ng : 3300-------
generator loss: 0.00033141396124847233
discriminator loss: -0.0026366012170910835
------ng : 3400-------
generator loss: -0.005086089950054884
discriminator loss: -0.004417239222675562
------ng : 3500-------
generator loss: -0.007487660273909569
discriminator loss: -0.004917657934129238
------ng : 3600-------
generator loss: -9.452396625420079e-05
discriminator loss: -0.005278181750327349
------ng : 3700-------
generator loss: -0.0008179800934158266
discriminator loss: -0.0040344363078475
------ng : 3800-------
generator loss: -0.0003580340417101979
discriminator loss: -0.003967558033764362
------ng : 3900-------
generator loss: -0.00040320679545402527
discriminator loss: -0.004793608095496893
------ng : 4000-------
generator loss: -0.00047542795073240995
discriminator loss: -0.004328595008701086
------ng : 4100-------
generator loss: -0.0013442179188132286
discriminator loss: -0.004114343784749508
------ng : 4200-------
generator loss: 0.0008765706443227828
discriminator loss: -0.003085864707827568
------ng : 4300-------
generator loss: 5.667686491506174e-05
discriminator loss: -0.003035081084817648
------ng : 4400-------
generator loss: -0.004925801418721676
discriminator loss: -0.0032230063807219267
------ng : 4500-------
generator loss: -0.0010573178296908736
discriminator loss: -0.0031587467528879642
------ng : 4600-------
generator loss: -0.0005989234196022153
discriminator loss: -0.0032377804163843393
------ng : 4700-------
generator loss: -0.00012407997564878315
discriminator loss: -0.0028299055993556976
------ng : 4800-------
generator loss: -0.0008929800824262202
discriminator loss: -0.003380637615919113
------ng : 4900-------
generator loss: -0.0019110628636553884
discriminator loss: -0.003735028440132737
slurmstepd: error: Detected 15040 oom-kill event(s) in StepId=29769129.batch cgroup. Some of your processes may have been killed by the cgroup out-of-memory handler.
Oct  6 14:28:07 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 14:28:07 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:71900KB rss:4023988KB rss_huge:978944KB mapped_file:71824KB swap:0KB inactive_anon:690220KB active_anon:3405448KB inactive_file:76KB active_file:0KB unevictable:0KB
Oct  6 14:28:09 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 14:28:09 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:61440KB rss:4034560KB rss_huge:1038336KB mapped_file:61440KB swap:0KB inactive_anon:687912KB active_anon:3408080KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 14:28:14 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 14:28:14 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:51264KB rss:4044672KB rss_huge:970752KB mapped_file:51264KB swap:0KB inactive_anon:682720KB active_anon:3413132KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 14:28:18 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 14:28:18 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:41052KB rss:4054916KB rss_huge:858112KB mapped_file:41052KB swap:0KB inactive_anon:682652KB active_anon:3413220KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 14:28:20 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 14:28:20 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:30720KB rss:4065280KB rss_huge:1044480KB mapped_file:30720KB swap:0KB inactive_anon:682664KB active_anon:3413320KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 14:56:29 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 14:56:29 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:71916KB rss:4024084KB rss_huge:626688KB mapped_file:71680KB swap:0KB inactive_anon:682672KB active_anon:3413092KB inactive_file:228KB active_file:8KB unevictable:0KB
Oct  6 14:56:31 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 14:56:31 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:61472KB rss:4034524KB rss_huge:677888KB mapped_file:61468KB swap:0KB inactive_anon:682784KB active_anon:3413180KB inactive_file:4KB active_file:0KB unevictable:0KB
Oct  6 14:56:34 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 14:56:34 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:51376KB rss:4044624KB rss_huge:675840KB mapped_file:51200KB swap:0KB inactive_anon:684384KB active_anon:3411440KB inactive_file:160KB active_file:16KB unevictable:0KB
Oct  6 14:56:36 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 14:56:36 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:40960KB rss:4055040KB rss_huge:622592KB mapped_file:40960KB swap:0KB inactive_anon:682708KB active_anon:3413284KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 14:56:38 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 14:56:38 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:30720KB rss:4065280KB rss_huge:878592KB mapped_file:30720KB swap:0KB inactive_anon:682680KB active_anon:3413308KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 15:25:41 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 15:25:41 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:71680KB rss:4024320KB rss_huge:1230848KB mapped_file:71680KB swap:0KB inactive_anon:692588KB active_anon:3403388KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 15:25:43 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 15:25:43 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:61440KB rss:4034560KB rss_huge:1167360KB mapped_file:61440KB swap:0KB inactive_anon:682736KB active_anon:3413248KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 15:25:47 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 15:25:47 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:51328KB rss:4044672KB rss_huge:993280KB mapped_file:51328KB swap:0KB inactive_anon:694604KB active_anon:3401228KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 15:25:52 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 15:25:52 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:40960KB rss:4055040KB rss_huge:884736KB mapped_file:40960KB swap:0KB inactive_anon:683180KB active_anon:3412772KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 15:25:54 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 15:25:54 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:30720KB rss:4065280KB rss_huge:1052672KB mapped_file:30720KB swap:0KB inactive_anon:682760KB active_anon:3413188KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 16:00:11 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 16:00:11 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:72332KB rss:4023604KB rss_huge:894976KB mapped_file:72276KB swap:0KB inactive_anon:684316KB active_anon:3410968KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 16:00:13 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 16:00:13 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:62384KB rss:4033616KB rss_huge:952320KB mapped_file:61456KB swap:0KB inactive_anon:684232KB active_anon:3410824KB inactive_file:536KB active_file:408KB unevictable:0KB
Oct  6 16:00:17 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 16:00:17 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:51660KB rss:4044340KB rss_huge:919552KB mapped_file:51200KB swap:0KB inactive_anon:684380KB active_anon:3411160KB inactive_file:268KB active_file:192KB unevictable:0KB
Oct  6 16:00:21 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 16:00:21 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:41040KB rss:4054912KB rss_huge:815104KB mapped_file:41040KB swap:0KB inactive_anon:685672KB active_anon:3410196KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 16:00:23 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 16:00:23 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:30720KB rss:4065280KB rss_huge:1071104KB mapped_file:30720KB swap:0KB inactive_anon:684460KB active_anon:3411532KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 16:30:28 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 16:30:28 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:71940KB rss:4024060KB rss_huge:1073152KB mapped_file:71936KB swap:0KB inactive_anon:683308KB active_anon:3412432KB inactive_file:4KB active_file:0KB unevictable:0KB
Oct  6 16:30:30 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 16:30:30 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:61444KB rss:4034556KB rss_huge:1038336KB mapped_file:61440KB swap:0KB inactive_anon:687808KB active_anon:3408188KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 16:30:35 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 16:30:35 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:51204KB rss:4044796KB rss_huge:897024KB mapped_file:51200KB swap:0KB inactive_anon:693268KB active_anon:3402728KB inactive_file:4KB active_file:0KB unevictable:0KB
Oct  6 16:30:41 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 16:30:41 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:49156KB rss:4046844KB rss_huge:755712KB mapped_file:49152KB swap:0KB inactive_anon:682676KB active_anon:3413320KB inactive_file:4KB active_file:0KB unevictable:0KB
Oct  6 16:30:42 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 16:30:42 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:36872KB rss:4059128KB rss_huge:888832KB mapped_file:36868KB swap:0KB inactive_anon:682784KB active_anon:3413208KB inactive_file:4KB active_file:4KB unevictable:0KB
Oct  6 18:04:07 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 18:04:07 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:72276KB rss:4023708KB rss_huge:749568KB mapped_file:71708KB swap:0KB inactive_anon:684364KB active_anon:3411024KB inactive_file:364KB active_file:120KB unevictable:0KB
Oct  6 18:04:10 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 18:04:10 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:62448KB rss:4033552KB rss_huge:854016KB mapped_file:61488KB swap:0KB inactive_anon:684252KB active_anon:3410740KB inactive_file:544KB active_file:464KB unevictable:0KB
Oct  6 18:04:14 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 18:04:14 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:51204KB rss:4044796KB rss_huge:755712KB mapped_file:51200KB swap:0KB inactive_anon:685648KB active_anon:3410348KB inactive_file:4KB active_file:0KB unevictable:0KB
Oct  6 18:04:19 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 18:04:19 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:49152KB rss:4046848KB rss_huge:659456KB mapped_file:49152KB swap:0KB inactive_anon:697040KB active_anon:3398960KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 18:04:21 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 18:04:21 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:36992KB rss:4059008KB rss_huge:831488KB mapped_file:36992KB swap:0KB inactive_anon:684376KB active_anon:3411448KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 18:53:10 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 18:53:10 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:71792KB rss:4024192KB rss_huge:952320KB mapped_file:71792KB swap:0KB inactive_anon:684444KB active_anon:3411400KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 18:53:14 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 18:53:14 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:63936KB rss:4032064KB rss_huge:974848KB mapped_file:61968KB swap:0KB inactive_anon:697664KB active_anon:3395840KB inactive_file:1264KB active_file:1232KB unevictable:0KB
Oct  6 18:53:19 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 18:53:19 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:51336KB rss:4044544KB rss_huge:843776KB mapped_file:51336KB swap:0KB inactive_anon:702636KB active_anon:3393104KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 18:53:25 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 18:53:25 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:49152KB rss:4046848KB rss_huge:731136KB mapped_file:49152KB swap:0KB inactive_anon:697264KB active_anon:3398724KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 18:53:26 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 18:53:26 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:37120KB rss:4058880KB rss_huge:864256KB mapped_file:37120KB swap:0KB inactive_anon:682632KB active_anon:3413100KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 20:11:42 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 20:11:42 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:71684KB rss:4024316KB rss_huge:659456KB mapped_file:71680KB swap:0KB inactive_anon:682772KB active_anon:3413096KB inactive_file:4KB active_file:0KB unevictable:0KB
Oct  6 20:11:47 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 20:11:47 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:63184KB rss:4032816KB rss_huge:716800KB mapped_file:61456KB swap:0KB inactive_anon:682452KB active_anon:3411804KB inactive_file:880KB active_file:864KB unevictable:0KB
Oct  6 20:11:54 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 20:11:54 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:51204KB rss:4044796KB rss_huge:653312KB mapped_file:51200KB swap:0KB inactive_anon:682696KB active_anon:3413300KB inactive_file:4KB active_file:0KB unevictable:0KB
Oct  6 20:12:02 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 20:12:02 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:49156KB rss:4046844KB rss_huge:573440KB mapped_file:49152KB swap:0KB inactive_anon:682676KB active_anon:3413320KB inactive_file:4KB active_file:0KB unevictable:0KB
Oct  6 20:12:04 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 20:12:04 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:36868KB rss:4059132KB rss_huge:737280KB mapped_file:36864KB swap:0KB inactive_anon:682668KB active_anon:3413328KB inactive_file:4KB active_file:0KB unevictable:0KB
Oct  6 20:54:08 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 20:54:08 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:72832KB rss:4023168KB rss_huge:1071104KB mapped_file:71936KB swap:0KB inactive_anon:705312KB active_anon:3389536KB inactive_file:684KB active_file:468KB unevictable:0KB
Oct  6 20:54:11 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 20:54:11 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:61548KB rss:4034452KB rss_huge:1251328KB mapped_file:61444KB swap:0KB inactive_anon:691452KB active_anon:3404440KB inactive_file:56KB active_file:52KB unevictable:0KB
Oct  6 20:54:14 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 20:54:14 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:51472KB rss:4044416KB rss_huge:1148928KB mapped_file:51472KB swap:0KB inactive_anon:686140KB active_anon:3409476KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 20:54:21 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 20:54:21 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:49160KB rss:4046720KB rss_huge:985088KB mapped_file:49160KB swap:0KB inactive_anon:686128KB active_anon:3409732KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 20:54:23 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 20:54:23 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:36864KB rss:4059136KB rss_huge:1081344KB mapped_file:36864KB swap:0KB inactive_anon:686076KB active_anon:3409748KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 22:26:18 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 22:26:18 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:72120KB rss:4023808KB rss_huge:1073152KB mapped_file:72120KB swap:0KB inactive_anon:704912KB active_anon:3390544KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 22:26:20 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 22:26:20 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:61696KB rss:4034304KB rss_huge:1257472KB mapped_file:61696KB swap:0KB inactive_anon:682892KB active_anon:3412816KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 22:26:25 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 22:26:25 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:51564KB rss:4044436KB rss_huge:1095680KB mapped_file:51200KB swap:0KB inactive_anon:701116KB active_anon:3394520KB inactive_file:288KB active_file:76KB unevictable:0KB
Oct  6 22:26:33 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 22:26:33 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:49280KB rss:4046720KB rss_huge:989184KB mapped_file:49280KB swap:0KB inactive_anon:684164KB active_anon:3411700KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 22:26:35 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 22:26:35 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:36864KB rss:4059136KB rss_huge:1085440KB mapped_file:36864KB swap:0KB inactive_anon:683448KB active_anon:3412548KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 23:58:23 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 23:58:23 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:71680KB rss:4024320KB rss_huge:1290240KB mapped_file:71680KB swap:0KB inactive_anon:697576KB active_anon:3398424KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 23:58:25 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 23:58:25 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:61696KB rss:4034304KB rss_huge:1402880KB mapped_file:61696KB swap:0KB inactive_anon:691736KB active_anon:3403992KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 23:58:29 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 23:58:29 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:51200KB rss:4044800KB rss_huge:1202176KB mapped_file:51200KB swap:0KB inactive_anon:694088KB active_anon:3401872KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 23:58:37 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 23:58:37 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:49152KB rss:4046848KB rss_huge:1095680KB mapped_file:49152KB swap:0KB inactive_anon:689184KB active_anon:3406800KB inactive_file:0KB active_file:0KB unevictable:0KB
Oct  6 23:58:39 spartan-gpgpu081 kernel: Task in /slurm/uid_13885/job_29769129/step_batch killed as a result of limit of /slurm/uid_13885/job_29769129/step_batch
Oct  6 23:58:39 spartan-gpgpu081 kernel: Memory cgroup stats for /slurm/uid_13885/job_29769129/step_batch: cache:36864KB rss:4059136KB rss_huge:1163264KB mapped_file:36864KB swap:0KB inactive_anon:682916KB active_anon:3413084KB inactive_file:0KB active_file:0KB unevictable:0KB
