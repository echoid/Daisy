train row : 30148
sample row: 30148
VGAN_generator(
  (input): Linear(in_features=128, out_features=100, bias=True)
  (inputbn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=100, out_features=100, bias=True)
  (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=100, out_features=100, bias=True)
  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=100, out_features=105, bias=True)
  (outputbn): BatchNorm1d(105, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=105, out_features=400, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=400, out_features=400, bias=True)
  (fc1): Linear(in_features=400, out_features=400, bias=True)
  (output): Linear(in_features=400, out_features=1, bias=True)
)
(0, False, 105)
-----------Epoch 0-----------
iterator 100, D_Loss:0.5803886651992798, G_Loss:5.290630340576172

iterator 200, D_Loss:0.4867834448814392, G_Loss:6.708839416503906

iterator 300, D_Loss:0.5296993255615234, G_Loss:7.692121505737305

iterator 400, D_Loss:0.5284506678581238, G_Loss:7.861950397491455

iterator 500, D_Loss:0.4803599715232849, G_Loss:7.381644248962402

iterator 600, D_Loss:0.49577754735946655, G_Loss:8.096702575683594

iterator 700, D_Loss:0.44443392753601074, G_Loss:8.802617073059082

iterator 800, D_Loss:0.4978998005390167, G_Loss:8.91625690460205

iterator 900, D_Loss:0.5330499410629272, G_Loss:8.1749849319458

iterator 1000, D_Loss:0.4787042737007141, G_Loss:8.403706550598145

iterator 1100, D_Loss:0.4494417905807495, G_Loss:7.71970796585083

iterator 1200, D_Loss:0.47855931520462036, G_Loss:6.935820579528809

iterator 1300, D_Loss:0.4893852174282074, G_Loss:7.446430206298828

iterator 1400, D_Loss:0.5011393427848816, G_Loss:7.074948310852051

iterator 1500, D_Loss:0.4578838646411896, G_Loss:7.146816253662109

iterator 1600, D_Loss:0.44131332635879517, G_Loss:6.188088893890381

iterator 1700, D_Loss:0.4729056656360626, G_Loss:6.249804496765137

iterator 1800, D_Loss:0.5161812901496887, G_Loss:7.006409168243408

iterator 1900, D_Loss:0.5550881624221802, G_Loss:6.706250190734863

iterator 2000, D_Loss:0.487801730632782, G_Loss:6.281007289886475

iterator 2100, D_Loss:0.4801297187805176, G_Loss:6.147737979888916

iterator 2200, D_Loss:0.48065316677093506, G_Loss:6.446255683898926

iterator 2300, D_Loss:0.5455714464187622, G_Loss:6.1341352462768555

iterator 2400, D_Loss:0.5404756665229797, G_Loss:6.832662105560303

iterator 2500, D_Loss:0.5396772623062134, G_Loss:6.143632888793945

iterator 2600, D_Loss:0.5247712135314941, G_Loss:6.128728866577148

iterator 2700, D_Loss:0.48752081394195557, G_Loss:6.3081536293029785

iterator 2800, D_Loss:0.5548619031906128, G_Loss:6.3759307861328125

iterator 2900, D_Loss:0.4921327233314514, G_Loss:5.861445426940918

iterator 3000, D_Loss:0.5018986463546753, G_Loss:5.908987045288086

iterator 3100, D_Loss:0.494373083114624, G_Loss:5.652121543884277

iterator 3200, D_Loss:0.5318300724029541, G_Loss:5.728754997253418

iterator 3300, D_Loss:0.52491694688797, G_Loss:5.6437458992004395

iterator 3400, D_Loss:0.5308895707130432, G_Loss:6.0650458335876465

iterator 3500, D_Loss:0.601512610912323, G_Loss:5.5489821434021

iterator 3600, D_Loss:0.5429859757423401, G_Loss:5.46205472946167

iterator 3700, D_Loss:0.5655189752578735, G_Loss:5.2139129638671875

iterator 3800, D_Loss:0.5650570392608643, G_Loss:4.742556571960449

iterator 3900, D_Loss:0.5891897678375244, G_Loss:5.021754741668701

iterator 4000, D_Loss:0.5415276288986206, G_Loss:5.181456089019775

iterator 4100, D_Loss:0.529095470905304, G_Loss:5.363664627075195

iterator 4200, D_Loss:0.557190477848053, G_Loss:5.017109394073486

iterator 4300, D_Loss:0.5653238296508789, G_Loss:4.844273090362549

iterator 4400, D_Loss:0.5134363770484924, G_Loss:4.794734954833984

iterator 4500, D_Loss:0.5849605798721313, G_Loss:4.790632724761963

iterator 4600, D_Loss:0.5698572397232056, G_Loss:5.146544456481934

iterator 4700, D_Loss:0.5637622475624084, G_Loss:4.605098247528076

iterator 4800, D_Loss:0.5465127825737, G_Loss:4.742656707763672

iterator 4900, D_Loss:0.6220556497573853, G_Loss:4.504476070404053

iterator 5000, D_Loss:0.6289849877357483, G_Loss:4.565773010253906

-----------Epoch 1-----------
iterator 100, D_Loss:0.5559998750686646, G_Loss:4.481422424316406

iterator 200, D_Loss:0.6051454544067383, G_Loss:4.0400800704956055

iterator 300, D_Loss:0.6217767000198364, G_Loss:4.070451736450195

iterator 400, D_Loss:0.6282231211662292, G_Loss:4.042023181915283

iterator 500, D_Loss:0.6441267132759094, G_Loss:3.87587833404541

iterator 600, D_Loss:0.6721978783607483, G_Loss:4.0818190574646

iterator 700, D_Loss:0.5831518173217773, G_Loss:4.397270202636719

iterator 800, D_Loss:0.6131417751312256, G_Loss:4.101439952850342

iterator 900, D_Loss:0.6259594559669495, G_Loss:4.343542575836182

iterator 1000, D_Loss:0.6513904333114624, G_Loss:4.526738166809082

iterator 1100, D_Loss:0.6220535635948181, G_Loss:4.409146785736084

iterator 1200, D_Loss:0.5537675023078918, G_Loss:4.446756362915039

iterator 1300, D_Loss:0.6500145196914673, G_Loss:4.186302185058594

iterator 1400, D_Loss:0.6916921138763428, G_Loss:4.1368513107299805

iterator 1500, D_Loss:0.6469300389289856, G_Loss:3.804797887802124

iterator 1600, D_Loss:0.6177176833152771, G_Loss:4.024168968200684

iterator 1700, D_Loss:0.6778112649917603, G_Loss:3.931671619415283

iterator 1800, D_Loss:0.6689411401748657, G_Loss:3.9784982204437256

iterator 1900, D_Loss:0.7155079245567322, G_Loss:3.8418238162994385

iterator 2000, D_Loss:0.6873116493225098, G_Loss:3.7469465732574463

iterator 2100, D_Loss:0.7265708446502686, G_Loss:3.597158670425415

iterator 2200, D_Loss:0.6414696574211121, G_Loss:3.5894999504089355

iterator 2300, D_Loss:0.7418593168258667, G_Loss:3.6087982654571533

iterator 2400, D_Loss:0.7622877359390259, G_Loss:3.6417455673217773

iterator 2500, D_Loss:0.6730237007141113, G_Loss:3.9913089275360107

iterator 2600, D_Loss:0.6792054772377014, G_Loss:3.9713830947875977

iterator 2700, D_Loss:0.7349900603294373, G_Loss:3.945723533630371

iterator 2800, D_Loss:0.7069882154464722, G_Loss:3.0833725929260254

iterator 2900, D_Loss:0.6610409021377563, G_Loss:3.653446674346924

iterator 3000, D_Loss:0.6644999980926514, G_Loss:3.7037503719329834

iterator 3100, D_Loss:0.6074541807174683, G_Loss:3.540888786315918

iterator 3200, D_Loss:0.6815540790557861, G_Loss:3.451158285140991

iterator 3300, D_Loss:0.6992937922477722, G_Loss:3.546677589416504

iterator 3400, D_Loss:0.7519053220748901, G_Loss:3.424182891845703

iterator 3500, D_Loss:0.7606604695320129, G_Loss:3.3423869609832764

iterator 3600, D_Loss:0.7464667558670044, G_Loss:3.4944088459014893

iterator 3700, D_Loss:0.7712761759757996, G_Loss:3.301987409591675

iterator 3800, D_Loss:0.7034860849380493, G_Loss:3.138955593109131

iterator 3900, D_Loss:0.8260409832000732, G_Loss:3.5080904960632324

iterator 4000, D_Loss:0.7510279417037964, G_Loss:3.2312822341918945

iterator 4100, D_Loss:0.7145673036575317, G_Loss:3.2566187381744385

iterator 4200, D_Loss:0.7351142764091492, G_Loss:3.4280972480773926

iterator 4300, D_Loss:0.6933031678199768, G_Loss:3.2891414165496826

iterator 4400, D_Loss:0.6965340971946716, G_Loss:3.1329586505889893

iterator 4500, D_Loss:0.8025558590888977, G_Loss:3.1105546951293945

iterator 4600, D_Loss:0.7673428654670715, G_Loss:2.9790658950805664

iterator 4700, D_Loss:0.821991503238678, G_Loss:3.0795974731445312

iterator 4800, D_Loss:0.7791429162025452, G_Loss:2.9748997688293457

iterator 4900, D_Loss:0.7719671130180359, G_Loss:3.0873560905456543

iterator 5000, D_Loss:0.7214908003807068, G_Loss:2.9959452152252197

-----------Epoch 2-----------
iterator 100, D_Loss:0.7544253468513489, G_Loss:2.8872299194335938

iterator 200, D_Loss:0.7380021810531616, G_Loss:3.20466685295105

iterator 300, D_Loss:0.8153835535049438, G_Loss:2.954240560531616

iterator 400, D_Loss:0.8140079975128174, G_Loss:2.812216281890869

iterator 500, D_Loss:0.8332159519195557, G_Loss:2.8807995319366455

iterator 600, D_Loss:0.837491512298584, G_Loss:2.7257912158966064

iterator 700, D_Loss:0.8224380612373352, G_Loss:3.0293242931365967

iterator 800, D_Loss:0.7728434205055237, G_Loss:2.970034122467041

iterator 900, D_Loss:0.7868127822875977, G_Loss:2.9210355281829834

iterator 1000, D_Loss:0.8450253009796143, G_Loss:2.635603189468384

iterator 1100, D_Loss:0.7267576456069946, G_Loss:2.9692795276641846

iterator 1200, D_Loss:0.7176232933998108, G_Loss:2.8067469596862793

iterator 1300, D_Loss:0.7700470685958862, G_Loss:3.02538800239563

iterator 1400, D_Loss:0.7959316372871399, G_Loss:2.9164273738861084

iterator 1500, D_Loss:0.9410470724105835, G_Loss:2.5629544258117676

iterator 1600, D_Loss:0.8267396092414856, G_Loss:2.770596742630005

iterator 1700, D_Loss:0.8419680595397949, G_Loss:2.59426212310791

iterator 1800, D_Loss:0.8297151327133179, G_Loss:2.6745378971099854

iterator 1900, D_Loss:0.880817174911499, G_Loss:2.7853262424468994

iterator 2000, D_Loss:0.8285146355628967, G_Loss:2.7868244647979736

iterator 2100, D_Loss:0.9130045175552368, G_Loss:2.621765613555908

iterator 2200, D_Loss:0.9519319534301758, G_Loss:2.502662181854248

iterator 2300, D_Loss:0.8428176641464233, G_Loss:2.766812801361084

iterator 2400, D_Loss:0.8422906398773193, G_Loss:2.557929039001465

iterator 2500, D_Loss:0.9225524067878723, G_Loss:2.5363500118255615

iterator 2600, D_Loss:0.8597946166992188, G_Loss:2.8266756534576416

iterator 2700, D_Loss:0.8121240735054016, G_Loss:2.6542861461639404

iterator 2800, D_Loss:0.8642874360084534, G_Loss:2.5135183334350586

iterator 2900, D_Loss:0.8345815539360046, G_Loss:2.6319024562835693

iterator 3000, D_Loss:0.8744492530822754, G_Loss:2.6750643253326416

iterator 3100, D_Loss:0.8015354871749878, G_Loss:2.5581912994384766

iterator 3200, D_Loss:0.847256064414978, G_Loss:2.61311411857605

iterator 3300, D_Loss:0.8485081195831299, G_Loss:2.6039392948150635

iterator 3400, D_Loss:0.841689944267273, G_Loss:2.698561191558838

iterator 3500, D_Loss:0.8763132691383362, G_Loss:2.417898416519165

iterator 3600, D_Loss:0.8850643634796143, G_Loss:2.418949604034424

iterator 3700, D_Loss:0.8296850323677063, G_Loss:2.6907784938812256

iterator 3800, D_Loss:0.8855018615722656, G_Loss:2.6232903003692627

iterator 3900, D_Loss:0.8464207053184509, G_Loss:2.2935702800750732

iterator 4000, D_Loss:0.8893073797225952, G_Loss:2.5846612453460693

iterator 4100, D_Loss:0.8890650868415833, G_Loss:2.546170711517334

iterator 4200, D_Loss:0.887544572353363, G_Loss:2.4724040031433105

iterator 4300, D_Loss:0.9609899520874023, G_Loss:2.1370811462402344

iterator 4400, D_Loss:0.8339858055114746, G_Loss:2.398956537246704

iterator 4500, D_Loss:0.9139076471328735, G_Loss:2.216627597808838

iterator 4600, D_Loss:0.8839302659034729, G_Loss:2.385138988494873

iterator 4700, D_Loss:0.942021906375885, G_Loss:2.3409454822540283

iterator 4800, D_Loss:0.9813892245292664, G_Loss:2.270648717880249

iterator 4900, D_Loss:0.8661589026451111, G_Loss:2.265632390975952

iterator 5000, D_Loss:0.9023891091346741, G_Loss:2.3182058334350586

-----------Epoch 3-----------
iterator 100, D_Loss:0.8990484476089478, G_Loss:2.2677793502807617

iterator 200, D_Loss:0.9449748992919922, G_Loss:2.3708579540252686

iterator 300, D_Loss:0.8833608031272888, G_Loss:2.4136850833892822

iterator 400, D_Loss:0.9437061548233032, G_Loss:2.054225444793701

iterator 500, D_Loss:0.9802583456039429, G_Loss:2.1087074279785156

iterator 600, D_Loss:0.9457252025604248, G_Loss:2.369476318359375

iterator 700, D_Loss:0.8623266220092773, G_Loss:2.365081310272217

iterator 800, D_Loss:0.9310232400894165, G_Loss:2.3840551376342773

iterator 900, D_Loss:0.8648251295089722, G_Loss:2.297105550765991

iterator 1000, D_Loss:0.8810907602310181, G_Loss:2.354292869567871

iterator 1100, D_Loss:0.8891600370407104, G_Loss:2.446702241897583

iterator 1200, D_Loss:0.9135937094688416, G_Loss:2.3982698917388916

iterator 1300, D_Loss:0.9562186002731323, G_Loss:2.087686777114868

iterator 1400, D_Loss:0.9115574359893799, G_Loss:2.2592220306396484

iterator 1500, D_Loss:0.965175211429596, G_Loss:2.1310062408447266

iterator 1600, D_Loss:0.8909380435943604, G_Loss:2.039872646331787

iterator 1700, D_Loss:0.9627560377120972, G_Loss:2.1241321563720703

iterator 1800, D_Loss:0.9101905822753906, G_Loss:2.344715118408203

iterator 1900, D_Loss:1.0017337799072266, G_Loss:2.1344127655029297

iterator 2000, D_Loss:0.858839750289917, G_Loss:2.1217539310455322

iterator 2100, D_Loss:0.9288656115531921, G_Loss:2.047290325164795

iterator 2200, D_Loss:0.9601131677627563, G_Loss:2.1366569995880127

iterator 2300, D_Loss:0.9433149099349976, G_Loss:1.895466923713684

iterator 2400, D_Loss:1.0729825496673584, G_Loss:2.0269181728363037

iterator 2500, D_Loss:0.942850649356842, G_Loss:2.053338050842285

iterator 2600, D_Loss:1.062316656112671, G_Loss:2.0927114486694336

iterator 2700, D_Loss:0.9166232943534851, G_Loss:2.278942584991455

iterator 2800, D_Loss:0.9437822103500366, G_Loss:2.204512357711792

iterator 2900, D_Loss:0.9265252351760864, G_Loss:2.420729398727417

iterator 3000, D_Loss:0.9784485697746277, G_Loss:2.097123384475708

iterator 3100, D_Loss:0.8875091075897217, G_Loss:1.9757705926895142

iterator 3200, D_Loss:0.9675177335739136, G_Loss:2.1296043395996094

iterator 3300, D_Loss:0.9193967580795288, G_Loss:2.0505588054656982

iterator 3400, D_Loss:0.9767551422119141, G_Loss:2.0667214393615723

iterator 3500, D_Loss:0.9960817098617554, G_Loss:2.1821157932281494

iterator 3600, D_Loss:0.8949047327041626, G_Loss:2.1951420307159424

iterator 3700, D_Loss:0.9602132439613342, G_Loss:2.0553195476531982

iterator 3800, D_Loss:0.9989140033721924, G_Loss:2.115100622177124

iterator 3900, D_Loss:0.9964092969894409, G_Loss:1.9493783712387085

iterator 4000, D_Loss:0.9320290088653564, G_Loss:2.1097054481506348

iterator 4100, D_Loss:0.9844685792922974, G_Loss:2.00791335105896

iterator 4200, D_Loss:1.0055382251739502, G_Loss:2.091562509536743

iterator 4300, D_Loss:0.908308744430542, G_Loss:2.1805708408355713

iterator 4400, D_Loss:0.9778131246566772, G_Loss:2.098234176635742

iterator 4500, D_Loss:0.9733039140701294, G_Loss:2.12292218208313

iterator 4600, D_Loss:0.895632803440094, G_Loss:2.1965725421905518

iterator 4700, D_Loss:0.939110517501831, G_Loss:2.166816473007202

iterator 4800, D_Loss:1.0118757486343384, G_Loss:2.1627883911132812

iterator 4900, D_Loss:0.9000401496887207, G_Loss:2.069815158843994

iterator 5000, D_Loss:0.9948439002037048, G_Loss:1.8819013833999634

-----------Epoch 4-----------
iterator 100, D_Loss:0.9476529359817505, G_Loss:2.1033473014831543

iterator 200, D_Loss:0.9195221066474915, G_Loss:2.1110076904296875

iterator 300, D_Loss:0.9627543091773987, G_Loss:2.046234130859375

iterator 400, D_Loss:0.97722989320755, G_Loss:2.30110764503479

iterator 500, D_Loss:1.0124540328979492, G_Loss:2.099304437637329

iterator 600, D_Loss:0.9756459593772888, G_Loss:2.0413928031921387

iterator 700, D_Loss:0.9755762815475464, G_Loss:2.166210412979126

iterator 800, D_Loss:1.006895661354065, G_Loss:1.9761230945587158

iterator 900, D_Loss:0.970107913017273, G_Loss:2.0448720455169678

iterator 1000, D_Loss:1.0047773122787476, G_Loss:1.9712424278259277

iterator 1100, D_Loss:1.029245376586914, G_Loss:2.051340103149414

iterator 1200, D_Loss:1.004009485244751, G_Loss:1.9795632362365723

iterator 1300, D_Loss:0.8790580034255981, G_Loss:2.105154514312744

iterator 1400, D_Loss:0.9239653944969177, G_Loss:2.1553773880004883

iterator 1500, D_Loss:0.9814034700393677, G_Loss:1.9450621604919434

iterator 1600, D_Loss:1.0199074745178223, G_Loss:1.8189678192138672

iterator 1700, D_Loss:1.071221113204956, G_Loss:1.9523979425430298

iterator 1800, D_Loss:0.9774800539016724, G_Loss:1.9817193746566772

iterator 1900, D_Loss:0.9731453657150269, G_Loss:2.025357484817505

iterator 2000, D_Loss:1.0112240314483643, G_Loss:1.779935598373413

iterator 2100, D_Loss:1.0232889652252197, G_Loss:1.860390067100525

iterator 2200, D_Loss:0.9858012199401855, G_Loss:1.9843875169754028

iterator 2300, D_Loss:0.9515508413314819, G_Loss:1.745914340019226

iterator 2400, D_Loss:1.0740087032318115, G_Loss:2.004157066345215

iterator 2500, D_Loss:1.0064811706542969, G_Loss:1.8115904331207275

iterator 2600, D_Loss:1.046091079711914, G_Loss:1.9709734916687012

iterator 2700, D_Loss:1.0558642148971558, G_Loss:1.9625205993652344

iterator 2800, D_Loss:1.0533859729766846, G_Loss:1.7450827360153198

iterator 2900, D_Loss:0.9927539229393005, G_Loss:1.8993868827819824

iterator 3000, D_Loss:0.9637398719787598, G_Loss:1.8728742599487305

iterator 3100, D_Loss:1.0502132177352905, G_Loss:1.9235285520553589

iterator 3200, D_Loss:1.0642832517623901, G_Loss:1.8552669286727905

iterator 3300, D_Loss:0.980010986328125, G_Loss:1.9272645711898804

iterator 3400, D_Loss:1.0342555046081543, G_Loss:1.9646002054214478

iterator 3500, D_Loss:1.0004487037658691, G_Loss:2.112830638885498

iterator 3600, D_Loss:1.0713269710540771, G_Loss:1.9829217195510864

iterator 3700, D_Loss:0.9241083264350891, G_Loss:1.8726495504379272

iterator 3800, D_Loss:1.0139553546905518, G_Loss:2.0625481605529785

iterator 3900, D_Loss:0.9754314422607422, G_Loss:1.8810359239578247

iterator 4000, D_Loss:0.984763503074646, G_Loss:2.152338981628418

iterator 4100, D_Loss:0.9853328466415405, G_Loss:2.0019137859344482

iterator 4200, D_Loss:0.990126371383667, G_Loss:1.8325984477996826

iterator 4300, D_Loss:0.9782987236976624, G_Loss:1.9052234888076782

iterator 4400, D_Loss:0.9402174949645996, G_Loss:1.8873426914215088

iterator 4500, D_Loss:1.0482826232910156, G_Loss:1.8537780046463013

iterator 4600, D_Loss:0.9188518524169922, G_Loss:2.122643232345581

iterator 4700, D_Loss:1.0272237062454224, G_Loss:1.838958501815796

iterator 4800, D_Loss:1.038642406463623, G_Loss:1.7477269172668457

iterator 4900, D_Loss:1.0116022825241089, G_Loss:1.8445589542388916

iterator 5000, D_Loss:1.0580466985702515, G_Loss:1.628543734550476

-----------Epoch 5-----------
iterator 100, D_Loss:1.010664701461792, G_Loss:1.937474012374878

iterator 200, D_Loss:0.9530152082443237, G_Loss:1.9367159605026245

iterator 300, D_Loss:1.0083733797073364, G_Loss:1.9279603958129883

iterator 400, D_Loss:1.0154708623886108, G_Loss:1.9946187734603882

iterator 500, D_Loss:0.9584214687347412, G_Loss:1.7532168626785278

iterator 600, D_Loss:1.0179972648620605, G_Loss:1.7951693534851074

iterator 700, D_Loss:1.0367778539657593, G_Loss:1.8421894311904907

iterator 800, D_Loss:1.0321235656738281, G_Loss:1.8833247423171997

iterator 900, D_Loss:0.9616069793701172, G_Loss:1.7646417617797852

iterator 1000, D_Loss:1.0025535821914673, G_Loss:1.6447514295578003

iterator 1100, D_Loss:0.9953191876411438, G_Loss:1.9226255416870117

iterator 1200, D_Loss:1.0070894956588745, G_Loss:2.0057177543640137

iterator 1300, D_Loss:1.0692923069000244, G_Loss:1.775324821472168

iterator 1400, D_Loss:1.0220122337341309, G_Loss:1.8407994508743286

iterator 1500, D_Loss:0.9906890988349915, G_Loss:1.8097978830337524

iterator 1600, D_Loss:0.972296953201294, G_Loss:1.8781437873840332

iterator 1700, D_Loss:0.9304620623588562, G_Loss:1.8053524494171143

iterator 1800, D_Loss:0.9289042949676514, G_Loss:1.8551181554794312

iterator 1900, D_Loss:1.0239275693893433, G_Loss:1.9584367275238037

iterator 2000, D_Loss:0.980962872505188, G_Loss:1.74722421169281

iterator 2100, D_Loss:0.9774584770202637, G_Loss:1.7427723407745361

iterator 2200, D_Loss:1.0818274021148682, G_Loss:1.6633055210113525

iterator 2300, D_Loss:1.013928771018982, G_Loss:1.7768481969833374

iterator 2400, D_Loss:0.9844809770584106, G_Loss:1.8820449113845825

iterator 2500, D_Loss:0.936379075050354, G_Loss:2.053786039352417

iterator 2600, D_Loss:1.0325038433074951, G_Loss:1.6971185207366943

iterator 2700, D_Loss:0.994157612323761, G_Loss:1.8481063842773438

iterator 2800, D_Loss:0.9912787079811096, G_Loss:1.870059609413147

iterator 2900, D_Loss:1.082082986831665, G_Loss:1.7797602415084839

iterator 3000, D_Loss:1.0305261611938477, G_Loss:1.7501232624053955

iterator 3100, D_Loss:1.0339765548706055, G_Loss:1.7271368503570557

iterator 3200, D_Loss:1.0770529508590698, G_Loss:1.785499930381775

iterator 3300, D_Loss:1.0121662616729736, G_Loss:1.7642526626586914

iterator 3400, D_Loss:1.148852825164795, G_Loss:1.725185513496399

iterator 3500, D_Loss:1.01678466796875, G_Loss:1.7640018463134766

iterator 3600, D_Loss:1.0718497037887573, G_Loss:1.7160142660140991

iterator 3700, D_Loss:0.9891853332519531, G_Loss:1.8069195747375488

iterator 3800, D_Loss:0.9991557598114014, G_Loss:1.781973958015442

iterator 3900, D_Loss:1.0049763917922974, G_Loss:1.8021637201309204

iterator 4000, D_Loss:1.0538668632507324, G_Loss:1.597327709197998

iterator 4100, D_Loss:0.9852200746536255, G_Loss:1.827125072479248

iterator 4200, D_Loss:1.058168649673462, G_Loss:1.7545905113220215

iterator 4300, D_Loss:1.0573270320892334, G_Loss:1.5937987565994263

iterator 4400, D_Loss:1.0579439401626587, G_Loss:1.568331003189087

iterator 4500, D_Loss:1.1002472639083862, G_Loss:1.615532398223877

iterator 4600, D_Loss:1.007083535194397, G_Loss:1.7405791282653809

iterator 4700, D_Loss:1.0400893688201904, G_Loss:1.6312121152877808

iterator 4800, D_Loss:1.0370049476623535, G_Loss:1.7904553413391113

iterator 4900, D_Loss:1.0399843454360962, G_Loss:1.531176209449768

iterator 5000, D_Loss:1.0542346239089966, G_Loss:1.7312623262405396

-----------Epoch 6-----------
iterator 100, D_Loss:0.9523746967315674, G_Loss:1.9773298501968384

iterator 200, D_Loss:1.0169490575790405, G_Loss:1.769148588180542

iterator 300, D_Loss:1.0418856143951416, G_Loss:1.8000056743621826

iterator 400, D_Loss:1.0998709201812744, G_Loss:1.6937085390090942

iterator 500, D_Loss:1.0761196613311768, G_Loss:1.8429710865020752

iterator 600, D_Loss:1.0001134872436523, G_Loss:1.518656611442566

iterator 700, D_Loss:1.019050121307373, G_Loss:1.81511652469635

iterator 800, D_Loss:1.0734578371047974, G_Loss:1.728678822517395

iterator 900, D_Loss:0.9982036352157593, G_Loss:1.7811967134475708

iterator 1000, D_Loss:1.0612716674804688, G_Loss:1.6360257863998413

iterator 1100, D_Loss:1.0134408473968506, G_Loss:1.6522583961486816

iterator 1200, D_Loss:1.140197992324829, G_Loss:1.5377188920974731

iterator 1300, D_Loss:1.0106186866760254, G_Loss:1.6865206956863403

iterator 1400, D_Loss:1.061991810798645, G_Loss:1.7675565481185913

iterator 1500, D_Loss:1.0561665296554565, G_Loss:1.9019595384597778

iterator 1600, D_Loss:1.0315656661987305, G_Loss:1.8177564144134521

iterator 1700, D_Loss:1.0385342836380005, G_Loss:1.710350513458252

iterator 1800, D_Loss:1.048327088356018, G_Loss:1.7590218782424927

iterator 1900, D_Loss:1.049088954925537, G_Loss:1.7896664142608643

iterator 2000, D_Loss:1.075713872909546, G_Loss:1.6388843059539795

iterator 2100, D_Loss:1.0465583801269531, G_Loss:1.8323390483856201

iterator 2200, D_Loss:1.0586587190628052, G_Loss:1.6951137781143188

iterator 2300, D_Loss:1.016824722290039, G_Loss:1.7426018714904785

iterator 2400, D_Loss:0.964438259601593, G_Loss:1.7019927501678467

iterator 2500, D_Loss:1.0419297218322754, G_Loss:1.6258864402770996

iterator 2600, D_Loss:1.0017976760864258, G_Loss:1.713112711906433

iterator 2700, D_Loss:1.098703384399414, G_Loss:1.7417844533920288

iterator 2800, D_Loss:1.001379132270813, G_Loss:1.7702211141586304

iterator 2900, D_Loss:1.081616997718811, G_Loss:1.7886143922805786

iterator 3000, D_Loss:1.0895943641662598, G_Loss:1.8096556663513184

iterator 3100, D_Loss:0.9911757707595825, G_Loss:1.6896990537643433

iterator 3200, D_Loss:1.0623271465301514, G_Loss:1.6872279644012451

iterator 3300, D_Loss:0.9519361257553101, G_Loss:1.7195829153060913

iterator 3400, D_Loss:0.9692779779434204, G_Loss:1.8852195739746094

iterator 3500, D_Loss:1.0632144212722778, G_Loss:1.6916661262512207

iterator 3600, D_Loss:1.0316104888916016, G_Loss:1.768273949623108

iterator 3700, D_Loss:1.065870761871338, G_Loss:1.704846978187561

iterator 3800, D_Loss:1.12453031539917, G_Loss:1.7038547992706299

iterator 3900, D_Loss:1.0582234859466553, G_Loss:1.683791995048523

iterator 4000, D_Loss:1.0810353755950928, G_Loss:1.8642457723617554

iterator 4100, D_Loss:1.02889883518219, G_Loss:1.7127541303634644

iterator 4200, D_Loss:0.985575258731842, G_Loss:1.663167953491211

iterator 4300, D_Loss:1.0714210271835327, G_Loss:1.6546146869659424

iterator 4400, D_Loss:1.026893973350525, G_Loss:1.6271255016326904

iterator 4500, D_Loss:1.0451812744140625, G_Loss:1.7272034883499146

iterator 4600, D_Loss:1.1164262294769287, G_Loss:1.7157186269760132

iterator 4700, D_Loss:1.1190460920333862, G_Loss:1.6456232070922852

iterator 4800, D_Loss:1.0486397743225098, G_Loss:1.694521188735962

iterator 4900, D_Loss:0.9479525685310364, G_Loss:1.6476950645446777

iterator 5000, D_Loss:1.049546241760254, G_Loss:1.7336465120315552

-----------Epoch 7-----------
iterator 100, D_Loss:0.99346524477005, G_Loss:1.7547141313552856

iterator 200, D_Loss:1.0042767524719238, G_Loss:1.7271586656570435

iterator 300, D_Loss:0.985451340675354, G_Loss:1.690952181816101

iterator 400, D_Loss:1.018048644065857, G_Loss:1.771748661994934

iterator 500, D_Loss:1.0328962802886963, G_Loss:1.6878066062927246

iterator 600, D_Loss:1.008770227432251, G_Loss:1.7884968519210815

iterator 700, D_Loss:1.009308099746704, G_Loss:1.583884596824646

iterator 800, D_Loss:1.0031551122665405, G_Loss:1.7919985055923462

iterator 900, D_Loss:0.9940585494041443, G_Loss:1.7221741676330566

iterator 1000, D_Loss:1.0006598234176636, G_Loss:1.744278907775879

iterator 1100, D_Loss:1.0637470483779907, G_Loss:1.7252240180969238

iterator 1200, D_Loss:1.0809885263442993, G_Loss:1.7257065773010254

iterator 1300, D_Loss:1.0258903503417969, G_Loss:1.7174842357635498

iterator 1400, D_Loss:0.9896532297134399, G_Loss:1.8071569204330444

iterator 1500, D_Loss:1.0863862037658691, G_Loss:1.7129725217819214

iterator 1600, D_Loss:1.0414949655532837, G_Loss:1.732702374458313

iterator 1700, D_Loss:1.0140907764434814, G_Loss:1.697743535041809

iterator 1800, D_Loss:1.0462477207183838, G_Loss:1.7234017848968506

iterator 1900, D_Loss:1.0147360563278198, G_Loss:1.9094045162200928

iterator 2000, D_Loss:1.0456138849258423, G_Loss:1.6058143377304077

iterator 2100, D_Loss:1.02672278881073, G_Loss:1.6423348188400269

iterator 2200, D_Loss:1.0217622518539429, G_Loss:1.7086986303329468

iterator 2300, D_Loss:0.9989646077156067, G_Loss:1.6991519927978516

iterator 2400, D_Loss:1.0503389835357666, G_Loss:1.7499366998672485

iterator 2500, D_Loss:1.0536766052246094, G_Loss:1.760138750076294

iterator 2600, D_Loss:0.994148850440979, G_Loss:1.6463218927383423

iterator 2700, D_Loss:1.0428924560546875, G_Loss:1.66505765914917

iterator 2800, D_Loss:1.0427641868591309, G_Loss:1.6622964143753052

iterator 2900, D_Loss:1.0428466796875, G_Loss:1.76235032081604

iterator 3000, D_Loss:1.1109588146209717, G_Loss:1.6816822290420532

iterator 3100, D_Loss:1.0202540159225464, G_Loss:1.791633129119873

iterator 3200, D_Loss:0.9850549101829529, G_Loss:1.7583262920379639

iterator 3300, D_Loss:1.040320634841919, G_Loss:1.6050119400024414

iterator 3400, D_Loss:1.0321331024169922, G_Loss:1.6419650316238403

iterator 3500, D_Loss:0.9629500508308411, G_Loss:1.6023244857788086

iterator 3600, D_Loss:1.0303378105163574, G_Loss:1.642590880393982

iterator 3700, D_Loss:1.093706727027893, G_Loss:1.7643498182296753

iterator 3800, D_Loss:0.9902232885360718, G_Loss:1.6599128246307373

iterator 3900, D_Loss:1.0375802516937256, G_Loss:1.7537662982940674

iterator 4000, D_Loss:1.0803422927856445, G_Loss:1.703611969947815

iterator 4100, D_Loss:0.9987517595291138, G_Loss:1.7156012058258057

iterator 4200, D_Loss:1.0103362798690796, G_Loss:1.7242341041564941

iterator 4300, D_Loss:1.0698564052581787, G_Loss:1.7876172065734863

iterator 4400, D_Loss:1.0108575820922852, G_Loss:1.65199875831604

iterator 4500, D_Loss:1.0640339851379395, G_Loss:1.8059238195419312

iterator 4600, D_Loss:1.063220500946045, G_Loss:1.7086267471313477

iterator 4700, D_Loss:1.026667594909668, G_Loss:1.9612679481506348

iterator 4800, D_Loss:1.030221700668335, G_Loss:1.8327170610427856

iterator 4900, D_Loss:0.993953287601471, G_Loss:1.6973276138305664

iterator 5000, D_Loss:0.9998542070388794, G_Loss:1.8168296813964844

-----------Epoch 8-----------
iterator 100, D_Loss:0.9773059487342834, G_Loss:1.8497828245162964

iterator 200, D_Loss:1.048133134841919, G_Loss:1.6026170253753662

iterator 300, D_Loss:0.9804074168205261, G_Loss:1.7834677696228027

iterator 400, D_Loss:0.9983223676681519, G_Loss:1.8167036771774292

iterator 500, D_Loss:1.0377743244171143, G_Loss:1.7599254846572876

iterator 600, D_Loss:1.0678634643554688, G_Loss:1.7494105100631714

iterator 700, D_Loss:1.0657057762145996, G_Loss:1.6731904745101929

iterator 800, D_Loss:1.0719943046569824, G_Loss:1.6790505647659302

iterator 900, D_Loss:0.9799617528915405, G_Loss:1.7317806482315063

iterator 1000, D_Loss:1.1067206859588623, G_Loss:1.902295470237732

iterator 1100, D_Loss:1.0774726867675781, G_Loss:1.663455843925476

iterator 1200, D_Loss:1.0289934873580933, G_Loss:1.6571301221847534

iterator 1300, D_Loss:1.0349962711334229, G_Loss:1.6115527153015137

iterator 1400, D_Loss:1.02364182472229, G_Loss:1.8323142528533936

iterator 1500, D_Loss:1.0706689357757568, G_Loss:1.7336702346801758

iterator 1600, D_Loss:1.0210484266281128, G_Loss:1.735607624053955

iterator 1700, D_Loss:1.0701137781143188, G_Loss:1.7200214862823486

iterator 1800, D_Loss:1.0125113725662231, G_Loss:1.8142532110214233

iterator 1900, D_Loss:0.9299603700637817, G_Loss:1.9081268310546875

iterator 2000, D_Loss:1.0352922677993774, G_Loss:1.8822729587554932

iterator 2100, D_Loss:1.0190914869308472, G_Loss:1.6910725831985474

iterator 2200, D_Loss:0.963401198387146, G_Loss:1.7171881198883057

iterator 2300, D_Loss:1.095929503440857, G_Loss:1.6423733234405518

iterator 2400, D_Loss:1.0396050214767456, G_Loss:1.6938600540161133

iterator 2500, D_Loss:1.0289555788040161, G_Loss:1.7098264694213867

iterator 2600, D_Loss:1.0913512706756592, G_Loss:1.7754716873168945

iterator 2700, D_Loss:1.0310693979263306, G_Loss:1.6892757415771484

iterator 2800, D_Loss:1.0514674186706543, G_Loss:1.6645230054855347

iterator 2900, D_Loss:1.110612154006958, G_Loss:1.7577722072601318

iterator 3000, D_Loss:1.0456562042236328, G_Loss:1.8129513263702393

iterator 3100, D_Loss:1.0070149898529053, G_Loss:1.6376078128814697

iterator 3200, D_Loss:1.009911060333252, G_Loss:1.757887363433838

iterator 3300, D_Loss:1.0336276292800903, G_Loss:1.8484809398651123

iterator 3400, D_Loss:1.0348929166793823, G_Loss:1.686858892440796

iterator 3500, D_Loss:1.0533714294433594, G_Loss:1.735121250152588

iterator 3600, D_Loss:1.0676127672195435, G_Loss:1.6746819019317627

iterator 3700, D_Loss:1.0256245136260986, G_Loss:1.7207392454147339

iterator 3800, D_Loss:0.9904398918151855, G_Loss:1.9509549140930176

iterator 3900, D_Loss:1.0424773693084717, G_Loss:1.7437621355056763

iterator 4000, D_Loss:1.041032075881958, G_Loss:1.5992331504821777

iterator 4100, D_Loss:1.0345485210418701, G_Loss:1.787236213684082

iterator 4200, D_Loss:1.0304518938064575, G_Loss:1.9001121520996094

iterator 4300, D_Loss:1.0093166828155518, G_Loss:1.8541754484176636

iterator 4400, D_Loss:1.1413965225219727, G_Loss:1.638412356376648

iterator 4500, D_Loss:1.0704537630081177, G_Loss:1.7461735010147095

iterator 4600, D_Loss:1.0295454263687134, G_Loss:1.8316174745559692

iterator 4700, D_Loss:0.9764429330825806, G_Loss:1.7945233583450317

iterator 4800, D_Loss:0.9920440316200256, G_Loss:1.871656060218811

iterator 4900, D_Loss:1.0189743041992188, G_Loss:1.998686671257019

iterator 5000, D_Loss:1.019058108329773, G_Loss:1.7769664525985718

-----------Epoch 9-----------
iterator 100, D_Loss:1.0679571628570557, G_Loss:1.863296627998352

iterator 200, D_Loss:1.0648181438446045, G_Loss:1.7865526676177979

iterator 300, D_Loss:1.027433156967163, G_Loss:1.5942035913467407

iterator 400, D_Loss:0.9908577799797058, G_Loss:1.7213975191116333

iterator 500, D_Loss:1.093878984451294, G_Loss:1.841577410697937

iterator 600, D_Loss:1.0743260383605957, G_Loss:1.7180225849151611

iterator 700, D_Loss:1.0341780185699463, G_Loss:1.7254092693328857

iterator 800, D_Loss:0.9933261275291443, G_Loss:1.747532844543457

iterator 900, D_Loss:0.9759604930877686, G_Loss:1.833059310913086

iterator 1000, D_Loss:1.0211665630340576, G_Loss:1.6986796855926514

iterator 1100, D_Loss:1.011554479598999, G_Loss:1.7134294509887695

iterator 1200, D_Loss:1.1007804870605469, G_Loss:1.5639941692352295

iterator 1300, D_Loss:1.0294114351272583, G_Loss:1.7893038988113403

iterator 1400, D_Loss:1.0801177024841309, G_Loss:1.8193697929382324

iterator 1500, D_Loss:1.0550755262374878, G_Loss:1.8060214519500732

iterator 1600, D_Loss:1.0024384260177612, G_Loss:1.8654893636703491

iterator 1700, D_Loss:1.0203806161880493, G_Loss:1.917673110961914

iterator 1800, D_Loss:1.0017774105072021, G_Loss:1.6611284017562866

iterator 1900, D_Loss:0.9835453033447266, G_Loss:1.9278908967971802

iterator 2000, D_Loss:1.0053592920303345, G_Loss:1.8311821222305298

iterator 2100, D_Loss:1.0034955739974976, G_Loss:1.804126501083374

iterator 2200, D_Loss:1.0279446840286255, G_Loss:1.7103323936462402

iterator 2300, D_Loss:0.9081401824951172, G_Loss:1.8545323610305786

iterator 2400, D_Loss:1.0201627016067505, G_Loss:1.7372781038284302

iterator 2500, D_Loss:0.9962430000305176, G_Loss:1.8309824466705322

iterator 2600, D_Loss:1.0647733211517334, G_Loss:1.8301374912261963

iterator 2700, D_Loss:0.9964854121208191, G_Loss:1.7431085109710693

iterator 2800, D_Loss:0.987727701663971, G_Loss:1.9360949993133545

iterator 2900, D_Loss:0.9641124606132507, G_Loss:1.8236068487167358

iterator 3000, D_Loss:0.9654666781425476, G_Loss:1.9174857139587402

iterator 3100, D_Loss:0.9593536257743835, G_Loss:1.8761504888534546

iterator 3200, D_Loss:1.0051966905593872, G_Loss:1.8717987537384033

iterator 3300, D_Loss:0.9465534687042236, G_Loss:1.749991536140442

iterator 3400, D_Loss:0.9623833894729614, G_Loss:1.8405680656433105

iterator 3500, D_Loss:1.0343453884124756, G_Loss:1.7998244762420654

iterator 3600, D_Loss:1.0410202741622925, G_Loss:1.872532606124878

iterator 3700, D_Loss:1.021298885345459, G_Loss:1.7554386854171753

iterator 3800, D_Loss:0.9559680223464966, G_Loss:2.050272226333618

iterator 3900, D_Loss:0.9479986429214478, G_Loss:1.8851546049118042

iterator 4000, D_Loss:1.0302892923355103, G_Loss:1.9590054750442505

iterator 4100, D_Loss:0.9622071981430054, G_Loss:1.9404842853546143

iterator 4200, D_Loss:0.9268916845321655, G_Loss:1.862990140914917

iterator 4300, D_Loss:0.9891798496246338, G_Loss:1.7467052936553955

iterator 4400, D_Loss:1.1154696941375732, G_Loss:1.778934359550476

iterator 4500, D_Loss:0.9509965777397156, G_Loss:1.7486615180969238

iterator 4600, D_Loss:0.987451434135437, G_Loss:1.8457117080688477

iterator 4700, D_Loss:0.9621143341064453, G_Loss:1.7873485088348389

iterator 4800, D_Loss:1.035848617553711, G_Loss:1.751009464263916

iterator 4900, D_Loss:0.9518769979476929, G_Loss:1.8492025136947632

iterator 5000, D_Loss:1.0029528141021729, G_Loss:1.7914390563964844

VGAN_generator(
  (input): Linear(in_features=256, out_features=200, bias=True)
  (inputbn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (bn0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=200, out_features=200, bias=True)
  (bn1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=200, out_features=200, bias=True)
  (bn2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=200, out_features=105, bias=True)
  (outputbn): BatchNorm1d(105, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=105, out_features=200, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (fc1): Linear(in_features=200, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=200, bias=True)
  (output): Linear(in_features=200, out_features=1, bias=True)
)
(0, False, 105)
-----------Epoch 0-----------
iterator 100, D_Loss:0.7003183960914612, G_Loss:5.354097843170166

iterator 200, D_Loss:0.6004743576049805, G_Loss:6.4397382736206055

iterator 300, D_Loss:0.5656845569610596, G_Loss:7.434243679046631

iterator 400, D_Loss:0.5797899961471558, G_Loss:7.129823207855225

iterator 500, D_Loss:0.5549585819244385, G_Loss:6.315884113311768

iterator 600, D_Loss:0.4886493384838104, G_Loss:6.569949626922607

iterator 700, D_Loss:0.5288838148117065, G_Loss:5.916399955749512

iterator 800, D_Loss:0.4957919120788574, G_Loss:5.718743324279785

iterator 900, D_Loss:0.5084435343742371, G_Loss:5.849126815795898

iterator 1000, D_Loss:0.5125837922096252, G_Loss:6.087294101715088

iterator 1100, D_Loss:0.5155152678489685, G_Loss:5.897572994232178

iterator 1200, D_Loss:0.550712525844574, G_Loss:6.203582763671875

iterator 1300, D_Loss:0.5371750593185425, G_Loss:6.178642272949219

iterator 1400, D_Loss:0.4996476471424103, G_Loss:6.10068416595459

iterator 1500, D_Loss:0.4860786199569702, G_Loss:6.5023369789123535

iterator 1600, D_Loss:0.5548487305641174, G_Loss:5.162872791290283

iterator 1700, D_Loss:0.5236692428588867, G_Loss:5.629939556121826

iterator 1800, D_Loss:0.5373689532279968, G_Loss:5.154790878295898

iterator 1900, D_Loss:0.5528649091720581, G_Loss:5.6363019943237305

iterator 2000, D_Loss:0.5115195512771606, G_Loss:5.439582824707031

iterator 2100, D_Loss:0.5370846390724182, G_Loss:5.115635871887207

iterator 2200, D_Loss:0.544428825378418, G_Loss:4.782823085784912

iterator 2300, D_Loss:0.545400083065033, G_Loss:5.267535209655762

iterator 2400, D_Loss:0.604181706905365, G_Loss:4.614363193511963

iterator 2500, D_Loss:0.5573224425315857, G_Loss:4.653872966766357

iterator 2600, D_Loss:0.5580662488937378, G_Loss:4.539653778076172

iterator 2700, D_Loss:0.5757827758789062, G_Loss:4.67457914352417

iterator 2800, D_Loss:0.5841929912567139, G_Loss:4.875842571258545

iterator 2900, D_Loss:0.5678648948669434, G_Loss:4.667932987213135

iterator 3000, D_Loss:0.5747913122177124, G_Loss:4.072487831115723

iterator 3100, D_Loss:0.5855675935745239, G_Loss:4.2822980880737305

iterator 3200, D_Loss:0.5472656488418579, G_Loss:4.393426418304443

iterator 3300, D_Loss:0.6239662170410156, G_Loss:4.3327484130859375

iterator 3400, D_Loss:0.5663058161735535, G_Loss:3.977046251296997

iterator 3500, D_Loss:0.5917984843254089, G_Loss:4.340510845184326

iterator 3600, D_Loss:0.613259494304657, G_Loss:4.182693004608154

iterator 3700, D_Loss:0.6232807636260986, G_Loss:3.9299004077911377

iterator 3800, D_Loss:0.6392408013343811, G_Loss:4.185837745666504

iterator 3900, D_Loss:0.6567941904067993, G_Loss:3.91160249710083

iterator 4000, D_Loss:0.6902461647987366, G_Loss:3.9438345432281494

iterator 4100, D_Loss:0.6267356276512146, G_Loss:3.7378056049346924

iterator 4200, D_Loss:0.6706011891365051, G_Loss:3.6221632957458496

iterator 4300, D_Loss:0.6708499193191528, G_Loss:3.6199350357055664

iterator 4400, D_Loss:0.6009464859962463, G_Loss:3.5732879638671875

iterator 4500, D_Loss:0.6385903358459473, G_Loss:3.592710494995117

iterator 4600, D_Loss:0.664094090461731, G_Loss:3.6411948204040527

iterator 4700, D_Loss:0.6867800951004028, G_Loss:3.4260847568511963

iterator 4800, D_Loss:0.6256134510040283, G_Loss:3.82112193107605

iterator 4900, D_Loss:0.6599490642547607, G_Loss:3.5767617225646973

iterator 5000, D_Loss:0.6905462741851807, G_Loss:3.623960256576538

-----------Epoch 1-----------
iterator 100, D_Loss:0.6582773327827454, G_Loss:3.589280843734741

iterator 200, D_Loss:0.700617790222168, G_Loss:3.3735175132751465

iterator 300, D_Loss:0.6911222338676453, G_Loss:3.551366090774536

iterator 400, D_Loss:0.6679277420043945, G_Loss:3.806858539581299

iterator 500, D_Loss:0.7176077365875244, G_Loss:3.3206593990325928

iterator 600, D_Loss:0.6383844614028931, G_Loss:3.7072010040283203

iterator 700, D_Loss:0.6963529586791992, G_Loss:3.4458131790161133

iterator 800, D_Loss:0.7089948654174805, G_Loss:3.4199953079223633

iterator 900, D_Loss:0.7165587544441223, G_Loss:3.3616647720336914

iterator 1000, D_Loss:0.7122109532356262, G_Loss:3.2879602909088135

iterator 1100, D_Loss:0.6938719749450684, G_Loss:3.6311423778533936

iterator 1200, D_Loss:0.7549529075622559, G_Loss:3.422016143798828

iterator 1300, D_Loss:0.7288845777511597, G_Loss:3.4501006603240967

iterator 1400, D_Loss:0.7099506258964539, G_Loss:3.3496646881103516

iterator 1500, D_Loss:0.6472800970077515, G_Loss:3.2608368396759033

iterator 1600, D_Loss:0.7018339037895203, G_Loss:3.6410279273986816

iterator 1700, D_Loss:0.7129884958267212, G_Loss:3.443265199661255

iterator 1800, D_Loss:0.7189662456512451, G_Loss:3.226425886154175

iterator 1900, D_Loss:0.7489344477653503, G_Loss:3.119718074798584

iterator 2000, D_Loss:0.7268196940422058, G_Loss:3.1411356925964355

iterator 2100, D_Loss:0.7095930576324463, G_Loss:3.207430124282837

iterator 2200, D_Loss:0.7618027329444885, G_Loss:3.364753007888794

iterator 2300, D_Loss:0.7404059171676636, G_Loss:3.2714052200317383

iterator 2400, D_Loss:0.7796763777732849, G_Loss:3.0198163986206055

iterator 2500, D_Loss:0.7833134531974792, G_Loss:2.888385534286499

iterator 2600, D_Loss:0.7395285964012146, G_Loss:3.216187000274658

iterator 2700, D_Loss:0.7513551712036133, G_Loss:2.9848978519439697

iterator 2800, D_Loss:0.7871984839439392, G_Loss:2.9913249015808105

iterator 2900, D_Loss:0.7840664386749268, G_Loss:3.021282911300659

iterator 3000, D_Loss:0.7479433417320251, G_Loss:3.026186943054199

iterator 3100, D_Loss:0.8222758769989014, G_Loss:3.078197956085205

iterator 3200, D_Loss:0.8016935586929321, G_Loss:2.849543809890747

iterator 3300, D_Loss:0.7372221350669861, G_Loss:3.0734710693359375

iterator 3400, D_Loss:0.7893305420875549, G_Loss:2.888720750808716

iterator 3500, D_Loss:0.7883420586585999, G_Loss:2.8366191387176514

iterator 3600, D_Loss:0.7920911312103271, G_Loss:3.185459613800049

iterator 3700, D_Loss:0.8243057131767273, G_Loss:2.7466111183166504

iterator 3800, D_Loss:0.8317367434501648, G_Loss:3.0220367908477783

iterator 3900, D_Loss:0.7714281678199768, G_Loss:3.018648862838745

iterator 4000, D_Loss:0.8181425333023071, G_Loss:2.922454595565796

iterator 4100, D_Loss:0.7465715408325195, G_Loss:2.9273018836975098

iterator 4200, D_Loss:0.8458454608917236, G_Loss:2.809307336807251

iterator 4300, D_Loss:0.7908867597579956, G_Loss:2.8164782524108887

iterator 4400, D_Loss:0.7981229424476624, G_Loss:2.695915460586548

iterator 4500, D_Loss:0.7632572054862976, G_Loss:2.6161487102508545

iterator 4600, D_Loss:0.7717039585113525, G_Loss:2.812201738357544

iterator 4700, D_Loss:0.7888402342796326, G_Loss:2.9955129623413086

iterator 4800, D_Loss:0.8120691776275635, G_Loss:2.7726964950561523

iterator 4900, D_Loss:0.8408387303352356, G_Loss:2.838104009628296

iterator 5000, D_Loss:0.7855954170227051, G_Loss:2.548408269882202

-----------Epoch 2-----------
iterator 100, D_Loss:0.8139513731002808, G_Loss:2.7256453037261963

iterator 200, D_Loss:0.8712302446365356, G_Loss:2.7813374996185303

iterator 300, D_Loss:0.8541724681854248, G_Loss:2.5655345916748047

iterator 400, D_Loss:0.8104945421218872, G_Loss:2.655625343322754

iterator 500, D_Loss:0.8842027187347412, G_Loss:2.450139284133911

iterator 600, D_Loss:0.8575862646102905, G_Loss:2.4762039184570312

iterator 700, D_Loss:0.9193886518478394, G_Loss:2.521873712539673

iterator 800, D_Loss:0.8508412837982178, G_Loss:2.4862866401672363

iterator 900, D_Loss:0.8573009371757507, G_Loss:2.55538010597229

iterator 1000, D_Loss:0.8950799703598022, G_Loss:2.584965705871582

iterator 1100, D_Loss:0.8495769500732422, G_Loss:2.4850730895996094

iterator 1200, D_Loss:0.9358363151550293, G_Loss:2.3134982585906982

iterator 1300, D_Loss:0.8964403867721558, G_Loss:2.473504066467285

iterator 1400, D_Loss:0.9430800676345825, G_Loss:2.573817491531372

iterator 1500, D_Loss:0.8877307176589966, G_Loss:2.53328013420105

iterator 1600, D_Loss:0.943490743637085, G_Loss:2.2289390563964844

iterator 1700, D_Loss:0.8940427303314209, G_Loss:2.151973247528076

iterator 1800, D_Loss:0.9001948833465576, G_Loss:2.3187549114227295

iterator 1900, D_Loss:0.9368579387664795, G_Loss:2.3551340103149414

iterator 2000, D_Loss:0.9142013788223267, G_Loss:2.264094591140747

iterator 2100, D_Loss:0.9162104725837708, G_Loss:2.1720073223114014

iterator 2200, D_Loss:0.9243453741073608, G_Loss:2.3168630599975586

iterator 2300, D_Loss:0.9418862462043762, G_Loss:2.098470687866211

iterator 2400, D_Loss:0.9392020106315613, G_Loss:2.118685722351074

iterator 2500, D_Loss:0.9905785322189331, G_Loss:2.185901165008545

iterator 2600, D_Loss:0.9747555255889893, G_Loss:2.0711095333099365

iterator 2700, D_Loss:0.9452875852584839, G_Loss:2.1651482582092285

iterator 2800, D_Loss:0.986950695514679, G_Loss:2.1913585662841797

iterator 2900, D_Loss:0.9601770043373108, G_Loss:2.1683430671691895

iterator 3000, D_Loss:0.9531250596046448, G_Loss:2.169477939605713

iterator 3100, D_Loss:0.9485445022583008, G_Loss:2.2162210941314697

iterator 3200, D_Loss:0.9299107789993286, G_Loss:2.058356523513794

iterator 3300, D_Loss:0.9468474388122559, G_Loss:2.1290390491485596

iterator 3400, D_Loss:0.955927312374115, G_Loss:1.9803329706192017

iterator 3500, D_Loss:0.9275813102722168, G_Loss:2.090665578842163

iterator 3600, D_Loss:1.0147662162780762, G_Loss:1.9548966884613037

iterator 3700, D_Loss:0.9897230863571167, G_Loss:2.0244126319885254

iterator 3800, D_Loss:1.0127716064453125, G_Loss:2.1611475944519043

iterator 3900, D_Loss:0.9546259641647339, G_Loss:2.253147602081299

iterator 4000, D_Loss:1.0130540132522583, G_Loss:1.961061954498291

iterator 4100, D_Loss:1.0045146942138672, G_Loss:1.8911006450653076

iterator 4200, D_Loss:0.9767065644264221, G_Loss:2.2200512886047363

iterator 4300, D_Loss:1.0075973272323608, G_Loss:2.0590670108795166

iterator 4400, D_Loss:0.9452570676803589, G_Loss:1.965821623802185

iterator 4500, D_Loss:1.0197590589523315, G_Loss:1.9265222549438477

iterator 4600, D_Loss:0.919189453125, G_Loss:2.259906053543091

iterator 4700, D_Loss:1.004737138748169, G_Loss:2.014038324356079

iterator 4800, D_Loss:1.0168706178665161, G_Loss:2.0554165840148926

iterator 4900, D_Loss:1.041595220565796, G_Loss:1.8388895988464355

iterator 5000, D_Loss:0.9995837807655334, G_Loss:2.261517286300659

-----------Epoch 3-----------
iterator 100, D_Loss:1.0823206901550293, G_Loss:1.9395583868026733

iterator 200, D_Loss:1.0325586795806885, G_Loss:1.8392894268035889

iterator 300, D_Loss:1.0271766185760498, G_Loss:1.8296966552734375

iterator 400, D_Loss:1.0740010738372803, G_Loss:1.688156247138977

iterator 500, D_Loss:1.046462893486023, G_Loss:1.7323468923568726

iterator 600, D_Loss:1.016892671585083, G_Loss:1.7966423034667969

iterator 700, D_Loss:1.0242819786071777, G_Loss:1.8667250871658325

iterator 800, D_Loss:1.0600529909133911, G_Loss:1.7820711135864258

iterator 900, D_Loss:1.082787275314331, G_Loss:1.7180153131484985

iterator 1000, D_Loss:1.0414453744888306, G_Loss:1.737565040588379

iterator 1100, D_Loss:1.0806885957717896, G_Loss:1.8549277782440186

iterator 1200, D_Loss:1.1236375570297241, G_Loss:1.70139479637146

iterator 1300, D_Loss:1.0709218978881836, G_Loss:1.6451791524887085

iterator 1400, D_Loss:1.033440351486206, G_Loss:1.7259142398834229

iterator 1500, D_Loss:1.075882911682129, G_Loss:1.6943305730819702

iterator 1600, D_Loss:1.0873883962631226, G_Loss:1.7310618162155151

iterator 1700, D_Loss:1.031130075454712, G_Loss:1.841247320175171

iterator 1800, D_Loss:1.0589830875396729, G_Loss:1.7777661085128784

iterator 1900, D_Loss:1.090085506439209, G_Loss:1.5999493598937988

iterator 2000, D_Loss:1.0814036130905151, G_Loss:1.636687159538269

iterator 2100, D_Loss:1.0784896612167358, G_Loss:1.6352732181549072

iterator 2200, D_Loss:1.0703692436218262, G_Loss:1.5944809913635254

iterator 2300, D_Loss:1.122476577758789, G_Loss:1.617458462715149

iterator 2400, D_Loss:1.0652656555175781, G_Loss:1.6688083410263062

iterator 2500, D_Loss:1.110348105430603, G_Loss:1.593995213508606

iterator 2600, D_Loss:1.0261850357055664, G_Loss:1.754238486289978

iterator 2700, D_Loss:1.0883455276489258, G_Loss:1.6595505475997925

iterator 2800, D_Loss:1.1010358333587646, G_Loss:1.6213778257369995

iterator 2900, D_Loss:1.079375147819519, G_Loss:1.69768226146698

iterator 3000, D_Loss:1.0588899850845337, G_Loss:1.7418177127838135

iterator 3100, D_Loss:1.04705011844635, G_Loss:1.6669399738311768

iterator 3200, D_Loss:1.0587425231933594, G_Loss:1.6494383811950684

iterator 3300, D_Loss:1.0606361627578735, G_Loss:1.7108079195022583

iterator 3400, D_Loss:1.086904525756836, G_Loss:1.6444454193115234

iterator 3500, D_Loss:1.100231647491455, G_Loss:1.5207560062408447

iterator 3600, D_Loss:1.103886365890503, G_Loss:1.8750126361846924

iterator 3700, D_Loss:1.1257632970809937, G_Loss:1.5402098894119263

iterator 3800, D_Loss:1.1172155141830444, G_Loss:1.5738739967346191

iterator 3900, D_Loss:1.1237285137176514, G_Loss:1.5071721076965332

iterator 4000, D_Loss:1.1896677017211914, G_Loss:1.4991931915283203

iterator 4100, D_Loss:1.1261707544326782, G_Loss:1.4115720987319946

iterator 4200, D_Loss:1.135623574256897, G_Loss:1.6194632053375244

iterator 4300, D_Loss:1.1943366527557373, G_Loss:1.2510905265808105

iterator 4400, D_Loss:1.1588630676269531, G_Loss:1.3887898921966553

iterator 4500, D_Loss:1.1258800029754639, G_Loss:1.5129127502441406

iterator 4600, D_Loss:1.099228858947754, G_Loss:1.5341615676879883

iterator 4700, D_Loss:1.1631641387939453, G_Loss:1.3996535539627075

iterator 4800, D_Loss:1.1242706775665283, G_Loss:1.4571146965026855

iterator 4900, D_Loss:1.1741206645965576, G_Loss:1.450089693069458

iterator 5000, D_Loss:1.1767466068267822, G_Loss:1.3346054553985596

-----------Epoch 4-----------
iterator 100, D_Loss:1.1228752136230469, G_Loss:1.387694001197815

iterator 200, D_Loss:1.1656372547149658, G_Loss:1.4653112888336182

iterator 300, D_Loss:1.0826542377471924, G_Loss:1.778375267982483

iterator 400, D_Loss:1.091577410697937, G_Loss:1.3655314445495605

iterator 500, D_Loss:1.1233794689178467, G_Loss:1.5183417797088623

iterator 600, D_Loss:1.0634338855743408, G_Loss:1.600497841835022

iterator 700, D_Loss:1.145495891571045, G_Loss:1.4620869159698486

iterator 800, D_Loss:1.1203227043151855, G_Loss:1.43667733669281

iterator 900, D_Loss:1.1485804319381714, G_Loss:1.4751050472259521

iterator 1000, D_Loss:1.1136398315429688, G_Loss:1.5711332559585571

iterator 1100, D_Loss:1.1731823682785034, G_Loss:1.3801789283752441

iterator 1200, D_Loss:1.124372959136963, G_Loss:1.456668734550476

iterator 1300, D_Loss:1.164526104927063, G_Loss:1.4357296228408813

iterator 1400, D_Loss:1.1639057397842407, G_Loss:1.363799810409546

iterator 1500, D_Loss:1.0860868692398071, G_Loss:1.5456223487854004

iterator 1600, D_Loss:1.1672663688659668, G_Loss:1.353713035583496

iterator 1700, D_Loss:1.1286649703979492, G_Loss:1.4161195755004883

iterator 1800, D_Loss:1.1732256412506104, G_Loss:1.41966712474823

iterator 1900, D_Loss:1.150418996810913, G_Loss:1.5046794414520264

iterator 2000, D_Loss:1.1798466444015503, G_Loss:1.3057035207748413

iterator 2100, D_Loss:1.2322337627410889, G_Loss:1.2727861404418945

iterator 2200, D_Loss:1.1645565032958984, G_Loss:1.2845197916030884

iterator 2300, D_Loss:1.1816257238388062, G_Loss:1.3809540271759033

iterator 2400, D_Loss:1.156247854232788, G_Loss:1.3684724569320679

iterator 2500, D_Loss:1.160660982131958, G_Loss:1.3385554552078247

iterator 2600, D_Loss:1.171808123588562, G_Loss:1.1918535232543945

iterator 2700, D_Loss:1.1681171655654907, G_Loss:1.3459877967834473

iterator 2800, D_Loss:1.198621392250061, G_Loss:1.2425950765609741

iterator 2900, D_Loss:1.1750400066375732, G_Loss:1.4529396295547485

iterator 3000, D_Loss:1.1626973152160645, G_Loss:1.252571940422058

iterator 3100, D_Loss:1.161321997642517, G_Loss:1.3312351703643799

iterator 3200, D_Loss:1.19379723072052, G_Loss:1.2631027698516846

iterator 3300, D_Loss:1.1962401866912842, G_Loss:1.2910417318344116

iterator 3400, D_Loss:1.227851390838623, G_Loss:1.2054674625396729

iterator 3500, D_Loss:1.213692307472229, G_Loss:1.262756109237671

iterator 3600, D_Loss:1.2131648063659668, G_Loss:1.2781668901443481

iterator 3700, D_Loss:1.2427382469177246, G_Loss:1.2804374694824219

iterator 3800, D_Loss:1.2191400527954102, G_Loss:1.1050654649734497

iterator 3900, D_Loss:1.1977918148040771, G_Loss:1.274524211883545

iterator 4000, D_Loss:1.204390287399292, G_Loss:1.2789303064346313

iterator 4100, D_Loss:1.1870054006576538, G_Loss:1.3258512020111084

iterator 4200, D_Loss:1.213149070739746, G_Loss:1.2698123455047607

iterator 4300, D_Loss:1.1569267511367798, G_Loss:1.3427317142486572

iterator 4400, D_Loss:1.24049973487854, G_Loss:1.127958059310913

iterator 4500, D_Loss:1.2108162641525269, G_Loss:1.2086882591247559

iterator 4600, D_Loss:1.2300227880477905, G_Loss:1.1337780952453613

iterator 4700, D_Loss:1.198777675628662, G_Loss:1.2765305042266846

iterator 4800, D_Loss:1.2023793458938599, G_Loss:1.1686301231384277

iterator 4900, D_Loss:1.2189984321594238, G_Loss:1.266696572303772

iterator 5000, D_Loss:1.1976654529571533, G_Loss:1.3011231422424316

-----------Epoch 5-----------
iterator 100, D_Loss:1.1638517379760742, G_Loss:1.2889817953109741

iterator 200, D_Loss:1.2220089435577393, G_Loss:1.1893539428710938

iterator 300, D_Loss:1.1729316711425781, G_Loss:1.3056687116622925

iterator 400, D_Loss:1.194506049156189, G_Loss:1.2763394117355347

iterator 500, D_Loss:1.2030452489852905, G_Loss:1.2224743366241455

iterator 600, D_Loss:1.2050997018814087, G_Loss:1.1928025484085083

iterator 700, D_Loss:1.196572184562683, G_Loss:1.2539472579956055

iterator 800, D_Loss:1.2276381254196167, G_Loss:1.1076407432556152

iterator 900, D_Loss:1.2680306434631348, G_Loss:1.116280198097229

iterator 1000, D_Loss:1.2593806982040405, G_Loss:1.115566372871399

iterator 1100, D_Loss:1.2549712657928467, G_Loss:1.13174569606781

iterator 1200, D_Loss:1.23292076587677, G_Loss:1.2196820974349976

iterator 1300, D_Loss:1.2582275867462158, G_Loss:1.1110631227493286

iterator 1400, D_Loss:1.1898579597473145, G_Loss:1.1936759948730469

iterator 1500, D_Loss:1.2637152671813965, G_Loss:1.1447800397872925

iterator 1600, D_Loss:1.2083210945129395, G_Loss:1.1284390687942505

iterator 1700, D_Loss:1.2527704238891602, G_Loss:1.0735102891921997

iterator 1800, D_Loss:1.2637255191802979, G_Loss:1.1002503633499146

iterator 1900, D_Loss:1.2085926532745361, G_Loss:1.0956175327301025

iterator 2000, D_Loss:1.2011334896087646, G_Loss:1.2398808002471924

iterator 2100, D_Loss:1.2012783288955688, G_Loss:1.1689870357513428

iterator 2200, D_Loss:1.26553475856781, G_Loss:1.1098196506500244

iterator 2300, D_Loss:1.2377195358276367, G_Loss:1.1185036897659302

iterator 2400, D_Loss:1.2138152122497559, G_Loss:1.206028938293457

iterator 2500, D_Loss:1.201617956161499, G_Loss:1.156198501586914

iterator 2600, D_Loss:1.2111475467681885, G_Loss:1.1495351791381836

iterator 2700, D_Loss:1.2458404302597046, G_Loss:1.0980437994003296

iterator 2800, D_Loss:1.2641606330871582, G_Loss:1.1654661893844604

iterator 2900, D_Loss:1.196935772895813, G_Loss:1.1872806549072266

iterator 3000, D_Loss:1.245489478111267, G_Loss:1.089221477508545

iterator 3100, D_Loss:1.2478489875793457, G_Loss:1.0510057210922241

iterator 3200, D_Loss:1.2175512313842773, G_Loss:1.1455378532409668

iterator 3300, D_Loss:1.2374815940856934, G_Loss:1.1815882921218872

iterator 3400, D_Loss:1.2540695667266846, G_Loss:1.0539026260375977

iterator 3500, D_Loss:1.257387399673462, G_Loss:1.0719664096832275

iterator 3600, D_Loss:1.2344276905059814, G_Loss:1.1420376300811768

iterator 3700, D_Loss:1.2165448665618896, G_Loss:1.1402463912963867

iterator 3800, D_Loss:1.2438539266586304, G_Loss:1.1002308130264282

iterator 3900, D_Loss:1.2543935775756836, G_Loss:1.0712616443634033

iterator 4000, D_Loss:1.2180020809173584, G_Loss:1.1618417501449585

iterator 4100, D_Loss:1.248384952545166, G_Loss:1.052804946899414

iterator 4200, D_Loss:1.2223713397979736, G_Loss:1.1252577304840088

iterator 4300, D_Loss:1.1985101699829102, G_Loss:1.158614993095398

iterator 4400, D_Loss:1.2051899433135986, G_Loss:1.2053054571151733

iterator 4500, D_Loss:1.2338061332702637, G_Loss:1.1852518320083618

iterator 4600, D_Loss:1.2316266298294067, G_Loss:1.0735383033752441

iterator 4700, D_Loss:1.239068627357483, G_Loss:1.1980851888656616

iterator 4800, D_Loss:1.2356345653533936, G_Loss:1.1154404878616333

iterator 4900, D_Loss:1.2450172901153564, G_Loss:1.1215150356292725

iterator 5000, D_Loss:1.283142328262329, G_Loss:1.1297351121902466

-----------Epoch 6-----------
iterator 100, D_Loss:1.2481131553649902, G_Loss:1.1073408126831055

iterator 200, D_Loss:1.2102985382080078, G_Loss:1.1620818376541138

iterator 300, D_Loss:1.2521294355392456, G_Loss:1.0868396759033203

iterator 400, D_Loss:1.275559425354004, G_Loss:1.1284359693527222

iterator 500, D_Loss:1.2777986526489258, G_Loss:1.168015718460083

iterator 600, D_Loss:1.2209701538085938, G_Loss:1.1357206106185913

iterator 700, D_Loss:1.2457081079483032, G_Loss:1.1724488735198975

iterator 800, D_Loss:1.230510950088501, G_Loss:1.1320022344589233

iterator 900, D_Loss:1.2566123008728027, G_Loss:1.1585304737091064

iterator 1000, D_Loss:1.2667067050933838, G_Loss:1.064828634262085

iterator 1100, D_Loss:1.269331932067871, G_Loss:1.0798965692520142

iterator 1200, D_Loss:1.2439162731170654, G_Loss:1.043104648590088

iterator 1300, D_Loss:1.237419605255127, G_Loss:1.1010876893997192

iterator 1400, D_Loss:1.2764183282852173, G_Loss:1.049799919128418

iterator 1500, D_Loss:1.2762866020202637, G_Loss:0.9919211268424988

iterator 1600, D_Loss:1.2243542671203613, G_Loss:1.0147889852523804

iterator 1700, D_Loss:1.2694764137268066, G_Loss:1.062062382698059

iterator 1800, D_Loss:1.26700758934021, G_Loss:1.0762531757354736

iterator 1900, D_Loss:1.2697457075119019, G_Loss:1.0372586250305176

iterator 2000, D_Loss:1.2687530517578125, G_Loss:1.0535166263580322

iterator 2100, D_Loss:1.2727539539337158, G_Loss:1.0394434928894043

iterator 2200, D_Loss:1.265339970588684, G_Loss:1.0476099252700806

iterator 2300, D_Loss:1.2440423965454102, G_Loss:1.0780197381973267

iterator 2400, D_Loss:1.2939503192901611, G_Loss:1.0026051998138428

iterator 2500, D_Loss:1.281563639640808, G_Loss:1.0528638362884521

iterator 2600, D_Loss:1.2720654010772705, G_Loss:1.0839320421218872

iterator 2700, D_Loss:1.2625243663787842, G_Loss:1.1017926931381226

iterator 2800, D_Loss:1.259690761566162, G_Loss:1.0921872854232788

iterator 2900, D_Loss:1.2495946884155273, G_Loss:1.0703048706054688

iterator 3000, D_Loss:1.2851359844207764, G_Loss:1.0559163093566895

iterator 3100, D_Loss:1.2780473232269287, G_Loss:1.0550224781036377

iterator 3200, D_Loss:1.2410998344421387, G_Loss:1.1804776191711426

iterator 3300, D_Loss:1.2418861389160156, G_Loss:1.029900312423706

iterator 3400, D_Loss:1.2543104887008667, G_Loss:1.126203179359436

iterator 3500, D_Loss:1.3159650564193726, G_Loss:1.0121866464614868

iterator 3600, D_Loss:1.2871463298797607, G_Loss:1.0176109075546265

iterator 3700, D_Loss:1.2842786312103271, G_Loss:1.0486356019973755

iterator 3800, D_Loss:1.3067078590393066, G_Loss:1.0473302602767944

iterator 3900, D_Loss:1.3011653423309326, G_Loss:1.0197913646697998

iterator 4000, D_Loss:1.2454675436019897, G_Loss:1.0616028308868408

iterator 4100, D_Loss:1.2603930234909058, G_Loss:1.0569511651992798

iterator 4200, D_Loss:1.2626514434814453, G_Loss:1.0537521839141846

iterator 4300, D_Loss:1.2501534223556519, G_Loss:1.0833717584609985

iterator 4400, D_Loss:1.296419620513916, G_Loss:1.002653956413269

iterator 4500, D_Loss:1.2799737453460693, G_Loss:1.0676532983779907

iterator 4600, D_Loss:1.2921628952026367, G_Loss:1.050821304321289

iterator 4700, D_Loss:1.302945613861084, G_Loss:0.9670857191085815

iterator 4800, D_Loss:1.3195998668670654, G_Loss:0.9650536179542542

iterator 4900, D_Loss:1.278505802154541, G_Loss:1.0252209901809692

iterator 5000, D_Loss:1.2746164798736572, G_Loss:1.0352418422698975

-----------Epoch 7-----------
iterator 100, D_Loss:1.308553695678711, G_Loss:1.0826406478881836

iterator 200, D_Loss:1.3021858930587769, G_Loss:1.0474730730056763

iterator 300, D_Loss:1.280396819114685, G_Loss:1.076732873916626

iterator 400, D_Loss:1.2569323778152466, G_Loss:1.0926026105880737

iterator 500, D_Loss:1.295382022857666, G_Loss:1.0240534543991089

iterator 600, D_Loss:1.2911803722381592, G_Loss:1.0214489698410034

iterator 700, D_Loss:1.2811431884765625, G_Loss:0.9872519373893738

iterator 800, D_Loss:1.2803137302398682, G_Loss:1.0152580738067627

iterator 900, D_Loss:1.3218640089035034, G_Loss:0.9959040880203247

iterator 1000, D_Loss:1.2872159481048584, G_Loss:1.0202500820159912

iterator 1100, D_Loss:1.279576301574707, G_Loss:0.9800741672515869

iterator 1200, D_Loss:1.2382872104644775, G_Loss:1.069805383682251

iterator 1300, D_Loss:1.3039857149124146, G_Loss:1.0520097017288208

iterator 1400, D_Loss:1.2893543243408203, G_Loss:1.0378423929214478

iterator 1500, D_Loss:1.283280611038208, G_Loss:1.0067195892333984

iterator 1600, D_Loss:1.2956552505493164, G_Loss:1.0114089250564575

iterator 1700, D_Loss:1.2910630702972412, G_Loss:1.0305070877075195

iterator 1800, D_Loss:1.2990219593048096, G_Loss:0.9995599985122681

iterator 1900, D_Loss:1.2848279476165771, G_Loss:1.02462637424469

iterator 2000, D_Loss:1.2609930038452148, G_Loss:1.0326201915740967

iterator 2100, D_Loss:1.273938536643982, G_Loss:1.1017138957977295

iterator 2200, D_Loss:1.2550876140594482, G_Loss:1.097394585609436

iterator 2300, D_Loss:1.2961164712905884, G_Loss:1.0116087198257446

iterator 2400, D_Loss:1.2965799570083618, G_Loss:1.0529725551605225

iterator 2500, D_Loss:1.2843172550201416, G_Loss:0.9879668951034546

iterator 2600, D_Loss:1.2940175533294678, G_Loss:1.0148018598556519

iterator 2700, D_Loss:1.2915637493133545, G_Loss:1.0154780149459839

iterator 2800, D_Loss:1.3139679431915283, G_Loss:0.9680300354957581

iterator 2900, D_Loss:1.2616995573043823, G_Loss:1.090404987335205

iterator 3000, D_Loss:1.2541989088058472, G_Loss:1.0560725927352905

iterator 3100, D_Loss:1.2802798748016357, G_Loss:0.9836113452911377

iterator 3200, D_Loss:1.2661187648773193, G_Loss:1.1139191389083862

iterator 3300, D_Loss:1.2330247163772583, G_Loss:1.0645673274993896

iterator 3400, D_Loss:1.2469550371170044, G_Loss:1.0876694917678833

iterator 3500, D_Loss:1.2789981365203857, G_Loss:1.0646377801895142

iterator 3600, D_Loss:1.2295262813568115, G_Loss:1.0829867124557495

iterator 3700, D_Loss:1.2648075819015503, G_Loss:1.0535794496536255

iterator 3800, D_Loss:1.268162727355957, G_Loss:1.0954642295837402

iterator 3900, D_Loss:1.2720012664794922, G_Loss:1.0908018350601196

iterator 4000, D_Loss:1.2451601028442383, G_Loss:1.1025934219360352

iterator 4100, D_Loss:1.2677198648452759, G_Loss:1.0367361307144165

iterator 4200, D_Loss:1.2194304466247559, G_Loss:1.0878055095672607

iterator 4300, D_Loss:1.2452740669250488, G_Loss:1.060256838798523

iterator 4400, D_Loss:1.2490965127944946, G_Loss:1.0941200256347656

iterator 4500, D_Loss:1.2763080596923828, G_Loss:0.9997503161430359

iterator 4600, D_Loss:1.3213813304901123, G_Loss:0.9963070750236511

iterator 4700, D_Loss:1.3089473247528076, G_Loss:1.0243914127349854

iterator 4800, D_Loss:1.2642358541488647, G_Loss:1.023189902305603

iterator 4900, D_Loss:1.3128000497817993, G_Loss:1.004014015197754

iterator 5000, D_Loss:1.3334581851959229, G_Loss:0.9368972778320312

-----------Epoch 8-----------
iterator 100, D_Loss:1.3140677213668823, G_Loss:0.9580169320106506

iterator 200, D_Loss:1.3127671480178833, G_Loss:0.9967870116233826

iterator 300, D_Loss:1.3039956092834473, G_Loss:1.004489541053772

iterator 400, D_Loss:1.2929861545562744, G_Loss:0.9603656530380249

iterator 500, D_Loss:1.29683256149292, G_Loss:0.9915086627006531

iterator 600, D_Loss:1.3224871158599854, G_Loss:0.965002715587616

iterator 700, D_Loss:1.3212673664093018, G_Loss:0.9577686786651611

iterator 800, D_Loss:1.3026418685913086, G_Loss:0.9642781615257263

iterator 900, D_Loss:1.3312431573867798, G_Loss:0.9824535250663757

iterator 1000, D_Loss:1.314272403717041, G_Loss:0.976813793182373

iterator 1100, D_Loss:1.318390130996704, G_Loss:0.9936100244522095

iterator 1200, D_Loss:1.3112623691558838, G_Loss:0.9750903844833374

iterator 1300, D_Loss:1.307357668876648, G_Loss:0.9800615310668945

iterator 1400, D_Loss:1.2940597534179688, G_Loss:1.0054458379745483

iterator 1500, D_Loss:1.328379511833191, G_Loss:0.9986199140548706

iterator 1600, D_Loss:1.295151948928833, G_Loss:1.0026708841323853

iterator 1700, D_Loss:1.2940378189086914, G_Loss:0.9753180742263794

iterator 1800, D_Loss:1.295109748840332, G_Loss:0.9810165762901306

iterator 1900, D_Loss:1.306996464729309, G_Loss:0.9629329442977905

iterator 2000, D_Loss:1.3041876554489136, G_Loss:0.9534346461296082

iterator 2100, D_Loss:1.2924368381500244, G_Loss:0.9827658534049988

iterator 2200, D_Loss:1.3182218074798584, G_Loss:0.9868680238723755

iterator 2300, D_Loss:1.303136944770813, G_Loss:0.9886834025382996

iterator 2400, D_Loss:1.3102604150772095, G_Loss:0.9885812401771545

iterator 2500, D_Loss:1.2869884967803955, G_Loss:0.9975972771644592

iterator 2600, D_Loss:1.2966797351837158, G_Loss:1.0386717319488525

iterator 2700, D_Loss:1.2819280624389648, G_Loss:1.0264089107513428

iterator 2800, D_Loss:1.272430181503296, G_Loss:1.0577664375305176

iterator 2900, D_Loss:1.291010856628418, G_Loss:1.025681495666504

iterator 3000, D_Loss:1.2906713485717773, G_Loss:1.0474902391433716

iterator 3100, D_Loss:1.2904531955718994, G_Loss:1.038156509399414

iterator 3200, D_Loss:1.3015812635421753, G_Loss:1.0120787620544434

iterator 3300, D_Loss:1.3157896995544434, G_Loss:0.9426053166389465

iterator 3400, D_Loss:1.3249576091766357, G_Loss:0.9541265964508057

iterator 3500, D_Loss:1.307236671447754, G_Loss:0.978173553943634

iterator 3600, D_Loss:1.312145709991455, G_Loss:0.9920434951782227

iterator 3700, D_Loss:1.3113878965377808, G_Loss:0.9787499308586121

iterator 3800, D_Loss:1.2945665121078491, G_Loss:0.9904200434684753

iterator 3900, D_Loss:1.3142945766448975, G_Loss:0.9714277982711792

iterator 4000, D_Loss:1.2854374647140503, G_Loss:1.0461359024047852

iterator 4100, D_Loss:1.2920640707015991, G_Loss:0.9794957041740417

iterator 4200, D_Loss:1.2753593921661377, G_Loss:1.0072782039642334

iterator 4300, D_Loss:1.295741081237793, G_Loss:0.9999444484710693

iterator 4400, D_Loss:1.2879903316497803, G_Loss:1.047099232673645

iterator 4500, D_Loss:1.2788437604904175, G_Loss:1.0329105854034424

iterator 4600, D_Loss:1.2756261825561523, G_Loss:1.059454083442688

iterator 4700, D_Loss:1.2742972373962402, G_Loss:1.046364188194275

iterator 4800, D_Loss:1.3142527341842651, G_Loss:0.9735912680625916

iterator 4900, D_Loss:1.266509771347046, G_Loss:1.0470480918884277

iterator 5000, D_Loss:1.2691948413848877, G_Loss:1.0591546297073364

-----------Epoch 9-----------
iterator 100, D_Loss:1.2872892618179321, G_Loss:0.9808037877082825

iterator 200, D_Loss:1.2833846807479858, G_Loss:1.0171129703521729

iterator 300, D_Loss:1.286321759223938, G_Loss:1.0149574279785156

iterator 400, D_Loss:1.2785885334014893, G_Loss:1.0665836334228516

iterator 500, D_Loss:1.2897950410842896, G_Loss:1.0417927503585815

iterator 600, D_Loss:1.268049955368042, G_Loss:1.0230551958084106

iterator 700, D_Loss:1.2649251222610474, G_Loss:1.0287336111068726

iterator 800, D_Loss:1.2600085735321045, G_Loss:1.04031503200531

iterator 900, D_Loss:1.2750403881072998, G_Loss:1.018752932548523

iterator 1000, D_Loss:1.2967307567596436, G_Loss:1.0425598621368408

iterator 1100, D_Loss:1.2950634956359863, G_Loss:1.0089139938354492

iterator 1200, D_Loss:1.2837443351745605, G_Loss:1.0076580047607422

iterator 1300, D_Loss:1.3009660243988037, G_Loss:1.0116764307022095

iterator 1400, D_Loss:1.281447172164917, G_Loss:1.0217173099517822

iterator 1500, D_Loss:1.3281108140945435, G_Loss:1.0097737312316895

iterator 1600, D_Loss:1.3136202096939087, G_Loss:0.9719266295433044

iterator 1700, D_Loss:1.3073303699493408, G_Loss:0.9825008511543274

iterator 1800, D_Loss:1.2914618253707886, G_Loss:1.003502607345581

iterator 1900, D_Loss:1.2888524532318115, G_Loss:1.0104424953460693

iterator 2000, D_Loss:1.3002487421035767, G_Loss:1.002733826637268

iterator 2100, D_Loss:1.2899153232574463, G_Loss:1.0258145332336426

iterator 2200, D_Loss:1.2817950248718262, G_Loss:1.0412393808364868

iterator 2300, D_Loss:1.298100233078003, G_Loss:1.0487092733383179

iterator 2400, D_Loss:1.2858076095581055, G_Loss:1.0297046899795532

iterator 2500, D_Loss:1.3015637397766113, G_Loss:1.002059817314148

iterator 2600, D_Loss:1.2846490144729614, G_Loss:0.9903225302696228

iterator 2700, D_Loss:1.3156394958496094, G_Loss:0.9890817403793335

iterator 2800, D_Loss:1.3022434711456299, G_Loss:0.976790726184845

iterator 2900, D_Loss:1.2971481084823608, G_Loss:0.9762662649154663

iterator 3000, D_Loss:1.2826826572418213, G_Loss:0.9874176979064941

iterator 3100, D_Loss:1.2761496305465698, G_Loss:0.9926827549934387

iterator 3200, D_Loss:1.2764956951141357, G_Loss:1.042818546295166

iterator 3300, D_Loss:1.3055956363677979, G_Loss:0.966073215007782

iterator 3400, D_Loss:1.2845232486724854, G_Loss:0.9927694797515869

iterator 3500, D_Loss:1.2949022054672241, G_Loss:0.9692147970199585

iterator 3600, D_Loss:1.306208848953247, G_Loss:0.9720730781555176

iterator 3700, D_Loss:1.2799162864685059, G_Loss:0.9748754501342773

iterator 3800, D_Loss:1.3318428993225098, G_Loss:0.9858717322349548

iterator 3900, D_Loss:1.3050436973571777, G_Loss:0.9763343930244446

iterator 4000, D_Loss:1.310964584350586, G_Loss:0.9714259505271912

iterator 4100, D_Loss:1.2974237203598022, G_Loss:0.9907411336898804

iterator 4200, D_Loss:1.3005459308624268, G_Loss:0.9680416584014893

iterator 4300, D_Loss:1.2785531282424927, G_Loss:1.0220131874084473

iterator 4400, D_Loss:1.3165329694747925, G_Loss:1.0089128017425537

iterator 4500, D_Loss:1.2891064882278442, G_Loss:1.0524637699127197

iterator 4600, D_Loss:1.2850267887115479, G_Loss:1.0250188112258911

iterator 4700, D_Loss:1.2612133026123047, G_Loss:1.0726490020751953

iterator 4800, D_Loss:1.2666934728622437, G_Loss:1.043380618095398

iterator 4900, D_Loss:1.2750611305236816, G_Loss:1.0553641319274902

iterator 5000, D_Loss:1.3234665393829346, G_Loss:0.9676655530929565

train row : 30148
sample row: 30148
VGAN_generator(
  (input): Linear(in_features=256, out_features=200, bias=True)
  (inputbn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (bn0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=200, out_features=15, bias=True)
  (outputbn): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=15, out_features=200, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (fc1): Linear(in_features=200, out_features=200, bias=True)
  (output): Linear(in_features=200, out_features=1, bias=True)
)
(0, False, 15)
-----------Epoch 0-----------
iterator 100, D_Loss:0.688385009765625, G_Loss:3.764533758163452

iterator 200, D_Loss:0.7176645994186401, G_Loss:4.4392409324646

iterator 300, D_Loss:0.6107150316238403, G_Loss:5.58353328704834

iterator 400, D_Loss:0.5709763169288635, G_Loss:5.853353500366211

iterator 500, D_Loss:0.5497614741325378, G_Loss:6.77285099029541

iterator 600, D_Loss:0.5536041855812073, G_Loss:6.388939380645752

iterator 700, D_Loss:0.48790785670280457, G_Loss:6.874735355377197

iterator 800, D_Loss:0.5113034844398499, G_Loss:7.134291172027588

iterator 900, D_Loss:0.4980495274066925, G_Loss:7.292571544647217

iterator 1000, D_Loss:0.538396954536438, G_Loss:7.435476303100586

iterator 1100, D_Loss:0.47088903188705444, G_Loss:8.209394454956055

iterator 1200, D_Loss:0.49080225825309753, G_Loss:7.455322265625

iterator 1300, D_Loss:0.510417640209198, G_Loss:7.49176549911499

iterator 1400, D_Loss:0.5275576114654541, G_Loss:7.262909412384033

iterator 1500, D_Loss:0.4812525510787964, G_Loss:7.472041130065918

iterator 1600, D_Loss:0.47138506174087524, G_Loss:7.096430778503418

iterator 1700, D_Loss:0.4994770884513855, G_Loss:6.860087871551514

iterator 1800, D_Loss:0.49187082052230835, G_Loss:7.032830715179443

iterator 1900, D_Loss:0.5292333364486694, G_Loss:6.8004536628723145

iterator 2000, D_Loss:0.507481038570404, G_Loss:7.04217529296875

iterator 2100, D_Loss:0.5085855722427368, G_Loss:6.2003254890441895

iterator 2200, D_Loss:0.5773813724517822, G_Loss:6.517838478088379

iterator 2300, D_Loss:0.5256001949310303, G_Loss:6.428525924682617

iterator 2400, D_Loss:0.5527638792991638, G_Loss:6.140383720397949

iterator 2500, D_Loss:0.5379802584648132, G_Loss:6.074274063110352

iterator 2600, D_Loss:0.5456153750419617, G_Loss:6.530198097229004

iterator 2700, D_Loss:0.5106622576713562, G_Loss:6.4071125984191895

iterator 2800, D_Loss:0.5175954699516296, G_Loss:5.682685375213623

iterator 2900, D_Loss:0.5283402800559998, G_Loss:5.540122985839844

iterator 3000, D_Loss:0.4889577031135559, G_Loss:5.626255989074707

iterator 3100, D_Loss:0.541240930557251, G_Loss:5.728477478027344

iterator 3200, D_Loss:0.5014105439186096, G_Loss:5.627450466156006

iterator 3300, D_Loss:0.5410870909690857, G_Loss:5.443068504333496

iterator 3400, D_Loss:0.5204729437828064, G_Loss:5.808642387390137

iterator 3500, D_Loss:0.5030407309532166, G_Loss:5.632121562957764

iterator 3600, D_Loss:0.528877317905426, G_Loss:5.379711627960205

iterator 3700, D_Loss:0.5234038829803467, G_Loss:5.346408843994141

iterator 3800, D_Loss:0.5637904405593872, G_Loss:5.253492832183838

iterator 3900, D_Loss:0.5265842080116272, G_Loss:5.292782783508301

iterator 4000, D_Loss:0.49579179286956787, G_Loss:5.2723469734191895

iterator 4100, D_Loss:0.5497123003005981, G_Loss:5.553390026092529

iterator 4200, D_Loss:0.513323962688446, G_Loss:5.524243354797363

iterator 4300, D_Loss:0.5192192792892456, G_Loss:5.514020919799805

iterator 4400, D_Loss:0.5248860120773315, G_Loss:5.582754135131836

iterator 4500, D_Loss:0.5528719425201416, G_Loss:5.378537178039551

iterator 4600, D_Loss:0.5171558260917664, G_Loss:5.2221856117248535

iterator 4700, D_Loss:0.5427855253219604, G_Loss:5.054936408996582

iterator 4800, D_Loss:0.5472336411476135, G_Loss:5.158390045166016

iterator 4900, D_Loss:0.52902752161026, G_Loss:5.255669593811035

iterator 5000, D_Loss:0.5193226337432861, G_Loss:5.32067346572876

-----------Epoch 1-----------
iterator 100, D_Loss:0.5058581829071045, G_Loss:5.171017646789551

iterator 200, D_Loss:0.5330584049224854, G_Loss:5.228827953338623

iterator 300, D_Loss:0.5122904181480408, G_Loss:5.273501873016357

iterator 400, D_Loss:0.520099401473999, G_Loss:5.225787162780762

iterator 500, D_Loss:0.5464197993278503, G_Loss:5.009382247924805

iterator 600, D_Loss:0.5547271966934204, G_Loss:5.24232292175293

iterator 700, D_Loss:0.5199594497680664, G_Loss:5.072669982910156

iterator 800, D_Loss:0.5318309664726257, G_Loss:5.340959548950195

iterator 900, D_Loss:0.5102673172950745, G_Loss:5.129191875457764

iterator 1000, D_Loss:0.5168302655220032, G_Loss:5.082754135131836

iterator 1100, D_Loss:0.503372311592102, G_Loss:5.050934791564941

iterator 1200, D_Loss:0.5241028666496277, G_Loss:5.138777732849121

iterator 1300, D_Loss:0.5528334975242615, G_Loss:5.103952407836914

iterator 1400, D_Loss:0.5769933462142944, G_Loss:4.9694719314575195

iterator 1500, D_Loss:0.5347257256507874, G_Loss:4.958054542541504

iterator 1600, D_Loss:0.5097352266311646, G_Loss:5.0441718101501465

iterator 1700, D_Loss:0.5319198966026306, G_Loss:4.927882194519043

iterator 1800, D_Loss:0.5291813015937805, G_Loss:4.852482795715332

iterator 1900, D_Loss:0.524743914604187, G_Loss:5.283295154571533

iterator 2000, D_Loss:0.563454806804657, G_Loss:5.0747270584106445

iterator 2100, D_Loss:0.5285196304321289, G_Loss:5.045226097106934

iterator 2200, D_Loss:0.5233209729194641, G_Loss:4.9910197257995605

iterator 2300, D_Loss:0.5374637842178345, G_Loss:4.770959854125977

iterator 2400, D_Loss:0.6105067133903503, G_Loss:4.811091899871826

iterator 2500, D_Loss:0.56612229347229, G_Loss:4.788605213165283

iterator 2600, D_Loss:0.5416880249977112, G_Loss:4.733663558959961

iterator 2700, D_Loss:0.5205329656600952, G_Loss:5.2281951904296875

iterator 2800, D_Loss:0.5875422954559326, G_Loss:4.814085960388184

iterator 2900, D_Loss:0.5500651597976685, G_Loss:4.795475006103516

iterator 3000, D_Loss:0.5579982399940491, G_Loss:4.586456775665283

iterator 3100, D_Loss:0.4828713536262512, G_Loss:4.9296674728393555

iterator 3200, D_Loss:0.5386191606521606, G_Loss:5.020116806030273

iterator 3300, D_Loss:0.5337308645248413, G_Loss:4.92773962020874

iterator 3400, D_Loss:0.5416299104690552, G_Loss:5.011974334716797

iterator 3500, D_Loss:0.5542548894882202, G_Loss:4.800222396850586

iterator 3600, D_Loss:0.5352362990379333, G_Loss:4.656806945800781

iterator 3700, D_Loss:0.5912610292434692, G_Loss:5.182631015777588

iterator 3800, D_Loss:0.5601196885108948, G_Loss:4.781680583953857

iterator 3900, D_Loss:0.567009449005127, G_Loss:4.740107536315918

iterator 4000, D_Loss:0.5608954429626465, G_Loss:4.695145606994629

iterator 4100, D_Loss:0.511673092842102, G_Loss:4.982766151428223

iterator 4200, D_Loss:0.5314323306083679, G_Loss:4.630636215209961

iterator 4300, D_Loss:0.5696884989738464, G_Loss:4.657354354858398

iterator 4400, D_Loss:0.5018231272697449, G_Loss:4.707961559295654

iterator 4500, D_Loss:0.5663970708847046, G_Loss:4.606529235839844

iterator 4600, D_Loss:0.5561378598213196, G_Loss:4.767757892608643

iterator 4700, D_Loss:0.5603293180465698, G_Loss:4.807867527008057

iterator 4800, D_Loss:0.5668449997901917, G_Loss:4.543650150299072

iterator 4900, D_Loss:0.5675055980682373, G_Loss:4.395291328430176

iterator 5000, D_Loss:0.5450742244720459, G_Loss:4.336318492889404

-----------Epoch 2-----------
iterator 100, D_Loss:0.5330595970153809, G_Loss:4.533737659454346

iterator 200, D_Loss:0.5240887403488159, G_Loss:4.878983020782471

iterator 300, D_Loss:0.5419706106185913, G_Loss:4.337337493896484

iterator 400, D_Loss:0.6105715036392212, G_Loss:4.646376132965088

iterator 500, D_Loss:0.62725830078125, G_Loss:4.743575096130371

iterator 600, D_Loss:0.5941872000694275, G_Loss:4.611247539520264

iterator 700, D_Loss:0.586336076259613, G_Loss:4.19754695892334

iterator 800, D_Loss:0.5973091125488281, G_Loss:4.348715782165527

iterator 900, D_Loss:0.6010817289352417, G_Loss:4.3738226890563965

iterator 1000, D_Loss:0.6139231324195862, G_Loss:4.163430213928223

iterator 1100, D_Loss:0.536829948425293, G_Loss:4.336121082305908

iterator 1200, D_Loss:0.5897111296653748, G_Loss:4.450077533721924

iterator 1300, D_Loss:0.604012131690979, G_Loss:4.209667205810547

iterator 1400, D_Loss:0.641219437122345, G_Loss:4.440730094909668

iterator 1500, D_Loss:0.5780695676803589, G_Loss:4.391353130340576

iterator 1600, D_Loss:0.6178978085517883, G_Loss:3.9817919731140137

iterator 1700, D_Loss:0.6321157217025757, G_Loss:3.963820219039917

iterator 1800, D_Loss:0.6139479875564575, G_Loss:4.019216060638428

iterator 1900, D_Loss:0.6653792262077332, G_Loss:4.183608055114746

iterator 2000, D_Loss:0.5837662220001221, G_Loss:3.9654123783111572

iterator 2100, D_Loss:0.6724839210510254, G_Loss:3.9444243907928467

iterator 2200, D_Loss:0.6270953416824341, G_Loss:4.009577751159668

iterator 2300, D_Loss:0.6433579325675964, G_Loss:3.920607089996338

iterator 2400, D_Loss:0.6873611807823181, G_Loss:4.073763370513916

iterator 2500, D_Loss:0.6566647291183472, G_Loss:4.33376932144165

iterator 2600, D_Loss:0.6237097978591919, G_Loss:4.232901096343994

iterator 2700, D_Loss:0.5826296210289001, G_Loss:3.765664577484131

iterator 2800, D_Loss:0.6544516086578369, G_Loss:3.754430055618286

iterator 2900, D_Loss:0.6596409678459167, G_Loss:3.970032215118408

iterator 3000, D_Loss:0.6579859852790833, G_Loss:3.8825626373291016

iterator 3100, D_Loss:0.6299765110015869, G_Loss:3.952526092529297

iterator 3200, D_Loss:0.6688022613525391, G_Loss:4.22184944152832

iterator 3300, D_Loss:0.649010419845581, G_Loss:3.664327383041382

iterator 3400, D_Loss:0.6237731575965881, G_Loss:3.845456600189209

iterator 3500, D_Loss:0.6437360048294067, G_Loss:3.5232203006744385

iterator 3600, D_Loss:0.6872713565826416, G_Loss:3.7170157432556152

iterator 3700, D_Loss:0.7000718712806702, G_Loss:3.669607639312744

iterator 3800, D_Loss:0.7251124382019043, G_Loss:3.4827420711517334

iterator 3900, D_Loss:0.6931976675987244, G_Loss:3.4190328121185303

iterator 4000, D_Loss:0.7011774182319641, G_Loss:3.298823833465576

iterator 4100, D_Loss:0.669716477394104, G_Loss:3.4761557579040527

iterator 4200, D_Loss:0.709865152835846, G_Loss:3.2561073303222656

iterator 4300, D_Loss:0.6776245832443237, G_Loss:3.4460127353668213

iterator 4400, D_Loss:0.6339071393013, G_Loss:3.8190512657165527

iterator 4500, D_Loss:0.6594558954238892, G_Loss:3.6009440422058105

iterator 4600, D_Loss:0.6722464561462402, G_Loss:3.2018930912017822

iterator 4700, D_Loss:0.6626967787742615, G_Loss:3.6053171157836914

iterator 4800, D_Loss:0.7128543853759766, G_Loss:3.6117093563079834

iterator 4900, D_Loss:0.7550044059753418, G_Loss:3.1224160194396973

iterator 5000, D_Loss:0.7558354139328003, G_Loss:3.292576789855957

-----------Epoch 3-----------
iterator 100, D_Loss:0.6954696178436279, G_Loss:3.6386146545410156

iterator 200, D_Loss:0.7218247652053833, G_Loss:3.491522789001465

iterator 300, D_Loss:0.681037425994873, G_Loss:3.3113107681274414

iterator 400, D_Loss:0.7086628675460815, G_Loss:3.0721638202667236

iterator 500, D_Loss:0.6391870975494385, G_Loss:3.2728183269500732

iterator 600, D_Loss:0.6682953834533691, G_Loss:3.3537888526916504

iterator 700, D_Loss:0.7468951940536499, G_Loss:3.1602821350097656

iterator 800, D_Loss:0.6630290150642395, G_Loss:3.2268691062927246

iterator 900, D_Loss:0.6668469309806824, G_Loss:3.0771501064300537

iterator 1000, D_Loss:0.7090833187103271, G_Loss:2.9292995929718018

iterator 1100, D_Loss:0.7121145129203796, G_Loss:3.0235679149627686

iterator 1200, D_Loss:0.668010950088501, G_Loss:2.9704511165618896

iterator 1300, D_Loss:0.7289425730705261, G_Loss:3.397223472595215

iterator 1400, D_Loss:0.7595157027244568, G_Loss:2.9227705001831055

iterator 1500, D_Loss:0.7879727482795715, G_Loss:2.940202474594116

iterator 1600, D_Loss:0.7084364891052246, G_Loss:3.125213623046875

iterator 1700, D_Loss:0.7247347831726074, G_Loss:2.9303925037384033

iterator 1800, D_Loss:0.7945883274078369, G_Loss:2.7134852409362793

iterator 1900, D_Loss:0.79463791847229, G_Loss:3.019988536834717

iterator 2000, D_Loss:0.7683767676353455, G_Loss:2.600979804992676

iterator 2100, D_Loss:0.82476806640625, G_Loss:2.7204818725585938

iterator 2200, D_Loss:0.8145747184753418, G_Loss:2.515746593475342

iterator 2300, D_Loss:0.7707521915435791, G_Loss:2.6702308654785156

iterator 2400, D_Loss:0.7618762254714966, G_Loss:3.0664944648742676

iterator 2500, D_Loss:0.7233127355575562, G_Loss:2.886052131652832

iterator 2600, D_Loss:0.7724184393882751, G_Loss:3.0176944732666016

iterator 2700, D_Loss:0.7682304978370667, G_Loss:3.240257978439331

iterator 2800, D_Loss:0.7088456749916077, G_Loss:2.608187675476074

iterator 2900, D_Loss:0.7370717525482178, G_Loss:2.923159599304199

iterator 3000, D_Loss:0.7146769762039185, G_Loss:2.6434037685394287

iterator 3100, D_Loss:0.7960362434387207, G_Loss:2.735332489013672

iterator 3200, D_Loss:0.7696448564529419, G_Loss:2.7220535278320312

iterator 3300, D_Loss:0.7457655072212219, G_Loss:2.934981346130371

iterator 3400, D_Loss:0.7480713129043579, G_Loss:2.7292914390563965

iterator 3500, D_Loss:0.7316889762878418, G_Loss:3.123181104660034

iterator 3600, D_Loss:0.7746978402137756, G_Loss:3.064539670944214

iterator 3700, D_Loss:0.8397811055183411, G_Loss:2.479436159133911

iterator 3800, D_Loss:0.7793708443641663, G_Loss:2.4932522773742676

iterator 3900, D_Loss:0.7871918678283691, G_Loss:2.5456676483154297

iterator 4000, D_Loss:0.8180806636810303, G_Loss:2.4015109539031982

iterator 4100, D_Loss:0.7621554732322693, G_Loss:2.5921573638916016

iterator 4200, D_Loss:0.8109859824180603, G_Loss:2.439100742340088

iterator 4300, D_Loss:0.8955740332603455, G_Loss:2.201995611190796

iterator 4400, D_Loss:0.8119499087333679, G_Loss:2.552732229232788

iterator 4500, D_Loss:0.8441065549850464, G_Loss:2.6753127574920654

iterator 4600, D_Loss:0.8583405017852783, G_Loss:2.4064154624938965

iterator 4700, D_Loss:0.8465660810470581, G_Loss:2.21553897857666

iterator 4800, D_Loss:0.9395216107368469, G_Loss:2.3400344848632812

iterator 4900, D_Loss:0.8383627533912659, G_Loss:2.2670178413391113

iterator 5000, D_Loss:0.8802484273910522, G_Loss:2.287909746170044

-----------Epoch 4-----------
iterator 100, D_Loss:0.8906660079956055, G_Loss:1.9871115684509277

iterator 200, D_Loss:0.875235378742218, G_Loss:2.0945792198181152

iterator 300, D_Loss:0.8814053535461426, G_Loss:2.4616262912750244

iterator 400, D_Loss:0.8110405206680298, G_Loss:2.2236907482147217

iterator 500, D_Loss:0.8927567601203918, G_Loss:2.26157283782959

iterator 600, D_Loss:0.839458703994751, G_Loss:2.194305181503296

iterator 700, D_Loss:0.8863983154296875, G_Loss:2.2918508052825928

iterator 800, D_Loss:0.8556915521621704, G_Loss:2.3217058181762695

iterator 900, D_Loss:0.8648353219032288, G_Loss:2.171847105026245

iterator 1000, D_Loss:0.9207836985588074, G_Loss:2.2073988914489746

iterator 1100, D_Loss:0.9040626883506775, G_Loss:2.2619571685791016

iterator 1200, D_Loss:0.846355676651001, G_Loss:2.0858051776885986

iterator 1300, D_Loss:0.9322885274887085, G_Loss:2.312946319580078

iterator 1400, D_Loss:0.8919609785079956, G_Loss:2.045968770980835

iterator 1500, D_Loss:0.8810141086578369, G_Loss:2.190692663192749

iterator 1600, D_Loss:0.8169203996658325, G_Loss:2.2616653442382812

iterator 1700, D_Loss:0.8431034088134766, G_Loss:2.290109157562256

iterator 1800, D_Loss:0.8307860493659973, G_Loss:2.2362022399902344

iterator 1900, D_Loss:0.9112075567245483, G_Loss:2.0632810592651367

iterator 2000, D_Loss:0.8634136319160461, G_Loss:2.0656232833862305

iterator 2100, D_Loss:0.9146002531051636, G_Loss:2.038490056991577

iterator 2200, D_Loss:0.8758553266525269, G_Loss:2.1041100025177

iterator 2300, D_Loss:0.9087213277816772, G_Loss:1.983138918876648

iterator 2400, D_Loss:0.8782805800437927, G_Loss:2.1012778282165527

iterator 2500, D_Loss:0.8769361972808838, G_Loss:1.9745029211044312

iterator 2600, D_Loss:0.8980664014816284, G_Loss:1.8799445629119873

iterator 2700, D_Loss:0.9192665815353394, G_Loss:2.088925838470459

iterator 2800, D_Loss:0.9400370121002197, G_Loss:1.935140609741211

iterator 2900, D_Loss:0.9141721725463867, G_Loss:2.0995500087738037

iterator 3000, D_Loss:0.942874550819397, G_Loss:1.945317268371582

iterator 3100, D_Loss:0.9375276565551758, G_Loss:1.8791248798370361

iterator 3200, D_Loss:0.9197527170181274, G_Loss:2.131688356399536

iterator 3300, D_Loss:0.897039532661438, G_Loss:1.8851383924484253

iterator 3400, D_Loss:0.9169182181358337, G_Loss:1.879583716392517

iterator 3500, D_Loss:0.9399435520172119, G_Loss:2.016417980194092

iterator 3600, D_Loss:0.9487088918685913, G_Loss:2.001870632171631

iterator 3700, D_Loss:0.9089476466178894, G_Loss:2.1550517082214355

iterator 3800, D_Loss:0.9269676208496094, G_Loss:1.836970329284668

iterator 3900, D_Loss:0.9622333645820618, G_Loss:1.9794307947158813

iterator 4000, D_Loss:0.9113324880599976, G_Loss:1.8631696701049805

iterator 4100, D_Loss:0.9112362861633301, G_Loss:2.0841565132141113

iterator 4200, D_Loss:0.8971469402313232, G_Loss:2.0033504962921143

iterator 4300, D_Loss:0.9588502645492554, G_Loss:1.911763310432434

iterator 4400, D_Loss:0.992017924785614, G_Loss:1.8884360790252686

iterator 4500, D_Loss:1.074438214302063, G_Loss:1.8017231225967407

iterator 4600, D_Loss:0.9639441967010498, G_Loss:1.8395923376083374

iterator 4700, D_Loss:0.9720701575279236, G_Loss:1.8667900562286377

iterator 4800, D_Loss:1.0354094505310059, G_Loss:1.7379345893859863

iterator 4900, D_Loss:0.9674823880195618, G_Loss:1.8849921226501465

iterator 5000, D_Loss:1.0102301836013794, G_Loss:1.9100406169891357

-----------Epoch 5-----------
iterator 100, D_Loss:0.9113119840621948, G_Loss:1.8035061359405518

iterator 200, D_Loss:0.9504929780960083, G_Loss:1.8047888278961182

iterator 300, D_Loss:0.9289473295211792, G_Loss:1.8045668601989746

iterator 400, D_Loss:0.9555075168609619, G_Loss:2.016537666320801

iterator 500, D_Loss:0.9866296052932739, G_Loss:1.8570550680160522

iterator 600, D_Loss:1.0007758140563965, G_Loss:1.7619985342025757

iterator 700, D_Loss:1.0154712200164795, G_Loss:1.7021658420562744

iterator 800, D_Loss:0.8784154057502747, G_Loss:1.9063481092453003

iterator 900, D_Loss:0.9239217638969421, G_Loss:1.8611596822738647

iterator 1000, D_Loss:0.9893110990524292, G_Loss:1.806960940361023

iterator 1100, D_Loss:0.9873659610748291, G_Loss:1.8270906209945679

iterator 1200, D_Loss:0.921180248260498, G_Loss:1.8404947519302368

iterator 1300, D_Loss:0.9608510136604309, G_Loss:1.7224023342132568

iterator 1400, D_Loss:0.9596592783927917, G_Loss:1.962052822113037

iterator 1500, D_Loss:1.0480948686599731, G_Loss:1.845808744430542

iterator 1600, D_Loss:0.9829449653625488, G_Loss:1.8337030410766602

iterator 1700, D_Loss:0.9827634692192078, G_Loss:1.8299126625061035

iterator 1800, D_Loss:0.9960663914680481, G_Loss:1.647905707359314

iterator 1900, D_Loss:0.9864449501037598, G_Loss:1.8285917043685913

iterator 2000, D_Loss:0.98215252161026, G_Loss:1.9352684020996094

iterator 2100, D_Loss:0.9876223206520081, G_Loss:1.8071603775024414

iterator 2200, D_Loss:0.972635805606842, G_Loss:1.787445306777954

iterator 2300, D_Loss:1.077777624130249, G_Loss:1.7609734535217285

iterator 2400, D_Loss:1.015842318534851, G_Loss:1.7651044130325317

iterator 2500, D_Loss:0.9987967014312744, G_Loss:1.6697452068328857

iterator 2600, D_Loss:0.9737375974655151, G_Loss:1.7635736465454102

iterator 2700, D_Loss:0.9566059112548828, G_Loss:2.010443925857544

iterator 2800, D_Loss:0.9773651361465454, G_Loss:1.8348636627197266

iterator 2900, D_Loss:0.9621015787124634, G_Loss:1.6566622257232666

iterator 3000, D_Loss:1.023446798324585, G_Loss:1.7412925958633423

iterator 3100, D_Loss:0.988998293876648, G_Loss:1.5337895154953003

iterator 3200, D_Loss:0.9842782020568848, G_Loss:1.8382298946380615

iterator 3300, D_Loss:1.0039660930633545, G_Loss:1.7250397205352783

iterator 3400, D_Loss:0.971019446849823, G_Loss:1.5806608200073242

iterator 3500, D_Loss:0.9833773970603943, G_Loss:1.7486127614974976

iterator 3600, D_Loss:0.964091420173645, G_Loss:1.7543400526046753

iterator 3700, D_Loss:0.9588320255279541, G_Loss:1.6791139841079712

iterator 3800, D_Loss:0.9863165616989136, G_Loss:1.6941885948181152

iterator 3900, D_Loss:0.959453284740448, G_Loss:1.570380449295044

iterator 4000, D_Loss:0.9989418983459473, G_Loss:1.8380217552185059

iterator 4100, D_Loss:0.9422072172164917, G_Loss:1.636374592781067

iterator 4200, D_Loss:0.9696173667907715, G_Loss:1.8105969429016113

iterator 4300, D_Loss:1.0815016031265259, G_Loss:1.7149593830108643

iterator 4400, D_Loss:1.016249418258667, G_Loss:1.7074921131134033

iterator 4500, D_Loss:1.0051629543304443, G_Loss:1.6065175533294678

iterator 4600, D_Loss:1.0037894248962402, G_Loss:1.687544822692871

iterator 4700, D_Loss:1.0651546716690063, G_Loss:1.6548230648040771

iterator 4800, D_Loss:1.0239429473876953, G_Loss:1.7478644847869873

iterator 4900, D_Loss:1.0110491514205933, G_Loss:1.7292068004608154

iterator 5000, D_Loss:1.021440029144287, G_Loss:1.6732178926467896

-----------Epoch 6-----------
iterator 100, D_Loss:0.981983482837677, G_Loss:1.7923606634140015

iterator 200, D_Loss:1.0283360481262207, G_Loss:1.7183740139007568

iterator 300, D_Loss:1.028537631034851, G_Loss:1.8069864511489868

iterator 400, D_Loss:1.0237382650375366, G_Loss:1.6375095844268799

iterator 500, D_Loss:1.0266824960708618, G_Loss:1.6551933288574219

iterator 600, D_Loss:1.0351767539978027, G_Loss:1.5568605661392212

iterator 700, D_Loss:1.0334358215332031, G_Loss:1.7750415802001953

iterator 800, D_Loss:1.021059513092041, G_Loss:1.6522952318191528

iterator 900, D_Loss:1.0436205863952637, G_Loss:1.7098751068115234

iterator 1000, D_Loss:1.0995776653289795, G_Loss:1.7471466064453125

iterator 1100, D_Loss:0.9960004687309265, G_Loss:1.6326048374176025

iterator 1200, D_Loss:1.0671857595443726, G_Loss:1.7099738121032715

iterator 1300, D_Loss:1.0742311477661133, G_Loss:1.609098196029663

iterator 1400, D_Loss:0.9675573110580444, G_Loss:1.7077592611312866

iterator 1500, D_Loss:1.0067501068115234, G_Loss:1.8507412672042847

iterator 1600, D_Loss:1.035300850868225, G_Loss:1.6619197130203247

iterator 1700, D_Loss:0.9682063460350037, G_Loss:1.6247966289520264

iterator 1800, D_Loss:1.0634440183639526, G_Loss:1.609908103942871

iterator 1900, D_Loss:1.0936076641082764, G_Loss:1.5400505065917969

iterator 2000, D_Loss:1.0417864322662354, G_Loss:1.6523083448410034

iterator 2100, D_Loss:1.0299644470214844, G_Loss:1.530200481414795

iterator 2200, D_Loss:1.0743579864501953, G_Loss:1.6741923093795776

iterator 2300, D_Loss:1.058024287223816, G_Loss:1.5390411615371704

iterator 2400, D_Loss:1.056080937385559, G_Loss:1.5352952480316162

iterator 2500, D_Loss:1.1363155841827393, G_Loss:1.611795425415039

iterator 2600, D_Loss:1.0743086338043213, G_Loss:1.5682330131530762

iterator 2700, D_Loss:1.0399465560913086, G_Loss:1.5741627216339111

iterator 2800, D_Loss:1.091553807258606, G_Loss:1.5194014310836792

iterator 2900, D_Loss:1.0404678583145142, G_Loss:1.4937124252319336

iterator 3000, D_Loss:1.0418272018432617, G_Loss:1.6411415338516235

iterator 3100, D_Loss:1.1417450904846191, G_Loss:1.4905076026916504

iterator 3200, D_Loss:1.0482044219970703, G_Loss:1.526793360710144

iterator 3300, D_Loss:1.0564333200454712, G_Loss:1.5088210105895996

iterator 3400, D_Loss:1.0706615447998047, G_Loss:1.5322731733322144

iterator 3500, D_Loss:1.0854651927947998, G_Loss:1.5737380981445312

iterator 3600, D_Loss:1.0885264873504639, G_Loss:1.4738630056381226

iterator 3700, D_Loss:1.0807472467422485, G_Loss:1.6753429174423218

iterator 3800, D_Loss:1.1088173389434814, G_Loss:1.4635075330734253

iterator 3900, D_Loss:1.0489939451217651, G_Loss:1.7621146440505981

iterator 4000, D_Loss:1.0559113025665283, G_Loss:1.6021288633346558

iterator 4100, D_Loss:1.0310957431793213, G_Loss:1.5448423624038696

iterator 4200, D_Loss:1.0535680055618286, G_Loss:1.6701620817184448

iterator 4300, D_Loss:1.0900623798370361, G_Loss:1.3990281820297241

iterator 4400, D_Loss:1.0386120080947876, G_Loss:1.6055951118469238

iterator 4500, D_Loss:1.1026593446731567, G_Loss:1.5059987306594849

iterator 4600, D_Loss:1.0612095594406128, G_Loss:1.5589923858642578

iterator 4700, D_Loss:1.0379606485366821, G_Loss:1.5504876375198364

iterator 4800, D_Loss:1.0809252262115479, G_Loss:1.535800814628601

iterator 4900, D_Loss:1.1180803775787354, G_Loss:1.6383955478668213

iterator 5000, D_Loss:1.0879499912261963, G_Loss:1.548855185508728

-----------Epoch 7-----------
iterator 100, D_Loss:1.0719003677368164, G_Loss:1.6010037660598755

iterator 200, D_Loss:1.0781614780426025, G_Loss:1.5916876792907715

iterator 300, D_Loss:1.0937219858169556, G_Loss:1.669334888458252

iterator 400, D_Loss:1.0587108135223389, G_Loss:1.5720903873443604

iterator 500, D_Loss:1.0683059692382812, G_Loss:1.3923712968826294

iterator 600, D_Loss:1.044575810432434, G_Loss:1.4935829639434814

iterator 700, D_Loss:1.0424177646636963, G_Loss:1.5610694885253906

iterator 800, D_Loss:1.019175410270691, G_Loss:1.571277379989624

iterator 900, D_Loss:1.082523226737976, G_Loss:1.5223175287246704

iterator 1000, D_Loss:1.0990159511566162, G_Loss:1.4814767837524414

iterator 1100, D_Loss:1.0658948421478271, G_Loss:1.4149267673492432

iterator 1200, D_Loss:1.0565404891967773, G_Loss:1.5387928485870361

iterator 1300, D_Loss:1.0517585277557373, G_Loss:1.5254164934158325

iterator 1400, D_Loss:1.0562657117843628, G_Loss:1.5173604488372803

iterator 1500, D_Loss:1.0955039262771606, G_Loss:1.6098427772521973

iterator 1600, D_Loss:1.0011190176010132, G_Loss:1.4765293598175049

iterator 1700, D_Loss:1.0476429462432861, G_Loss:1.4122154712677002

iterator 1800, D_Loss:1.0575352907180786, G_Loss:1.5304605960845947

iterator 1900, D_Loss:1.0282142162322998, G_Loss:1.6347839832305908

iterator 2000, D_Loss:1.0222820043563843, G_Loss:1.5936200618743896

iterator 2100, D_Loss:1.0607726573944092, G_Loss:1.482324481010437

iterator 2200, D_Loss:1.0604407787322998, G_Loss:1.5489197969436646

iterator 2300, D_Loss:1.0254535675048828, G_Loss:1.5122346878051758

iterator 2400, D_Loss:1.0830471515655518, G_Loss:1.6603741645812988

iterator 2500, D_Loss:1.0623246431350708, G_Loss:1.543399691581726

iterator 2600, D_Loss:1.0133099555969238, G_Loss:1.4136221408843994

iterator 2700, D_Loss:1.0290944576263428, G_Loss:1.5524805784225464

iterator 2800, D_Loss:1.1169476509094238, G_Loss:1.4874608516693115

iterator 2900, D_Loss:1.039580225944519, G_Loss:1.7576560974121094

iterator 3000, D_Loss:1.0230076313018799, G_Loss:1.6500475406646729

iterator 3100, D_Loss:1.0500428676605225, G_Loss:1.64944326877594

iterator 3200, D_Loss:1.0472261905670166, G_Loss:1.6393848657608032

iterator 3300, D_Loss:0.9979388117790222, G_Loss:1.556406021118164

iterator 3400, D_Loss:1.0844630002975464, G_Loss:1.508489727973938

iterator 3500, D_Loss:1.043054461479187, G_Loss:1.554334282875061

iterator 3600, D_Loss:1.0902268886566162, G_Loss:1.4013527631759644

iterator 3700, D_Loss:1.095112919807434, G_Loss:1.4428452253341675

iterator 3800, D_Loss:1.0488638877868652, G_Loss:1.509890079498291

iterator 3900, D_Loss:1.0800766944885254, G_Loss:1.516715168952942

iterator 4000, D_Loss:1.0439558029174805, G_Loss:1.5337605476379395

iterator 4100, D_Loss:1.082556962966919, G_Loss:1.587317705154419

iterator 4200, D_Loss:1.1007745265960693, G_Loss:1.533326268196106

iterator 4300, D_Loss:1.0731675624847412, G_Loss:1.544994831085205

iterator 4400, D_Loss:1.0475635528564453, G_Loss:1.7626357078552246

iterator 4500, D_Loss:1.0752534866333008, G_Loss:1.5130703449249268

iterator 4600, D_Loss:1.0122673511505127, G_Loss:1.6732096672058105

iterator 4700, D_Loss:1.017519235610962, G_Loss:1.5711013078689575

iterator 4800, D_Loss:1.086033582687378, G_Loss:1.4761197566986084

iterator 4900, D_Loss:1.0270493030548096, G_Loss:1.6316264867782593

iterator 5000, D_Loss:1.0440280437469482, G_Loss:1.4884328842163086

-----------Epoch 8-----------
iterator 100, D_Loss:1.038054347038269, G_Loss:1.586527943611145

iterator 200, D_Loss:1.0475152730941772, G_Loss:1.7164291143417358

iterator 300, D_Loss:1.0266319513320923, G_Loss:1.5873247385025024

iterator 400, D_Loss:1.0613327026367188, G_Loss:1.5004346370697021

iterator 500, D_Loss:1.0775201320648193, G_Loss:1.5293431282043457

iterator 600, D_Loss:1.056809425354004, G_Loss:1.4014008045196533

iterator 700, D_Loss:1.0341192483901978, G_Loss:1.544390320777893

iterator 800, D_Loss:1.0104973316192627, G_Loss:1.7180191278457642

iterator 900, D_Loss:1.0480824708938599, G_Loss:1.4620139598846436

iterator 1000, D_Loss:1.080138087272644, G_Loss:1.5373412370681763

iterator 1100, D_Loss:1.0459043979644775, G_Loss:1.5188157558441162

iterator 1200, D_Loss:1.0727139711380005, G_Loss:1.485291838645935

iterator 1300, D_Loss:1.0690574645996094, G_Loss:1.4007350206375122

iterator 1400, D_Loss:1.0795689821243286, G_Loss:1.5568124055862427

iterator 1500, D_Loss:1.0481369495391846, G_Loss:1.5467675924301147

iterator 1600, D_Loss:1.0916396379470825, G_Loss:1.4964120388031006

iterator 1700, D_Loss:1.0351403951644897, G_Loss:1.5607786178588867

iterator 1800, D_Loss:1.0267565250396729, G_Loss:1.609403133392334

iterator 1900, D_Loss:1.056288719177246, G_Loss:1.640980839729309

iterator 2000, D_Loss:1.0910513401031494, G_Loss:1.5896024703979492

iterator 2100, D_Loss:1.0860044956207275, G_Loss:1.509012222290039

iterator 2200, D_Loss:1.0229902267456055, G_Loss:1.6556371450424194

iterator 2300, D_Loss:1.0036823749542236, G_Loss:1.4839088916778564

iterator 2400, D_Loss:1.0905380249023438, G_Loss:1.6076992750167847

iterator 2500, D_Loss:1.0474772453308105, G_Loss:1.5289831161499023

iterator 2600, D_Loss:0.9836199283599854, G_Loss:1.6396065950393677

iterator 2700, D_Loss:0.9981168508529663, G_Loss:1.5675766468048096

iterator 2800, D_Loss:1.08039128780365, G_Loss:1.5652626752853394

iterator 2900, D_Loss:0.9975050687789917, G_Loss:1.69974684715271

iterator 3000, D_Loss:1.020365834236145, G_Loss:1.5647903680801392

iterator 3100, D_Loss:1.0212005376815796, G_Loss:1.5910191535949707

iterator 3200, D_Loss:1.0562572479248047, G_Loss:1.7235316038131714

iterator 3300, D_Loss:1.0392045974731445, G_Loss:1.7809503078460693

iterator 3400, D_Loss:0.9989076852798462, G_Loss:1.6892513036727905

iterator 3500, D_Loss:1.0501896142959595, G_Loss:1.6261584758758545

iterator 3600, D_Loss:1.055309772491455, G_Loss:1.6603155136108398

iterator 3700, D_Loss:1.0152068138122559, G_Loss:1.6622788906097412

iterator 3800, D_Loss:0.9523265361785889, G_Loss:1.7051390409469604

iterator 3900, D_Loss:0.9830530881881714, G_Loss:1.787933349609375

iterator 4000, D_Loss:1.0504995584487915, G_Loss:1.6417553424835205

iterator 4100, D_Loss:1.0095821619033813, G_Loss:1.653505563735962

iterator 4200, D_Loss:1.060122013092041, G_Loss:1.580534815788269

iterator 4300, D_Loss:1.0667059421539307, G_Loss:1.6287734508514404

iterator 4400, D_Loss:1.038912057876587, G_Loss:1.6232048273086548

iterator 4500, D_Loss:1.0097030401229858, G_Loss:1.7224531173706055

iterator 4600, D_Loss:1.00644850730896, G_Loss:1.5436064004898071

iterator 4700, D_Loss:0.9613728523254395, G_Loss:1.499389410018921

iterator 4800, D_Loss:1.025265097618103, G_Loss:1.7084605693817139

iterator 4900, D_Loss:1.0991121530532837, G_Loss:1.6448912620544434

iterator 5000, D_Loss:1.0288183689117432, G_Loss:1.5779850482940674

-----------Epoch 9-----------
iterator 100, D_Loss:1.0336498022079468, G_Loss:1.601379632949829

iterator 200, D_Loss:0.9410190582275391, G_Loss:1.6486620903015137

iterator 300, D_Loss:1.0413997173309326, G_Loss:1.7929165363311768

iterator 400, D_Loss:1.0067741870880127, G_Loss:1.6464080810546875

iterator 500, D_Loss:1.040672779083252, G_Loss:1.6309813261032104

iterator 600, D_Loss:1.011514663696289, G_Loss:1.5194345712661743

iterator 700, D_Loss:0.9711430072784424, G_Loss:1.6245074272155762

iterator 800, D_Loss:1.0383847951889038, G_Loss:1.6238210201263428

iterator 900, D_Loss:1.0210633277893066, G_Loss:1.7207704782485962

iterator 1000, D_Loss:0.9952362775802612, G_Loss:1.4845366477966309

iterator 1100, D_Loss:1.0332478284835815, G_Loss:1.7290722131729126

iterator 1200, D_Loss:0.9566279053688049, G_Loss:1.5974791049957275

iterator 1300, D_Loss:1.0298948287963867, G_Loss:1.513505220413208

iterator 1400, D_Loss:0.971205472946167, G_Loss:1.633969783782959

iterator 1500, D_Loss:1.0349195003509521, G_Loss:1.7846901416778564

iterator 1600, D_Loss:1.0039522647857666, G_Loss:1.613660216331482

iterator 1700, D_Loss:0.9860811829566956, G_Loss:1.6409670114517212

iterator 1800, D_Loss:1.0137090682983398, G_Loss:1.588199257850647

iterator 1900, D_Loss:1.0254400968551636, G_Loss:1.645082950592041

iterator 2000, D_Loss:0.9915100336074829, G_Loss:1.5224065780639648

iterator 2100, D_Loss:1.070328950881958, G_Loss:1.7237577438354492

iterator 2200, D_Loss:1.0132858753204346, G_Loss:1.5771781206130981

iterator 2300, D_Loss:1.0183055400848389, G_Loss:1.541968822479248

iterator 2400, D_Loss:0.9869052171707153, G_Loss:1.802587628364563

iterator 2500, D_Loss:1.0668561458587646, G_Loss:1.5901799201965332

iterator 2600, D_Loss:1.0343135595321655, G_Loss:1.557301640510559

iterator 2700, D_Loss:0.9929243922233582, G_Loss:1.5111424922943115

iterator 2800, D_Loss:1.063152551651001, G_Loss:1.6139901876449585

iterator 2900, D_Loss:0.9863819479942322, G_Loss:1.5437763929367065

iterator 3000, D_Loss:0.9764325618743896, G_Loss:1.7419655323028564

iterator 3100, D_Loss:1.030165433883667, G_Loss:1.5372123718261719

iterator 3200, D_Loss:1.0039663314819336, G_Loss:1.524515986442566

iterator 3300, D_Loss:1.0173046588897705, G_Loss:1.783613920211792

iterator 3400, D_Loss:1.0113354921340942, G_Loss:1.59010910987854

iterator 3500, D_Loss:1.0598933696746826, G_Loss:1.683327317237854

iterator 3600, D_Loss:0.9641047120094299, G_Loss:1.571258544921875

iterator 3700, D_Loss:0.9887000322341919, G_Loss:1.5923587083816528

iterator 3800, D_Loss:1.0505626201629639, G_Loss:1.6906886100769043

iterator 3900, D_Loss:1.0458893775939941, G_Loss:1.7635674476623535

iterator 4000, D_Loss:1.0207959413528442, G_Loss:1.6607050895690918

iterator 4100, D_Loss:1.0524333715438843, G_Loss:1.9038121700286865

iterator 4200, D_Loss:1.0039544105529785, G_Loss:1.6705678701400757

iterator 4300, D_Loss:1.0093493461608887, G_Loss:1.6007781028747559

iterator 4400, D_Loss:1.003267765045166, G_Loss:1.7202081680297852

iterator 4500, D_Loss:0.9962202310562134, G_Loss:1.516274333000183

iterator 4600, D_Loss:0.9733999967575073, G_Loss:1.599217176437378

iterator 4700, D_Loss:1.0110628604888916, G_Loss:1.6552518606185913

iterator 4800, D_Loss:0.9985283017158508, G_Loss:1.6388580799102783

iterator 4900, D_Loss:0.9171727299690247, G_Loss:1.6448171138763428

iterator 5000, D_Loss:1.0714128017425537, G_Loss:1.6195327043533325

VGAN_generator(
  (input): Linear(in_features=256, out_features=100, bias=True)
  (inputbn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=100, out_features=100, bias=True)
  (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=100, out_features=15, bias=True)
  (outputbn): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=15, out_features=100, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (output): Linear(in_features=100, out_features=1, bias=True)
)
(0, False, 15)
-----------Epoch 0-----------
iterator 100, D_Loss:1.260432481765747, G_Loss:0.8080135583877563

iterator 200, D_Loss:0.9709378480911255, G_Loss:1.1811453104019165

iterator 300, D_Loss:0.8305239677429199, G_Loss:1.8149456977844238

iterator 400, D_Loss:0.849388062953949, G_Loss:2.341179847717285

iterator 500, D_Loss:0.7484388947486877, G_Loss:2.8135085105895996

iterator 600, D_Loss:0.780779242515564, G_Loss:3.055723190307617

iterator 700, D_Loss:0.7157904505729675, G_Loss:3.2181761264801025

iterator 800, D_Loss:0.7594524025917053, G_Loss:3.3769688606262207

iterator 900, D_Loss:0.7356811761856079, G_Loss:3.6879892349243164

iterator 1000, D_Loss:0.7226517796516418, G_Loss:3.7101030349731445

iterator 1100, D_Loss:0.6276391744613647, G_Loss:3.7904036045074463

iterator 1200, D_Loss:0.6669845581054688, G_Loss:4.000021934509277

iterator 1300, D_Loss:0.6835386753082275, G_Loss:4.0671844482421875

iterator 1400, D_Loss:0.6811432838439941, G_Loss:4.412607669830322

iterator 1500, D_Loss:0.6245121955871582, G_Loss:4.157212257385254

iterator 1600, D_Loss:0.5885759592056274, G_Loss:4.324648380279541

iterator 1700, D_Loss:0.6585303544998169, G_Loss:4.334113121032715

iterator 1800, D_Loss:0.6134912967681885, G_Loss:4.624630928039551

iterator 1900, D_Loss:0.654502272605896, G_Loss:4.536459445953369

iterator 2000, D_Loss:0.6373700499534607, G_Loss:4.628269672393799

iterator 2100, D_Loss:0.6579821705818176, G_Loss:4.726138114929199

iterator 2200, D_Loss:0.6146531105041504, G_Loss:4.632731914520264

iterator 2300, D_Loss:0.5976308584213257, G_Loss:4.6501994132995605

iterator 2400, D_Loss:0.6573357582092285, G_Loss:4.742271900177002

iterator 2500, D_Loss:0.6368147730827332, G_Loss:4.873987197875977

iterator 2600, D_Loss:0.6088687181472778, G_Loss:4.892635345458984

iterator 2700, D_Loss:0.5944247841835022, G_Loss:4.864211082458496

iterator 2800, D_Loss:0.6392247080802917, G_Loss:4.898563385009766

iterator 2900, D_Loss:0.5267212390899658, G_Loss:4.937646865844727

iterator 3000, D_Loss:0.5662668347358704, G_Loss:4.892810821533203

iterator 3100, D_Loss:0.5504849553108215, G_Loss:4.672667026519775

iterator 3200, D_Loss:0.5825321674346924, G_Loss:4.673631191253662

iterator 3300, D_Loss:0.5739748477935791, G_Loss:4.995047569274902

iterator 3400, D_Loss:0.5552516579627991, G_Loss:4.58258056640625

iterator 3500, D_Loss:0.5576789379119873, G_Loss:4.857349872589111

iterator 3600, D_Loss:0.5954767465591431, G_Loss:4.689887046813965

iterator 3700, D_Loss:0.6027814149856567, G_Loss:4.635794639587402

iterator 3800, D_Loss:0.5555034875869751, G_Loss:4.69937801361084

iterator 3900, D_Loss:0.5615764260292053, G_Loss:4.7882466316223145

iterator 4000, D_Loss:0.5321031212806702, G_Loss:4.665984630584717

iterator 4100, D_Loss:0.5605478882789612, G_Loss:4.744420051574707

iterator 4200, D_Loss:0.5502362251281738, G_Loss:4.812377452850342

iterator 4300, D_Loss:0.5940492153167725, G_Loss:4.558173656463623

iterator 4400, D_Loss:0.542550265789032, G_Loss:4.622869968414307

iterator 4500, D_Loss:0.583305835723877, G_Loss:4.633116245269775

iterator 4600, D_Loss:0.5473821759223938, G_Loss:4.638725280761719

iterator 4700, D_Loss:0.5635268092155457, G_Loss:4.585253715515137

iterator 4800, D_Loss:0.5815048217773438, G_Loss:4.808454513549805

iterator 4900, D_Loss:0.5899673700332642, G_Loss:4.483486175537109

iterator 5000, D_Loss:0.5895226001739502, G_Loss:4.637272834777832

-----------Epoch 1-----------
iterator 100, D_Loss:0.5098093152046204, G_Loss:4.446029186248779

iterator 200, D_Loss:0.5153303146362305, G_Loss:4.455859661102295

iterator 300, D_Loss:0.581981360912323, G_Loss:4.563497543334961

iterator 400, D_Loss:0.5924698114395142, G_Loss:4.669861793518066

iterator 500, D_Loss:0.6123842000961304, G_Loss:4.554043769836426

iterator 600, D_Loss:0.6111069321632385, G_Loss:4.524662971496582

iterator 700, D_Loss:0.5158518552780151, G_Loss:4.608063697814941

iterator 800, D_Loss:0.5343097448348999, G_Loss:4.388060092926025

iterator 900, D_Loss:0.6148259043693542, G_Loss:4.681114673614502

iterator 1000, D_Loss:0.5954990386962891, G_Loss:4.250726699829102

iterator 1100, D_Loss:0.530681848526001, G_Loss:4.5199456214904785

iterator 1200, D_Loss:0.5337920188903809, G_Loss:4.356906890869141

iterator 1300, D_Loss:0.5742558240890503, G_Loss:4.341733932495117

iterator 1400, D_Loss:0.634807288646698, G_Loss:4.149778366088867

iterator 1500, D_Loss:0.5616856217384338, G_Loss:4.504724979400635

iterator 1600, D_Loss:0.5404401421546936, G_Loss:4.388904571533203

iterator 1700, D_Loss:0.5799753665924072, G_Loss:4.147869110107422

iterator 1800, D_Loss:0.5450599789619446, G_Loss:4.368529796600342

iterator 1900, D_Loss:0.6539168953895569, G_Loss:4.232661724090576

iterator 2000, D_Loss:0.5917656421661377, G_Loss:3.9932727813720703

iterator 2100, D_Loss:0.5824131965637207, G_Loss:4.271452903747559

iterator 2200, D_Loss:0.6243303418159485, G_Loss:4.188895225524902

iterator 2300, D_Loss:0.5528554916381836, G_Loss:4.338301658630371

iterator 2400, D_Loss:0.6940677165985107, G_Loss:4.191630840301514

iterator 2500, D_Loss:0.6097524762153625, G_Loss:4.001451015472412

iterator 2600, D_Loss:0.6271010041236877, G_Loss:3.855222463607788

iterator 2700, D_Loss:0.6369861364364624, G_Loss:3.911834716796875

iterator 2800, D_Loss:0.5921192169189453, G_Loss:4.1481804847717285

iterator 2900, D_Loss:0.5716127157211304, G_Loss:4.071012020111084

iterator 3000, D_Loss:0.5715290307998657, G_Loss:3.8127858638763428

iterator 3100, D_Loss:0.5642306804656982, G_Loss:4.034919738769531

iterator 3200, D_Loss:0.6027361750602722, G_Loss:4.088405609130859

iterator 3300, D_Loss:0.5452260375022888, G_Loss:3.917189121246338

iterator 3400, D_Loss:0.5752737522125244, G_Loss:3.916749954223633

iterator 3500, D_Loss:0.581089973449707, G_Loss:4.150609493255615

iterator 3600, D_Loss:0.5806063413619995, G_Loss:4.003625392913818

iterator 3700, D_Loss:0.6208888292312622, G_Loss:4.190472602844238

iterator 3800, D_Loss:0.565315842628479, G_Loss:4.08289909362793

iterator 3900, D_Loss:0.5767446756362915, G_Loss:3.74483323097229

iterator 4000, D_Loss:0.5902359485626221, G_Loss:3.9208946228027344

iterator 4100, D_Loss:0.5480764508247375, G_Loss:3.858088254928589

iterator 4200, D_Loss:0.5833939909934998, G_Loss:3.7584996223449707

iterator 4300, D_Loss:0.5496148467063904, G_Loss:3.8598744869232178

iterator 4400, D_Loss:0.578800618648529, G_Loss:3.9577295780181885

iterator 4500, D_Loss:0.6045663356781006, G_Loss:3.941525936126709

iterator 4600, D_Loss:0.5510544776916504, G_Loss:4.063388347625732

iterator 4700, D_Loss:0.6160849928855896, G_Loss:4.369530200958252

iterator 4800, D_Loss:0.6120349764823914, G_Loss:3.682039499282837

iterator 4900, D_Loss:0.6326107978820801, G_Loss:3.973203659057617

iterator 5000, D_Loss:0.5961784720420837, G_Loss:3.7202651500701904

-----------Epoch 2-----------
iterator 100, D_Loss:0.5412368178367615, G_Loss:4.095339775085449

iterator 200, D_Loss:0.5882230401039124, G_Loss:4.201610565185547

iterator 300, D_Loss:0.5892135500907898, G_Loss:3.7705283164978027

iterator 400, D_Loss:0.6144320368766785, G_Loss:4.025601387023926

iterator 500, D_Loss:0.6036077737808228, G_Loss:3.852834701538086

iterator 600, D_Loss:0.5700831413269043, G_Loss:3.850374460220337

iterator 700, D_Loss:0.5617300271987915, G_Loss:4.101053237915039

iterator 800, D_Loss:0.5975344181060791, G_Loss:3.7690200805664062

iterator 900, D_Loss:0.5951569080352783, G_Loss:4.1092329025268555

iterator 1000, D_Loss:0.5694938898086548, G_Loss:3.9050354957580566

iterator 1100, D_Loss:0.6005010008811951, G_Loss:4.224097728729248

iterator 1200, D_Loss:0.5656342506408691, G_Loss:3.8434035778045654

iterator 1300, D_Loss:0.5788187980651855, G_Loss:3.793062686920166

iterator 1400, D_Loss:0.6213055849075317, G_Loss:3.889620780944824

iterator 1500, D_Loss:0.585626482963562, G_Loss:3.8854353427886963

iterator 1600, D_Loss:0.5683317184448242, G_Loss:3.9065685272216797

iterator 1700, D_Loss:0.5871486067771912, G_Loss:3.717792272567749

iterator 1800, D_Loss:0.5922651886940002, G_Loss:3.7045819759368896

iterator 1900, D_Loss:0.6723793148994446, G_Loss:3.7060093879699707

iterator 2000, D_Loss:0.6150718927383423, G_Loss:3.7942845821380615

iterator 2100, D_Loss:0.5981780290603638, G_Loss:3.8768765926361084

iterator 2200, D_Loss:0.5864856243133545, G_Loss:3.8587663173675537

iterator 2300, D_Loss:0.6312077045440674, G_Loss:4.029181003570557

iterator 2400, D_Loss:0.7178840041160583, G_Loss:3.794351816177368

iterator 2500, D_Loss:0.665289044380188, G_Loss:3.675743818283081

iterator 2600, D_Loss:0.6057669520378113, G_Loss:3.6158876419067383

iterator 2700, D_Loss:0.6218863725662231, G_Loss:3.7793149948120117

iterator 2800, D_Loss:0.6240578293800354, G_Loss:3.6012918949127197

iterator 2900, D_Loss:0.5833668112754822, G_Loss:3.6290221214294434

iterator 3000, D_Loss:0.5849355459213257, G_Loss:3.6354012489318848

iterator 3100, D_Loss:0.589297354221344, G_Loss:3.595917224884033

iterator 3200, D_Loss:0.6097874045372009, G_Loss:3.7844088077545166

iterator 3300, D_Loss:0.6081165075302124, G_Loss:3.720940113067627

iterator 3400, D_Loss:0.5846907496452332, G_Loss:3.534454822540283

iterator 3500, D_Loss:0.6010080575942993, G_Loss:3.611069440841675

iterator 3600, D_Loss:0.6232845187187195, G_Loss:3.8268024921417236

iterator 3700, D_Loss:0.5877201557159424, G_Loss:3.7656266689300537

iterator 3800, D_Loss:0.606050968170166, G_Loss:3.7529656887054443

iterator 3900, D_Loss:0.6244022250175476, G_Loss:3.614530086517334

iterator 4000, D_Loss:0.566635251045227, G_Loss:3.5788724422454834

iterator 4100, D_Loss:0.5900566577911377, G_Loss:3.660320997238159

iterator 4200, D_Loss:0.5736618638038635, G_Loss:3.562337875366211

iterator 4300, D_Loss:0.558599591255188, G_Loss:3.6751608848571777

iterator 4400, D_Loss:0.6142095923423767, G_Loss:3.7416796684265137

iterator 4500, D_Loss:0.6490744352340698, G_Loss:3.7338318824768066

iterator 4600, D_Loss:0.5826185941696167, G_Loss:3.6620168685913086

iterator 4700, D_Loss:0.6171644926071167, G_Loss:3.5357279777526855

iterator 4800, D_Loss:0.6386280655860901, G_Loss:3.9486074447631836

iterator 4900, D_Loss:0.6377350091934204, G_Loss:3.5256452560424805

iterator 5000, D_Loss:0.6215302348136902, G_Loss:3.7192728519439697

-----------Epoch 3-----------
iterator 100, D_Loss:0.6069732308387756, G_Loss:3.626810073852539

iterator 200, D_Loss:0.5867199897766113, G_Loss:3.6877388954162598

iterator 300, D_Loss:0.6516550183296204, G_Loss:3.6458241939544678

iterator 400, D_Loss:0.6229540109634399, G_Loss:3.687577962875366

iterator 500, D_Loss:0.6140865087509155, G_Loss:3.653069496154785

iterator 600, D_Loss:0.6294508576393127, G_Loss:3.8561832904815674

iterator 700, D_Loss:0.5962951183319092, G_Loss:3.781231641769409

iterator 800, D_Loss:0.6215335130691528, G_Loss:3.4670071601867676

iterator 900, D_Loss:0.6172124743461609, G_Loss:3.758476734161377

iterator 1000, D_Loss:0.6339032649993896, G_Loss:3.76540207862854

iterator 1100, D_Loss:0.573316752910614, G_Loss:3.542416572570801

iterator 1200, D_Loss:0.579277753829956, G_Loss:3.600210189819336

iterator 1300, D_Loss:0.6430193185806274, G_Loss:3.7338733673095703

iterator 1400, D_Loss:0.6641100645065308, G_Loss:3.3309566974639893

iterator 1500, D_Loss:0.6411528587341309, G_Loss:3.3188600540161133

iterator 1600, D_Loss:0.6511507034301758, G_Loss:3.617934226989746

iterator 1700, D_Loss:0.589030385017395, G_Loss:3.4616029262542725

iterator 1800, D_Loss:0.581937849521637, G_Loss:3.6671085357666016

iterator 1900, D_Loss:0.6065502166748047, G_Loss:3.7215614318847656

iterator 2000, D_Loss:0.6233976483345032, G_Loss:3.702589988708496

iterator 2100, D_Loss:0.5859211683273315, G_Loss:3.5388267040252686

iterator 2200, D_Loss:0.6341149806976318, G_Loss:3.5668153762817383

iterator 2300, D_Loss:0.5970495939254761, G_Loss:3.485405445098877

iterator 2400, D_Loss:0.7371731400489807, G_Loss:3.3717236518859863

iterator 2500, D_Loss:0.6285234689712524, G_Loss:3.385202169418335

iterator 2600, D_Loss:0.629118800163269, G_Loss:3.476689577102661

iterator 2700, D_Loss:0.667155921459198, G_Loss:3.6368443965911865

iterator 2800, D_Loss:0.6528208255767822, G_Loss:3.981128454208374

iterator 2900, D_Loss:0.623884916305542, G_Loss:3.450270891189575

iterator 3000, D_Loss:0.632457435131073, G_Loss:3.4586758613586426

iterator 3100, D_Loss:0.6318773627281189, G_Loss:3.533716917037964

iterator 3200, D_Loss:0.6343250274658203, G_Loss:3.554509162902832

iterator 3300, D_Loss:0.6046057939529419, G_Loss:3.4017555713653564

iterator 3400, D_Loss:0.5893464684486389, G_Loss:3.3961098194122314

iterator 3500, D_Loss:0.6058793067932129, G_Loss:3.666517734527588

iterator 3600, D_Loss:0.6508725881576538, G_Loss:3.176881790161133

iterator 3700, D_Loss:0.6235713362693787, G_Loss:3.590705394744873

iterator 3800, D_Loss:0.6196956038475037, G_Loss:3.531416177749634

iterator 3900, D_Loss:0.6407197713851929, G_Loss:3.562300443649292

iterator 4000, D_Loss:0.6306799650192261, G_Loss:3.7148540019989014

iterator 4100, D_Loss:0.622669517993927, G_Loss:3.6437978744506836

iterator 4200, D_Loss:0.5766204595565796, G_Loss:3.3055882453918457

iterator 4300, D_Loss:0.6143805384635925, G_Loss:3.300126552581787

iterator 4400, D_Loss:0.6439841389656067, G_Loss:3.411533832550049

iterator 4500, D_Loss:0.6601892709732056, G_Loss:3.295168876647949

iterator 4600, D_Loss:0.653446614742279, G_Loss:3.334388017654419

iterator 4700, D_Loss:0.6252397298812866, G_Loss:3.3356873989105225

iterator 4800, D_Loss:0.6593083143234253, G_Loss:3.20104718208313

iterator 4900, D_Loss:0.6845334768295288, G_Loss:3.256795883178711

iterator 5000, D_Loss:0.6776374578475952, G_Loss:3.3721084594726562

-----------Epoch 4-----------
iterator 100, D_Loss:0.6184558868408203, G_Loss:3.372670888900757

iterator 200, D_Loss:0.6542201042175293, G_Loss:3.175766944885254

iterator 300, D_Loss:0.6370835304260254, G_Loss:3.259617567062378

iterator 400, D_Loss:0.6536950469017029, G_Loss:3.013291120529175

iterator 500, D_Loss:0.6321004629135132, G_Loss:3.2222235202789307

iterator 600, D_Loss:0.6720231771469116, G_Loss:3.1187338829040527

iterator 700, D_Loss:0.6177725195884705, G_Loss:3.1472811698913574

iterator 800, D_Loss:0.6205677390098572, G_Loss:3.2802720069885254

iterator 900, D_Loss:0.6742094159126282, G_Loss:3.216008186340332

iterator 1000, D_Loss:0.6395921111106873, G_Loss:3.0770297050476074

iterator 1100, D_Loss:0.6548432111740112, G_Loss:3.178061008453369

iterator 1200, D_Loss:0.6190330386161804, G_Loss:3.164027214050293

iterator 1300, D_Loss:0.6273432970046997, G_Loss:3.2291107177734375

iterator 1400, D_Loss:0.6671960353851318, G_Loss:3.178802490234375

iterator 1500, D_Loss:0.6561945676803589, G_Loss:3.254002332687378

iterator 1600, D_Loss:0.6174792647361755, G_Loss:3.166999340057373

iterator 1700, D_Loss:0.6395113468170166, G_Loss:3.168975353240967

iterator 1800, D_Loss:0.6423861384391785, G_Loss:3.350297451019287

iterator 1900, D_Loss:0.6497321128845215, G_Loss:3.2023589611053467

iterator 2000, D_Loss:0.6490612626075745, G_Loss:3.132753372192383

iterator 2100, D_Loss:0.6962770223617554, G_Loss:3.1598517894744873

iterator 2200, D_Loss:0.6713528037071228, G_Loss:3.1505789756774902

iterator 2300, D_Loss:0.6628128290176392, G_Loss:3.1223526000976562

iterator 2400, D_Loss:0.7191904783248901, G_Loss:3.2310352325439453

iterator 2500, D_Loss:0.6819806098937988, G_Loss:3.237776756286621

iterator 2600, D_Loss:0.6880770325660706, G_Loss:3.1213202476501465

iterator 2700, D_Loss:0.6372778415679932, G_Loss:3.193574905395508

iterator 2800, D_Loss:0.6887155771255493, G_Loss:3.1326329708099365

iterator 2900, D_Loss:0.6551096439361572, G_Loss:3.070289134979248

iterator 3000, D_Loss:0.6291142106056213, G_Loss:3.0552175045013428

iterator 3100, D_Loss:0.6615320444107056, G_Loss:3.262746572494507

iterator 3200, D_Loss:0.7003207802772522, G_Loss:3.0562469959259033

iterator 3300, D_Loss:0.6576365828514099, G_Loss:2.9616525173187256

iterator 3400, D_Loss:0.6829931735992432, G_Loss:3.0481135845184326

iterator 3500, D_Loss:0.6688991189002991, G_Loss:3.023698091506958

iterator 3600, D_Loss:0.6227849125862122, G_Loss:2.9566941261291504

iterator 3700, D_Loss:0.6819500923156738, G_Loss:2.8812475204467773

iterator 3800, D_Loss:0.6735420823097229, G_Loss:3.017591953277588

iterator 3900, D_Loss:0.7011564373970032, G_Loss:2.841433048248291

iterator 4000, D_Loss:0.7178610563278198, G_Loss:2.9846978187561035

iterator 4100, D_Loss:0.6708892583847046, G_Loss:2.9556496143341064

iterator 4200, D_Loss:0.655001699924469, G_Loss:3.109323740005493

iterator 4300, D_Loss:0.7343020439147949, G_Loss:2.83436918258667

iterator 4400, D_Loss:0.6660796403884888, G_Loss:2.828995943069458

iterator 4500, D_Loss:0.7592129707336426, G_Loss:2.9879910945892334

iterator 4600, D_Loss:0.6441135406494141, G_Loss:2.9362032413482666

iterator 4700, D_Loss:0.701804518699646, G_Loss:2.9305686950683594

iterator 4800, D_Loss:0.6897599697113037, G_Loss:2.8722915649414062

iterator 4900, D_Loss:0.6651631593704224, G_Loss:2.9758968353271484

iterator 5000, D_Loss:0.7202273011207581, G_Loss:2.7973318099975586

-----------Epoch 5-----------
iterator 100, D_Loss:0.6654831171035767, G_Loss:2.929992198944092

iterator 200, D_Loss:0.6389219164848328, G_Loss:2.765511989593506

iterator 300, D_Loss:0.7226167917251587, G_Loss:2.910895347595215

iterator 400, D_Loss:0.735214114189148, G_Loss:2.7846999168395996

iterator 500, D_Loss:0.7488282918930054, G_Loss:2.7331647872924805

iterator 600, D_Loss:0.742189884185791, G_Loss:2.6934807300567627

iterator 700, D_Loss:0.7067537307739258, G_Loss:2.771120309829712

iterator 800, D_Loss:0.7276579141616821, G_Loss:2.8038790225982666

iterator 900, D_Loss:0.7034195065498352, G_Loss:2.7441916465759277

iterator 1000, D_Loss:0.7042219042778015, G_Loss:2.8044052124023438

iterator 1100, D_Loss:0.7410250902175903, G_Loss:2.7466182708740234

iterator 1200, D_Loss:0.680743932723999, G_Loss:2.769587516784668

iterator 1300, D_Loss:0.7774888277053833, G_Loss:2.796753406524658

iterator 1400, D_Loss:0.7069730758666992, G_Loss:2.689610004425049

iterator 1500, D_Loss:0.7408707141876221, G_Loss:2.7155516147613525

iterator 1600, D_Loss:0.6873284578323364, G_Loss:2.764923572540283

iterator 1700, D_Loss:0.7135462760925293, G_Loss:2.855881690979004

iterator 1800, D_Loss:0.6767358183860779, G_Loss:2.700108766555786

iterator 1900, D_Loss:0.7664393186569214, G_Loss:2.7471001148223877

iterator 2000, D_Loss:0.6868717670440674, G_Loss:2.8187918663024902

iterator 2100, D_Loss:0.7307819128036499, G_Loss:2.7406458854675293

iterator 2200, D_Loss:0.716352105140686, G_Loss:2.726358413696289

iterator 2300, D_Loss:0.7132354974746704, G_Loss:2.7136900424957275

iterator 2400, D_Loss:0.6783788800239563, G_Loss:2.9292960166931152

iterator 2500, D_Loss:0.7363565564155579, G_Loss:2.661754608154297

iterator 2600, D_Loss:0.6943717002868652, G_Loss:2.7788829803466797

iterator 2700, D_Loss:0.7257959842681885, G_Loss:2.658665418624878

iterator 2800, D_Loss:0.6839931011199951, G_Loss:2.6658072471618652

iterator 2900, D_Loss:0.7161262035369873, G_Loss:2.745894193649292

iterator 3000, D_Loss:0.7256364822387695, G_Loss:2.738438367843628

iterator 3100, D_Loss:0.7230989933013916, G_Loss:2.8923048973083496

iterator 3200, D_Loss:0.6902623772621155, G_Loss:2.7375576496124268

iterator 3300, D_Loss:0.7327309250831604, G_Loss:2.770005702972412

iterator 3400, D_Loss:0.7019543647766113, G_Loss:2.6432013511657715

iterator 3500, D_Loss:0.781724214553833, G_Loss:2.6607825756073

iterator 3600, D_Loss:0.7291849851608276, G_Loss:2.6073496341705322

iterator 3700, D_Loss:0.7850481867790222, G_Loss:2.594163656234741

iterator 3800, D_Loss:0.7186689376831055, G_Loss:2.776124954223633

iterator 3900, D_Loss:0.7535839080810547, G_Loss:2.6091084480285645

iterator 4000, D_Loss:0.769512414932251, G_Loss:2.6966423988342285

iterator 4100, D_Loss:0.7605370283126831, G_Loss:2.619462490081787

iterator 4200, D_Loss:0.7212187051773071, G_Loss:2.6463069915771484

iterator 4300, D_Loss:0.7547222375869751, G_Loss:2.6694037914276123

iterator 4400, D_Loss:0.7271262407302856, G_Loss:2.6658544540405273

iterator 4500, D_Loss:0.7734972238540649, G_Loss:2.7105093002319336

iterator 4600, D_Loss:0.7052714824676514, G_Loss:2.6132571697235107

iterator 4700, D_Loss:0.7397887110710144, G_Loss:2.630462646484375

iterator 4800, D_Loss:0.7335487008094788, G_Loss:2.537968397140503

iterator 4900, D_Loss:0.7345457077026367, G_Loss:2.6245689392089844

iterator 5000, D_Loss:0.774989902973175, G_Loss:2.532597064971924

-----------Epoch 6-----------
iterator 100, D_Loss:0.7693891525268555, G_Loss:2.514652967453003

iterator 200, D_Loss:0.7424047589302063, G_Loss:2.4961390495300293

iterator 300, D_Loss:0.7359892129898071, G_Loss:2.4543402194976807

iterator 400, D_Loss:0.7455901503562927, G_Loss:2.623751640319824

iterator 500, D_Loss:0.7607066631317139, G_Loss:2.6050946712493896

iterator 600, D_Loss:0.789438009262085, G_Loss:2.584165573120117

iterator 700, D_Loss:0.7541167736053467, G_Loss:2.617133855819702

iterator 800, D_Loss:0.8153864741325378, G_Loss:2.471025228500366

iterator 900, D_Loss:0.7071525454521179, G_Loss:2.4156084060668945

iterator 1000, D_Loss:0.7631464600563049, G_Loss:2.5839147567749023

iterator 1100, D_Loss:0.7686286568641663, G_Loss:2.5634260177612305

iterator 1200, D_Loss:0.7825098037719727, G_Loss:2.6517820358276367

iterator 1300, D_Loss:0.8071025013923645, G_Loss:2.48293137550354

iterator 1400, D_Loss:0.7280360460281372, G_Loss:2.515605926513672

iterator 1500, D_Loss:0.8325843811035156, G_Loss:2.447633743286133

iterator 1600, D_Loss:0.711763322353363, G_Loss:2.447423219680786

iterator 1700, D_Loss:0.7821269035339355, G_Loss:2.5524253845214844

iterator 1800, D_Loss:0.7508615255355835, G_Loss:2.4602558612823486

iterator 1900, D_Loss:0.7981245517730713, G_Loss:2.495762825012207

iterator 2000, D_Loss:0.8253543376922607, G_Loss:2.3973491191864014

iterator 2100, D_Loss:0.81636643409729, G_Loss:2.42978572845459

iterator 2200, D_Loss:0.772222101688385, G_Loss:2.2938339710235596

iterator 2300, D_Loss:0.7306184768676758, G_Loss:2.3946940898895264

iterator 2400, D_Loss:0.7928038239479065, G_Loss:2.453831911087036

iterator 2500, D_Loss:0.7994838356971741, G_Loss:2.4189579486846924

iterator 2600, D_Loss:0.7883394956588745, G_Loss:2.522118091583252

iterator 2700, D_Loss:0.7730940580368042, G_Loss:2.4869303703308105

iterator 2800, D_Loss:0.7833214402198792, G_Loss:2.3628060817718506

iterator 2900, D_Loss:0.7488263249397278, G_Loss:2.4412145614624023

iterator 3000, D_Loss:0.7617284059524536, G_Loss:2.50247859954834

iterator 3100, D_Loss:0.817762017250061, G_Loss:2.4831173419952393

iterator 3200, D_Loss:0.7462238073348999, G_Loss:2.351339340209961

iterator 3300, D_Loss:0.7711447477340698, G_Loss:2.414569854736328

iterator 3400, D_Loss:0.8028485774993896, G_Loss:2.276113271713257

iterator 3500, D_Loss:0.8308665156364441, G_Loss:2.3195576667785645

iterator 3600, D_Loss:0.7549049258232117, G_Loss:2.4110641479492188

iterator 3700, D_Loss:0.7607635855674744, G_Loss:2.3892650604248047

iterator 3800, D_Loss:0.777827262878418, G_Loss:2.2927098274230957

iterator 3900, D_Loss:0.841670036315918, G_Loss:2.296534776687622

iterator 4000, D_Loss:0.8491767644882202, G_Loss:2.4708988666534424

iterator 4100, D_Loss:0.7890183925628662, G_Loss:2.1928043365478516

iterator 4200, D_Loss:0.7942941784858704, G_Loss:2.363605499267578

iterator 4300, D_Loss:0.8326607346534729, G_Loss:2.327411413192749

iterator 4400, D_Loss:0.7984986305236816, G_Loss:2.4313275814056396

iterator 4500, D_Loss:0.8639645576477051, G_Loss:2.359856605529785

iterator 4600, D_Loss:0.782562792301178, G_Loss:2.2884068489074707

iterator 4700, D_Loss:0.7869817018508911, G_Loss:2.2037665843963623

iterator 4800, D_Loss:0.8578625321388245, G_Loss:2.1440751552581787

iterator 4900, D_Loss:0.8574603796005249, G_Loss:2.3381128311157227

iterator 5000, D_Loss:0.8275130987167358, G_Loss:2.290872097015381

-----------Epoch 7-----------
iterator 100, D_Loss:0.7820629477500916, G_Loss:2.4054980278015137

iterator 200, D_Loss:0.8218541145324707, G_Loss:2.2944233417510986

iterator 300, D_Loss:0.8286980390548706, G_Loss:2.2865371704101562

iterator 400, D_Loss:0.744652271270752, G_Loss:2.3665201663970947

iterator 500, D_Loss:0.8698431849479675, G_Loss:2.2494022846221924

iterator 600, D_Loss:0.8289493322372437, G_Loss:2.140821695327759

iterator 700, D_Loss:0.8285179138183594, G_Loss:2.0849294662475586

iterator 800, D_Loss:0.8099377155303955, G_Loss:2.165799379348755

iterator 900, D_Loss:0.8268309235572815, G_Loss:2.2358553409576416

iterator 1000, D_Loss:0.8300953507423401, G_Loss:2.087368965148926

iterator 1100, D_Loss:0.8547650575637817, G_Loss:2.156583786010742

iterator 1200, D_Loss:0.8314723968505859, G_Loss:2.1448755264282227

iterator 1300, D_Loss:0.8484697341918945, G_Loss:2.189805746078491

iterator 1400, D_Loss:0.8224146962165833, G_Loss:2.2825634479522705

iterator 1500, D_Loss:0.9032626748085022, G_Loss:2.2696127891540527

iterator 1600, D_Loss:0.7894160747528076, G_Loss:2.011829376220703

iterator 1700, D_Loss:0.7972962260246277, G_Loss:2.2335262298583984

iterator 1800, D_Loss:0.8076558113098145, G_Loss:2.1998300552368164

iterator 1900, D_Loss:0.8521459102630615, G_Loss:2.0988731384277344

iterator 2000, D_Loss:0.810063898563385, G_Loss:2.241105556488037

iterator 2100, D_Loss:0.8094397783279419, G_Loss:2.1204123497009277

iterator 2200, D_Loss:0.8402805924415588, G_Loss:2.19119930267334

iterator 2300, D_Loss:0.8303115367889404, G_Loss:2.224259376525879

iterator 2400, D_Loss:0.7864982485771179, G_Loss:2.2961902618408203

iterator 2500, D_Loss:0.8689159154891968, G_Loss:2.250370979309082

iterator 2600, D_Loss:0.8012288808822632, G_Loss:2.1927525997161865

iterator 2700, D_Loss:0.836269736289978, G_Loss:2.0882861614227295

iterator 2800, D_Loss:0.7872892618179321, G_Loss:2.1450629234313965

iterator 2900, D_Loss:0.8737334609031677, G_Loss:2.167691469192505

iterator 3000, D_Loss:0.8606446385383606, G_Loss:2.116351366043091

iterator 3100, D_Loss:0.8170154690742493, G_Loss:2.1042592525482178

iterator 3200, D_Loss:0.8133129477500916, G_Loss:2.198376178741455

iterator 3300, D_Loss:0.8115524053573608, G_Loss:2.209003210067749

iterator 3400, D_Loss:0.7855740189552307, G_Loss:2.0561306476593018

iterator 3500, D_Loss:0.8086940050125122, G_Loss:2.113962173461914

iterator 3600, D_Loss:0.8438063859939575, G_Loss:2.2371978759765625

iterator 3700, D_Loss:0.8527490496635437, G_Loss:2.157809257507324

iterator 3800, D_Loss:0.8714150190353394, G_Loss:2.113722801208496

iterator 3900, D_Loss:0.8495548367500305, G_Loss:2.167048692703247

iterator 4000, D_Loss:0.8502700328826904, G_Loss:2.107269287109375

iterator 4100, D_Loss:0.8404015302658081, G_Loss:2.0895376205444336

iterator 4200, D_Loss:0.8339686989784241, G_Loss:2.0873866081237793

iterator 4300, D_Loss:0.8620100617408752, G_Loss:2.1159374713897705

iterator 4400, D_Loss:0.8396841287612915, G_Loss:2.0444979667663574

iterator 4500, D_Loss:0.9133410453796387, G_Loss:2.0064542293548584

iterator 4600, D_Loss:0.855952262878418, G_Loss:2.156859874725342

iterator 4700, D_Loss:0.825609564781189, G_Loss:2.2004218101501465

iterator 4800, D_Loss:0.8606573939323425, G_Loss:2.0762526988983154

iterator 4900, D_Loss:0.8475903272628784, G_Loss:2.099454402923584

iterator 5000, D_Loss:0.9050201177597046, G_Loss:2.0397160053253174

-----------Epoch 8-----------
iterator 100, D_Loss:0.8392243385314941, G_Loss:2.0833191871643066

iterator 200, D_Loss:0.8379496932029724, G_Loss:2.1745522022247314

iterator 300, D_Loss:0.9214693307876587, G_Loss:2.024380683898926

iterator 400, D_Loss:0.8584514856338501, G_Loss:1.9421137571334839

iterator 500, D_Loss:0.8155845403671265, G_Loss:2.090355634689331

iterator 600, D_Loss:0.8601457476615906, G_Loss:2.109642505645752

iterator 700, D_Loss:0.870597243309021, G_Loss:1.8361355066299438

iterator 800, D_Loss:0.8895843029022217, G_Loss:1.9975612163543701

iterator 900, D_Loss:0.8216017484664917, G_Loss:2.016068935394287

iterator 1000, D_Loss:0.8724814653396606, G_Loss:1.9494924545288086

iterator 1100, D_Loss:0.8406928777694702, G_Loss:2.0633296966552734

iterator 1200, D_Loss:0.8761091232299805, G_Loss:2.0489139556884766

iterator 1300, D_Loss:0.9454441070556641, G_Loss:1.9025853872299194

iterator 1400, D_Loss:0.8111027479171753, G_Loss:1.974258542060852

iterator 1500, D_Loss:0.9019990563392639, G_Loss:2.0214738845825195

iterator 1600, D_Loss:0.8846689462661743, G_Loss:1.9319350719451904

iterator 1700, D_Loss:0.8608511686325073, G_Loss:1.9655708074569702

iterator 1800, D_Loss:0.881006121635437, G_Loss:1.988065481185913

iterator 1900, D_Loss:0.9352999925613403, G_Loss:1.9390997886657715

iterator 2000, D_Loss:0.8395209312438965, G_Loss:2.057912826538086

iterator 2100, D_Loss:0.8966878652572632, G_Loss:1.944626808166504

iterator 2200, D_Loss:0.8068087100982666, G_Loss:2.0341715812683105

iterator 2300, D_Loss:0.9058498740196228, G_Loss:1.9377115964889526

iterator 2400, D_Loss:0.8629399538040161, G_Loss:1.9769635200500488

iterator 2500, D_Loss:0.9194650053977966, G_Loss:1.9497241973876953

iterator 2600, D_Loss:0.9039260745048523, G_Loss:2.0076210498809814

iterator 2700, D_Loss:0.8624663352966309, G_Loss:2.0796823501586914

iterator 2800, D_Loss:0.9263349771499634, G_Loss:1.8820589780807495

iterator 2900, D_Loss:0.8963056802749634, G_Loss:1.8687331676483154

iterator 3000, D_Loss:0.8576377034187317, G_Loss:1.9502419233322144

iterator 3100, D_Loss:0.89827561378479, G_Loss:1.938452124595642

iterator 3200, D_Loss:0.8872902989387512, G_Loss:1.9377740621566772

iterator 3300, D_Loss:0.9038715958595276, G_Loss:1.9923964738845825

iterator 3400, D_Loss:0.8472296595573425, G_Loss:2.0290379524230957

iterator 3500, D_Loss:0.8794988989830017, G_Loss:1.9281526803970337

iterator 3600, D_Loss:0.9182248711585999, G_Loss:2.0428171157836914

iterator 3700, D_Loss:0.9075503349304199, G_Loss:1.8481508493423462

iterator 3800, D_Loss:0.9139853715896606, G_Loss:2.006416082382202

iterator 3900, D_Loss:0.8761436343193054, G_Loss:1.9019296169281006

iterator 4000, D_Loss:0.9702459573745728, G_Loss:1.9334166049957275

iterator 4100, D_Loss:0.9045069813728333, G_Loss:1.9142383337020874

iterator 4200, D_Loss:0.8920435905456543, G_Loss:1.8481762409210205

iterator 4300, D_Loss:0.9279985427856445, G_Loss:1.8359565734863281

iterator 4400, D_Loss:0.848619282245636, G_Loss:1.9417957067489624

iterator 4500, D_Loss:0.944016695022583, G_Loss:1.8116556406021118

iterator 4600, D_Loss:0.9398556351661682, G_Loss:1.9495012760162354

iterator 4700, D_Loss:0.8980617523193359, G_Loss:1.8152867555618286

iterator 4800, D_Loss:0.9352049827575684, G_Loss:1.8612462282180786

iterator 4900, D_Loss:0.9056649208068848, G_Loss:1.8904750347137451

iterator 5000, D_Loss:0.9110044240951538, G_Loss:1.7938599586486816

-----------Epoch 9-----------
iterator 100, D_Loss:0.929348349571228, G_Loss:1.8633290529251099

iterator 200, D_Loss:0.8615462183952332, G_Loss:1.879319429397583

iterator 300, D_Loss:0.9620264172554016, G_Loss:1.8992449045181274

iterator 400, D_Loss:0.9452084898948669, G_Loss:1.9289002418518066

iterator 500, D_Loss:0.9104757308959961, G_Loss:1.9415977001190186

iterator 600, D_Loss:0.9611163139343262, G_Loss:1.8492789268493652

iterator 700, D_Loss:0.9441946744918823, G_Loss:1.727860689163208

iterator 800, D_Loss:0.9052990078926086, G_Loss:1.9661202430725098

iterator 900, D_Loss:0.9216821193695068, G_Loss:1.8982737064361572

iterator 1000, D_Loss:0.953569769859314, G_Loss:1.7444875240325928

iterator 1100, D_Loss:0.9063602089881897, G_Loss:1.9969100952148438

iterator 1200, D_Loss:0.9022235870361328, G_Loss:1.8966763019561768

iterator 1300, D_Loss:0.9004796147346497, G_Loss:1.821962594985962

iterator 1400, D_Loss:0.9279219508171082, G_Loss:1.8830430507659912

iterator 1500, D_Loss:0.9535545706748962, G_Loss:1.923133134841919

iterator 1600, D_Loss:0.9053102731704712, G_Loss:1.8788033723831177

iterator 1700, D_Loss:0.891612708568573, G_Loss:1.8349497318267822

iterator 1800, D_Loss:0.9350149631500244, G_Loss:1.8185672760009766

iterator 1900, D_Loss:0.9303313493728638, G_Loss:1.9355062246322632

iterator 2000, D_Loss:0.9414576888084412, G_Loss:1.8639612197875977

iterator 2100, D_Loss:1.0036829710006714, G_Loss:1.7988741397857666

iterator 2200, D_Loss:0.939050555229187, G_Loss:1.874077320098877

iterator 2300, D_Loss:0.9304711818695068, G_Loss:1.7298818826675415

iterator 2400, D_Loss:0.9383866786956787, G_Loss:1.7935761213302612

iterator 2500, D_Loss:0.9622747898101807, G_Loss:1.8958134651184082

iterator 2600, D_Loss:0.9395252466201782, G_Loss:1.8625413179397583

iterator 2700, D_Loss:0.896899938583374, G_Loss:1.8797798156738281

iterator 2800, D_Loss:0.9765392541885376, G_Loss:1.7966961860656738

iterator 2900, D_Loss:0.9298672676086426, G_Loss:1.8078213930130005

iterator 3000, D_Loss:0.9628692865371704, G_Loss:1.8153901100158691

iterator 3100, D_Loss:0.9693480730056763, G_Loss:1.847926139831543

iterator 3200, D_Loss:0.9522948265075684, G_Loss:1.8604509830474854

iterator 3300, D_Loss:0.9398590326309204, G_Loss:1.7275967597961426

iterator 3400, D_Loss:0.954173743724823, G_Loss:1.7413709163665771

iterator 3500, D_Loss:0.9735106229782104, G_Loss:1.7399386167526245

iterator 3600, D_Loss:0.8797322511672974, G_Loss:1.8044613599777222

iterator 3700, D_Loss:0.9248145818710327, G_Loss:1.809414029121399

iterator 3800, D_Loss:0.9572077393531799, G_Loss:1.8002647161483765

iterator 3900, D_Loss:0.9895457029342651, G_Loss:1.8195780515670776

iterator 4000, D_Loss:0.9914141893386841, G_Loss:1.829240322113037

iterator 4100, D_Loss:0.9994295239448547, G_Loss:1.7096279859542847

iterator 4200, D_Loss:0.8876913785934448, G_Loss:1.6966097354888916

iterator 4300, D_Loss:1.0297664403915405, G_Loss:1.5605518817901611

iterator 4400, D_Loss:0.9724408388137817, G_Loss:1.8044407367706299

iterator 4500, D_Loss:0.9850271940231323, G_Loss:1.77053964138031

iterator 4600, D_Loss:0.907066285610199, G_Loss:1.7067115306854248

iterator 4700, D_Loss:0.9244940876960754, G_Loss:1.8792121410369873

iterator 4800, D_Loss:0.9920327663421631, G_Loss:1.8412034511566162

iterator 4900, D_Loss:0.94871586561203, G_Loss:1.825085997581482

iterator 5000, D_Loss:0.9102090001106262, G_Loss:1.8075435161590576

train row : 30148
sample row: 30148
VGAN_generator(
  (input): Linear(in_features=256, out_features=300, bias=True)
  (inputbn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=300, out_features=300, bias=True)
  (bn0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=300, out_features=135, bias=True)
  (outputbn): BatchNorm1d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=135, out_features=200, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (fc1): Linear(in_features=200, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=200, bias=True)
  (output): Linear(in_features=200, out_features=1, bias=True)
)
(0, False, 135)
-----------Epoch 0-----------
iterator 100, D_Loss:0.5968485474586487, G_Loss:12.664772033691406

iterator 200, D_Loss:0.44425198435783386, G_Loss:12.89126968383789

iterator 300, D_Loss:0.45668572187423706, G_Loss:12.529706954956055

iterator 400, D_Loss:0.4352073669433594, G_Loss:12.615533828735352

iterator 500, D_Loss:0.4647919237613678, G_Loss:12.58184814453125

iterator 600, D_Loss:0.45306816697120667, G_Loss:10.630758285522461

iterator 700, D_Loss:0.4611901342868805, G_Loss:11.599759101867676

iterator 800, D_Loss:0.4885237216949463, G_Loss:11.054155349731445

iterator 900, D_Loss:0.4741232097148895, G_Loss:9.37063217163086

iterator 1000, D_Loss:0.4705082178115845, G_Loss:9.858367919921875

iterator 1100, D_Loss:0.47862082719802856, G_Loss:8.92853832244873

iterator 1200, D_Loss:0.45385506749153137, G_Loss:9.353902816772461

iterator 1300, D_Loss:0.5125439763069153, G_Loss:8.79877758026123

iterator 1400, D_Loss:0.4937513768672943, G_Loss:7.892028331756592

iterator 1500, D_Loss:0.500785231590271, G_Loss:8.550915718078613

iterator 1600, D_Loss:0.4997674524784088, G_Loss:8.123963356018066

iterator 1700, D_Loss:0.4999326467514038, G_Loss:8.83182144165039

iterator 1800, D_Loss:0.5218325853347778, G_Loss:7.449643611907959

iterator 1900, D_Loss:0.4833039343357086, G_Loss:8.27652359008789

iterator 2000, D_Loss:0.5108688473701477, G_Loss:7.691247940063477

iterator 2100, D_Loss:0.4990329444408417, G_Loss:7.507930755615234

iterator 2200, D_Loss:0.5014923214912415, G_Loss:7.471320152282715

iterator 2300, D_Loss:0.5444615483283997, G_Loss:7.7356462478637695

iterator 2400, D_Loss:0.5708014965057373, G_Loss:7.141659259796143

iterator 2500, D_Loss:0.5356690287590027, G_Loss:7.104679107666016

iterator 2600, D_Loss:0.5215945243835449, G_Loss:6.346485137939453

iterator 2700, D_Loss:0.5284056663513184, G_Loss:6.814083099365234

iterator 2800, D_Loss:0.6140080094337463, G_Loss:6.982249736785889

iterator 2900, D_Loss:0.5502741932868958, G_Loss:6.511633396148682

iterator 3000, D_Loss:0.5711111426353455, G_Loss:6.439549446105957

iterator 3100, D_Loss:0.5458477139472961, G_Loss:6.441859245300293

iterator 3200, D_Loss:0.6080250144004822, G_Loss:5.914775371551514

iterator 3300, D_Loss:0.5537517070770264, G_Loss:6.338993072509766

iterator 3400, D_Loss:0.5469232201576233, G_Loss:6.283422470092773

iterator 3500, D_Loss:0.5746877193450928, G_Loss:6.192516326904297

iterator 3600, D_Loss:0.5998134613037109, G_Loss:6.211448669433594

iterator 3700, D_Loss:0.5869789719581604, G_Loss:6.016820907592773

iterator 3800, D_Loss:0.5973984003067017, G_Loss:6.337728500366211

iterator 3900, D_Loss:0.5562076568603516, G_Loss:5.8696393966674805

iterator 4000, D_Loss:0.5723791122436523, G_Loss:5.575788974761963

iterator 4100, D_Loss:0.7134307622909546, G_Loss:5.7666120529174805

iterator 4200, D_Loss:0.6298375725746155, G_Loss:6.348011016845703

iterator 4300, D_Loss:0.5964076519012451, G_Loss:6.0859293937683105

iterator 4400, D_Loss:0.590311586856842, G_Loss:5.850276947021484

iterator 4500, D_Loss:0.6026009917259216, G_Loss:5.895407199859619

iterator 4600, D_Loss:0.618140459060669, G_Loss:5.379342079162598

iterator 4700, D_Loss:0.6225596070289612, G_Loss:5.124204635620117

iterator 4800, D_Loss:0.651252806186676, G_Loss:5.049054145812988

iterator 4900, D_Loss:0.624905526638031, G_Loss:4.793962001800537

iterator 5000, D_Loss:0.6245501637458801, G_Loss:4.638795375823975

-----------Epoch 1-----------
iterator 100, D_Loss:0.635539710521698, G_Loss:5.252918720245361

iterator 200, D_Loss:0.5893046855926514, G_Loss:4.952835559844971

iterator 300, D_Loss:0.6524349451065063, G_Loss:5.268463134765625

iterator 400, D_Loss:0.6056158542633057, G_Loss:5.035328388214111

iterator 500, D_Loss:0.6274605393409729, G_Loss:5.5557732582092285

iterator 600, D_Loss:0.6513630151748657, G_Loss:5.1967902183532715

iterator 700, D_Loss:0.623187243938446, G_Loss:5.120183944702148

iterator 800, D_Loss:0.654350757598877, G_Loss:5.301239013671875

iterator 900, D_Loss:0.6356788277626038, G_Loss:4.494861602783203

iterator 1000, D_Loss:0.6150326728820801, G_Loss:4.8478264808654785

iterator 1100, D_Loss:0.6274855136871338, G_Loss:4.535452842712402

iterator 1200, D_Loss:0.70107102394104, G_Loss:4.673318386077881

iterator 1300, D_Loss:0.7435532212257385, G_Loss:4.780424118041992

iterator 1400, D_Loss:0.6980341076850891, G_Loss:4.3374834060668945

iterator 1500, D_Loss:0.7006551027297974, G_Loss:4.249672889709473

iterator 1600, D_Loss:0.7263245582580566, G_Loss:4.1144280433654785

iterator 1700, D_Loss:0.694121241569519, G_Loss:4.186213493347168

iterator 1800, D_Loss:0.7540473937988281, G_Loss:4.000962734222412

iterator 1900, D_Loss:0.7348164916038513, G_Loss:3.508228063583374

iterator 2000, D_Loss:0.7268024682998657, G_Loss:3.6937811374664307

iterator 2100, D_Loss:0.7253074645996094, G_Loss:3.998535633087158

iterator 2200, D_Loss:0.7184278964996338, G_Loss:3.6690120697021484

iterator 2300, D_Loss:0.7344560623168945, G_Loss:3.6681888103485107

iterator 2400, D_Loss:0.7751922607421875, G_Loss:3.3943374156951904

iterator 2500, D_Loss:0.7131755352020264, G_Loss:3.4884583950042725

iterator 2600, D_Loss:0.7334992289543152, G_Loss:3.701838254928589

iterator 2700, D_Loss:0.7466338872909546, G_Loss:3.512133836746216

iterator 2800, D_Loss:0.7732181549072266, G_Loss:3.577946662902832

iterator 2900, D_Loss:0.754888653755188, G_Loss:3.7013444900512695

iterator 3000, D_Loss:0.7585293650627136, G_Loss:3.8598732948303223

iterator 3100, D_Loss:0.7773922085762024, G_Loss:3.1920158863067627

iterator 3200, D_Loss:0.7872284650802612, G_Loss:3.3919196128845215

iterator 3300, D_Loss:0.8439692854881287, G_Loss:3.3422584533691406

iterator 3400, D_Loss:0.7901692390441895, G_Loss:3.541938304901123

iterator 3500, D_Loss:0.8368524312973022, G_Loss:3.244701623916626

iterator 3600, D_Loss:0.7986612915992737, G_Loss:2.8016295433044434

iterator 3700, D_Loss:0.9318634271621704, G_Loss:2.927381753921509

iterator 3800, D_Loss:0.8239871859550476, G_Loss:3.044069290161133

iterator 3900, D_Loss:0.8071260452270508, G_Loss:3.1295876502990723

iterator 4000, D_Loss:0.8580849170684814, G_Loss:2.7697842121124268

iterator 4100, D_Loss:0.9001862406730652, G_Loss:2.7587361335754395

iterator 4200, D_Loss:0.8300908803939819, G_Loss:2.5391428470611572

iterator 4300, D_Loss:0.8346941471099854, G_Loss:2.768653631210327

iterator 4400, D_Loss:0.7810965180397034, G_Loss:3.022524118423462

iterator 4500, D_Loss:0.8711529970169067, G_Loss:3.094050407409668

iterator 4600, D_Loss:0.7806615233421326, G_Loss:2.8536949157714844

iterator 4700, D_Loss:0.8317145109176636, G_Loss:2.947218418121338

iterator 4800, D_Loss:0.8588827848434448, G_Loss:2.7461137771606445

iterator 4900, D_Loss:0.8922054171562195, G_Loss:2.967036724090576

iterator 5000, D_Loss:0.7860562205314636, G_Loss:3.1324973106384277

-----------Epoch 2-----------
iterator 100, D_Loss:0.7954983711242676, G_Loss:2.756171703338623

iterator 200, D_Loss:0.923471987247467, G_Loss:2.9254722595214844

iterator 300, D_Loss:0.8667565584182739, G_Loss:2.9921092987060547

iterator 400, D_Loss:0.8209394216537476, G_Loss:2.9093527793884277

iterator 500, D_Loss:0.8435952067375183, G_Loss:3.2128474712371826

iterator 600, D_Loss:0.8296501636505127, G_Loss:2.6726975440979004

iterator 700, D_Loss:0.7813094258308411, G_Loss:2.959015369415283

iterator 800, D_Loss:0.8154236078262329, G_Loss:3.09804368019104

iterator 900, D_Loss:0.7941398024559021, G_Loss:2.8696141242980957

iterator 1000, D_Loss:0.7749145030975342, G_Loss:2.8077754974365234

iterator 1100, D_Loss:0.8104315996170044, G_Loss:3.039823532104492

iterator 1200, D_Loss:0.8506125211715698, G_Loss:3.11993145942688

iterator 1300, D_Loss:0.8253430128097534, G_Loss:3.1823766231536865

iterator 1400, D_Loss:0.7852745056152344, G_Loss:3.021925210952759

iterator 1500, D_Loss:0.8573934435844421, G_Loss:2.7386929988861084

iterator 1600, D_Loss:0.8459423780441284, G_Loss:2.932591199874878

iterator 1700, D_Loss:0.7496037483215332, G_Loss:2.9975786209106445

iterator 1800, D_Loss:0.7849595546722412, G_Loss:3.5198190212249756

iterator 1900, D_Loss:0.8001161217689514, G_Loss:3.0679659843444824

iterator 2000, D_Loss:0.808905303478241, G_Loss:3.1045827865600586

iterator 2100, D_Loss:0.8099291324615479, G_Loss:2.7712578773498535

iterator 2200, D_Loss:0.8841454982757568, G_Loss:3.0555522441864014

iterator 2300, D_Loss:0.8201227188110352, G_Loss:3.2000155448913574

iterator 2400, D_Loss:0.7644144892692566, G_Loss:3.128690719604492

iterator 2500, D_Loss:0.8556549549102783, G_Loss:3.021599769592285

iterator 2600, D_Loss:0.7984254360198975, G_Loss:3.156097888946533

iterator 2700, D_Loss:0.7685911655426025, G_Loss:3.021409273147583

iterator 2800, D_Loss:0.8179354667663574, G_Loss:3.352464437484741

iterator 2900, D_Loss:0.8022292852401733, G_Loss:3.3127756118774414

iterator 3000, D_Loss:0.864768922328949, G_Loss:3.1038169860839844

iterator 3100, D_Loss:0.8339742422103882, G_Loss:3.1159753799438477

iterator 3200, D_Loss:0.7871195077896118, G_Loss:3.110405921936035

iterator 3300, D_Loss:0.7694359421730042, G_Loss:3.1070919036865234

iterator 3400, D_Loss:0.8435875177383423, G_Loss:3.1107656955718994

iterator 3500, D_Loss:0.8077850937843323, G_Loss:3.3381755352020264

iterator 3600, D_Loss:0.7900680303573608, G_Loss:3.23934268951416

iterator 3700, D_Loss:0.8452247381210327, G_Loss:3.3634841442108154

iterator 3800, D_Loss:0.8157259225845337, G_Loss:3.5220718383789062

iterator 3900, D_Loss:0.7805055379867554, G_Loss:3.3445544242858887

iterator 4000, D_Loss:0.7540847063064575, G_Loss:3.0455703735351562

iterator 4100, D_Loss:0.7346947193145752, G_Loss:3.2872836589813232

iterator 4200, D_Loss:0.8093423843383789, G_Loss:3.0641567707061768

iterator 4300, D_Loss:0.8379209637641907, G_Loss:3.353820562362671

iterator 4400, D_Loss:0.7526044249534607, G_Loss:3.407944679260254

iterator 4500, D_Loss:0.8366998434066772, G_Loss:3.1185832023620605

iterator 4600, D_Loss:0.8293862342834473, G_Loss:3.338860034942627

iterator 4700, D_Loss:0.845809817314148, G_Loss:3.0098299980163574

iterator 4800, D_Loss:0.8128250241279602, G_Loss:3.091352939605713

iterator 4900, D_Loss:0.7716082334518433, G_Loss:3.187631845474243

iterator 5000, D_Loss:0.8063268661499023, G_Loss:3.1682708263397217

-----------Epoch 3-----------
iterator 100, D_Loss:0.7971962094306946, G_Loss:3.04154372215271

iterator 200, D_Loss:0.8198027014732361, G_Loss:2.948779344558716

iterator 300, D_Loss:0.8311797380447388, G_Loss:3.081012725830078

iterator 400, D_Loss:0.7647775411605835, G_Loss:2.987309217453003

iterator 500, D_Loss:0.7976017594337463, G_Loss:2.978271722793579

iterator 600, D_Loss:0.808443009853363, G_Loss:3.1571755409240723

iterator 700, D_Loss:0.7769769430160522, G_Loss:3.0744194984436035

iterator 800, D_Loss:0.8492217063903809, G_Loss:2.973813056945801

iterator 900, D_Loss:0.7778128981590271, G_Loss:2.9930875301361084

iterator 1000, D_Loss:0.7527879476547241, G_Loss:3.4763121604919434

iterator 1100, D_Loss:0.7745152115821838, G_Loss:3.10937237739563

iterator 1200, D_Loss:0.8221734762191772, G_Loss:2.9360525608062744

iterator 1300, D_Loss:0.8198198080062866, G_Loss:3.2019941806793213

iterator 1400, D_Loss:0.8131221532821655, G_Loss:2.895131826400757

iterator 1500, D_Loss:0.8004023432731628, G_Loss:3.154736042022705

iterator 1600, D_Loss:0.7412451505661011, G_Loss:3.201097011566162

iterator 1700, D_Loss:0.8380299806594849, G_Loss:3.0988245010375977

iterator 1800, D_Loss:0.792259156703949, G_Loss:3.1580967903137207

iterator 1900, D_Loss:0.7730783224105835, G_Loss:3.1005704402923584

iterator 2000, D_Loss:0.8241269588470459, G_Loss:3.233914613723755

iterator 2100, D_Loss:0.8047404289245605, G_Loss:3.2889583110809326

iterator 2200, D_Loss:0.8330610990524292, G_Loss:3.0649726390838623

iterator 2300, D_Loss:0.828963577747345, G_Loss:3.020533323287964

iterator 2400, D_Loss:0.8386749029159546, G_Loss:2.7203922271728516

iterator 2500, D_Loss:0.8375174403190613, G_Loss:2.635338068008423

iterator 2600, D_Loss:0.8226108551025391, G_Loss:3.238940715789795

iterator 2700, D_Loss:0.7962960004806519, G_Loss:2.886730194091797

iterator 2800, D_Loss:0.764843761920929, G_Loss:2.93011736869812

iterator 2900, D_Loss:0.7768040299415588, G_Loss:3.192986249923706

iterator 3000, D_Loss:0.8772258758544922, G_Loss:3.369642734527588

iterator 3100, D_Loss:0.7657688856124878, G_Loss:2.880819082260132

iterator 3200, D_Loss:0.7950234413146973, G_Loss:3.129397392272949

iterator 3300, D_Loss:0.7707143425941467, G_Loss:2.928529739379883

iterator 3400, D_Loss:0.8409173488616943, G_Loss:2.7903900146484375

iterator 3500, D_Loss:0.8073002099990845, G_Loss:2.932513952255249

iterator 3600, D_Loss:0.8281843066215515, G_Loss:2.988654375076294

iterator 3700, D_Loss:0.8760610222816467, G_Loss:2.920945644378662

iterator 3800, D_Loss:0.8499243259429932, G_Loss:2.8949644565582275

iterator 3900, D_Loss:0.767315149307251, G_Loss:3.5527143478393555

iterator 4000, D_Loss:0.7970455884933472, G_Loss:3.020601749420166

iterator 4100, D_Loss:0.7976151704788208, G_Loss:2.8951287269592285

iterator 4200, D_Loss:0.8219228982925415, G_Loss:3.1884117126464844

iterator 4300, D_Loss:0.903096079826355, G_Loss:3.2219414710998535

iterator 4400, D_Loss:0.8043643832206726, G_Loss:2.998775005340576

iterator 4500, D_Loss:0.8393278121948242, G_Loss:3.121293067932129

iterator 4600, D_Loss:0.8036549091339111, G_Loss:2.9409472942352295

iterator 4700, D_Loss:0.8352115750312805, G_Loss:2.914018154144287

iterator 4800, D_Loss:0.8827223777770996, G_Loss:3.3187718391418457

iterator 4900, D_Loss:0.844021201133728, G_Loss:2.885591745376587

iterator 5000, D_Loss:0.9183376431465149, G_Loss:3.1709582805633545

-----------Epoch 4-----------
iterator 100, D_Loss:0.853245198726654, G_Loss:3.001009464263916

iterator 200, D_Loss:0.8164042830467224, G_Loss:2.8471856117248535

iterator 300, D_Loss:0.8245100975036621, G_Loss:2.765348196029663

iterator 400, D_Loss:0.818166971206665, G_Loss:2.946277379989624

iterator 500, D_Loss:0.7852702140808105, G_Loss:2.943563938140869

iterator 600, D_Loss:0.8366702795028687, G_Loss:3.144713878631592

iterator 700, D_Loss:0.82608962059021, G_Loss:2.6708548069000244

iterator 800, D_Loss:0.7969366908073425, G_Loss:2.9281327724456787

iterator 900, D_Loss:0.831047773361206, G_Loss:2.6009881496429443

iterator 1000, D_Loss:0.7845438122749329, G_Loss:2.886425018310547

iterator 1100, D_Loss:0.8034656047821045, G_Loss:2.800741672515869

iterator 1200, D_Loss:0.854136049747467, G_Loss:2.91426420211792

iterator 1300, D_Loss:0.8482092618942261, G_Loss:2.8391053676605225

iterator 1400, D_Loss:0.8181836605072021, G_Loss:2.90460205078125

iterator 1500, D_Loss:0.7774064540863037, G_Loss:2.857844114303589

iterator 1600, D_Loss:0.8066167831420898, G_Loss:3.018099546432495

iterator 1700, D_Loss:0.8708587288856506, G_Loss:2.8520777225494385

iterator 1800, D_Loss:0.7793002724647522, G_Loss:3.2791547775268555

iterator 1900, D_Loss:0.774586021900177, G_Loss:3.084855079650879

iterator 2000, D_Loss:0.8888044357299805, G_Loss:3.2418606281280518

iterator 2100, D_Loss:0.8562523126602173, G_Loss:2.632776975631714

iterator 2200, D_Loss:0.8333872556686401, G_Loss:2.8264400959014893

iterator 2300, D_Loss:0.8325390219688416, G_Loss:2.6897661685943604

iterator 2400, D_Loss:0.8091896772384644, G_Loss:2.9968783855438232

iterator 2500, D_Loss:0.8767441511154175, G_Loss:2.5433058738708496

iterator 2600, D_Loss:0.8148839473724365, G_Loss:3.0459554195404053

iterator 2700, D_Loss:0.8056162595748901, G_Loss:2.859464406967163

iterator 2800, D_Loss:0.909511148929596, G_Loss:2.9967665672302246

iterator 2900, D_Loss:0.8381050229072571, G_Loss:3.290586233139038

iterator 3000, D_Loss:0.8809055685997009, G_Loss:2.7923223972320557

iterator 3100, D_Loss:0.8729206323623657, G_Loss:3.189948797225952

iterator 3200, D_Loss:0.8262962102890015, G_Loss:2.8878865242004395

iterator 3300, D_Loss:0.8588733673095703, G_Loss:3.0693564414978027

iterator 3400, D_Loss:0.8559999465942383, G_Loss:2.9333832263946533

iterator 3500, D_Loss:0.8160187005996704, G_Loss:2.961566209793091

iterator 3600, D_Loss:0.8191553354263306, G_Loss:3.0009751319885254

iterator 3700, D_Loss:0.857446014881134, G_Loss:3.043529987335205

iterator 3800, D_Loss:0.8196589946746826, G_Loss:2.703770160675049

iterator 3900, D_Loss:0.7936524748802185, G_Loss:3.0210771560668945

iterator 4000, D_Loss:0.8323221802711487, G_Loss:2.569915294647217

iterator 4100, D_Loss:0.8466492891311646, G_Loss:2.7997963428497314

iterator 4200, D_Loss:0.902854859828949, G_Loss:2.7985169887542725

iterator 4300, D_Loss:0.8424838781356812, G_Loss:2.807515859603882

iterator 4400, D_Loss:0.7864804863929749, G_Loss:2.8694963455200195

iterator 4500, D_Loss:0.8885125517845154, G_Loss:3.1418490409851074

iterator 4600, D_Loss:0.734140932559967, G_Loss:2.9237189292907715

iterator 4700, D_Loss:0.8391454219818115, G_Loss:3.1236181259155273

iterator 4800, D_Loss:0.7931904196739197, G_Loss:2.9316349029541016

iterator 4900, D_Loss:0.9097439646720886, G_Loss:2.8548035621643066

iterator 5000, D_Loss:0.8760786056518555, G_Loss:2.619941473007202

-----------Epoch 5-----------
iterator 100, D_Loss:0.8324247002601624, G_Loss:2.8724124431610107

iterator 200, D_Loss:0.876354992389679, G_Loss:2.9131946563720703

iterator 300, D_Loss:0.839519202709198, G_Loss:2.7856178283691406

iterator 400, D_Loss:0.7846056818962097, G_Loss:2.836904525756836

iterator 500, D_Loss:0.8435798287391663, G_Loss:3.092094898223877

iterator 600, D_Loss:0.8193791508674622, G_Loss:3.3361926078796387

iterator 700, D_Loss:0.8209069967269897, G_Loss:2.7571544647216797

iterator 800, D_Loss:0.8454558849334717, G_Loss:2.761667013168335

iterator 900, D_Loss:0.8488603234291077, G_Loss:2.8589248657226562

iterator 1000, D_Loss:0.9411085844039917, G_Loss:2.7524280548095703

iterator 1100, D_Loss:0.8320012092590332, G_Loss:2.8713552951812744

iterator 1200, D_Loss:0.815345287322998, G_Loss:2.7375128269195557

iterator 1300, D_Loss:0.8377869129180908, G_Loss:2.798757314682007

iterator 1400, D_Loss:0.8959783315658569, G_Loss:2.802030324935913

iterator 1500, D_Loss:0.8243274092674255, G_Loss:2.931954860687256

iterator 1600, D_Loss:0.7984824180603027, G_Loss:2.5930795669555664

iterator 1700, D_Loss:0.7932849526405334, G_Loss:2.725048780441284

iterator 1800, D_Loss:0.8518273234367371, G_Loss:3.284496307373047

iterator 1900, D_Loss:0.8838825225830078, G_Loss:2.578235149383545

iterator 2000, D_Loss:0.8308963775634766, G_Loss:3.2610185146331787

iterator 2100, D_Loss:0.8961263298988342, G_Loss:2.862327814102173

iterator 2200, D_Loss:0.831852912902832, G_Loss:2.8170530796051025

iterator 2300, D_Loss:0.8391796946525574, G_Loss:2.8145503997802734

iterator 2400, D_Loss:0.8651201128959656, G_Loss:3.188535690307617

iterator 2500, D_Loss:0.8409850597381592, G_Loss:2.785916805267334

iterator 2600, D_Loss:0.8099038600921631, G_Loss:3.0092828273773193

iterator 2700, D_Loss:0.8166783452033997, G_Loss:2.659604787826538

iterator 2800, D_Loss:0.8789466619491577, G_Loss:2.7712628841400146

iterator 2900, D_Loss:0.7953799366950989, G_Loss:3.139490842819214

iterator 3000, D_Loss:0.8644763231277466, G_Loss:2.5920815467834473

iterator 3100, D_Loss:0.8661408424377441, G_Loss:2.888021230697632

iterator 3200, D_Loss:0.8261723518371582, G_Loss:2.5682730674743652

iterator 3300, D_Loss:0.8636934757232666, G_Loss:2.8698904514312744

iterator 3400, D_Loss:0.7836204171180725, G_Loss:2.8879783153533936

iterator 3500, D_Loss:0.8097547292709351, G_Loss:3.0002005100250244

iterator 3600, D_Loss:0.8008496761322021, G_Loss:3.0823802947998047

iterator 3700, D_Loss:0.8370469808578491, G_Loss:3.0837910175323486

iterator 3800, D_Loss:0.770187497138977, G_Loss:3.2166030406951904

iterator 3900, D_Loss:0.8443222641944885, G_Loss:2.9423611164093018

iterator 4000, D_Loss:0.8410093188285828, G_Loss:3.095416784286499

iterator 4100, D_Loss:0.7787002325057983, G_Loss:2.8005847930908203

iterator 4200, D_Loss:0.8510582447052002, G_Loss:2.812248945236206

iterator 4300, D_Loss:0.8744280338287354, G_Loss:2.697101593017578

iterator 4400, D_Loss:0.868002712726593, G_Loss:2.8829164505004883

iterator 4500, D_Loss:0.8424370288848877, G_Loss:2.795388698577881

iterator 4600, D_Loss:0.8884292244911194, G_Loss:2.7269318103790283

iterator 4700, D_Loss:0.8554327487945557, G_Loss:2.738429069519043

iterator 4800, D_Loss:0.8044324517250061, G_Loss:2.8125159740448

iterator 4900, D_Loss:0.8391700387001038, G_Loss:3.086585521697998

iterator 5000, D_Loss:0.8348029851913452, G_Loss:2.758359909057617

-----------Epoch 6-----------
iterator 100, D_Loss:0.8400068283081055, G_Loss:3.007777214050293

iterator 200, D_Loss:0.8457281589508057, G_Loss:2.546283006668091

iterator 300, D_Loss:0.7873442769050598, G_Loss:2.8848628997802734

iterator 400, D_Loss:0.8518620729446411, G_Loss:2.8851301670074463

iterator 500, D_Loss:0.8470101952552795, G_Loss:2.864715814590454

iterator 600, D_Loss:0.7924972772598267, G_Loss:2.818208932876587

iterator 700, D_Loss:0.8146686553955078, G_Loss:2.93571138381958

iterator 800, D_Loss:0.8754544854164124, G_Loss:2.98480486869812

iterator 900, D_Loss:0.9123691916465759, G_Loss:2.942336082458496

iterator 1000, D_Loss:0.9375736713409424, G_Loss:2.8275623321533203

iterator 1100, D_Loss:0.8761898279190063, G_Loss:2.903986692428589

iterator 1200, D_Loss:0.8061131834983826, G_Loss:2.6540000438690186

iterator 1300, D_Loss:0.7730945348739624, G_Loss:2.725708484649658

iterator 1400, D_Loss:0.8113049864768982, G_Loss:2.83921217918396

iterator 1500, D_Loss:0.8409663438796997, G_Loss:3.3014986515045166

iterator 1600, D_Loss:0.7906409502029419, G_Loss:2.8707854747772217

iterator 1700, D_Loss:0.8215389847755432, G_Loss:2.8850748538970947

iterator 1800, D_Loss:0.8543436527252197, G_Loss:2.854459285736084

iterator 1900, D_Loss:0.8718608617782593, G_Loss:2.762254238128662

iterator 2000, D_Loss:0.8173965811729431, G_Loss:2.9446709156036377

iterator 2100, D_Loss:0.8085875511169434, G_Loss:2.8941123485565186

iterator 2200, D_Loss:0.8131994009017944, G_Loss:2.984261989593506

iterator 2300, D_Loss:0.8174980878829956, G_Loss:2.733510971069336

iterator 2400, D_Loss:0.8020104169845581, G_Loss:2.8996474742889404

iterator 2500, D_Loss:0.8549277782440186, G_Loss:2.9467735290527344

iterator 2600, D_Loss:0.8459652662277222, G_Loss:2.748431444168091

iterator 2700, D_Loss:0.810046911239624, G_Loss:2.6566238403320312

iterator 2800, D_Loss:0.9347333312034607, G_Loss:2.8484411239624023

iterator 2900, D_Loss:0.8226180672645569, G_Loss:2.769735336303711

iterator 3000, D_Loss:0.9045772552490234, G_Loss:3.0730881690979004

iterator 3100, D_Loss:0.8483692407608032, G_Loss:2.9395997524261475

iterator 3200, D_Loss:0.851769208908081, G_Loss:3.0263688564300537

iterator 3300, D_Loss:0.8376104831695557, G_Loss:2.880331039428711

iterator 3400, D_Loss:0.876793384552002, G_Loss:2.699218511581421

iterator 3500, D_Loss:0.8738477230072021, G_Loss:3.0692145824432373

iterator 3600, D_Loss:0.844695508480072, G_Loss:2.669261932373047

iterator 3700, D_Loss:0.7892948985099792, G_Loss:3.2958176136016846

iterator 3800, D_Loss:0.8619067668914795, G_Loss:2.648912191390991

iterator 3900, D_Loss:0.8766351938247681, G_Loss:2.815781354904175

iterator 4000, D_Loss:0.8764501214027405, G_Loss:2.825770616531372

iterator 4100, D_Loss:0.8587018251419067, G_Loss:2.5915744304656982

iterator 4200, D_Loss:0.7983369827270508, G_Loss:3.1640849113464355

iterator 4300, D_Loss:0.827452540397644, G_Loss:2.848792791366577

iterator 4400, D_Loss:0.8529160022735596, G_Loss:3.048210620880127

iterator 4500, D_Loss:0.8495499491691589, G_Loss:3.2253527641296387

iterator 4600, D_Loss:0.8936235308647156, G_Loss:2.771005392074585

iterator 4700, D_Loss:0.836247444152832, G_Loss:2.6763362884521484

iterator 4800, D_Loss:0.8372036218643188, G_Loss:2.950007200241089

iterator 4900, D_Loss:0.8326245546340942, G_Loss:2.667403221130371

iterator 5000, D_Loss:0.8774160742759705, G_Loss:2.544313430786133

-----------Epoch 7-----------
iterator 100, D_Loss:0.8426370620727539, G_Loss:2.7693254947662354

iterator 200, D_Loss:0.9365932941436768, G_Loss:2.648942708969116

iterator 300, D_Loss:0.8006762266159058, G_Loss:2.8979361057281494

iterator 400, D_Loss:0.8903117179870605, G_Loss:2.900646209716797

iterator 500, D_Loss:0.8846156597137451, G_Loss:3.0490477085113525

iterator 600, D_Loss:0.852827787399292, G_Loss:3.123166799545288

iterator 700, D_Loss:0.7998582124710083, G_Loss:3.0340957641601562

iterator 800, D_Loss:0.8608081936836243, G_Loss:2.9471242427825928

iterator 900, D_Loss:0.8319116234779358, G_Loss:2.893510341644287

iterator 1000, D_Loss:0.862898588180542, G_Loss:2.7450287342071533

iterator 1100, D_Loss:0.8318313360214233, G_Loss:2.863558530807495

iterator 1200, D_Loss:0.8534495830535889, G_Loss:2.8110430240631104

iterator 1300, D_Loss:0.8605897426605225, G_Loss:2.686573028564453

iterator 1400, D_Loss:0.8571199178695679, G_Loss:3.0194714069366455

iterator 1500, D_Loss:0.8099144697189331, G_Loss:2.7590396404266357

iterator 1600, D_Loss:0.768491268157959, G_Loss:2.9195103645324707

iterator 1700, D_Loss:0.851445198059082, G_Loss:2.997758388519287

iterator 1800, D_Loss:0.831915557384491, G_Loss:3.407064914703369

iterator 1900, D_Loss:0.8493221402168274, G_Loss:2.8888607025146484

iterator 2000, D_Loss:0.8601400852203369, G_Loss:2.781508684158325

iterator 2100, D_Loss:0.8762884736061096, G_Loss:2.8794310092926025

iterator 2200, D_Loss:0.8115195035934448, G_Loss:2.7484030723571777

iterator 2300, D_Loss:0.924044132232666, G_Loss:2.6220333576202393

iterator 2400, D_Loss:0.8132357597351074, G_Loss:2.8135387897491455

iterator 2500, D_Loss:0.8598203659057617, G_Loss:2.714935541152954

iterator 2600, D_Loss:0.8536421060562134, G_Loss:2.9518277645111084

iterator 2700, D_Loss:0.910696268081665, G_Loss:2.499086618423462

iterator 2800, D_Loss:0.7665533423423767, G_Loss:3.3214783668518066

iterator 2900, D_Loss:0.8572707176208496, G_Loss:2.6965630054473877

iterator 3000, D_Loss:0.8500035405158997, G_Loss:2.817446708679199

iterator 3100, D_Loss:0.9154704809188843, G_Loss:3.1746208667755127

iterator 3200, D_Loss:0.7984048128128052, G_Loss:2.772568464279175

iterator 3300, D_Loss:0.8231717348098755, G_Loss:3.058988571166992

iterator 3400, D_Loss:0.8581956624984741, G_Loss:2.5535995960235596

iterator 3500, D_Loss:0.8742562532424927, G_Loss:2.9096035957336426

iterator 3600, D_Loss:0.8580594062805176, G_Loss:2.6282732486724854

iterator 3700, D_Loss:0.8126833438873291, G_Loss:2.9473791122436523

iterator 3800, D_Loss:0.7826309204101562, G_Loss:2.6615679264068604

iterator 3900, D_Loss:0.8884264230728149, G_Loss:2.9893898963928223

iterator 4000, D_Loss:0.8352344036102295, G_Loss:2.7281644344329834

iterator 4100, D_Loss:0.9310312271118164, G_Loss:2.7382588386535645

iterator 4200, D_Loss:0.9539688229560852, G_Loss:2.7679638862609863

iterator 4300, D_Loss:0.8567869067192078, G_Loss:2.8958396911621094

iterator 4400, D_Loss:0.8268468379974365, G_Loss:2.405381679534912

iterator 4500, D_Loss:0.8367025852203369, G_Loss:3.0776634216308594

iterator 4600, D_Loss:0.8225926160812378, G_Loss:2.604508638381958

iterator 4700, D_Loss:0.856378436088562, G_Loss:2.734902858734131

iterator 4800, D_Loss:0.8759884238243103, G_Loss:2.6585490703582764

iterator 4900, D_Loss:0.8024805784225464, G_Loss:3.046875238418579

iterator 5000, D_Loss:0.9349460005760193, G_Loss:2.679133415222168

-----------Epoch 8-----------
iterator 100, D_Loss:0.8344346284866333, G_Loss:2.7993013858795166

iterator 200, D_Loss:0.8849376440048218, G_Loss:2.9035682678222656

iterator 300, D_Loss:0.8461700677871704, G_Loss:2.724525213241577

iterator 400, D_Loss:0.8700546622276306, G_Loss:2.5681819915771484

iterator 500, D_Loss:0.9139727354049683, G_Loss:2.994751453399658

iterator 600, D_Loss:0.7532838582992554, G_Loss:2.7962286472320557

iterator 700, D_Loss:0.8706005215644836, G_Loss:2.686643600463867

iterator 800, D_Loss:0.8895516395568848, G_Loss:2.550994634628296

iterator 900, D_Loss:0.9096265435218811, G_Loss:2.430973529815674

iterator 1000, D_Loss:0.8890743255615234, G_Loss:2.3203301429748535

iterator 1100, D_Loss:0.8303089141845703, G_Loss:2.752728223800659

iterator 1200, D_Loss:0.8967247009277344, G_Loss:2.664602756500244

iterator 1300, D_Loss:0.8711532354354858, G_Loss:2.613447427749634

iterator 1400, D_Loss:0.8829598426818848, G_Loss:2.9957051277160645

iterator 1500, D_Loss:0.8957898020744324, G_Loss:2.8964898586273193

iterator 1600, D_Loss:0.8448079228401184, G_Loss:2.669459581375122

iterator 1700, D_Loss:0.860835075378418, G_Loss:2.5347278118133545

iterator 1800, D_Loss:0.8208609819412231, G_Loss:2.776395797729492

iterator 1900, D_Loss:0.8607794046401978, G_Loss:2.4290130138397217

iterator 2000, D_Loss:0.8557603359222412, G_Loss:2.6855268478393555

iterator 2100, D_Loss:0.9012093544006348, G_Loss:2.7854650020599365

iterator 2200, D_Loss:0.8178640604019165, G_Loss:2.6450204849243164

iterator 2300, D_Loss:0.9105539917945862, G_Loss:2.556976079940796

iterator 2400, D_Loss:0.8908708095550537, G_Loss:2.59513521194458

iterator 2500, D_Loss:0.8209877014160156, G_Loss:2.774367570877075

iterator 2600, D_Loss:0.8187609910964966, G_Loss:2.738257884979248

iterator 2700, D_Loss:0.8578487634658813, G_Loss:2.4874587059020996

iterator 2800, D_Loss:0.889165997505188, G_Loss:2.9898219108581543

iterator 2900, D_Loss:0.886308491230011, G_Loss:2.5733449459075928

iterator 3000, D_Loss:0.9323092699050903, G_Loss:2.79893159866333

iterator 3100, D_Loss:0.9358651638031006, G_Loss:2.813588857650757

iterator 3200, D_Loss:0.885191798210144, G_Loss:2.572413682937622

iterator 3300, D_Loss:0.8681206703186035, G_Loss:2.532099723815918

iterator 3400, D_Loss:0.8767371773719788, G_Loss:2.598573684692383

iterator 3500, D_Loss:0.8339455127716064, G_Loss:2.8988349437713623

iterator 3600, D_Loss:0.831081211566925, G_Loss:2.669325351715088

iterator 3700, D_Loss:0.9186568260192871, G_Loss:2.6376383304595947

iterator 3800, D_Loss:0.8627105951309204, G_Loss:2.580320119857788

iterator 3900, D_Loss:0.8949214220046997, G_Loss:2.7514734268188477

iterator 4000, D_Loss:0.8782116174697876, G_Loss:2.837677478790283

iterator 4100, D_Loss:0.8401899337768555, G_Loss:2.898693084716797

iterator 4200, D_Loss:0.9111619591712952, G_Loss:2.707890748977661

iterator 4300, D_Loss:0.8553295135498047, G_Loss:3.08497953414917

iterator 4400, D_Loss:0.8690032958984375, G_Loss:2.664112091064453

iterator 4500, D_Loss:0.8552586436271667, G_Loss:2.861713171005249

iterator 4600, D_Loss:0.8063411712646484, G_Loss:2.593367099761963

iterator 4700, D_Loss:0.8840641975402832, G_Loss:2.9813716411590576

iterator 4800, D_Loss:0.8814591765403748, G_Loss:2.5768918991088867

iterator 4900, D_Loss:0.7930498123168945, G_Loss:2.567816734313965

iterator 5000, D_Loss:0.8701200485229492, G_Loss:2.6952967643737793

-----------Epoch 9-----------
iterator 100, D_Loss:0.8676363825798035, G_Loss:2.7966511249542236

iterator 200, D_Loss:0.8943518996238708, G_Loss:2.5143842697143555

iterator 300, D_Loss:0.8013008832931519, G_Loss:2.5185368061065674

iterator 400, D_Loss:0.8700311183929443, G_Loss:2.5724451541900635

iterator 500, D_Loss:0.9066316485404968, G_Loss:2.779085874557495

iterator 600, D_Loss:0.8424716591835022, G_Loss:2.4948854446411133

iterator 700, D_Loss:0.8675060272216797, G_Loss:2.8204972743988037

iterator 800, D_Loss:0.8737697005271912, G_Loss:2.5542774200439453

iterator 900, D_Loss:0.93486487865448, G_Loss:2.4050683975219727

iterator 1000, D_Loss:0.9506720304489136, G_Loss:2.6399500370025635

iterator 1100, D_Loss:0.8086668848991394, G_Loss:2.4982850551605225

iterator 1200, D_Loss:0.9152238368988037, G_Loss:2.3139123916625977

iterator 1300, D_Loss:0.8953958749771118, G_Loss:2.507915735244751

iterator 1400, D_Loss:0.8944637179374695, G_Loss:2.1899538040161133

iterator 1500, D_Loss:0.8851269483566284, G_Loss:2.80060076713562

iterator 1600, D_Loss:0.848343551158905, G_Loss:2.6998581886291504

iterator 1700, D_Loss:0.8420664072036743, G_Loss:2.6594126224517822

iterator 1800, D_Loss:0.8609380722045898, G_Loss:2.60593318939209

iterator 1900, D_Loss:0.9160441160202026, G_Loss:2.6359498500823975

iterator 2000, D_Loss:0.8987759351730347, G_Loss:2.6298232078552246

iterator 2100, D_Loss:0.9158196449279785, G_Loss:2.5769217014312744

iterator 2200, D_Loss:0.8948038816452026, G_Loss:2.5268383026123047

iterator 2300, D_Loss:0.8386282324790955, G_Loss:2.395974636077881

iterator 2400, D_Loss:0.8559591770172119, G_Loss:2.999283790588379

iterator 2500, D_Loss:0.8980696201324463, G_Loss:2.7882540225982666

iterator 2600, D_Loss:0.9220443367958069, G_Loss:2.764810800552368

iterator 2700, D_Loss:0.9085988998413086, G_Loss:2.418978691101074

iterator 2800, D_Loss:0.8895478844642639, G_Loss:2.5583879947662354

iterator 2900, D_Loss:0.8073495626449585, G_Loss:2.7724497318267822

iterator 3000, D_Loss:0.8949832916259766, G_Loss:2.5621988773345947

iterator 3100, D_Loss:0.8740091919898987, G_Loss:2.746212959289551

iterator 3200, D_Loss:0.8830443620681763, G_Loss:2.7057950496673584

iterator 3300, D_Loss:0.9247502684593201, G_Loss:2.547168731689453

iterator 3400, D_Loss:0.8658608198165894, G_Loss:2.5384247303009033

iterator 3500, D_Loss:0.9297066926956177, G_Loss:2.3859496116638184

iterator 3600, D_Loss:0.7919008135795593, G_Loss:2.930917501449585

iterator 3700, D_Loss:0.9002347588539124, G_Loss:2.563040018081665

iterator 3800, D_Loss:0.7990460395812988, G_Loss:2.93894624710083

iterator 3900, D_Loss:0.8613263368606567, G_Loss:2.784289598464966

iterator 4000, D_Loss:0.8947805166244507, G_Loss:2.5694124698638916

iterator 4100, D_Loss:0.9223257303237915, G_Loss:2.525651693344116

iterator 4200, D_Loss:0.9506545066833496, G_Loss:2.5445399284362793

iterator 4300, D_Loss:0.933820366859436, G_Loss:2.473031520843506

iterator 4400, D_Loss:1.0025213956832886, G_Loss:2.567821979522705

iterator 4500, D_Loss:0.9207210540771484, G_Loss:2.6462557315826416

iterator 4600, D_Loss:0.8373527526855469, G_Loss:2.4683878421783447

iterator 4700, D_Loss:0.8662897348403931, G_Loss:2.5773143768310547

iterator 4800, D_Loss:0.8710445761680603, G_Loss:2.5964643955230713

iterator 4900, D_Loss:0.8460007905960083, G_Loss:2.6045548915863037

iterator 5000, D_Loss:0.887779712677002, G_Loss:2.602912664413452

VGAN_generator(
  (input): Linear(in_features=128, out_features=300, bias=True)
  (inputbn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=300, out_features=300, bias=True)
  (bn0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=300, out_features=300, bias=True)
  (bn1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=300, out_features=135, bias=True)
  (outputbn): BatchNorm1d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=135, out_features=200, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (fc1): Linear(in_features=200, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=200, bias=True)
  (output): Linear(in_features=200, out_features=1, bias=True)
)
(0, False, 135)
-----------Epoch 0-----------
iterator 100, D_Loss:0.8455665111541748, G_Loss:9.003435134887695

iterator 200, D_Loss:0.5698524117469788, G_Loss:11.159344673156738

iterator 300, D_Loss:0.5556261539459229, G_Loss:11.616289138793945

iterator 400, D_Loss:0.5324919819831848, G_Loss:11.634581565856934

iterator 500, D_Loss:0.5793496370315552, G_Loss:12.279573440551758

iterator 600, D_Loss:0.49302539229393005, G_Loss:10.856170654296875

iterator 700, D_Loss:0.5168023109436035, G_Loss:13.492058753967285

iterator 800, D_Loss:0.50676429271698, G_Loss:13.703804016113281

iterator 900, D_Loss:0.4936537444591522, G_Loss:11.984786987304688

iterator 1000, D_Loss:0.4815518260002136, G_Loss:13.365827560424805

iterator 1100, D_Loss:0.4352456033229828, G_Loss:14.335811614990234

iterator 1200, D_Loss:0.4565872848033905, G_Loss:14.230640411376953

iterator 1300, D_Loss:0.4854695498943329, G_Loss:13.273910522460938

iterator 1400, D_Loss:0.5156351327896118, G_Loss:11.754714012145996

iterator 1500, D_Loss:0.45773208141326904, G_Loss:12.210389137268066

iterator 1600, D_Loss:0.43147507309913635, G_Loss:12.87977409362793

iterator 1700, D_Loss:0.4457601308822632, G_Loss:13.828632354736328

iterator 1800, D_Loss:0.48226499557495117, G_Loss:12.596149444580078

iterator 1900, D_Loss:0.4534120559692383, G_Loss:12.646177291870117

iterator 2000, D_Loss:0.48261168599128723, G_Loss:11.717704772949219

iterator 2100, D_Loss:0.43629786372184753, G_Loss:11.207555770874023

iterator 2200, D_Loss:0.44503313302993774, G_Loss:11.44312858581543

iterator 2300, D_Loss:0.4759849011898041, G_Loss:12.210657119750977

iterator 2400, D_Loss:0.4593804180622101, G_Loss:10.985443115234375

iterator 2500, D_Loss:0.46292421221733093, G_Loss:10.754438400268555

iterator 2600, D_Loss:0.43769606947898865, G_Loss:10.696441650390625

iterator 2700, D_Loss:0.4349656105041504, G_Loss:10.599875450134277

iterator 2800, D_Loss:0.4596352279186249, G_Loss:10.734272003173828

iterator 2900, D_Loss:0.4422132968902588, G_Loss:10.649287223815918

iterator 3000, D_Loss:0.4602110683917999, G_Loss:11.152220726013184

iterator 3100, D_Loss:0.47571876645088196, G_Loss:10.387533187866211

iterator 3200, D_Loss:0.4682137966156006, G_Loss:10.649360656738281

iterator 3300, D_Loss:0.4618808627128601, G_Loss:9.810394287109375

iterator 3400, D_Loss:0.47059082984924316, G_Loss:10.18409538269043

iterator 3500, D_Loss:0.44576495885849, G_Loss:10.459156036376953

iterator 3600, D_Loss:0.45852237939834595, G_Loss:10.409529685974121

iterator 3700, D_Loss:0.4663144052028656, G_Loss:10.275678634643555

iterator 3800, D_Loss:0.4549252986907959, G_Loss:9.98793888092041

iterator 3900, D_Loss:0.4741920530796051, G_Loss:9.81828784942627

iterator 4000, D_Loss:0.44146841764450073, G_Loss:9.793193817138672

iterator 4100, D_Loss:0.4787229895591736, G_Loss:10.100107192993164

iterator 4200, D_Loss:0.4633849561214447, G_Loss:9.934990882873535

iterator 4300, D_Loss:0.4604175388813019, G_Loss:9.916543960571289

iterator 4400, D_Loss:0.46201667189598083, G_Loss:9.786481857299805

iterator 4500, D_Loss:0.4529522955417633, G_Loss:9.854376792907715

iterator 4600, D_Loss:0.4659220278263092, G_Loss:9.566791534423828

iterator 4700, D_Loss:0.45136240124702454, G_Loss:9.57778263092041

iterator 4800, D_Loss:0.44924744963645935, G_Loss:9.949190139770508

iterator 4900, D_Loss:0.4895206093788147, G_Loss:9.169073104858398

iterator 5000, D_Loss:0.44774219393730164, G_Loss:9.647167205810547

-----------Epoch 1-----------
iterator 100, D_Loss:0.45359528064727783, G_Loss:9.634127616882324

iterator 200, D_Loss:0.43742674589157104, G_Loss:9.37713623046875

iterator 300, D_Loss:0.4556907117366791, G_Loss:8.927192687988281

iterator 400, D_Loss:0.47278404235839844, G_Loss:8.977749824523926

iterator 500, D_Loss:0.4675004780292511, G_Loss:9.656107902526855

iterator 600, D_Loss:0.46331682801246643, G_Loss:9.401017189025879

iterator 700, D_Loss:0.4745457172393799, G_Loss:9.476354598999023

iterator 800, D_Loss:0.45753198862075806, G_Loss:9.792741775512695

iterator 900, D_Loss:0.4814687669277191, G_Loss:8.500971794128418

iterator 1000, D_Loss:0.47413966059684753, G_Loss:9.038219451904297

iterator 1100, D_Loss:0.44666919112205505, G_Loss:8.804520606994629

iterator 1200, D_Loss:0.5063542127609253, G_Loss:9.162667274475098

iterator 1300, D_Loss:0.4782152771949768, G_Loss:8.32994270324707

iterator 1400, D_Loss:0.4605843722820282, G_Loss:8.284552574157715

iterator 1500, D_Loss:0.4742628335952759, G_Loss:8.537635803222656

iterator 1600, D_Loss:0.5138640403747559, G_Loss:8.46481990814209

iterator 1700, D_Loss:0.4783859848976135, G_Loss:8.69083023071289

iterator 1800, D_Loss:0.506704568862915, G_Loss:7.832380294799805

iterator 1900, D_Loss:0.5023441314697266, G_Loss:8.37903881072998

iterator 2000, D_Loss:0.4653559625148773, G_Loss:8.071494102478027

iterator 2100, D_Loss:0.4846370220184326, G_Loss:7.503111839294434

iterator 2200, D_Loss:0.49820879101753235, G_Loss:8.05888843536377

iterator 2300, D_Loss:0.49112406373023987, G_Loss:8.855360984802246

iterator 2400, D_Loss:0.5158578753471375, G_Loss:8.221997261047363

iterator 2500, D_Loss:0.46469390392303467, G_Loss:8.121744155883789

iterator 2600, D_Loss:0.48531875014305115, G_Loss:8.123337745666504

iterator 2700, D_Loss:0.5115698575973511, G_Loss:8.211873054504395

iterator 2800, D_Loss:0.5052200555801392, G_Loss:7.767848014831543

iterator 2900, D_Loss:0.5318190455436707, G_Loss:7.6942267417907715

iterator 3000, D_Loss:0.49267813563346863, G_Loss:8.288036346435547

iterator 3100, D_Loss:0.48884478211402893, G_Loss:7.465446472167969

iterator 3200, D_Loss:0.5115369558334351, G_Loss:7.77205753326416

iterator 3300, D_Loss:0.5242329835891724, G_Loss:7.649974822998047

iterator 3400, D_Loss:0.5113171935081482, G_Loss:7.539685249328613

iterator 3500, D_Loss:0.5234686136245728, G_Loss:7.669253349304199

iterator 3600, D_Loss:0.506210446357727, G_Loss:7.770451545715332

iterator 3700, D_Loss:0.5163077712059021, G_Loss:7.744399070739746

iterator 3800, D_Loss:0.5233520269393921, G_Loss:8.158980369567871

iterator 3900, D_Loss:0.5267095565795898, G_Loss:7.419564723968506

iterator 4000, D_Loss:0.5268081426620483, G_Loss:7.458311080932617

iterator 4100, D_Loss:0.5136436820030212, G_Loss:7.727964878082275

iterator 4200, D_Loss:0.5127890110015869, G_Loss:8.30318832397461

iterator 4300, D_Loss:0.46434512734413147, G_Loss:7.837118148803711

iterator 4400, D_Loss:0.5147275924682617, G_Loss:7.895223140716553

iterator 4500, D_Loss:0.4900532364845276, G_Loss:8.20089340209961

iterator 4600, D_Loss:0.4523846209049225, G_Loss:7.389404773712158

iterator 4700, D_Loss:0.5116786956787109, G_Loss:8.436600685119629

iterator 4800, D_Loss:0.5273054242134094, G_Loss:7.998052597045898

iterator 4900, D_Loss:0.541577935218811, G_Loss:7.237463474273682

iterator 5000, D_Loss:0.4706287384033203, G_Loss:7.778647422790527

-----------Epoch 2-----------
iterator 100, D_Loss:0.5529163479804993, G_Loss:7.176496982574463

iterator 200, D_Loss:0.5197000503540039, G_Loss:7.01245641708374

iterator 300, D_Loss:0.5498074293136597, G_Loss:6.817769527435303

iterator 400, D_Loss:0.5029688477516174, G_Loss:6.784146308898926

iterator 500, D_Loss:0.5210452079772949, G_Loss:7.071562767028809

iterator 600, D_Loss:0.495383083820343, G_Loss:6.6328654289245605

iterator 700, D_Loss:0.5367727875709534, G_Loss:7.391988754272461

iterator 800, D_Loss:0.5133985877037048, G_Loss:7.048581123352051

iterator 900, D_Loss:0.5574199557304382, G_Loss:7.126091480255127

iterator 1000, D_Loss:0.5161895155906677, G_Loss:7.008196830749512

iterator 1100, D_Loss:0.448085218667984, G_Loss:6.984930038452148

iterator 1200, D_Loss:0.5124799609184265, G_Loss:6.9014573097229

iterator 1300, D_Loss:0.5208932757377625, G_Loss:7.160105228424072

iterator 1400, D_Loss:0.5241290926933289, G_Loss:6.7296977043151855

iterator 1500, D_Loss:0.5337100028991699, G_Loss:6.739051818847656

iterator 1600, D_Loss:0.5534105896949768, G_Loss:7.063358306884766

iterator 1700, D_Loss:0.5500444173812866, G_Loss:7.282772064208984

iterator 1800, D_Loss:0.5700691938400269, G_Loss:6.608813285827637

iterator 1900, D_Loss:0.47989365458488464, G_Loss:6.539736270904541

iterator 2000, D_Loss:0.531478226184845, G_Loss:6.150728225708008

iterator 2100, D_Loss:0.5715910196304321, G_Loss:5.940752029418945

iterator 2200, D_Loss:0.5229001641273499, G_Loss:6.566844463348389

iterator 2300, D_Loss:0.5359102487564087, G_Loss:6.781330108642578

iterator 2400, D_Loss:0.5415664911270142, G_Loss:6.690495491027832

iterator 2500, D_Loss:0.5409517884254456, G_Loss:6.927788734436035

iterator 2600, D_Loss:0.48953181505203247, G_Loss:6.722347259521484

iterator 2700, D_Loss:0.5463536977767944, G_Loss:6.97727108001709

iterator 2800, D_Loss:0.5594735145568848, G_Loss:6.419907093048096

iterator 2900, D_Loss:0.5880938768386841, G_Loss:6.38535737991333

iterator 3000, D_Loss:0.5343545079231262, G_Loss:7.138192176818848

iterator 3100, D_Loss:0.5857537984848022, G_Loss:6.395181179046631

iterator 3200, D_Loss:0.597542941570282, G_Loss:6.741360187530518

iterator 3300, D_Loss:0.5692728757858276, G_Loss:6.201165676116943

iterator 3400, D_Loss:0.6061173677444458, G_Loss:6.257936000823975

iterator 3500, D_Loss:0.5585322976112366, G_Loss:6.1440043449401855

iterator 3600, D_Loss:0.5211708545684814, G_Loss:6.021565914154053

iterator 3700, D_Loss:0.5295363664627075, G_Loss:6.194311618804932

iterator 3800, D_Loss:0.5403135418891907, G_Loss:6.497213840484619

iterator 3900, D_Loss:0.5709052085876465, G_Loss:5.893938064575195

iterator 4000, D_Loss:0.5494110584259033, G_Loss:5.786205291748047

iterator 4100, D_Loss:0.5012750625610352, G_Loss:6.183380603790283

iterator 4200, D_Loss:0.5452349781990051, G_Loss:6.62185525894165

iterator 4300, D_Loss:0.551011323928833, G_Loss:6.368319511413574

iterator 4400, D_Loss:0.5942597985267639, G_Loss:6.032703876495361

iterator 4500, D_Loss:0.5325350165367126, G_Loss:6.201925277709961

iterator 4600, D_Loss:0.49548086524009705, G_Loss:6.0232391357421875

iterator 4700, D_Loss:0.5680996775627136, G_Loss:6.327780246734619

iterator 4800, D_Loss:0.5658814311027527, G_Loss:6.41346549987793

iterator 4900, D_Loss:0.6339834928512573, G_Loss:6.0794782638549805

iterator 5000, D_Loss:0.5903695821762085, G_Loss:5.801743507385254

-----------Epoch 3-----------
iterator 100, D_Loss:0.5440754890441895, G_Loss:6.105229377746582

iterator 200, D_Loss:0.5310271382331848, G_Loss:5.701098442077637

iterator 300, D_Loss:0.5576441287994385, G_Loss:5.600505828857422

iterator 400, D_Loss:0.5328361392021179, G_Loss:5.54920768737793

iterator 500, D_Loss:0.5998943448066711, G_Loss:5.944609642028809

iterator 600, D_Loss:0.5756958723068237, G_Loss:5.293420791625977

iterator 700, D_Loss:0.5098931789398193, G_Loss:6.050668716430664

iterator 800, D_Loss:0.6438215970993042, G_Loss:5.818757057189941

iterator 900, D_Loss:0.594788670539856, G_Loss:5.242156028747559

iterator 1000, D_Loss:0.5820585489273071, G_Loss:5.452600479125977

iterator 1100, D_Loss:0.5818224549293518, G_Loss:5.9226789474487305

iterator 1200, D_Loss:0.5382504463195801, G_Loss:5.618705749511719

iterator 1300, D_Loss:0.522598922252655, G_Loss:5.285749912261963

iterator 1400, D_Loss:0.5556831955909729, G_Loss:5.370383262634277

iterator 1500, D_Loss:0.565005362033844, G_Loss:5.317291736602783

iterator 1600, D_Loss:0.6219373345375061, G_Loss:5.664363384246826

iterator 1700, D_Loss:0.5437891483306885, G_Loss:6.207458019256592

iterator 1800, D_Loss:0.6153398752212524, G_Loss:5.6877946853637695

iterator 1900, D_Loss:0.6062888503074646, G_Loss:5.523879528045654

iterator 2000, D_Loss:0.585851788520813, G_Loss:5.63818883895874

iterator 2100, D_Loss:0.5594239830970764, G_Loss:5.5697174072265625

iterator 2200, D_Loss:0.6290835738182068, G_Loss:5.382917881011963

iterator 2300, D_Loss:0.5723757743835449, G_Loss:5.729629039764404

iterator 2400, D_Loss:0.5941243767738342, G_Loss:5.481626033782959

iterator 2500, D_Loss:0.587314248085022, G_Loss:5.490058898925781

iterator 2600, D_Loss:0.6332595348358154, G_Loss:5.667849540710449

iterator 2700, D_Loss:0.6447001099586487, G_Loss:5.4126667976379395

iterator 2800, D_Loss:0.6027708053588867, G_Loss:5.619914531707764

iterator 2900, D_Loss:0.6496134400367737, G_Loss:5.140288352966309

iterator 3000, D_Loss:0.5875287652015686, G_Loss:5.587329864501953

iterator 3100, D_Loss:0.6494825482368469, G_Loss:5.114274024963379

iterator 3200, D_Loss:0.6114749312400818, G_Loss:5.622941017150879

iterator 3300, D_Loss:0.5792073011398315, G_Loss:5.144735813140869

iterator 3400, D_Loss:0.6133671402931213, G_Loss:5.003033638000488

iterator 3500, D_Loss:0.6089612245559692, G_Loss:5.148160934448242

iterator 3600, D_Loss:0.5998026728630066, G_Loss:5.366744041442871

iterator 3700, D_Loss:0.638670802116394, G_Loss:5.474567413330078

iterator 3800, D_Loss:0.6521894335746765, G_Loss:5.606874942779541

iterator 3900, D_Loss:0.6204639673233032, G_Loss:4.9966959953308105

iterator 4000, D_Loss:0.5858636498451233, G_Loss:4.950079917907715

iterator 4100, D_Loss:0.5699664950370789, G_Loss:5.301426887512207

iterator 4200, D_Loss:0.6282804608345032, G_Loss:5.356215476989746

iterator 4300, D_Loss:0.6050244569778442, G_Loss:5.008730888366699

iterator 4400, D_Loss:0.6085692644119263, G_Loss:5.041714668273926

iterator 4500, D_Loss:0.6164357662200928, G_Loss:5.324009895324707

iterator 4600, D_Loss:0.5130612850189209, G_Loss:5.0404052734375

iterator 4700, D_Loss:0.5868538618087769, G_Loss:4.855767726898193

iterator 4800, D_Loss:0.5720136165618896, G_Loss:5.0404510498046875

iterator 4900, D_Loss:0.5734360218048096, G_Loss:5.127418518066406

iterator 5000, D_Loss:0.5948911309242249, G_Loss:5.562549591064453

-----------Epoch 4-----------
iterator 100, D_Loss:0.581644594669342, G_Loss:4.932372570037842

iterator 200, D_Loss:0.6461396217346191, G_Loss:5.136778354644775

iterator 300, D_Loss:0.5947416424751282, G_Loss:4.8516845703125

iterator 400, D_Loss:0.6248619556427002, G_Loss:4.8615498542785645

iterator 500, D_Loss:0.543218731880188, G_Loss:5.255016803741455

iterator 600, D_Loss:0.5793911218643188, G_Loss:4.8646464347839355

iterator 700, D_Loss:0.5501797795295715, G_Loss:4.9906487464904785

iterator 800, D_Loss:0.6082109212875366, G_Loss:4.929535388946533

iterator 900, D_Loss:0.5856914520263672, G_Loss:4.5469584465026855

iterator 1000, D_Loss:0.5954006910324097, G_Loss:5.154337406158447

iterator 1100, D_Loss:0.5920093059539795, G_Loss:4.8720574378967285

iterator 1200, D_Loss:0.5987548828125, G_Loss:5.034180641174316

iterator 1300, D_Loss:0.5713684558868408, G_Loss:4.843876838684082

iterator 1400, D_Loss:0.59573894739151, G_Loss:5.042729377746582

iterator 1500, D_Loss:0.6128632426261902, G_Loss:4.600226402282715

iterator 1600, D_Loss:0.5606266856193542, G_Loss:4.948194980621338

iterator 1700, D_Loss:0.6090614795684814, G_Loss:5.174916744232178

iterator 1800, D_Loss:0.6059755682945251, G_Loss:4.827348709106445

iterator 1900, D_Loss:0.6023427248001099, G_Loss:4.759500503540039

iterator 2000, D_Loss:0.608167290687561, G_Loss:5.11282205581665

iterator 2100, D_Loss:0.5439050197601318, G_Loss:4.890839576721191

iterator 2200, D_Loss:0.6106773614883423, G_Loss:4.658450603485107

iterator 2300, D_Loss:0.6330181956291199, G_Loss:4.8513078689575195

iterator 2400, D_Loss:0.6184858083724976, G_Loss:4.625317573547363

iterator 2500, D_Loss:0.6190693378448486, G_Loss:4.402710914611816

iterator 2600, D_Loss:0.6162738800048828, G_Loss:5.050353050231934

iterator 2700, D_Loss:0.5708122253417969, G_Loss:5.083321571350098

iterator 2800, D_Loss:0.5536321997642517, G_Loss:4.881345748901367

iterator 2900, D_Loss:0.618592381477356, G_Loss:4.754833221435547

iterator 3000, D_Loss:0.6252263188362122, G_Loss:5.1392292976379395

iterator 3100, D_Loss:0.6121963262557983, G_Loss:5.2123212814331055

iterator 3200, D_Loss:0.6042529940605164, G_Loss:4.7952189445495605

iterator 3300, D_Loss:0.5740805864334106, G_Loss:4.6647629737854

iterator 3400, D_Loss:0.5658437013626099, G_Loss:4.6550469398498535

iterator 3500, D_Loss:0.6151705980300903, G_Loss:4.780216693878174

iterator 3600, D_Loss:0.572860598564148, G_Loss:4.904956817626953

iterator 3700, D_Loss:0.5849814414978027, G_Loss:4.916924476623535

iterator 3800, D_Loss:0.5812909007072449, G_Loss:4.746908187866211

iterator 3900, D_Loss:0.6241158843040466, G_Loss:4.497408390045166

iterator 4000, D_Loss:0.6197596788406372, G_Loss:4.841283321380615

iterator 4100, D_Loss:0.6273248195648193, G_Loss:4.642085075378418

iterator 4200, D_Loss:0.5789274573326111, G_Loss:4.797623157501221

iterator 4300, D_Loss:0.5738451480865479, G_Loss:4.666125297546387

iterator 4400, D_Loss:0.6239962577819824, G_Loss:4.706497669219971

iterator 4500, D_Loss:0.5991100668907166, G_Loss:4.875195503234863

iterator 4600, D_Loss:0.525596022605896, G_Loss:4.849237442016602

iterator 4700, D_Loss:0.5781001448631287, G_Loss:4.522854328155518

iterator 4800, D_Loss:0.7253557443618774, G_Loss:4.4426774978637695

iterator 4900, D_Loss:0.6046196818351746, G_Loss:4.405281066894531

iterator 5000, D_Loss:0.5956926941871643, G_Loss:4.414687156677246

-----------Epoch 5-----------
iterator 100, D_Loss:0.672302782535553, G_Loss:4.547613620758057

iterator 200, D_Loss:0.5671566128730774, G_Loss:4.513246059417725

iterator 300, D_Loss:0.605715811252594, G_Loss:4.195087909698486

iterator 400, D_Loss:0.5867891311645508, G_Loss:4.423877716064453

iterator 500, D_Loss:0.6480631828308105, G_Loss:4.9041266441345215

iterator 600, D_Loss:0.6476708054542542, G_Loss:4.564655303955078

iterator 700, D_Loss:0.6251088976860046, G_Loss:4.290500640869141

iterator 800, D_Loss:0.6107321381568909, G_Loss:4.337783336639404

iterator 900, D_Loss:0.6949222087860107, G_Loss:4.154815196990967

iterator 1000, D_Loss:0.5805974006652832, G_Loss:4.54565954208374

iterator 1100, D_Loss:0.6269235014915466, G_Loss:4.314242362976074

iterator 1200, D_Loss:0.6631847620010376, G_Loss:4.330749034881592

iterator 1300, D_Loss:0.66621333360672, G_Loss:4.413031101226807

iterator 1400, D_Loss:0.6201058030128479, G_Loss:4.391655921936035

iterator 1500, D_Loss:0.5890363454818726, G_Loss:4.584891319274902

iterator 1600, D_Loss:0.594454288482666, G_Loss:4.5459513664245605

iterator 1700, D_Loss:0.5443367958068848, G_Loss:4.762130260467529

iterator 1800, D_Loss:0.6214756965637207, G_Loss:4.170206069946289

iterator 1900, D_Loss:0.6109843254089355, G_Loss:4.12677001953125

iterator 2000, D_Loss:0.6807376146316528, G_Loss:4.048123359680176

iterator 2100, D_Loss:0.6446436643600464, G_Loss:4.315073490142822

iterator 2200, D_Loss:0.6743336915969849, G_Loss:3.958984136581421

iterator 2300, D_Loss:0.7167212963104248, G_Loss:4.365058422088623

iterator 2400, D_Loss:0.6277161836624146, G_Loss:4.2333784103393555

iterator 2500, D_Loss:0.6400965452194214, G_Loss:3.9919965267181396

iterator 2600, D_Loss:0.5954721570014954, G_Loss:4.1106038093566895

iterator 2700, D_Loss:0.6069287061691284, G_Loss:4.076797962188721

iterator 2800, D_Loss:0.6734081506729126, G_Loss:3.6997337341308594

iterator 2900, D_Loss:0.6007578372955322, G_Loss:4.230212688446045

iterator 3000, D_Loss:0.7223265171051025, G_Loss:4.442164897918701

iterator 3100, D_Loss:0.6658016443252563, G_Loss:4.068240642547607

iterator 3200, D_Loss:0.5999195575714111, G_Loss:3.9084553718566895

iterator 3300, D_Loss:0.6026383638381958, G_Loss:4.015674591064453

iterator 3400, D_Loss:0.6741222143173218, G_Loss:3.7556464672088623

iterator 3500, D_Loss:0.5841267108917236, G_Loss:3.8330276012420654

iterator 3600, D_Loss:0.5725717544555664, G_Loss:4.1200361251831055

iterator 3700, D_Loss:0.6286754608154297, G_Loss:3.957009792327881

iterator 3800, D_Loss:0.6297146677970886, G_Loss:4.088293075561523

iterator 3900, D_Loss:0.6658289432525635, G_Loss:3.6559224128723145

iterator 4000, D_Loss:0.7018318176269531, G_Loss:3.897831916809082

iterator 4100, D_Loss:0.6535573601722717, G_Loss:3.8932735919952393

iterator 4200, D_Loss:0.5619796514511108, G_Loss:4.0002923011779785

iterator 4300, D_Loss:0.6191561222076416, G_Loss:4.156708717346191

iterator 4400, D_Loss:0.6385576725006104, G_Loss:4.086513042449951

iterator 4500, D_Loss:0.6508992910385132, G_Loss:3.783568859100342

iterator 4600, D_Loss:0.6297008991241455, G_Loss:3.8447351455688477

iterator 4700, D_Loss:0.6966680288314819, G_Loss:3.9125618934631348

iterator 4800, D_Loss:0.6982248425483704, G_Loss:4.085954189300537

iterator 4900, D_Loss:0.6350993514060974, G_Loss:4.337756633758545

iterator 5000, D_Loss:0.620279848575592, G_Loss:3.885319948196411

-----------Epoch 6-----------
iterator 100, D_Loss:0.6351683139801025, G_Loss:3.9233555793762207

iterator 200, D_Loss:0.6455885171890259, G_Loss:3.9549763202667236

iterator 300, D_Loss:0.6769120693206787, G_Loss:3.9642744064331055

iterator 400, D_Loss:0.6790117025375366, G_Loss:4.07100772857666

iterator 500, D_Loss:0.6803138852119446, G_Loss:3.950906991958618

iterator 600, D_Loss:0.6461222171783447, G_Loss:3.9410552978515625

iterator 700, D_Loss:0.6077835559844971, G_Loss:4.241005897521973

iterator 800, D_Loss:0.6799720525741577, G_Loss:4.033001899719238

iterator 900, D_Loss:0.7334434986114502, G_Loss:3.8328089714050293

iterator 1000, D_Loss:0.6260088086128235, G_Loss:3.857241153717041

iterator 1100, D_Loss:0.6983400583267212, G_Loss:3.825521945953369

iterator 1200, D_Loss:0.7018102407455444, G_Loss:3.811599016189575

iterator 1300, D_Loss:0.7218261957168579, G_Loss:3.7396507263183594

iterator 1400, D_Loss:0.7110607624053955, G_Loss:3.6891872882843018

iterator 1500, D_Loss:0.7939323782920837, G_Loss:3.2983715534210205

iterator 1600, D_Loss:0.7061982154846191, G_Loss:3.7836155891418457

iterator 1700, D_Loss:0.6802546977996826, G_Loss:3.6225059032440186

iterator 1800, D_Loss:0.6412473320960999, G_Loss:3.6745383739471436

iterator 1900, D_Loss:0.6973235607147217, G_Loss:3.6991772651672363

iterator 2000, D_Loss:0.630746603012085, G_Loss:4.1257476806640625

iterator 2100, D_Loss:0.7183035612106323, G_Loss:3.283684253692627

iterator 2200, D_Loss:0.6851992607116699, G_Loss:3.820221424102783

iterator 2300, D_Loss:0.6762793064117432, G_Loss:3.5204005241394043

iterator 2400, D_Loss:0.7212457656860352, G_Loss:3.98445200920105

iterator 2500, D_Loss:0.6665554046630859, G_Loss:3.5960657596588135

iterator 2600, D_Loss:0.7118297815322876, G_Loss:3.7099015712738037

iterator 2700, D_Loss:0.7308527231216431, G_Loss:3.495438575744629

iterator 2800, D_Loss:0.8005759119987488, G_Loss:3.8664615154266357

iterator 2900, D_Loss:0.6600434184074402, G_Loss:3.4432766437530518

iterator 3000, D_Loss:0.699341356754303, G_Loss:3.5369722843170166

iterator 3100, D_Loss:0.711203932762146, G_Loss:3.330195426940918

iterator 3200, D_Loss:0.6980376243591309, G_Loss:3.656290054321289

iterator 3300, D_Loss:0.6472129225730896, G_Loss:3.5607869625091553

iterator 3400, D_Loss:0.7051434516906738, G_Loss:3.6426100730895996

iterator 3500, D_Loss:0.712921142578125, G_Loss:3.248436450958252

iterator 3600, D_Loss:0.6389188766479492, G_Loss:3.852911949157715

iterator 3700, D_Loss:0.6594830751419067, G_Loss:3.5443077087402344

iterator 3800, D_Loss:0.6667627692222595, G_Loss:3.6761655807495117

iterator 3900, D_Loss:0.6372565627098083, G_Loss:3.6292974948883057

iterator 4000, D_Loss:0.6990743279457092, G_Loss:3.4717588424682617

iterator 4100, D_Loss:0.7247434258460999, G_Loss:3.503905773162842

iterator 4200, D_Loss:0.6584042310714722, G_Loss:3.598151922225952

iterator 4300, D_Loss:0.643946647644043, G_Loss:3.7697510719299316

iterator 4400, D_Loss:0.7021380662918091, G_Loss:3.4610228538513184

iterator 4500, D_Loss:0.6698843240737915, G_Loss:3.385039806365967

iterator 4600, D_Loss:0.7463318109512329, G_Loss:3.5272765159606934

iterator 4700, D_Loss:0.7725919485092163, G_Loss:3.451228141784668

iterator 4800, D_Loss:0.6116236448287964, G_Loss:3.260596752166748

iterator 4900, D_Loss:0.7635434865951538, G_Loss:3.4929862022399902

iterator 5000, D_Loss:0.6898990273475647, G_Loss:3.6771318912506104

-----------Epoch 7-----------
iterator 100, D_Loss:0.7074307203292847, G_Loss:3.4015750885009766

iterator 200, D_Loss:0.651201069355011, G_Loss:3.5320208072662354

iterator 300, D_Loss:0.7067332863807678, G_Loss:3.24125075340271

iterator 400, D_Loss:0.7099944949150085, G_Loss:3.5047385692596436

iterator 500, D_Loss:0.7049375772476196, G_Loss:3.808321475982666

iterator 600, D_Loss:0.6845468878746033, G_Loss:3.5637450218200684

iterator 700, D_Loss:0.6593857407569885, G_Loss:3.590425968170166

iterator 800, D_Loss:0.7634174823760986, G_Loss:3.531522274017334

iterator 900, D_Loss:0.636780321598053, G_Loss:3.888805627822876

iterator 1000, D_Loss:0.6654151678085327, G_Loss:3.63704776763916

iterator 1100, D_Loss:0.7411580085754395, G_Loss:3.47908091545105

iterator 1200, D_Loss:0.6499922871589661, G_Loss:3.4942171573638916

iterator 1300, D_Loss:0.7357535362243652, G_Loss:3.3913862705230713

iterator 1400, D_Loss:0.6566616892814636, G_Loss:3.5803797245025635

iterator 1500, D_Loss:0.6359534859657288, G_Loss:3.606895923614502

iterator 1600, D_Loss:0.6752486824989319, G_Loss:3.6723129749298096

iterator 1700, D_Loss:0.7513454556465149, G_Loss:3.324416160583496

iterator 1800, D_Loss:0.679863691329956, G_Loss:3.6843461990356445

iterator 1900, D_Loss:0.7178397178649902, G_Loss:3.2362890243530273

iterator 2000, D_Loss:0.7336692810058594, G_Loss:3.50055193901062

iterator 2100, D_Loss:0.6629118919372559, G_Loss:3.9300804138183594

iterator 2200, D_Loss:0.7155992388725281, G_Loss:3.4777400493621826

iterator 2300, D_Loss:0.6491526961326599, G_Loss:3.781780958175659

iterator 2400, D_Loss:0.7198231816291809, G_Loss:3.585819721221924

iterator 2500, D_Loss:0.6614915728569031, G_Loss:3.652003288269043

iterator 2600, D_Loss:0.6304693222045898, G_Loss:3.599944591522217

iterator 2700, D_Loss:0.7721103429794312, G_Loss:3.5946602821350098

iterator 2800, D_Loss:0.6527090668678284, G_Loss:3.5948073863983154

iterator 2900, D_Loss:0.6299728155136108, G_Loss:3.539581060409546

iterator 3000, D_Loss:0.6423556208610535, G_Loss:3.7999167442321777

iterator 3100, D_Loss:0.6786337494850159, G_Loss:3.714179277420044

iterator 3200, D_Loss:0.670791506767273, G_Loss:3.806128978729248

iterator 3300, D_Loss:0.68578040599823, G_Loss:3.165395736694336

iterator 3400, D_Loss:0.6645479202270508, G_Loss:3.555136203765869

iterator 3500, D_Loss:0.744831919670105, G_Loss:3.441859722137451

iterator 3600, D_Loss:0.7017310857772827, G_Loss:3.4042420387268066

iterator 3700, D_Loss:0.7182615995407104, G_Loss:3.2330737113952637

iterator 3800, D_Loss:0.7019937038421631, G_Loss:3.432905435562134

iterator 3900, D_Loss:0.6210689544677734, G_Loss:3.5542256832122803

iterator 4000, D_Loss:0.6526416540145874, G_Loss:3.523719310760498

iterator 4100, D_Loss:0.6647369861602783, G_Loss:3.538754940032959

iterator 4200, D_Loss:0.626564085483551, G_Loss:3.9437150955200195

iterator 4300, D_Loss:0.6675807237625122, G_Loss:3.576404571533203

iterator 4400, D_Loss:0.7205525040626526, G_Loss:3.4754021167755127

iterator 4500, D_Loss:0.7643593549728394, G_Loss:3.2819297313690186

iterator 4600, D_Loss:0.7055189609527588, G_Loss:3.506314277648926

iterator 4700, D_Loss:0.7997349500656128, G_Loss:3.2706756591796875

iterator 4800, D_Loss:0.687177300453186, G_Loss:3.640651226043701

iterator 4900, D_Loss:0.6307684183120728, G_Loss:3.737468957901001

iterator 5000, D_Loss:0.7091567516326904, G_Loss:3.4457035064697266

-----------Epoch 8-----------
iterator 100, D_Loss:0.6363210678100586, G_Loss:3.4837398529052734

iterator 200, D_Loss:0.6834098100662231, G_Loss:3.3412699699401855

iterator 300, D_Loss:0.6976637244224548, G_Loss:3.3829843997955322

iterator 400, D_Loss:0.6485248804092407, G_Loss:3.625282049179077

iterator 500, D_Loss:0.7046511769294739, G_Loss:3.4971415996551514

iterator 600, D_Loss:0.620942234992981, G_Loss:3.6886069774627686

iterator 700, D_Loss:0.6915749311447144, G_Loss:3.4521141052246094

iterator 800, D_Loss:0.7497077584266663, G_Loss:3.5895466804504395

iterator 900, D_Loss:0.6996904611587524, G_Loss:3.8383283615112305

iterator 1000, D_Loss:0.6476940512657166, G_Loss:3.6787455081939697

iterator 1100, D_Loss:0.706283688545227, G_Loss:3.542172431945801

iterator 1200, D_Loss:0.6540642380714417, G_Loss:3.8452165126800537

iterator 1300, D_Loss:0.6450382471084595, G_Loss:3.7268354892730713

iterator 1400, D_Loss:0.6598881483078003, G_Loss:3.6712353229522705

iterator 1500, D_Loss:0.6767248511314392, G_Loss:3.77207612991333

iterator 1600, D_Loss:0.6810557842254639, G_Loss:3.465576648712158

iterator 1700, D_Loss:0.7187490463256836, G_Loss:3.3825905323028564

iterator 1800, D_Loss:0.8298195600509644, G_Loss:3.1879327297210693

iterator 1900, D_Loss:0.681725025177002, G_Loss:3.7475380897521973

iterator 2000, D_Loss:0.719235897064209, G_Loss:3.499821662902832

iterator 2100, D_Loss:0.7764486074447632, G_Loss:3.1707444190979004

iterator 2200, D_Loss:0.6786077618598938, G_Loss:3.1539320945739746

iterator 2300, D_Loss:0.742936909198761, G_Loss:3.274381399154663

iterator 2400, D_Loss:0.7040128707885742, G_Loss:3.2369911670684814

iterator 2500, D_Loss:0.7077541351318359, G_Loss:3.1752896308898926

iterator 2600, D_Loss:0.6837396621704102, G_Loss:3.5847222805023193

iterator 2700, D_Loss:0.7370038032531738, G_Loss:3.333085775375366

iterator 2800, D_Loss:0.6752382516860962, G_Loss:3.6037352085113525

iterator 2900, D_Loss:0.6964235305786133, G_Loss:3.273071527481079

iterator 3000, D_Loss:0.6582008004188538, G_Loss:3.830362558364868

iterator 3100, D_Loss:0.6534587740898132, G_Loss:3.5895791053771973

iterator 3200, D_Loss:0.687279224395752, G_Loss:3.5554511547088623

iterator 3300, D_Loss:0.6672214269638062, G_Loss:3.0731072425842285

iterator 3400, D_Loss:0.7350391149520874, G_Loss:3.2703912258148193

iterator 3500, D_Loss:0.7096585035324097, G_Loss:3.4261536598205566

iterator 3600, D_Loss:0.649751603603363, G_Loss:3.4470183849334717

iterator 3700, D_Loss:0.6646556258201599, G_Loss:3.9626224040985107

iterator 3800, D_Loss:0.683311939239502, G_Loss:3.298748731613159

iterator 3900, D_Loss:0.7195379734039307, G_Loss:3.6107993125915527

iterator 4000, D_Loss:0.7176786661148071, G_Loss:3.4056365489959717

iterator 4100, D_Loss:0.733555793762207, G_Loss:3.3733317852020264

iterator 4200, D_Loss:0.7358754873275757, G_Loss:3.154081344604492

iterator 4300, D_Loss:0.7175217270851135, G_Loss:3.271289348602295

iterator 4400, D_Loss:0.7146486043930054, G_Loss:3.408379316329956

iterator 4500, D_Loss:0.7250650525093079, G_Loss:3.3072454929351807

iterator 4600, D_Loss:0.71390700340271, G_Loss:3.607083320617676

iterator 4700, D_Loss:0.7102968096733093, G_Loss:3.517416477203369

iterator 4800, D_Loss:0.7187104225158691, G_Loss:3.348964214324951

iterator 4900, D_Loss:0.825832724571228, G_Loss:2.98119854927063

iterator 5000, D_Loss:0.7389175891876221, G_Loss:3.138132333755493

-----------Epoch 9-----------
iterator 100, D_Loss:0.7647366523742676, G_Loss:3.1267037391662598

iterator 200, D_Loss:0.7611221671104431, G_Loss:3.1530323028564453

iterator 300, D_Loss:0.6998194456100464, G_Loss:3.2875194549560547

iterator 400, D_Loss:0.7460154891014099, G_Loss:3.081367254257202

iterator 500, D_Loss:0.6443588733673096, G_Loss:3.213193416595459

iterator 600, D_Loss:0.6998211145401001, G_Loss:3.2432782649993896

iterator 700, D_Loss:0.7502572536468506, G_Loss:3.144454002380371

iterator 800, D_Loss:0.7011193037033081, G_Loss:3.2854220867156982

iterator 900, D_Loss:0.7432346343994141, G_Loss:3.287050485610962

iterator 1000, D_Loss:0.7708202600479126, G_Loss:3.252774715423584

iterator 1100, D_Loss:0.6821736097335815, G_Loss:3.189755439758301

iterator 1200, D_Loss:0.7939074635505676, G_Loss:3.1852457523345947

iterator 1300, D_Loss:0.7294065952301025, G_Loss:3.379777431488037

iterator 1400, D_Loss:0.707887589931488, G_Loss:3.3750765323638916

iterator 1500, D_Loss:0.7401046752929688, G_Loss:3.3649377822875977

iterator 1600, D_Loss:0.7837705612182617, G_Loss:3.138978958129883

iterator 1700, D_Loss:0.7686154842376709, G_Loss:3.1890242099761963

iterator 1800, D_Loss:0.7704989314079285, G_Loss:3.1377618312835693

iterator 1900, D_Loss:0.7352956533432007, G_Loss:3.2999699115753174

iterator 2000, D_Loss:0.7647237777709961, G_Loss:2.9658360481262207

iterator 2100, D_Loss:0.7084414958953857, G_Loss:3.2095205783843994

iterator 2200, D_Loss:0.6744006872177124, G_Loss:3.0762546062469482

iterator 2300, D_Loss:0.7328560948371887, G_Loss:3.109431028366089

iterator 2400, D_Loss:0.6819125413894653, G_Loss:3.1068787574768066

iterator 2500, D_Loss:0.7811682224273682, G_Loss:3.1007330417633057

iterator 2600, D_Loss:0.6783481240272522, G_Loss:3.5352399349212646

iterator 2700, D_Loss:0.7687027454376221, G_Loss:3.1438629627227783

iterator 2800, D_Loss:0.68954998254776, G_Loss:3.352576494216919

iterator 2900, D_Loss:0.8208733797073364, G_Loss:3.2705421447753906

iterator 3000, D_Loss:0.7653363943099976, G_Loss:3.337631940841675

iterator 3100, D_Loss:0.7528120279312134, G_Loss:3.0333878993988037

iterator 3200, D_Loss:0.8105376958847046, G_Loss:3.382352828979492

iterator 3300, D_Loss:0.7468390464782715, G_Loss:3.3289527893066406

iterator 3400, D_Loss:0.7732013463973999, G_Loss:3.1386547088623047

iterator 3500, D_Loss:0.7372427582740784, G_Loss:3.1976583003997803

iterator 3600, D_Loss:0.7374512553215027, G_Loss:3.1387722492218018

iterator 3700, D_Loss:0.759615421295166, G_Loss:2.874513626098633

iterator 3800, D_Loss:0.7296735048294067, G_Loss:3.012291669845581

iterator 3900, D_Loss:0.7674182057380676, G_Loss:3.1224141120910645

iterator 4000, D_Loss:0.7006007432937622, G_Loss:2.8614675998687744

iterator 4100, D_Loss:0.746390163898468, G_Loss:3.240719795227051

iterator 4200, D_Loss:0.8201117515563965, G_Loss:3.2315642833709717

iterator 4300, D_Loss:0.7213492393493652, G_Loss:3.1227965354919434

iterator 4400, D_Loss:0.7780145406723022, G_Loss:3.639702081680298

iterator 4500, D_Loss:0.7225736379623413, G_Loss:3.2709760665893555

iterator 4600, D_Loss:0.6808555126190186, G_Loss:3.5757384300231934

iterator 4700, D_Loss:0.767371416091919, G_Loss:3.2666594982147217

iterator 4800, D_Loss:0.6912699937820435, G_Loss:2.9014453887939453

iterator 4900, D_Loss:0.6465988159179688, G_Loss:3.109971761703491

iterator 5000, D_Loss:0.681726336479187, G_Loss:3.371866464614868

train row : 30148
sample row: 30148
VGAN_generator(
  (input): Linear(in_features=128, out_features=100, bias=True)
  (inputbn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=100, out_features=100, bias=True)
  (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=100, out_features=45, bias=True)
  (outputbn): BatchNorm1d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=45, out_features=200, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (fc1): Linear(in_features=200, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=200, bias=True)
  (output): Linear(in_features=200, out_features=1, bias=True)
)
(0, False, 45)
-----------Epoch 0-----------
iterator 100, D_Loss:1.1730294227600098, G_Loss:7.698119163513184

iterator 200, D_Loss:0.5568476915359497, G_Loss:9.247259140014648

iterator 300, D_Loss:0.5479323267936707, G_Loss:10.258594512939453

iterator 400, D_Loss:0.514741837978363, G_Loss:11.001577377319336

iterator 500, D_Loss:0.5864728093147278, G_Loss:11.514263153076172

iterator 600, D_Loss:0.5251445770263672, G_Loss:9.483644485473633

iterator 700, D_Loss:0.5125007033348083, G_Loss:10.635756492614746

iterator 800, D_Loss:0.543289840221405, G_Loss:10.774700164794922

iterator 900, D_Loss:0.5525014996528625, G_Loss:10.13792896270752

iterator 1000, D_Loss:0.49305954575538635, G_Loss:11.404098510742188

iterator 1100, D_Loss:0.5074543356895447, G_Loss:11.463297843933105

iterator 1200, D_Loss:0.46872806549072266, G_Loss:10.93807601928711

iterator 1300, D_Loss:0.5172122120857239, G_Loss:10.828243255615234

iterator 1400, D_Loss:0.510334849357605, G_Loss:11.932140350341797

iterator 1500, D_Loss:0.5566108822822571, G_Loss:10.854909896850586

iterator 1600, D_Loss:0.48062604665756226, G_Loss:11.990165710449219

iterator 1700, D_Loss:0.4689410328865051, G_Loss:10.913766860961914

iterator 1800, D_Loss:0.49125123023986816, G_Loss:10.917381286621094

iterator 1900, D_Loss:0.47635766863822937, G_Loss:10.471328735351562

iterator 2000, D_Loss:0.4817648231983185, G_Loss:11.805208206176758

iterator 2100, D_Loss:0.49075672030448914, G_Loss:10.805379867553711

iterator 2200, D_Loss:0.45998477935791016, G_Loss:10.537553787231445

iterator 2300, D_Loss:0.45999807119369507, G_Loss:11.326130867004395

iterator 2400, D_Loss:0.46125712990760803, G_Loss:11.031198501586914

iterator 2500, D_Loss:0.5314860343933105, G_Loss:12.127738952636719

iterator 2600, D_Loss:0.5129994750022888, G_Loss:10.775168418884277

iterator 2700, D_Loss:0.5039255619049072, G_Loss:10.766233444213867

iterator 2800, D_Loss:0.48524394631385803, G_Loss:10.242501258850098

iterator 2900, D_Loss:0.4366167485713959, G_Loss:9.91309642791748

iterator 3000, D_Loss:0.48690032958984375, G_Loss:10.49941349029541

iterator 3100, D_Loss:0.46100112795829773, G_Loss:10.094286918640137

iterator 3200, D_Loss:0.47126972675323486, G_Loss:11.241085052490234

iterator 3300, D_Loss:0.45972055196762085, G_Loss:10.486454010009766

iterator 3400, D_Loss:0.4904995262622833, G_Loss:10.778726577758789

iterator 3500, D_Loss:0.4631839692592621, G_Loss:10.824714660644531

iterator 3600, D_Loss:0.4831027686595917, G_Loss:10.2802152633667

iterator 3700, D_Loss:0.5192577838897705, G_Loss:9.665473937988281

iterator 3800, D_Loss:0.4519636034965515, G_Loss:11.265783309936523

iterator 3900, D_Loss:0.475754052400589, G_Loss:10.281740188598633

iterator 4000, D_Loss:0.4592044949531555, G_Loss:9.523456573486328

iterator 4100, D_Loss:0.46785417199134827, G_Loss:11.430032730102539

iterator 4200, D_Loss:0.4389605224132538, G_Loss:9.304327011108398

iterator 4300, D_Loss:0.5049046277999878, G_Loss:10.476316452026367

iterator 4400, D_Loss:0.4933273196220398, G_Loss:10.185846328735352

iterator 4500, D_Loss:0.4753188490867615, G_Loss:9.048219680786133

iterator 4600, D_Loss:0.4514593482017517, G_Loss:9.736285209655762

iterator 4700, D_Loss:0.49379727244377136, G_Loss:9.020611763000488

iterator 4800, D_Loss:0.4268031418323517, G_Loss:9.152050018310547

iterator 4900, D_Loss:0.4527919888496399, G_Loss:10.027534484863281

iterator 5000, D_Loss:0.4527936279773712, G_Loss:9.065431594848633

-----------Epoch 1-----------
iterator 100, D_Loss:0.4521556794643402, G_Loss:9.605098724365234

iterator 200, D_Loss:0.43914517760276794, G_Loss:9.574445724487305

iterator 300, D_Loss:0.44976475834846497, G_Loss:9.206942558288574

iterator 400, D_Loss:0.435934454202652, G_Loss:9.479920387268066

iterator 500, D_Loss:0.4999179542064667, G_Loss:9.768491744995117

iterator 600, D_Loss:0.49848341941833496, G_Loss:8.430841445922852

iterator 700, D_Loss:0.45352691411972046, G_Loss:8.852991104125977

iterator 800, D_Loss:0.4676016867160797, G_Loss:8.639097213745117

iterator 900, D_Loss:0.4787989556789398, G_Loss:8.299042701721191

iterator 1000, D_Loss:0.4611620306968689, G_Loss:8.932408332824707

iterator 1100, D_Loss:0.42802196741104126, G_Loss:9.173550605773926

iterator 1200, D_Loss:0.5325394868850708, G_Loss:8.479570388793945

iterator 1300, D_Loss:0.4836631119251251, G_Loss:7.795699596405029

iterator 1400, D_Loss:0.5115294456481934, G_Loss:8.103248596191406

iterator 1500, D_Loss:0.540375292301178, G_Loss:8.447693824768066

iterator 1600, D_Loss:0.5135688781738281, G_Loss:8.870243072509766

iterator 1700, D_Loss:0.4514194428920746, G_Loss:8.006778717041016

iterator 1800, D_Loss:0.5229274034500122, G_Loss:8.232168197631836

iterator 1900, D_Loss:0.48091402649879456, G_Loss:7.732810974121094

iterator 2000, D_Loss:0.4849160611629486, G_Loss:7.9409894943237305

iterator 2100, D_Loss:0.5351276397705078, G_Loss:7.465847969055176

iterator 2200, D_Loss:0.4927152097225189, G_Loss:7.419218063354492

iterator 2300, D_Loss:0.490608811378479, G_Loss:7.716902732849121

iterator 2400, D_Loss:0.4893362522125244, G_Loss:8.07610034942627

iterator 2500, D_Loss:0.4986737370491028, G_Loss:8.986878395080566

iterator 2600, D_Loss:0.509918212890625, G_Loss:7.83001708984375

iterator 2700, D_Loss:0.5102119445800781, G_Loss:7.614062786102295

iterator 2800, D_Loss:0.48878100514411926, G_Loss:7.599427700042725

iterator 2900, D_Loss:0.5209301710128784, G_Loss:7.331418514251709

iterator 3000, D_Loss:0.47833359241485596, G_Loss:7.816598892211914

iterator 3100, D_Loss:0.5221682786941528, G_Loss:7.529665470123291

iterator 3200, D_Loss:0.5792589783668518, G_Loss:8.1119384765625

iterator 3300, D_Loss:0.49351948499679565, G_Loss:7.447158336639404

iterator 3400, D_Loss:0.5088881254196167, G_Loss:7.686275005340576

iterator 3500, D_Loss:0.46380648016929626, G_Loss:7.420427322387695

iterator 3600, D_Loss:0.4673168659210205, G_Loss:8.071887969970703

iterator 3700, D_Loss:0.5269404053688049, G_Loss:7.187440872192383

iterator 3800, D_Loss:0.4970927834510803, G_Loss:7.890379905700684

iterator 3900, D_Loss:0.5379990339279175, G_Loss:7.4847636222839355

iterator 4000, D_Loss:0.51639723777771, G_Loss:7.373395919799805

iterator 4100, D_Loss:0.5344500541687012, G_Loss:8.643295288085938

iterator 4200, D_Loss:0.5077683925628662, G_Loss:6.869053840637207

iterator 4300, D_Loss:0.503832221031189, G_Loss:7.635510444641113

iterator 4400, D_Loss:0.48715177178382874, G_Loss:7.38556432723999

iterator 4500, D_Loss:0.5202583074569702, G_Loss:6.803852558135986

iterator 4600, D_Loss:0.4115469455718994, G_Loss:7.275612831115723

iterator 4700, D_Loss:0.5079074501991272, G_Loss:7.176656723022461

iterator 4800, D_Loss:0.5194042921066284, G_Loss:7.065006256103516

iterator 4900, D_Loss:0.5210298299789429, G_Loss:7.639506816864014

iterator 5000, D_Loss:0.5493369102478027, G_Loss:6.8348283767700195

-----------Epoch 2-----------
iterator 100, D_Loss:0.5364792943000793, G_Loss:7.211704254150391

iterator 200, D_Loss:0.5156340599060059, G_Loss:7.062445640563965

iterator 300, D_Loss:0.6265560984611511, G_Loss:6.829920768737793

iterator 400, D_Loss:0.4363235831260681, G_Loss:6.959247589111328

iterator 500, D_Loss:0.5581986904144287, G_Loss:7.233278751373291

iterator 600, D_Loss:0.5385189056396484, G_Loss:6.754291534423828

iterator 700, D_Loss:0.5354142189025879, G_Loss:6.282352447509766

iterator 800, D_Loss:0.477946013212204, G_Loss:6.3196210861206055

iterator 900, D_Loss:0.5016805529594421, G_Loss:6.498867988586426

iterator 1000, D_Loss:0.5312303900718689, G_Loss:6.804361343383789

iterator 1100, D_Loss:0.49963271617889404, G_Loss:7.027388572692871

iterator 1200, D_Loss:0.5162805914878845, G_Loss:6.446920871734619

iterator 1300, D_Loss:0.5641945004463196, G_Loss:6.4766716957092285

iterator 1400, D_Loss:0.5193709135055542, G_Loss:6.380796909332275

iterator 1500, D_Loss:0.5621676445007324, G_Loss:6.301530838012695

iterator 1600, D_Loss:0.5498471856117249, G_Loss:6.6537580490112305

iterator 1700, D_Loss:0.5329916477203369, G_Loss:6.596576690673828

iterator 1800, D_Loss:0.48166748881340027, G_Loss:6.506496429443359

iterator 1900, D_Loss:0.5493913888931274, G_Loss:6.479222297668457

iterator 2000, D_Loss:0.5753189325332642, G_Loss:6.550933837890625

iterator 2100, D_Loss:0.5690484642982483, G_Loss:6.02000093460083

iterator 2200, D_Loss:0.45129281282424927, G_Loss:6.436208248138428

iterator 2300, D_Loss:0.49056920409202576, G_Loss:6.121821880340576

iterator 2400, D_Loss:0.4668130576610565, G_Loss:6.422263145446777

iterator 2500, D_Loss:0.6034627556800842, G_Loss:6.97991943359375

iterator 2600, D_Loss:0.48990947008132935, G_Loss:6.82729434967041

iterator 2700, D_Loss:0.5754674077033997, G_Loss:6.390408992767334

iterator 2800, D_Loss:0.5266717076301575, G_Loss:6.148109436035156

iterator 2900, D_Loss:0.49281972646713257, G_Loss:6.048585891723633

iterator 3000, D_Loss:0.5267376899719238, G_Loss:6.416128158569336

iterator 3100, D_Loss:0.49269378185272217, G_Loss:5.756100177764893

iterator 3200, D_Loss:0.5444918274879456, G_Loss:6.316473484039307

iterator 3300, D_Loss:0.528565526008606, G_Loss:6.238674163818359

iterator 3400, D_Loss:0.5558007955551147, G_Loss:6.516617298126221

iterator 3500, D_Loss:0.568100094795227, G_Loss:6.049246788024902

iterator 3600, D_Loss:0.4310428500175476, G_Loss:7.252997398376465

iterator 3700, D_Loss:0.5341178178787231, G_Loss:5.824956893920898

iterator 3800, D_Loss:0.5754680037498474, G_Loss:6.389277458190918

iterator 3900, D_Loss:0.5536512136459351, G_Loss:6.535390853881836

iterator 4000, D_Loss:0.5325903296470642, G_Loss:6.034278869628906

iterator 4100, D_Loss:0.564631998538971, G_Loss:6.532073020935059

iterator 4200, D_Loss:0.590480387210846, G_Loss:5.539966583251953

iterator 4300, D_Loss:0.5434777140617371, G_Loss:6.163516998291016

iterator 4400, D_Loss:0.6344155669212341, G_Loss:6.703089714050293

iterator 4500, D_Loss:0.5548886656761169, G_Loss:5.892323970794678

iterator 4600, D_Loss:0.5592849254608154, G_Loss:6.477529525756836

iterator 4700, D_Loss:0.5983471870422363, G_Loss:5.962676048278809

iterator 4800, D_Loss:0.48299989104270935, G_Loss:6.003034591674805

iterator 4900, D_Loss:0.5267825126647949, G_Loss:6.063835144042969

iterator 5000, D_Loss:0.4871651530265808, G_Loss:5.775572776794434

-----------Epoch 3-----------
iterator 100, D_Loss:0.5533703565597534, G_Loss:6.367720127105713

iterator 200, D_Loss:0.5545414090156555, G_Loss:6.4811224937438965

iterator 300, D_Loss:0.5644642114639282, G_Loss:5.901103973388672

iterator 400, D_Loss:0.5735102891921997, G_Loss:6.09140157699585

iterator 500, D_Loss:0.5732651948928833, G_Loss:5.562162399291992

iterator 600, D_Loss:0.5499438643455505, G_Loss:5.622140884399414

iterator 700, D_Loss:0.5307149887084961, G_Loss:6.095926284790039

iterator 800, D_Loss:0.5556766390800476, G_Loss:5.775135040283203

iterator 900, D_Loss:0.5330070853233337, G_Loss:5.7060322761535645

iterator 1000, D_Loss:0.5605238676071167, G_Loss:6.263129711151123

iterator 1100, D_Loss:0.547288179397583, G_Loss:6.103975772857666

iterator 1200, D_Loss:0.5099741220474243, G_Loss:5.8398356437683105

iterator 1300, D_Loss:0.5601344704627991, G_Loss:5.764011383056641

iterator 1400, D_Loss:0.5256664156913757, G_Loss:5.638478755950928

iterator 1500, D_Loss:0.46798965334892273, G_Loss:5.692322254180908

iterator 1600, D_Loss:0.539676308631897, G_Loss:5.880905628204346

iterator 1700, D_Loss:0.5347902178764343, G_Loss:5.451764106750488

iterator 1800, D_Loss:0.5377925634384155, G_Loss:6.046532154083252

iterator 1900, D_Loss:0.5467994809150696, G_Loss:5.895938873291016

iterator 2000, D_Loss:0.592414379119873, G_Loss:6.035775184631348

iterator 2100, D_Loss:0.5458847284317017, G_Loss:5.5724077224731445

iterator 2200, D_Loss:0.6060500741004944, G_Loss:5.230828285217285

iterator 2300, D_Loss:0.620082676410675, G_Loss:5.612403392791748

iterator 2400, D_Loss:0.5759825110435486, G_Loss:5.370067596435547

iterator 2500, D_Loss:0.6137375831604004, G_Loss:5.893158912658691

iterator 2600, D_Loss:0.6122631430625916, G_Loss:5.648825645446777

iterator 2700, D_Loss:0.5339335203170776, G_Loss:5.518026828765869

iterator 2800, D_Loss:0.5454934239387512, G_Loss:5.507105827331543

iterator 2900, D_Loss:0.5110869407653809, G_Loss:5.647008895874023

iterator 3000, D_Loss:0.5955308675765991, G_Loss:5.568121910095215

iterator 3100, D_Loss:0.5656134486198425, G_Loss:5.832446098327637

iterator 3200, D_Loss:0.509075939655304, G_Loss:5.895089626312256

iterator 3300, D_Loss:0.5477654337882996, G_Loss:6.136941432952881

iterator 3400, D_Loss:0.549695611000061, G_Loss:6.209060192108154

iterator 3500, D_Loss:0.5678004622459412, G_Loss:5.66405725479126

iterator 3600, D_Loss:0.4684193730354309, G_Loss:5.861904144287109

iterator 3700, D_Loss:0.5858705639839172, G_Loss:5.033628940582275

iterator 3800, D_Loss:0.5348195433616638, G_Loss:6.0791239738464355

iterator 3900, D_Loss:0.5482081770896912, G_Loss:5.9616193771362305

iterator 4000, D_Loss:0.5439181327819824, G_Loss:5.467691898345947

iterator 4100, D_Loss:0.5460174679756165, G_Loss:6.535280704498291

iterator 4200, D_Loss:0.5189805030822754, G_Loss:5.561077117919922

iterator 4300, D_Loss:0.5782945156097412, G_Loss:6.210906028747559

iterator 4400, D_Loss:0.5349816679954529, G_Loss:6.263598918914795

iterator 4500, D_Loss:0.6340879201889038, G_Loss:5.524526119232178

iterator 4600, D_Loss:0.6422145962715149, G_Loss:5.692391395568848

iterator 4700, D_Loss:0.573974072933197, G_Loss:5.395985126495361

iterator 4800, D_Loss:0.5216184258460999, G_Loss:5.661952495574951

iterator 4900, D_Loss:0.5368818044662476, G_Loss:5.863321304321289

iterator 5000, D_Loss:0.5040026307106018, G_Loss:5.482919692993164

-----------Epoch 4-----------
iterator 100, D_Loss:0.5146010518074036, G_Loss:5.583127021789551

iterator 200, D_Loss:0.5217339992523193, G_Loss:5.343905925750732

iterator 300, D_Loss:0.6070412993431091, G_Loss:5.612420082092285

iterator 400, D_Loss:0.6681774854660034, G_Loss:5.783507823944092

iterator 500, D_Loss:0.5638024806976318, G_Loss:5.917828559875488

iterator 600, D_Loss:0.5515173077583313, G_Loss:5.316225528717041

iterator 700, D_Loss:0.5711029171943665, G_Loss:5.6792778968811035

iterator 800, D_Loss:0.6409172415733337, G_Loss:5.161649703979492

iterator 900, D_Loss:0.5980284810066223, G_Loss:5.637441635131836

iterator 1000, D_Loss:0.4837791323661804, G_Loss:5.527919292449951

iterator 1100, D_Loss:0.515744149684906, G_Loss:5.787023067474365

iterator 1200, D_Loss:0.5553808808326721, G_Loss:5.409672260284424

iterator 1300, D_Loss:0.555465579032898, G_Loss:5.230257987976074

iterator 1400, D_Loss:0.5946840047836304, G_Loss:5.61431360244751

iterator 1500, D_Loss:0.5460975170135498, G_Loss:5.318361759185791

iterator 1600, D_Loss:0.6112279295921326, G_Loss:4.874826908111572

iterator 1700, D_Loss:0.5501645803451538, G_Loss:5.651412487030029

iterator 1800, D_Loss:0.5785515308380127, G_Loss:5.183801651000977

iterator 1900, D_Loss:0.58189857006073, G_Loss:4.815086841583252

iterator 2000, D_Loss:0.5550853610038757, G_Loss:5.355983257293701

iterator 2100, D_Loss:0.5663150548934937, G_Loss:5.079983234405518

iterator 2200, D_Loss:0.559396505355835, G_Loss:5.44197940826416

iterator 2300, D_Loss:0.5812283754348755, G_Loss:5.249772071838379

iterator 2400, D_Loss:0.5542401671409607, G_Loss:4.837450981140137

iterator 2500, D_Loss:0.5552722811698914, G_Loss:5.68705415725708

iterator 2600, D_Loss:0.5597823858261108, G_Loss:5.307003974914551

iterator 2700, D_Loss:0.6160814166069031, G_Loss:4.923986911773682

iterator 2800, D_Loss:0.5257877707481384, G_Loss:4.8624114990234375

iterator 2900, D_Loss:0.5087072253227234, G_Loss:4.948038101196289

iterator 3000, D_Loss:0.5661798119544983, G_Loss:5.11260986328125

iterator 3100, D_Loss:0.5547499060630798, G_Loss:5.740886688232422

iterator 3200, D_Loss:0.5509968996047974, G_Loss:5.1817827224731445

iterator 3300, D_Loss:0.5387428998947144, G_Loss:5.265166282653809

iterator 3400, D_Loss:0.5629516839981079, G_Loss:5.155019760131836

iterator 3500, D_Loss:0.5933626890182495, G_Loss:4.511667728424072

iterator 3600, D_Loss:0.5993770360946655, G_Loss:5.64644718170166

iterator 3700, D_Loss:0.5727396011352539, G_Loss:5.141762733459473

iterator 3800, D_Loss:0.5963380932807922, G_Loss:5.464138507843018

iterator 3900, D_Loss:0.6147528886795044, G_Loss:5.546914577484131

iterator 4000, D_Loss:0.5952880382537842, G_Loss:4.989713668823242

iterator 4100, D_Loss:0.5662192702293396, G_Loss:5.55450963973999

iterator 4200, D_Loss:0.5447382926940918, G_Loss:4.613044261932373

iterator 4300, D_Loss:0.6131253242492676, G_Loss:4.988061904907227

iterator 4400, D_Loss:0.5218289494514465, G_Loss:5.147738933563232

iterator 4500, D_Loss:0.6557855606079102, G_Loss:4.673953056335449

iterator 4600, D_Loss:0.4952683448791504, G_Loss:5.275343418121338

iterator 4700, D_Loss:0.5302241444587708, G_Loss:5.422701358795166

iterator 4800, D_Loss:0.5758064985275269, G_Loss:5.027009963989258

iterator 4900, D_Loss:0.596340537071228, G_Loss:5.223041534423828

iterator 5000, D_Loss:0.5807868838310242, G_Loss:5.159139156341553

-----------Epoch 5-----------
iterator 100, D_Loss:0.5553737282752991, G_Loss:5.096174716949463

iterator 200, D_Loss:0.5601673126220703, G_Loss:5.080596923828125

iterator 300, D_Loss:0.5793455839157104, G_Loss:5.310039520263672

iterator 400, D_Loss:0.49531492590904236, G_Loss:5.03178071975708

iterator 500, D_Loss:0.6402110457420349, G_Loss:4.4608869552612305

iterator 600, D_Loss:0.5314971804618835, G_Loss:4.927975177764893

iterator 700, D_Loss:0.599139392375946, G_Loss:4.850488662719727

iterator 800, D_Loss:0.5494421720504761, G_Loss:4.582735538482666

iterator 900, D_Loss:0.5504590272903442, G_Loss:4.66566801071167

iterator 1000, D_Loss:0.546006977558136, G_Loss:4.51003360748291

iterator 1100, D_Loss:0.530750036239624, G_Loss:5.344003677368164

iterator 1200, D_Loss:0.5061135292053223, G_Loss:4.87580680847168

iterator 1300, D_Loss:0.6440185308456421, G_Loss:5.199511528015137

iterator 1400, D_Loss:0.7230641841888428, G_Loss:5.053920745849609

iterator 1500, D_Loss:0.577707052230835, G_Loss:4.817927360534668

iterator 1600, D_Loss:0.5749659538269043, G_Loss:5.342453479766846

iterator 1700, D_Loss:0.5359725952148438, G_Loss:4.887726783752441

iterator 1800, D_Loss:0.5624052286148071, G_Loss:4.821263790130615

iterator 1900, D_Loss:0.5507142543792725, G_Loss:4.674763202667236

iterator 2000, D_Loss:0.5519341230392456, G_Loss:5.088095664978027

iterator 2100, D_Loss:0.5962790846824646, G_Loss:4.999464988708496

iterator 2200, D_Loss:0.5872848629951477, G_Loss:5.157632827758789

iterator 2300, D_Loss:0.6154035925865173, G_Loss:5.079381465911865

iterator 2400, D_Loss:0.6106924414634705, G_Loss:4.899871826171875

iterator 2500, D_Loss:0.5088651180267334, G_Loss:5.270071506500244

iterator 2600, D_Loss:0.5593749284744263, G_Loss:5.377557754516602

iterator 2700, D_Loss:0.7591569423675537, G_Loss:4.459837913513184

iterator 2800, D_Loss:0.6359140276908875, G_Loss:4.437923431396484

iterator 2900, D_Loss:0.6340433955192566, G_Loss:4.1911187171936035

iterator 3000, D_Loss:0.5131667852401733, G_Loss:4.999641418457031

iterator 3100, D_Loss:0.5637057423591614, G_Loss:5.031662464141846

iterator 3200, D_Loss:0.5727618932723999, G_Loss:5.2555766105651855

iterator 3300, D_Loss:0.5475980639457703, G_Loss:5.119472026824951

iterator 3400, D_Loss:0.5260146260261536, G_Loss:5.182260990142822

iterator 3500, D_Loss:0.5354125499725342, G_Loss:4.732358455657959

iterator 3600, D_Loss:0.5937055349349976, G_Loss:5.429251194000244

iterator 3700, D_Loss:0.5798684358596802, G_Loss:4.6304192543029785

iterator 3800, D_Loss:0.6209303736686707, G_Loss:5.126124858856201

iterator 3900, D_Loss:0.580396831035614, G_Loss:5.152576446533203

iterator 4000, D_Loss:0.5742533802986145, G_Loss:5.1444411277771

iterator 4100, D_Loss:0.5117982029914856, G_Loss:5.326435089111328

iterator 4200, D_Loss:0.5694149732589722, G_Loss:5.090258598327637

iterator 4300, D_Loss:0.6065360307693481, G_Loss:4.617043972015381

iterator 4400, D_Loss:0.5748149752616882, G_Loss:5.086513519287109

iterator 4500, D_Loss:0.5494816303253174, G_Loss:4.682222366333008

iterator 4600, D_Loss:0.6413658857345581, G_Loss:4.93199348449707

iterator 4700, D_Loss:0.5357763171195984, G_Loss:5.00755500793457

iterator 4800, D_Loss:0.5330063700675964, G_Loss:4.555337905883789

iterator 4900, D_Loss:0.4673568904399872, G_Loss:4.674183368682861

iterator 5000, D_Loss:0.5675902962684631, G_Loss:4.889309406280518

-----------Epoch 6-----------
iterator 100, D_Loss:0.6476365923881531, G_Loss:5.277818202972412

iterator 200, D_Loss:0.5980658531188965, G_Loss:4.990151405334473

iterator 300, D_Loss:0.5407501459121704, G_Loss:4.929075717926025

iterator 400, D_Loss:0.5814499855041504, G_Loss:5.258094310760498

iterator 500, D_Loss:0.586350679397583, G_Loss:5.195558547973633

iterator 600, D_Loss:0.524612545967102, G_Loss:5.552285194396973

iterator 700, D_Loss:0.5771386623382568, G_Loss:4.9924821853637695

iterator 800, D_Loss:0.5818139314651489, G_Loss:5.448719024658203

iterator 900, D_Loss:0.5180445313453674, G_Loss:4.946105003356934

iterator 1000, D_Loss:0.5959485769271851, G_Loss:4.721526622772217

iterator 1100, D_Loss:0.6144111752510071, G_Loss:4.915513515472412

iterator 1200, D_Loss:0.574837863445282, G_Loss:4.6658101081848145

iterator 1300, D_Loss:0.6460046172142029, G_Loss:4.388281345367432

iterator 1400, D_Loss:0.5772033333778381, G_Loss:4.986241817474365

iterator 1500, D_Loss:0.5422185063362122, G_Loss:4.6667585372924805

iterator 1600, D_Loss:0.5331434011459351, G_Loss:5.087381839752197

iterator 1700, D_Loss:0.5106490850448608, G_Loss:4.521780967712402

iterator 1800, D_Loss:0.5702486038208008, G_Loss:5.157083988189697

iterator 1900, D_Loss:0.6100196838378906, G_Loss:4.592931270599365

iterator 2000, D_Loss:0.5780359506607056, G_Loss:4.626737594604492

iterator 2100, D_Loss:0.5388597249984741, G_Loss:4.542449951171875

iterator 2200, D_Loss:0.6676220893859863, G_Loss:4.498276233673096

iterator 2300, D_Loss:0.5336445569992065, G_Loss:4.377136707305908

iterator 2400, D_Loss:0.6267194151878357, G_Loss:4.788281440734863

iterator 2500, D_Loss:0.6740315556526184, G_Loss:4.64081335067749

iterator 2600, D_Loss:0.6187805533409119, G_Loss:4.8611555099487305

iterator 2700, D_Loss:0.5867374539375305, G_Loss:4.444558620452881

iterator 2800, D_Loss:0.5125257968902588, G_Loss:4.857769012451172

iterator 2900, D_Loss:0.5815907716751099, G_Loss:4.6513872146606445

iterator 3000, D_Loss:0.6170322895050049, G_Loss:4.849272727966309

iterator 3100, D_Loss:0.7008132934570312, G_Loss:4.608358383178711

iterator 3200, D_Loss:0.6040154695510864, G_Loss:4.84235143661499

iterator 3300, D_Loss:0.7144738435745239, G_Loss:4.772524833679199

iterator 3400, D_Loss:0.5703706741333008, G_Loss:4.479497909545898

iterator 3500, D_Loss:0.64185631275177, G_Loss:4.483177661895752

iterator 3600, D_Loss:0.5852072834968567, G_Loss:4.957977294921875

iterator 3700, D_Loss:0.5461919903755188, G_Loss:4.287625789642334

iterator 3800, D_Loss:0.6519781351089478, G_Loss:4.6865692138671875

iterator 3900, D_Loss:0.6789019107818604, G_Loss:4.801053047180176

iterator 4000, D_Loss:0.5347278714179993, G_Loss:4.671924591064453

iterator 4100, D_Loss:0.5574871897697449, G_Loss:4.962005615234375

iterator 4200, D_Loss:0.5879892706871033, G_Loss:4.398655891418457

iterator 4300, D_Loss:0.5525524616241455, G_Loss:4.815349102020264

iterator 4400, D_Loss:0.5697876214981079, G_Loss:4.773498058319092

iterator 4500, D_Loss:0.5548288226127625, G_Loss:4.548337936401367

iterator 4600, D_Loss:0.5724797248840332, G_Loss:4.586433410644531

iterator 4700, D_Loss:0.5036466121673584, G_Loss:4.665256977081299

iterator 4800, D_Loss:0.5448039174079895, G_Loss:4.6842041015625

iterator 4900, D_Loss:0.5630279779434204, G_Loss:5.420174598693848

iterator 5000, D_Loss:0.5630956292152405, G_Loss:5.062603950500488

-----------Epoch 7-----------
iterator 100, D_Loss:0.5081272125244141, G_Loss:5.218838691711426

iterator 200, D_Loss:0.6083394289016724, G_Loss:5.178342342376709

iterator 300, D_Loss:0.7162554860115051, G_Loss:4.793912887573242

iterator 400, D_Loss:0.6559498906135559, G_Loss:4.72870397567749

iterator 500, D_Loss:0.5700263977050781, G_Loss:5.015719413757324

iterator 600, D_Loss:0.5766881704330444, G_Loss:5.2269816398620605

iterator 700, D_Loss:0.5575860738754272, G_Loss:4.825282573699951

iterator 800, D_Loss:0.561138927936554, G_Loss:4.957364082336426

iterator 900, D_Loss:0.6153802871704102, G_Loss:4.959880828857422

iterator 1000, D_Loss:0.5215572714805603, G_Loss:4.778768062591553

iterator 1100, D_Loss:0.6603129506111145, G_Loss:4.700982570648193

iterator 1200, D_Loss:0.5793279409408569, G_Loss:4.90175199508667

iterator 1300, D_Loss:0.6868858337402344, G_Loss:4.7207136154174805

iterator 1400, D_Loss:0.6403511762619019, G_Loss:4.6012654304504395

iterator 1500, D_Loss:0.5022947788238525, G_Loss:4.21073579788208

iterator 1600, D_Loss:0.5761611461639404, G_Loss:4.4585676193237305

iterator 1700, D_Loss:0.5459121465682983, G_Loss:4.828867435455322

iterator 1800, D_Loss:0.5614153146743774, G_Loss:4.548473834991455

iterator 1900, D_Loss:0.5894087553024292, G_Loss:4.491626262664795

iterator 2000, D_Loss:0.6837899684906006, G_Loss:4.2562150955200195

iterator 2100, D_Loss:0.596341073513031, G_Loss:4.679619312286377

iterator 2200, D_Loss:0.49401211738586426, G_Loss:4.377751350402832

iterator 2300, D_Loss:0.5225629806518555, G_Loss:4.489406108856201

iterator 2400, D_Loss:0.5803432464599609, G_Loss:4.423242092132568

iterator 2500, D_Loss:0.5259115099906921, G_Loss:4.786129474639893

iterator 2600, D_Loss:0.6259636878967285, G_Loss:4.751523494720459

iterator 2700, D_Loss:0.5829344987869263, G_Loss:4.5366597175598145

iterator 2800, D_Loss:0.5686051249504089, G_Loss:4.598674297332764

iterator 2900, D_Loss:0.6675507426261902, G_Loss:4.826413154602051

iterator 3000, D_Loss:0.5304614305496216, G_Loss:4.8679938316345215

iterator 3100, D_Loss:0.5728684663772583, G_Loss:4.638091087341309

iterator 3200, D_Loss:0.5430205464363098, G_Loss:4.73788595199585

iterator 3300, D_Loss:0.5112060308456421, G_Loss:4.534658432006836

iterator 3400, D_Loss:0.515593945980072, G_Loss:4.884128570556641

iterator 3500, D_Loss:0.5156758427619934, G_Loss:4.923476219177246

iterator 3600, D_Loss:0.5939881801605225, G_Loss:4.906234264373779

iterator 3700, D_Loss:0.600598931312561, G_Loss:4.718938827514648

iterator 3800, D_Loss:0.5176252722740173, G_Loss:5.258638858795166

iterator 3900, D_Loss:0.5837793350219727, G_Loss:5.077444076538086

iterator 4000, D_Loss:0.564768373966217, G_Loss:5.0908098220825195

iterator 4100, D_Loss:0.5507615804672241, G_Loss:5.121079921722412

iterator 4200, D_Loss:0.5555832982063293, G_Loss:4.551781177520752

iterator 4300, D_Loss:0.5629147291183472, G_Loss:4.355928897857666

iterator 4400, D_Loss:0.5947110056877136, G_Loss:4.773910045623779

iterator 4500, D_Loss:0.6170743703842163, G_Loss:4.3207197189331055

iterator 4600, D_Loss:0.6791467070579529, G_Loss:4.493795394897461

iterator 4700, D_Loss:0.5644129514694214, G_Loss:4.6529860496521

iterator 4800, D_Loss:0.5919255614280701, G_Loss:4.4476447105407715

iterator 4900, D_Loss:0.4997785687446594, G_Loss:4.458815574645996

iterator 5000, D_Loss:0.5731449723243713, G_Loss:4.529251575469971

-----------Epoch 8-----------
iterator 100, D_Loss:0.6908390522003174, G_Loss:4.282283306121826

iterator 200, D_Loss:0.6039592027664185, G_Loss:4.672665596008301

iterator 300, D_Loss:0.6143105030059814, G_Loss:4.715450286865234

iterator 400, D_Loss:0.6573842763900757, G_Loss:4.601997375488281

iterator 500, D_Loss:0.6778804063796997, G_Loss:4.810336589813232

iterator 600, D_Loss:0.6062244176864624, G_Loss:4.2930121421813965

iterator 700, D_Loss:0.6955010890960693, G_Loss:4.323387145996094

iterator 800, D_Loss:0.604809045791626, G_Loss:4.342704772949219

iterator 900, D_Loss:0.5970130562782288, G_Loss:4.525118350982666

iterator 1000, D_Loss:0.5232683420181274, G_Loss:4.798342227935791

iterator 1100, D_Loss:0.6214423775672913, G_Loss:4.895632266998291

iterator 1200, D_Loss:0.6286194920539856, G_Loss:4.836128234863281

iterator 1300, D_Loss:0.5203070044517517, G_Loss:4.544662952423096

iterator 1400, D_Loss:0.6580170392990112, G_Loss:5.055657863616943

iterator 1500, D_Loss:0.6005184650421143, G_Loss:4.7800612449646

iterator 1600, D_Loss:0.6202685236930847, G_Loss:4.585773468017578

iterator 1700, D_Loss:0.5546969175338745, G_Loss:4.722413539886475

iterator 1800, D_Loss:0.6061846017837524, G_Loss:4.483870029449463

iterator 1900, D_Loss:0.5460968017578125, G_Loss:4.95712947845459

iterator 2000, D_Loss:0.5420140027999878, G_Loss:4.706933498382568

iterator 2100, D_Loss:0.6006308794021606, G_Loss:5.083272457122803

iterator 2200, D_Loss:0.6260538697242737, G_Loss:4.4832868576049805

iterator 2300, D_Loss:0.6192044019699097, G_Loss:4.474920272827148

iterator 2400, D_Loss:0.5979259014129639, G_Loss:4.389081001281738

iterator 2500, D_Loss:0.5219135284423828, G_Loss:4.65603494644165

iterator 2600, D_Loss:0.5651467442512512, G_Loss:4.5924482345581055

iterator 2700, D_Loss:0.6420832276344299, G_Loss:4.400519847869873

iterator 2800, D_Loss:0.5948918461799622, G_Loss:5.0195231437683105

iterator 2900, D_Loss:0.511063814163208, G_Loss:4.138793468475342

iterator 3000, D_Loss:0.5400164127349854, G_Loss:4.638717174530029

iterator 3100, D_Loss:0.5620784759521484, G_Loss:4.637122631072998

iterator 3200, D_Loss:0.5122368335723877, G_Loss:4.3949761390686035

iterator 3300, D_Loss:0.5799581408500671, G_Loss:4.140074253082275

iterator 3400, D_Loss:0.6303249001502991, G_Loss:5.007508277893066

iterator 3500, D_Loss:0.620872974395752, G_Loss:4.5591912269592285

iterator 3600, D_Loss:0.545471727848053, G_Loss:4.563459396362305

iterator 3700, D_Loss:0.6220368146896362, G_Loss:4.409566402435303

iterator 3800, D_Loss:0.6097469925880432, G_Loss:4.824141025543213

iterator 3900, D_Loss:0.6225212812423706, G_Loss:5.134789943695068

iterator 4000, D_Loss:0.5421969890594482, G_Loss:4.676395893096924

iterator 4100, D_Loss:0.583553671836853, G_Loss:4.951269626617432

iterator 4200, D_Loss:0.580913782119751, G_Loss:4.462194442749023

iterator 4300, D_Loss:0.6118630170822144, G_Loss:4.578597545623779

iterator 4400, D_Loss:0.5122327208518982, G_Loss:4.339107513427734

iterator 4500, D_Loss:0.5807964205741882, G_Loss:4.719423770904541

iterator 4600, D_Loss:0.625055193901062, G_Loss:4.433469772338867

iterator 4700, D_Loss:0.5547634959220886, G_Loss:4.6111907958984375

iterator 4800, D_Loss:0.5649245977401733, G_Loss:4.479088306427002

iterator 4900, D_Loss:0.5908436179161072, G_Loss:4.582892417907715

iterator 5000, D_Loss:0.5982775092124939, G_Loss:4.629457950592041

-----------Epoch 9-----------
iterator 100, D_Loss:0.571537435054779, G_Loss:4.5604143142700195

iterator 200, D_Loss:0.572261393070221, G_Loss:4.899963855743408

iterator 300, D_Loss:0.5790851712226868, G_Loss:4.693533897399902

iterator 400, D_Loss:0.5886164307594299, G_Loss:4.641821384429932

iterator 500, D_Loss:0.5859939455986023, G_Loss:4.161176681518555

iterator 600, D_Loss:0.6205757856369019, G_Loss:4.275912284851074

iterator 700, D_Loss:0.6562087535858154, G_Loss:4.597329139709473

iterator 800, D_Loss:0.6331685781478882, G_Loss:4.103198051452637

iterator 900, D_Loss:0.5167291164398193, G_Loss:4.803648471832275

iterator 1000, D_Loss:0.602226734161377, G_Loss:4.5709147453308105

iterator 1100, D_Loss:0.5679576992988586, G_Loss:4.814978122711182

iterator 1200, D_Loss:0.6829994916915894, G_Loss:4.622129440307617

iterator 1300, D_Loss:0.5739498734474182, G_Loss:4.6654839515686035

iterator 1400, D_Loss:0.5670148730278015, G_Loss:4.4150519371032715

iterator 1500, D_Loss:0.5734559893608093, G_Loss:4.314440727233887

iterator 1600, D_Loss:0.663890540599823, G_Loss:4.502371788024902

iterator 1700, D_Loss:0.527187705039978, G_Loss:4.443359375

iterator 1800, D_Loss:0.5497816801071167, G_Loss:4.725751876831055

iterator 1900, D_Loss:0.5611966848373413, G_Loss:4.720064163208008

iterator 2000, D_Loss:0.5510834455490112, G_Loss:3.977783441543579

iterator 2100, D_Loss:0.6068829894065857, G_Loss:4.470224857330322

iterator 2200, D_Loss:0.5520695447921753, G_Loss:4.400261402130127

iterator 2300, D_Loss:0.5480294227600098, G_Loss:4.6233601570129395

iterator 2400, D_Loss:0.661666989326477, G_Loss:4.609241962432861

iterator 2500, D_Loss:0.6307625770568848, G_Loss:4.3868255615234375

iterator 2600, D_Loss:0.5321882963180542, G_Loss:4.652149200439453

iterator 2700, D_Loss:0.5267866849899292, G_Loss:4.470855712890625

iterator 2800, D_Loss:0.5502646565437317, G_Loss:4.802116870880127

iterator 2900, D_Loss:0.5336939096450806, G_Loss:4.255370140075684

iterator 3000, D_Loss:0.6185754537582397, G_Loss:4.622615337371826

iterator 3100, D_Loss:0.5829021334648132, G_Loss:4.270120620727539

iterator 3200, D_Loss:0.5761524438858032, G_Loss:4.702519416809082

iterator 3300, D_Loss:0.5975744724273682, G_Loss:4.372724533081055

iterator 3400, D_Loss:0.6465103626251221, G_Loss:4.488826274871826

iterator 3500, D_Loss:0.5744296312332153, G_Loss:4.55774450302124

iterator 3600, D_Loss:0.6064921021461487, G_Loss:4.194402694702148

iterator 3700, D_Loss:0.5790748596191406, G_Loss:4.057952404022217

iterator 3800, D_Loss:0.5771826505661011, G_Loss:4.585687637329102

iterator 3900, D_Loss:0.6224713325500488, G_Loss:4.313159942626953

iterator 4000, D_Loss:0.5427135229110718, G_Loss:4.301390647888184

iterator 4100, D_Loss:0.5647255182266235, G_Loss:4.257417678833008

iterator 4200, D_Loss:0.5939082503318787, G_Loss:4.602112770080566

iterator 4300, D_Loss:0.5659378170967102, G_Loss:4.4846272468566895

iterator 4400, D_Loss:0.6287850737571716, G_Loss:4.225216865539551

iterator 4500, D_Loss:0.5186170339584351, G_Loss:4.280765533447266

iterator 4600, D_Loss:0.5189884305000305, G_Loss:4.452374458312988

iterator 4700, D_Loss:0.5423893332481384, G_Loss:4.537381172180176

iterator 4800, D_Loss:0.6262663006782532, G_Loss:4.495725154876709

iterator 4900, D_Loss:0.5609474778175354, G_Loss:4.394124984741211

iterator 5000, D_Loss:0.6151125431060791, G_Loss:4.173478603363037

VGAN_generator(
  (input): Linear(in_features=256, out_features=300, bias=True)
  (inputbn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=300, out_features=300, bias=True)
  (bn0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=300, out_features=300, bias=True)
  (bn1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=300, out_features=45, bias=True)
  (outputbn): BatchNorm1d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=45, out_features=300, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=300, out_features=300, bias=True)
  (fc1): Linear(in_features=300, out_features=300, bias=True)
  (fc2): Linear(in_features=300, out_features=300, bias=True)
  (output): Linear(in_features=300, out_features=1, bias=True)
)
(0, False, 45)
-----------Epoch 0-----------
iterator 100, D_Loss:0.5141373872756958, G_Loss:12.751045227050781

iterator 200, D_Loss:0.4457976818084717, G_Loss:12.303573608398438

iterator 300, D_Loss:0.4719335436820984, G_Loss:11.560619354248047

iterator 400, D_Loss:0.46907293796539307, G_Loss:9.812501907348633

iterator 500, D_Loss:0.4885024428367615, G_Loss:10.691404342651367

iterator 600, D_Loss:0.4361726641654968, G_Loss:10.497710227966309

iterator 700, D_Loss:0.5074632167816162, G_Loss:8.492631912231445

iterator 800, D_Loss:0.47413989901542664, G_Loss:8.113739967346191

iterator 900, D_Loss:0.5374830365180969, G_Loss:7.660045623779297

iterator 1000, D_Loss:0.46285831928253174, G_Loss:8.008919715881348

iterator 1100, D_Loss:0.46529754996299744, G_Loss:7.356821537017822

iterator 1200, D_Loss:0.45921245217323303, G_Loss:6.764558792114258

iterator 1300, D_Loss:0.4969031512737274, G_Loss:6.948530673980713

iterator 1400, D_Loss:0.5745061039924622, G_Loss:5.94119119644165

iterator 1500, D_Loss:0.5237650275230408, G_Loss:6.830031394958496

iterator 1600, D_Loss:0.6140164136886597, G_Loss:5.967823028564453

iterator 1700, D_Loss:0.5854177474975586, G_Loss:6.703462600708008

iterator 1800, D_Loss:0.6199405193328857, G_Loss:6.035131454467773

iterator 1900, D_Loss:0.5919720530509949, G_Loss:5.183728218078613

iterator 2000, D_Loss:0.6236670613288879, G_Loss:5.720282077789307

iterator 2100, D_Loss:0.5480166077613831, G_Loss:5.250082969665527

iterator 2200, D_Loss:0.5305695533752441, G_Loss:5.623383045196533

iterator 2300, D_Loss:0.546150803565979, G_Loss:5.1186652183532715

iterator 2400, D_Loss:0.5116636157035828, G_Loss:5.335061073303223

iterator 2500, D_Loss:0.6170527338981628, G_Loss:5.136683464050293

iterator 2600, D_Loss:0.5793572664260864, G_Loss:4.985651969909668

iterator 2700, D_Loss:0.6351175904273987, G_Loss:4.684617519378662

iterator 2800, D_Loss:0.6340488195419312, G_Loss:4.880295753479004

iterator 2900, D_Loss:0.6210821866989136, G_Loss:4.127638816833496

iterator 3000, D_Loss:0.5935495495796204, G_Loss:3.8637290000915527

iterator 3100, D_Loss:0.6919291615486145, G_Loss:4.40238618850708

iterator 3200, D_Loss:0.7827794551849365, G_Loss:3.898198127746582

iterator 3300, D_Loss:0.668959379196167, G_Loss:4.457775592803955

iterator 3400, D_Loss:0.6323978900909424, G_Loss:4.4243245124816895

iterator 3500, D_Loss:0.7284421920776367, G_Loss:4.018595218658447

iterator 3600, D_Loss:0.6289843320846558, G_Loss:4.006361961364746

iterator 3700, D_Loss:0.5923499464988708, G_Loss:3.9817886352539062

iterator 3800, D_Loss:0.664779007434845, G_Loss:4.175971031188965

iterator 3900, D_Loss:0.6355440020561218, G_Loss:4.372200965881348

iterator 4000, D_Loss:0.7781082391738892, G_Loss:3.71590518951416

iterator 4100, D_Loss:0.6117681264877319, G_Loss:4.155005931854248

iterator 4200, D_Loss:0.6967965364456177, G_Loss:3.496335506439209

iterator 4300, D_Loss:0.6908445954322815, G_Loss:3.6398515701293945

iterator 4400, D_Loss:0.6553385257720947, G_Loss:3.6288998126983643

iterator 4500, D_Loss:0.7329121828079224, G_Loss:3.76350998878479

iterator 4600, D_Loss:0.7758769989013672, G_Loss:3.4086005687713623

iterator 4700, D_Loss:0.7635601162910461, G_Loss:4.607476711273193

iterator 4800, D_Loss:0.6887736320495605, G_Loss:3.613682508468628

iterator 4900, D_Loss:0.8259547352790833, G_Loss:3.3221168518066406

iterator 5000, D_Loss:0.8780756592750549, G_Loss:3.8288931846618652

-----------Epoch 1-----------
iterator 100, D_Loss:0.7558010816574097, G_Loss:3.2780864238739014

iterator 200, D_Loss:0.8390120267868042, G_Loss:3.2566733360290527

iterator 300, D_Loss:0.6783143877983093, G_Loss:3.5056021213531494

iterator 400, D_Loss:0.7713172435760498, G_Loss:3.5276317596435547

iterator 500, D_Loss:0.7968885898590088, G_Loss:3.1329715251922607

iterator 600, D_Loss:0.7879366874694824, G_Loss:3.0156352519989014

iterator 700, D_Loss:0.755693793296814, G_Loss:3.293891191482544

iterator 800, D_Loss:0.7726426720619202, G_Loss:3.0608620643615723

iterator 900, D_Loss:0.85910964012146, G_Loss:3.2495663166046143

iterator 1000, D_Loss:0.8106763958930969, G_Loss:3.1809539794921875

iterator 1100, D_Loss:0.782203733921051, G_Loss:3.852128505706787

iterator 1200, D_Loss:0.7181230783462524, G_Loss:3.1372666358947754

iterator 1300, D_Loss:0.8697530031204224, G_Loss:2.9041740894317627

iterator 1400, D_Loss:0.7420753836631775, G_Loss:3.3113927841186523

iterator 1500, D_Loss:0.8325127363204956, G_Loss:2.937473773956299

iterator 1600, D_Loss:0.8221616744995117, G_Loss:3.036825180053711

iterator 1700, D_Loss:0.8275119066238403, G_Loss:2.8838984966278076

iterator 1800, D_Loss:0.9138714075088501, G_Loss:3.1725897789001465

iterator 1900, D_Loss:0.8711897134780884, G_Loss:2.80509877204895

iterator 2000, D_Loss:0.8386529684066772, G_Loss:2.806025266647339

iterator 2100, D_Loss:0.7948572635650635, G_Loss:3.237434148788452

iterator 2200, D_Loss:0.8766123652458191, G_Loss:2.9272847175598145

iterator 2300, D_Loss:0.7812434434890747, G_Loss:2.794528007507324

iterator 2400, D_Loss:0.7868515849113464, G_Loss:3.4470930099487305

iterator 2500, D_Loss:0.8592791557312012, G_Loss:3.1407320499420166

iterator 2600, D_Loss:0.7524763941764832, G_Loss:3.0192549228668213

iterator 2700, D_Loss:0.8418881893157959, G_Loss:2.567955255508423

iterator 2800, D_Loss:0.7674078941345215, G_Loss:3.4533562660217285

iterator 2900, D_Loss:0.9077022075653076, G_Loss:3.0360970497131348

iterator 3000, D_Loss:0.9322751760482788, G_Loss:2.7683610916137695

iterator 3100, D_Loss:0.8699862360954285, G_Loss:3.1910252571105957

iterator 3200, D_Loss:0.8321530818939209, G_Loss:2.811314821243286

iterator 3300, D_Loss:0.9051589369773865, G_Loss:2.538515090942383

iterator 3400, D_Loss:0.7886202931404114, G_Loss:3.6566853523254395

iterator 3500, D_Loss:0.7720893621444702, G_Loss:2.656069278717041

iterator 3600, D_Loss:0.7707076072692871, G_Loss:3.60581111907959

iterator 3700, D_Loss:0.9165509939193726, G_Loss:2.8314220905303955

iterator 3800, D_Loss:0.786497950553894, G_Loss:3.462337017059326

iterator 3900, D_Loss:0.8225886225700378, G_Loss:2.6583573818206787

iterator 4000, D_Loss:1.0028313398361206, G_Loss:2.2525057792663574

iterator 4100, D_Loss:0.8867141604423523, G_Loss:2.466667890548706

iterator 4200, D_Loss:0.8319757580757141, G_Loss:3.1127877235412598

iterator 4300, D_Loss:0.7141522169113159, G_Loss:3.314666748046875

iterator 4400, D_Loss:0.8623059391975403, G_Loss:3.174083948135376

iterator 4500, D_Loss:0.9001699686050415, G_Loss:3.140808343887329

iterator 4600, D_Loss:0.7163051962852478, G_Loss:3.4705147743225098

iterator 4700, D_Loss:0.8028051257133484, G_Loss:3.063026189804077

iterator 4800, D_Loss:0.8205716609954834, G_Loss:2.712766647338867

iterator 4900, D_Loss:0.91780686378479, G_Loss:3.084897518157959

iterator 5000, D_Loss:0.7867121696472168, G_Loss:3.4207468032836914

-----------Epoch 2-----------
iterator 100, D_Loss:0.8880712985992432, G_Loss:2.697922706604004

iterator 200, D_Loss:0.7328752279281616, G_Loss:2.870255470275879

iterator 300, D_Loss:0.8507748246192932, G_Loss:2.6632463932037354

iterator 400, D_Loss:0.7636055946350098, G_Loss:2.8910534381866455

iterator 500, D_Loss:0.8110082745552063, G_Loss:3.3689920902252197

iterator 600, D_Loss:0.7699195146560669, G_Loss:3.9247705936431885

iterator 700, D_Loss:0.8803477883338928, G_Loss:3.6667661666870117

iterator 800, D_Loss:0.8779069185256958, G_Loss:2.8075547218322754

iterator 900, D_Loss:0.7970015406608582, G_Loss:3.563342809677124

iterator 1000, D_Loss:0.8250894546508789, G_Loss:2.7991549968719482

iterator 1100, D_Loss:0.7637574672698975, G_Loss:3.2925448417663574

iterator 1200, D_Loss:0.8441394567489624, G_Loss:2.9297094345092773

iterator 1300, D_Loss:0.8422101140022278, G_Loss:2.7671539783477783

iterator 1400, D_Loss:0.8032006621360779, G_Loss:3.520897626876831

iterator 1500, D_Loss:0.7467677593231201, G_Loss:3.98112154006958

iterator 1600, D_Loss:0.8021703362464905, G_Loss:3.9835011959075928

iterator 1700, D_Loss:0.7671808004379272, G_Loss:3.423682928085327

iterator 1800, D_Loss:0.867629885673523, G_Loss:3.723148822784424

iterator 1900, D_Loss:0.6335983276367188, G_Loss:3.4063873291015625

iterator 2000, D_Loss:0.8170216083526611, G_Loss:3.25803279876709

iterator 2100, D_Loss:0.6725872755050659, G_Loss:3.8881945610046387

iterator 2200, D_Loss:0.7596529722213745, G_Loss:3.0502593517303467

iterator 2300, D_Loss:0.9143575429916382, G_Loss:3.4910879135131836

iterator 2400, D_Loss:0.8155190944671631, G_Loss:3.5907132625579834

iterator 2500, D_Loss:0.778672456741333, G_Loss:3.8602426052093506

iterator 2600, D_Loss:0.9178789854049683, G_Loss:3.294442892074585

iterator 2700, D_Loss:0.7185314297676086, G_Loss:3.6311888694763184

iterator 2800, D_Loss:0.906915545463562, G_Loss:3.1466827392578125

iterator 2900, D_Loss:0.8662727475166321, G_Loss:2.628753900527954

iterator 3000, D_Loss:0.7433159351348877, G_Loss:3.5995216369628906

iterator 3100, D_Loss:0.8389473557472229, G_Loss:3.0585925579071045

iterator 3200, D_Loss:0.8772954344749451, G_Loss:2.8119914531707764

iterator 3300, D_Loss:0.903549313545227, G_Loss:2.4477462768554688

iterator 3400, D_Loss:0.7601063847541809, G_Loss:3.503307819366455

iterator 3500, D_Loss:0.8161401748657227, G_Loss:3.6109683513641357

iterator 3600, D_Loss:0.8534173965454102, G_Loss:2.8331055641174316

iterator 3700, D_Loss:0.7608610391616821, G_Loss:3.353499412536621

iterator 3800, D_Loss:0.8294792175292969, G_Loss:3.8303446769714355

iterator 3900, D_Loss:0.7265524864196777, G_Loss:4.544669151306152

iterator 4000, D_Loss:0.781830370426178, G_Loss:3.042625665664673

iterator 4100, D_Loss:0.846888542175293, G_Loss:4.0025458335876465

iterator 4200, D_Loss:0.7878861427307129, G_Loss:2.8484559059143066

iterator 4300, D_Loss:0.7872120141983032, G_Loss:3.5398786067962646

iterator 4400, D_Loss:0.7866915464401245, G_Loss:3.829806089401245

iterator 4500, D_Loss:0.8230525255203247, G_Loss:3.1538941860198975

iterator 4600, D_Loss:0.8880261182785034, G_Loss:2.9949328899383545

iterator 4700, D_Loss:0.8425722122192383, G_Loss:3.370227813720703

iterator 4800, D_Loss:0.781818151473999, G_Loss:3.786816120147705

iterator 4900, D_Loss:0.8476712703704834, G_Loss:4.033105373382568

iterator 5000, D_Loss:0.7796816825866699, G_Loss:3.9284746646881104

-----------Epoch 3-----------
iterator 100, D_Loss:0.820128858089447, G_Loss:3.0975451469421387

iterator 200, D_Loss:0.7961248159408569, G_Loss:2.871175765991211

iterator 300, D_Loss:0.7851938009262085, G_Loss:3.2834107875823975

iterator 400, D_Loss:0.703914225101471, G_Loss:2.6743526458740234

iterator 500, D_Loss:0.8071499466896057, G_Loss:3.692988157272339

iterator 600, D_Loss:0.7041703462600708, G_Loss:3.1478307247161865

iterator 700, D_Loss:0.7704260349273682, G_Loss:3.1870956420898438

iterator 800, D_Loss:0.8572948575019836, G_Loss:2.9368224143981934

iterator 900, D_Loss:0.8780341148376465, G_Loss:3.007533550262451

iterator 1000, D_Loss:0.8122933506965637, G_Loss:3.58811092376709

iterator 1100, D_Loss:0.8075035810470581, G_Loss:3.864640712738037

iterator 1200, D_Loss:0.8079719543457031, G_Loss:3.70517635345459

iterator 1300, D_Loss:0.8943396806716919, G_Loss:2.925990343093872

iterator 1400, D_Loss:0.8255919218063354, G_Loss:3.542957067489624

iterator 1500, D_Loss:0.7182590961456299, G_Loss:4.244810581207275

iterator 1600, D_Loss:0.8490597009658813, G_Loss:3.4300551414489746

iterator 1700, D_Loss:0.7642840147018433, G_Loss:3.0257742404937744

iterator 1800, D_Loss:0.7673999071121216, G_Loss:3.3010447025299072

iterator 1900, D_Loss:0.6950188279151917, G_Loss:4.4085822105407715

iterator 2000, D_Loss:0.8332458138465881, G_Loss:3.5174849033355713

iterator 2100, D_Loss:0.8068519234657288, G_Loss:3.631225347518921

iterator 2200, D_Loss:0.7273181676864624, G_Loss:4.075911045074463

iterator 2300, D_Loss:0.6971514225006104, G_Loss:3.4978880882263184

iterator 2400, D_Loss:0.8480439782142639, G_Loss:3.298579454421997

iterator 2500, D_Loss:0.7716823220252991, G_Loss:4.106998920440674

iterator 2600, D_Loss:0.7970041036605835, G_Loss:4.372981071472168

iterator 2700, D_Loss:0.7924556732177734, G_Loss:2.989140510559082

iterator 2800, D_Loss:0.8684470057487488, G_Loss:3.4100470542907715

iterator 2900, D_Loss:0.7826662063598633, G_Loss:4.19740629196167

iterator 3000, D_Loss:0.7957025170326233, G_Loss:3.5642905235290527

iterator 3100, D_Loss:0.7818991541862488, G_Loss:4.5452423095703125

iterator 3200, D_Loss:0.8621154427528381, G_Loss:2.5091843605041504

iterator 3300, D_Loss:0.8248725533485413, G_Loss:4.069278717041016

iterator 3400, D_Loss:0.8001111149787903, G_Loss:3.353562593460083

iterator 3500, D_Loss:0.8010262250900269, G_Loss:3.8637495040893555

iterator 3600, D_Loss:0.7206650972366333, G_Loss:3.373736619949341

iterator 3700, D_Loss:0.8015400171279907, G_Loss:3.678194999694824

iterator 3800, D_Loss:0.782339334487915, G_Loss:3.926445484161377

iterator 3900, D_Loss:0.8248723149299622, G_Loss:2.6126434803009033

iterator 4000, D_Loss:0.8253501057624817, G_Loss:3.2936160564422607

iterator 4100, D_Loss:0.856968879699707, G_Loss:3.4741973876953125

iterator 4200, D_Loss:0.8341865539550781, G_Loss:3.3552119731903076

iterator 4300, D_Loss:0.7746683359146118, G_Loss:3.4361350536346436

iterator 4400, D_Loss:0.7897470593452454, G_Loss:3.921931743621826

iterator 4500, D_Loss:0.7240471839904785, G_Loss:4.119176864624023

iterator 4600, D_Loss:0.8122238516807556, G_Loss:3.68282413482666

iterator 4700, D_Loss:0.761278510093689, G_Loss:3.3524866104125977

iterator 4800, D_Loss:0.7561138868331909, G_Loss:3.075944662094116

iterator 4900, D_Loss:0.793477475643158, G_Loss:4.916841983795166

iterator 5000, D_Loss:0.7422963380813599, G_Loss:3.4766645431518555

-----------Epoch 4-----------
iterator 100, D_Loss:0.7889207005500793, G_Loss:3.7836802005767822

iterator 200, D_Loss:0.7258192896842957, G_Loss:3.361088991165161

iterator 300, D_Loss:0.8122830390930176, G_Loss:3.7198708057403564

iterator 400, D_Loss:0.7461264133453369, G_Loss:3.573428153991699

iterator 500, D_Loss:0.8176683187484741, G_Loss:4.221468448638916

iterator 600, D_Loss:0.7344861030578613, G_Loss:3.766702651977539

iterator 700, D_Loss:0.8124649524688721, G_Loss:3.640850305557251

iterator 800, D_Loss:0.8232004046440125, G_Loss:3.2712154388427734

iterator 900, D_Loss:0.7595615386962891, G_Loss:3.286045789718628

iterator 1000, D_Loss:0.8819084167480469, G_Loss:3.573793649673462

iterator 1100, D_Loss:0.8202642202377319, G_Loss:3.9066803455352783

iterator 1200, D_Loss:0.6680094003677368, G_Loss:3.565394401550293

iterator 1300, D_Loss:0.8155047297477722, G_Loss:3.4158053398132324

iterator 1400, D_Loss:0.8292251825332642, G_Loss:2.9558310508728027

iterator 1500, D_Loss:0.8953659534454346, G_Loss:3.061333656311035

iterator 1600, D_Loss:0.869674563407898, G_Loss:3.817777156829834

iterator 1700, D_Loss:0.9048312902450562, G_Loss:2.9199085235595703

iterator 1800, D_Loss:0.7752125263214111, G_Loss:3.607525110244751

iterator 1900, D_Loss:0.7352720499038696, G_Loss:3.859424114227295

iterator 2000, D_Loss:0.7887887358665466, G_Loss:3.3265252113342285

iterator 2100, D_Loss:0.7674314379692078, G_Loss:3.044593095779419

iterator 2200, D_Loss:0.7708714008331299, G_Loss:3.555406093597412

iterator 2300, D_Loss:0.7656811475753784, G_Loss:3.8222641944885254

iterator 2400, D_Loss:0.7457889318466187, G_Loss:4.005316734313965

iterator 2500, D_Loss:0.8301401138305664, G_Loss:3.7810425758361816

iterator 2600, D_Loss:0.6528124809265137, G_Loss:3.8053219318389893

iterator 2700, D_Loss:0.7922139167785645, G_Loss:3.4019241333007812

iterator 2800, D_Loss:0.8020093441009521, G_Loss:3.437401294708252

iterator 2900, D_Loss:0.7734358906745911, G_Loss:4.3783721923828125

iterator 3000, D_Loss:0.7528260350227356, G_Loss:3.1892974376678467

iterator 3100, D_Loss:0.9250856637954712, G_Loss:3.0547432899475098

iterator 3200, D_Loss:0.8433868885040283, G_Loss:3.214970350265503

iterator 3300, D_Loss:0.775781512260437, G_Loss:4.144164085388184

iterator 3400, D_Loss:0.6574563980102539, G_Loss:3.5492539405822754

iterator 3500, D_Loss:0.7570828795433044, G_Loss:3.7296299934387207

iterator 3600, D_Loss:0.7674820423126221, G_Loss:3.7619998455047607

iterator 3700, D_Loss:0.8445309996604919, G_Loss:3.5097169876098633

iterator 3800, D_Loss:0.7936388254165649, G_Loss:3.069380760192871

iterator 3900, D_Loss:0.7444025278091431, G_Loss:3.3483824729919434

iterator 4000, D_Loss:0.8383822441101074, G_Loss:4.286997318267822

iterator 4100, D_Loss:0.8178699016571045, G_Loss:3.441361427307129

iterator 4200, D_Loss:0.7747392654418945, G_Loss:3.465980291366577

iterator 4300, D_Loss:0.8453271389007568, G_Loss:3.748159170150757

iterator 4400, D_Loss:0.7853550910949707, G_Loss:3.4930930137634277

iterator 4500, D_Loss:0.7683946490287781, G_Loss:3.4057183265686035

iterator 4600, D_Loss:0.8010369539260864, G_Loss:3.327566623687744

iterator 4700, D_Loss:0.7428117990493774, G_Loss:4.905250072479248

iterator 4800, D_Loss:0.7176271677017212, G_Loss:3.8181939125061035

iterator 4900, D_Loss:0.7217645049095154, G_Loss:3.8246591091156006

iterator 5000, D_Loss:0.8988747596740723, G_Loss:3.2627980709075928

-----------Epoch 5-----------
iterator 100, D_Loss:0.8273338675498962, G_Loss:4.090670108795166

iterator 200, D_Loss:0.7972241640090942, G_Loss:2.8619329929351807

iterator 300, D_Loss:0.7726091146469116, G_Loss:3.93245792388916

iterator 400, D_Loss:0.8019307851791382, G_Loss:4.379526615142822

iterator 500, D_Loss:0.9128921627998352, G_Loss:3.98453950881958

iterator 600, D_Loss:0.7998640537261963, G_Loss:3.4812028408050537

iterator 700, D_Loss:0.7875163555145264, G_Loss:3.9439611434936523

iterator 800, D_Loss:0.751187801361084, G_Loss:2.9541494846343994

iterator 900, D_Loss:0.8606982231140137, G_Loss:2.6163716316223145

iterator 1000, D_Loss:0.7736109495162964, G_Loss:3.2470383644104004

iterator 1100, D_Loss:0.7517449259757996, G_Loss:3.9473180770874023

iterator 1200, D_Loss:0.8118381500244141, G_Loss:3.4067821502685547

iterator 1300, D_Loss:0.9405490159988403, G_Loss:2.407991409301758

iterator 1400, D_Loss:0.706828773021698, G_Loss:4.166672229766846

iterator 1500, D_Loss:0.7829751968383789, G_Loss:3.5226662158966064

iterator 1600, D_Loss:0.7159944772720337, G_Loss:4.234992027282715

iterator 1700, D_Loss:0.6939116716384888, G_Loss:3.0206923484802246

iterator 1800, D_Loss:0.760439395904541, G_Loss:2.924826145172119

iterator 1900, D_Loss:0.8096100091934204, G_Loss:3.251209259033203

iterator 2000, D_Loss:0.7431548237800598, G_Loss:4.134392261505127

iterator 2100, D_Loss:0.7498515844345093, G_Loss:3.5364274978637695

iterator 2200, D_Loss:0.7391785979270935, G_Loss:2.9910097122192383

iterator 2300, D_Loss:0.7757747173309326, G_Loss:4.361083507537842

iterator 2400, D_Loss:0.7351487278938293, G_Loss:3.716376304626465

iterator 2500, D_Loss:0.6644140481948853, G_Loss:3.8007616996765137

iterator 2600, D_Loss:0.7811266779899597, G_Loss:3.8267769813537598

iterator 2700, D_Loss:0.7929642200469971, G_Loss:3.53918719291687

iterator 2800, D_Loss:0.7321916818618774, G_Loss:3.6310434341430664

iterator 2900, D_Loss:0.7600579261779785, G_Loss:5.15712833404541

iterator 3000, D_Loss:0.6857743859291077, G_Loss:3.677992343902588

iterator 3100, D_Loss:0.8444753885269165, G_Loss:3.264500141143799

iterator 3200, D_Loss:0.8138049840927124, G_Loss:3.5337228775024414

iterator 3300, D_Loss:0.9104287624359131, G_Loss:3.0942490100860596

iterator 3400, D_Loss:0.8093420267105103, G_Loss:3.581134796142578

iterator 3500, D_Loss:0.797800600528717, G_Loss:2.4792370796203613

iterator 3600, D_Loss:0.7441145777702332, G_Loss:3.2395832538604736

iterator 3700, D_Loss:0.8053957223892212, G_Loss:3.6097395420074463

iterator 3800, D_Loss:0.7559152841567993, G_Loss:4.301924228668213

iterator 3900, D_Loss:0.9551821351051331, G_Loss:3.114623546600342

iterator 4000, D_Loss:0.8199537992477417, G_Loss:3.511003255844116

iterator 4100, D_Loss:0.8345527052879333, G_Loss:3.276991605758667

iterator 4200, D_Loss:0.8907591104507446, G_Loss:3.850956916809082

iterator 4300, D_Loss:0.818681001663208, G_Loss:3.294065237045288

iterator 4400, D_Loss:0.8216338753700256, G_Loss:3.2414278984069824

iterator 4500, D_Loss:0.7562296986579895, G_Loss:3.8352270126342773

iterator 4600, D_Loss:0.8974528908729553, G_Loss:3.304948568344116

iterator 4700, D_Loss:0.817955493927002, G_Loss:4.112009048461914

iterator 4800, D_Loss:0.7442188262939453, G_Loss:3.0897727012634277

iterator 4900, D_Loss:0.885045051574707, G_Loss:3.9969801902770996

iterator 5000, D_Loss:0.8868738412857056, G_Loss:3.7239019870758057

-----------Epoch 6-----------
iterator 100, D_Loss:0.7933019995689392, G_Loss:5.061795711517334

iterator 200, D_Loss:0.8423199653625488, G_Loss:3.367832660675049

iterator 300, D_Loss:0.7988873720169067, G_Loss:3.157085418701172

iterator 400, D_Loss:0.6940998435020447, G_Loss:3.534952402114868

iterator 500, D_Loss:0.7621529698371887, G_Loss:3.646284818649292

iterator 600, D_Loss:0.8029991388320923, G_Loss:3.882636547088623

iterator 700, D_Loss:0.8095327019691467, G_Loss:3.233891248703003

iterator 800, D_Loss:0.9034203886985779, G_Loss:3.2618632316589355

iterator 900, D_Loss:0.8288729190826416, G_Loss:4.016263961791992

iterator 1000, D_Loss:0.7978847026824951, G_Loss:3.50529146194458

iterator 1100, D_Loss:0.8046413660049438, G_Loss:3.549290657043457

iterator 1200, D_Loss:0.7637028694152832, G_Loss:3.726728677749634

iterator 1300, D_Loss:0.8799870610237122, G_Loss:3.303696632385254

iterator 1400, D_Loss:0.7997587323188782, G_Loss:3.2285358905792236

iterator 1500, D_Loss:0.7449569702148438, G_Loss:3.4784915447235107

iterator 1600, D_Loss:0.7724303603172302, G_Loss:3.671241044998169

iterator 1700, D_Loss:0.7289603352546692, G_Loss:3.373253107070923

iterator 1800, D_Loss:0.9004647731781006, G_Loss:3.2952170372009277

iterator 1900, D_Loss:0.736303985118866, G_Loss:3.238577365875244

iterator 2000, D_Loss:0.8772521018981934, G_Loss:3.348977565765381

iterator 2100, D_Loss:0.6914300322532654, G_Loss:3.1561100482940674

iterator 2200, D_Loss:0.8207719922065735, G_Loss:3.713331699371338

iterator 2300, D_Loss:0.8393538594245911, G_Loss:2.8375391960144043

iterator 2400, D_Loss:0.8124198317527771, G_Loss:3.615208625793457

iterator 2500, D_Loss:0.7841426134109497, G_Loss:3.154930591583252

iterator 2600, D_Loss:0.8710305094718933, G_Loss:3.4787755012512207

iterator 2700, D_Loss:0.8085079789161682, G_Loss:3.5223047733306885

iterator 2800, D_Loss:0.8496919870376587, G_Loss:3.5088019371032715

iterator 2900, D_Loss:0.8385921716690063, G_Loss:3.085367441177368

iterator 3000, D_Loss:0.8151571750640869, G_Loss:2.7756476402282715

iterator 3100, D_Loss:0.891180157661438, G_Loss:2.7142863273620605

iterator 3200, D_Loss:0.9514496326446533, G_Loss:3.0139412879943848

iterator 3300, D_Loss:0.716829240322113, G_Loss:3.1841821670532227

iterator 3400, D_Loss:0.8075276017189026, G_Loss:2.9036214351654053

iterator 3500, D_Loss:0.9698854684829712, G_Loss:2.748314619064331

iterator 3600, D_Loss:0.7442678213119507, G_Loss:3.0481228828430176

iterator 3700, D_Loss:0.806013286113739, G_Loss:3.659559965133667

iterator 3800, D_Loss:0.9079819917678833, G_Loss:4.206407070159912

iterator 3900, D_Loss:0.8141602277755737, G_Loss:3.4551188945770264

iterator 4000, D_Loss:0.8446998000144958, G_Loss:3.4926950931549072

iterator 4100, D_Loss:0.7216039896011353, G_Loss:3.3047261238098145

iterator 4200, D_Loss:0.8901030421257019, G_Loss:3.2061691284179688

iterator 4300, D_Loss:0.6578073501586914, G_Loss:3.3336427211761475

iterator 4400, D_Loss:0.8646439909934998, G_Loss:3.0567140579223633

iterator 4500, D_Loss:0.7912468910217285, G_Loss:3.195348024368286

iterator 4600, D_Loss:0.9310286641120911, G_Loss:3.1081736087799072

iterator 4700, D_Loss:0.9160606861114502, G_Loss:3.5560107231140137

iterator 4800, D_Loss:0.7980431318283081, G_Loss:3.2465555667877197

iterator 4900, D_Loss:0.822657585144043, G_Loss:3.3284993171691895

iterator 5000, D_Loss:0.8525218963623047, G_Loss:2.3983333110809326

-----------Epoch 7-----------
iterator 100, D_Loss:0.9397767782211304, G_Loss:3.944978713989258

iterator 200, D_Loss:0.8809186816215515, G_Loss:2.8841123580932617

iterator 300, D_Loss:0.8790761232376099, G_Loss:3.0474207401275635

iterator 400, D_Loss:0.8886399865150452, G_Loss:2.976172924041748

iterator 500, D_Loss:0.7824687361717224, G_Loss:3.728140354156494

iterator 600, D_Loss:0.8046274185180664, G_Loss:4.153801441192627

iterator 700, D_Loss:0.7160604000091553, G_Loss:3.7593674659729004

iterator 800, D_Loss:0.8775999546051025, G_Loss:4.0653815269470215

iterator 900, D_Loss:0.9673915505409241, G_Loss:2.7971596717834473

iterator 1000, D_Loss:0.9580118656158447, G_Loss:2.6843745708465576

iterator 1100, D_Loss:0.8427760601043701, G_Loss:3.3158066272735596

iterator 1200, D_Loss:0.8297392129898071, G_Loss:3.523522138595581

iterator 1300, D_Loss:0.8587316274642944, G_Loss:3.1988043785095215

iterator 1400, D_Loss:0.9033423662185669, G_Loss:4.044536590576172

iterator 1500, D_Loss:0.8722599148750305, G_Loss:3.1286842823028564

iterator 1600, D_Loss:0.889769971370697, G_Loss:2.982866048812866

iterator 1700, D_Loss:0.7759913206100464, G_Loss:3.2206521034240723

iterator 1800, D_Loss:0.9074387550354004, G_Loss:3.0634407997131348

iterator 1900, D_Loss:0.744210958480835, G_Loss:3.240316867828369

iterator 2000, D_Loss:0.8814362287521362, G_Loss:2.3110132217407227

iterator 2100, D_Loss:0.7966234683990479, G_Loss:3.646327018737793

iterator 2200, D_Loss:0.7646631002426147, G_Loss:3.533142328262329

iterator 2300, D_Loss:0.8172829151153564, G_Loss:4.037403583526611

iterator 2400, D_Loss:0.865354061126709, G_Loss:3.119940757751465

iterator 2500, D_Loss:0.8267477750778198, G_Loss:3.5720033645629883

iterator 2600, D_Loss:0.7591346502304077, G_Loss:2.6583542823791504

iterator 2700, D_Loss:0.8136153817176819, G_Loss:3.0449156761169434

iterator 2800, D_Loss:0.8537372350692749, G_Loss:2.4363059997558594

iterator 2900, D_Loss:1.0488176345825195, G_Loss:2.763336420059204

iterator 3000, D_Loss:0.7878402471542358, G_Loss:2.9944536685943604

iterator 3100, D_Loss:0.8952829241752625, G_Loss:3.927943468093872

iterator 3200, D_Loss:0.8595391511917114, G_Loss:2.496626853942871

iterator 3300, D_Loss:0.8663780093193054, G_Loss:3.2210726737976074

iterator 3400, D_Loss:0.7721689939498901, G_Loss:3.313143730163574

iterator 3500, D_Loss:0.8399591445922852, G_Loss:2.543637990951538

iterator 3600, D_Loss:0.7922896146774292, G_Loss:2.58803653717041

iterator 3700, D_Loss:0.8707466125488281, G_Loss:2.7013933658599854

iterator 3800, D_Loss:0.8744316101074219, G_Loss:3.0963642597198486

iterator 3900, D_Loss:0.9435198307037354, G_Loss:3.082139015197754

iterator 4000, D_Loss:0.8009457588195801, G_Loss:3.5579116344451904

iterator 4100, D_Loss:0.8621054887771606, G_Loss:2.884979248046875

iterator 4200, D_Loss:0.8038960695266724, G_Loss:2.8727340698242188

iterator 4300, D_Loss:0.7676401138305664, G_Loss:3.2940869331359863

iterator 4400, D_Loss:0.7921531200408936, G_Loss:3.3620963096618652

iterator 4500, D_Loss:0.815435528755188, G_Loss:2.9828989505767822

iterator 4600, D_Loss:0.7666871547698975, G_Loss:3.0369338989257812

iterator 4700, D_Loss:0.8174973130226135, G_Loss:3.2003188133239746

iterator 4800, D_Loss:0.7909913063049316, G_Loss:2.7439956665039062

iterator 4900, D_Loss:0.8547062873840332, G_Loss:3.104142189025879

iterator 5000, D_Loss:0.8565191030502319, G_Loss:2.6832492351531982

-----------Epoch 8-----------
iterator 100, D_Loss:0.9935623407363892, G_Loss:3.90340518951416

iterator 200, D_Loss:0.8584405183792114, G_Loss:3.19966721534729

iterator 300, D_Loss:0.8533164262771606, G_Loss:2.6687397956848145

iterator 400, D_Loss:0.8872171640396118, G_Loss:2.5048365592956543

iterator 500, D_Loss:0.8667466044425964, G_Loss:3.2434353828430176

iterator 600, D_Loss:0.8043748140335083, G_Loss:3.0365054607391357

iterator 700, D_Loss:0.8170440793037415, G_Loss:3.2381515502929688

iterator 800, D_Loss:0.8957479000091553, G_Loss:2.775369167327881

iterator 900, D_Loss:0.9435468316078186, G_Loss:3.3749775886535645

iterator 1000, D_Loss:0.781841516494751, G_Loss:3.0121829509735107

iterator 1100, D_Loss:0.8628182411193848, G_Loss:3.1766839027404785

iterator 1200, D_Loss:0.8896464109420776, G_Loss:3.67805552482605

iterator 1300, D_Loss:0.9567848443984985, G_Loss:3.188904047012329

iterator 1400, D_Loss:0.8169147372245789, G_Loss:3.012552499771118

iterator 1500, D_Loss:0.9090130925178528, G_Loss:3.395878553390503

iterator 1600, D_Loss:0.9161959886550903, G_Loss:3.0266637802124023

iterator 1700, D_Loss:0.8361205458641052, G_Loss:3.041769027709961

iterator 1800, D_Loss:0.8869036436080933, G_Loss:3.7593886852264404

iterator 1900, D_Loss:0.8321633338928223, G_Loss:2.8246679306030273

iterator 2000, D_Loss:0.9703900218009949, G_Loss:3.0152459144592285

iterator 2100, D_Loss:0.8689498901367188, G_Loss:2.9280033111572266

iterator 2200, D_Loss:0.7649937868118286, G_Loss:3.1098313331604004

iterator 2300, D_Loss:0.9593804478645325, G_Loss:3.6036274433135986

iterator 2400, D_Loss:0.8870353102684021, G_Loss:3.3034117221832275

iterator 2500, D_Loss:0.8127487897872925, G_Loss:4.3322577476501465

iterator 2600, D_Loss:0.8233261108398438, G_Loss:2.7916066646575928

iterator 2700, D_Loss:0.8027098178863525, G_Loss:3.526642322540283

iterator 2800, D_Loss:0.8621158599853516, G_Loss:2.9250783920288086

iterator 2900, D_Loss:0.7790780663490295, G_Loss:4.01393985748291

iterator 3000, D_Loss:0.7196985483169556, G_Loss:3.429949998855591

iterator 3100, D_Loss:0.8699483275413513, G_Loss:2.5272445678710938

iterator 3200, D_Loss:0.9140535593032837, G_Loss:2.8106837272644043

iterator 3300, D_Loss:0.8217967748641968, G_Loss:3.8291101455688477

iterator 3400, D_Loss:0.6868152618408203, G_Loss:3.7333123683929443

iterator 3500, D_Loss:0.8301428556442261, G_Loss:2.2295901775360107

iterator 3600, D_Loss:0.946941077709198, G_Loss:2.542591094970703

iterator 3700, D_Loss:0.788283109664917, G_Loss:3.04379940032959

iterator 3800, D_Loss:0.913275957107544, G_Loss:2.551133394241333

iterator 3900, D_Loss:0.9332322478294373, G_Loss:2.235212802886963

iterator 4000, D_Loss:0.837958812713623, G_Loss:2.4785609245300293

iterator 4100, D_Loss:0.7700892090797424, G_Loss:3.1527562141418457

iterator 4200, D_Loss:0.7873161435127258, G_Loss:3.4097774028778076

iterator 4300, D_Loss:0.8386106491088867, G_Loss:2.9092652797698975

iterator 4400, D_Loss:0.9720184803009033, G_Loss:3.6912009716033936

iterator 4500, D_Loss:0.75503009557724, G_Loss:2.5955779552459717

iterator 4600, D_Loss:0.905901312828064, G_Loss:2.7205324172973633

iterator 4700, D_Loss:0.8250965476036072, G_Loss:3.3902852535247803

iterator 4800, D_Loss:0.7839008569717407, G_Loss:3.125307559967041

iterator 4900, D_Loss:0.8303762674331665, G_Loss:4.1475677490234375

iterator 5000, D_Loss:0.8525711297988892, G_Loss:3.045339345932007

-----------Epoch 9-----------
iterator 100, D_Loss:0.8573800325393677, G_Loss:2.9315929412841797

iterator 200, D_Loss:0.9298564195632935, G_Loss:3.040712594985962

iterator 300, D_Loss:0.8152930736541748, G_Loss:3.2860820293426514

iterator 400, D_Loss:0.823286235332489, G_Loss:2.286844491958618

iterator 500, D_Loss:0.7790762186050415, G_Loss:2.811394691467285

iterator 600, D_Loss:0.8231508135795593, G_Loss:3.2694432735443115

iterator 700, D_Loss:0.8631017804145813, G_Loss:2.6243865489959717

iterator 800, D_Loss:0.7884220480918884, G_Loss:3.157198667526245

iterator 900, D_Loss:0.8422046899795532, G_Loss:3.175959825515747

iterator 1000, D_Loss:0.8448121547698975, G_Loss:3.0616822242736816

iterator 1100, D_Loss:0.8391716480255127, G_Loss:3.102048873901367

iterator 1200, D_Loss:0.9503474831581116, G_Loss:2.923889398574829

iterator 1300, D_Loss:0.9014747738838196, G_Loss:2.4242429733276367

iterator 1400, D_Loss:0.7206929922103882, G_Loss:3.280172824859619

iterator 1500, D_Loss:0.8422752618789673, G_Loss:2.636216402053833

iterator 1600, D_Loss:0.8873534202575684, G_Loss:3.5942513942718506

iterator 1700, D_Loss:0.8351595401763916, G_Loss:3.7700693607330322

iterator 1800, D_Loss:0.8545107841491699, G_Loss:2.809856653213501

iterator 1900, D_Loss:0.8416267037391663, G_Loss:3.2361817359924316

iterator 2000, D_Loss:0.9467000961303711, G_Loss:3.6303369998931885

iterator 2100, D_Loss:0.8042582273483276, G_Loss:3.5371592044830322

iterator 2200, D_Loss:0.9402921795845032, G_Loss:3.065279960632324

iterator 2300, D_Loss:0.7744114398956299, G_Loss:3.464442729949951

iterator 2400, D_Loss:0.7891786098480225, G_Loss:2.822844982147217

iterator 2500, D_Loss:0.8733487725257874, G_Loss:2.793376922607422

iterator 2600, D_Loss:0.777682363986969, G_Loss:3.800865888595581

iterator 2700, D_Loss:0.787289559841156, G_Loss:2.637542247772217

iterator 2800, D_Loss:0.783987283706665, G_Loss:3.578237533569336

iterator 2900, D_Loss:0.9327030777931213, G_Loss:2.829599142074585

iterator 3000, D_Loss:1.0459315776824951, G_Loss:2.8764984607696533

iterator 3100, D_Loss:0.8578547835350037, G_Loss:3.2218680381774902

iterator 3200, D_Loss:0.8013332486152649, G_Loss:3.268428087234497

iterator 3300, D_Loss:0.7079389095306396, G_Loss:3.5926389694213867

iterator 3400, D_Loss:0.6787344217300415, G_Loss:3.220865249633789

iterator 3500, D_Loss:1.0406086444854736, G_Loss:2.400529146194458

iterator 3600, D_Loss:0.9838818311691284, G_Loss:2.597149610519409

iterator 3700, D_Loss:0.7884817719459534, G_Loss:3.5061678886413574

iterator 3800, D_Loss:0.8045241832733154, G_Loss:3.4868361949920654

iterator 3900, D_Loss:0.8204882740974426, G_Loss:2.918938398361206

iterator 4000, D_Loss:0.9083099961280823, G_Loss:2.30737042427063

iterator 4100, D_Loss:0.8912732601165771, G_Loss:2.8096935749053955

iterator 4200, D_Loss:0.7536932229995728, G_Loss:4.233601093292236

iterator 4300, D_Loss:0.8504902124404907, G_Loss:2.739762783050537

iterator 4400, D_Loss:0.9906686544418335, G_Loss:2.824413299560547

iterator 4500, D_Loss:0.8974800705909729, G_Loss:2.7085659503936768

iterator 4600, D_Loss:0.956027626991272, G_Loss:3.801936626434326

iterator 4700, D_Loss:0.7927060127258301, G_Loss:3.6623430252075195

iterator 4800, D_Loss:0.7712992429733276, G_Loss:2.831165313720703

iterator 4900, D_Loss:0.8586959838867188, G_Loss:2.6094603538513184

iterator 5000, D_Loss:0.7857503890991211, G_Loss:2.716334342956543

train row : 30148
sample row: 30148
LGAN_generator(
  (LSTM): LSTMCell(400, 300)
  (gmfc00): Linear(in_features=200, out_features=1, bias=True)
  (gmfc01): Linear(in_features=200, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=200, bias=True)
  (gmfe00): Linear(in_features=300, out_features=200, bias=True)
  (gmfe01): Linear(in_features=300, out_features=200, bias=True)
  (fc10): Linear(in_features=200, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=200, bias=True)
  (fe1): Linear(in_features=300, out_features=200, bias=True)
  (gmfc20): Linear(in_features=200, out_features=1, bias=True)
  (gmfc21): Linear(in_features=200, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=200, bias=True)
  (gmfe20): Linear(in_features=300, out_features=200, bias=True)
  (gmfe21): Linear(in_features=300, out_features=200, bias=True)
  (fc30): Linear(in_features=200, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=200, bias=True)
  (fe3): Linear(in_features=300, out_features=200, bias=True)
  (gmfc40): Linear(in_features=200, out_features=1, bias=True)
  (gmfc41): Linear(in_features=200, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=200, bias=True)
  (gmfe40): Linear(in_features=300, out_features=200, bias=True)
  (gmfe41): Linear(in_features=300, out_features=200, bias=True)
  (fc50): Linear(in_features=200, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=200, bias=True)
  (fe5): Linear(in_features=300, out_features=200, bias=True)
  (fc60): Linear(in_features=200, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=200, bias=True)
  (fe6): Linear(in_features=300, out_features=200, bias=True)
  (fc70): Linear(in_features=200, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=200, bias=True)
  (fe7): Linear(in_features=300, out_features=200, bias=True)
  (fc80): Linear(in_features=200, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=200, bias=True)
  (fe8): Linear(in_features=300, out_features=200, bias=True)
  (fc90): Linear(in_features=200, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=200, bias=True)
  (fe9): Linear(in_features=300, out_features=200, bias=True)
  (gmfc100): Linear(in_features=200, out_features=1, bias=True)
  (gmfc101): Linear(in_features=200, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=200, bias=True)
  (gmfe100): Linear(in_features=300, out_features=200, bias=True)
  (gmfe101): Linear(in_features=300, out_features=200, bias=True)
  (gmfc110): Linear(in_features=200, out_features=1, bias=True)
  (gmfc111): Linear(in_features=200, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=200, bias=True)
  (gmfe110): Linear(in_features=300, out_features=200, bias=True)
  (gmfe111): Linear(in_features=300, out_features=200, bias=True)
  (gmfc120): Linear(in_features=200, out_features=1, bias=True)
  (gmfc121): Linear(in_features=200, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=200, bias=True)
  (gmfe120): Linear(in_features=300, out_features=200, bias=True)
  (gmfe121): Linear(in_features=300, out_features=200, bias=True)
  (fc130): Linear(in_features=200, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=200, bias=True)
  (fe13): Linear(in_features=300, out_features=200, bias=True)
  (fc140): Linear(in_features=200, out_features=2, bias=True)
  (fc141): Linear(in_features=2, out_features=200, bias=True)
  (fe14): Linear(in_features=300, out_features=200, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=500, bias=True)
  (inputbn): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=500, out_features=500, bias=True)
  (bn0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=500, out_features=500, bias=True)
  (bn1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=500, out_features=500, bias=True)
  (bn2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=500, out_features=500, bias=True)
  (bn3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc4): Linear(in_features=500, out_features=500, bias=True)
  (bn4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=500, out_features=1, bias=True)
)
(0, False, 135)
-----------Epoch 0-----------
iterator 100, D_Loss:1.3956108093261719, G_Loss:0.9636914134025574

iterator 200, D_Loss:1.3764410018920898, G_Loss:1.0714269876480103

iterator 300, D_Loss:1.4068820476531982, G_Loss:0.9929214715957642

iterator 400, D_Loss:1.3823206424713135, G_Loss:0.9789959192276001

iterator 500, D_Loss:1.3863296508789062, G_Loss:1.099163293838501

iterator 600, D_Loss:1.3465116024017334, G_Loss:0.9841389060020447

iterator 700, D_Loss:1.3914122581481934, G_Loss:0.9720813035964966

iterator 800, D_Loss:1.3926990032196045, G_Loss:0.9971247911453247

iterator 900, D_Loss:1.3416894674301147, G_Loss:1.0187873840332031

iterator 1000, D_Loss:1.3196015357971191, G_Loss:1.041782021522522

iterator 1100, D_Loss:1.3881587982177734, G_Loss:1.0996767282485962

iterator 1200, D_Loss:1.2216026782989502, G_Loss:1.2937240600585938

iterator 1300, D_Loss:1.3230509757995605, G_Loss:1.1902258396148682

iterator 1400, D_Loss:1.0944093465805054, G_Loss:1.4670366048812866

iterator 1500, D_Loss:1.4157136678695679, G_Loss:1.706376314163208

iterator 1600, D_Loss:1.245015263557434, G_Loss:1.4534071683883667

iterator 1700, D_Loss:0.9269329309463501, G_Loss:1.8400038480758667

iterator 1800, D_Loss:0.7691936492919922, G_Loss:2.1571755409240723

iterator 1900, D_Loss:0.8976140022277832, G_Loss:2.0337040424346924

iterator 2000, D_Loss:0.7699705362319946, G_Loss:2.465195894241333

iterator 2100, D_Loss:0.6069880127906799, G_Loss:1.8055989742279053

iterator 2200, D_Loss:0.6156268119812012, G_Loss:3.1438791751861572

iterator 2300, D_Loss:0.8067149519920349, G_Loss:3.1079046726226807

iterator 2400, D_Loss:0.49750208854675293, G_Loss:3.6875081062316895

iterator 2500, D_Loss:0.5263171792030334, G_Loss:4.292016983032227

iterator 2600, D_Loss:1.3415274620056152, G_Loss:4.190877437591553

iterator 2700, D_Loss:0.48372289538383484, G_Loss:4.237459182739258

iterator 2800, D_Loss:0.5205318927764893, G_Loss:4.494900226593018

iterator 2900, D_Loss:0.8525788187980652, G_Loss:3.2321808338165283

iterator 3000, D_Loss:0.5853738784790039, G_Loss:3.879197597503662

iterator 3100, D_Loss:0.7475959658622742, G_Loss:4.296797752380371

iterator 3200, D_Loss:0.5657460689544678, G_Loss:2.7944676876068115

iterator 3300, D_Loss:0.5399026274681091, G_Loss:4.679685592651367

iterator 3400, D_Loss:0.4919929802417755, G_Loss:4.627231597900391

iterator 3500, D_Loss:0.4801119565963745, G_Loss:4.763550758361816

iterator 3600, D_Loss:0.658852756023407, G_Loss:3.0580685138702393

iterator 3700, D_Loss:0.4797564446926117, G_Loss:4.549819469451904

iterator 3800, D_Loss:0.47887206077575684, G_Loss:6.071428298950195

iterator 3900, D_Loss:0.4657231569290161, G_Loss:5.125245094299316

iterator 4000, D_Loss:0.5130414962768555, G_Loss:4.562994003295898

iterator 4100, D_Loss:0.5568841695785522, G_Loss:4.164936542510986

iterator 4200, D_Loss:0.4829055666923523, G_Loss:4.238329887390137

iterator 4300, D_Loss:0.47713151574134827, G_Loss:5.544938564300537

iterator 4400, D_Loss:0.48190033435821533, G_Loss:5.718181133270264

iterator 4500, D_Loss:0.4775140583515167, G_Loss:4.899202346801758

iterator 4600, D_Loss:0.5715419054031372, G_Loss:6.477129936218262

iterator 4700, D_Loss:0.5420939326286316, G_Loss:5.4030442237854

iterator 4800, D_Loss:0.6337565183639526, G_Loss:3.2856736183166504

iterator 4900, D_Loss:0.7396845817565918, G_Loss:3.9957447052001953

iterator 5000, D_Loss:1.0728434324264526, G_Loss:5.493899345397949

-----------Epoch 1-----------
iterator 100, D_Loss:0.46337080001831055, G_Loss:2.9758052825927734

iterator 200, D_Loss:0.5388287305831909, G_Loss:2.7260308265686035

iterator 300, D_Loss:0.6840744018554688, G_Loss:5.265021800994873

iterator 400, D_Loss:0.6504371166229248, G_Loss:2.426032781600952

iterator 500, D_Loss:0.5305016040802002, G_Loss:1.7727785110473633

iterator 600, D_Loss:0.4979196786880493, G_Loss:4.591336250305176

iterator 700, D_Loss:0.4811389446258545, G_Loss:5.024409294128418

iterator 800, D_Loss:0.6165984272956848, G_Loss:3.5483899116516113

iterator 900, D_Loss:0.5031866431236267, G_Loss:4.9306535720825195

iterator 1000, D_Loss:0.5355632305145264, G_Loss:4.104219436645508

iterator 1100, D_Loss:0.5532104969024658, G_Loss:4.7168803215026855

iterator 1200, D_Loss:0.5146403908729553, G_Loss:5.036588191986084

iterator 1300, D_Loss:0.5200096964836121, G_Loss:5.6417999267578125

iterator 1400, D_Loss:0.5875698328018188, G_Loss:4.244701385498047

iterator 1500, D_Loss:0.5563562512397766, G_Loss:4.782739162445068

iterator 1600, D_Loss:0.5253869891166687, G_Loss:3.027669906616211

iterator 1700, D_Loss:0.5364465117454529, G_Loss:1.8728976249694824

iterator 1800, D_Loss:0.5187126398086548, G_Loss:1.8364909887313843

iterator 1900, D_Loss:0.49469587206840515, G_Loss:4.965317249298096

iterator 2000, D_Loss:0.6115767955780029, G_Loss:4.885124683380127

iterator 2100, D_Loss:0.7703290581703186, G_Loss:4.605751991271973

iterator 2200, D_Loss:0.5374312400817871, G_Loss:4.867399215698242

iterator 2300, D_Loss:1.0434318780899048, G_Loss:1.4227888584136963

iterator 2400, D_Loss:0.9519762992858887, G_Loss:4.98445987701416

iterator 2500, D_Loss:0.5591762661933899, G_Loss:6.000561714172363

iterator 2600, D_Loss:1.5007025003433228, G_Loss:3.4851484298706055

iterator 2700, D_Loss:0.4555414617061615, G_Loss:5.811403274536133

iterator 2800, D_Loss:0.5497055649757385, G_Loss:5.534205436706543

iterator 2900, D_Loss:0.6423250436782837, G_Loss:3.9279232025146484

iterator 3000, D_Loss:0.4841407537460327, G_Loss:8.119556427001953

iterator 3100, D_Loss:0.48385098576545715, G_Loss:9.62056827545166

iterator 3200, D_Loss:1.3063429594039917, G_Loss:5.564679145812988

iterator 3300, D_Loss:0.4651610851287842, G_Loss:4.841525554656982

iterator 3400, D_Loss:0.5628613829612732, G_Loss:4.002831935882568

iterator 3500, D_Loss:0.9935725331306458, G_Loss:6.224524974822998

iterator 3600, D_Loss:0.43452930450439453, G_Loss:4.872092247009277

iterator 3700, D_Loss:0.5126175284385681, G_Loss:6.59379768371582

iterator 3800, D_Loss:0.7507310509681702, G_Loss:6.297173023223877

iterator 3900, D_Loss:1.0727572441101074, G_Loss:6.726897239685059

iterator 4000, D_Loss:0.9110032320022583, G_Loss:4.81576681137085

iterator 4100, D_Loss:0.4539961814880371, G_Loss:5.359073638916016

iterator 4200, D_Loss:0.5400000810623169, G_Loss:7.354864597320557

iterator 4300, D_Loss:0.5814346075057983, G_Loss:3.460421085357666

iterator 4400, D_Loss:0.45543864369392395, G_Loss:7.175713539123535

iterator 4500, D_Loss:0.47068214416503906, G_Loss:5.77946662902832

iterator 4600, D_Loss:0.47656482458114624, G_Loss:6.353478908538818

iterator 4700, D_Loss:0.5285249948501587, G_Loss:8.16739559173584

iterator 4800, D_Loss:0.47539666295051575, G_Loss:2.6586410999298096

iterator 4900, D_Loss:0.4846761226654053, G_Loss:4.404848098754883

iterator 5000, D_Loss:0.48363327980041504, G_Loss:6.413748264312744

-----------Epoch 2-----------
iterator 100, D_Loss:0.4602581858634949, G_Loss:7.148815155029297

iterator 200, D_Loss:0.5346884727478027, G_Loss:3.563256025314331

iterator 300, D_Loss:0.5295992493629456, G_Loss:2.530744791030884

iterator 400, D_Loss:0.7430899143218994, G_Loss:5.410192012786865

iterator 500, D_Loss:0.44631439447402954, G_Loss:3.4336774349212646

iterator 600, D_Loss:0.620139479637146, G_Loss:4.066830635070801

iterator 700, D_Loss:0.532801628112793, G_Loss:3.465501308441162

iterator 800, D_Loss:0.6269170045852661, G_Loss:6.708998203277588

iterator 900, D_Loss:0.6610063910484314, G_Loss:4.156251430511475

iterator 1000, D_Loss:0.4297122061252594, G_Loss:1.3026351928710938

iterator 1100, D_Loss:0.7220016717910767, G_Loss:5.833876609802246

iterator 1200, D_Loss:0.5453030467033386, G_Loss:5.274696350097656

iterator 1300, D_Loss:1.5862412452697754, G_Loss:2.854090690612793

iterator 1400, D_Loss:0.6143949627876282, G_Loss:5.21229362487793

iterator 1500, D_Loss:0.47739896178245544, G_Loss:7.5382914543151855

iterator 1600, D_Loss:0.45458102226257324, G_Loss:5.839559078216553

iterator 1700, D_Loss:0.5228983163833618, G_Loss:3.2071352005004883

iterator 1800, D_Loss:0.7328910827636719, G_Loss:6.399471759796143

iterator 1900, D_Loss:0.9115322232246399, G_Loss:6.913354873657227

iterator 2000, D_Loss:0.4635874330997467, G_Loss:7.684788703918457

iterator 2100, D_Loss:0.7230921387672424, G_Loss:7.118675708770752

iterator 2200, D_Loss:0.7112346887588501, G_Loss:7.640214443206787

iterator 2300, D_Loss:1.014250636100769, G_Loss:3.2728662490844727

iterator 2400, D_Loss:0.5921225547790527, G_Loss:7.853220462799072

iterator 2500, D_Loss:0.4866105020046234, G_Loss:4.541165828704834

iterator 2600, D_Loss:0.7373760938644409, G_Loss:1.0851715803146362

iterator 2700, D_Loss:0.5291270613670349, G_Loss:1.6182868480682373

iterator 2800, D_Loss:0.62688809633255, G_Loss:5.631072521209717

iterator 2900, D_Loss:0.5135154128074646, G_Loss:7.548543930053711

iterator 3000, D_Loss:0.4642803966999054, G_Loss:5.603994369506836

iterator 3100, D_Loss:0.5281299352645874, G_Loss:7.3774027824401855

iterator 3200, D_Loss:0.5075023770332336, G_Loss:2.750211715698242

iterator 3300, D_Loss:1.1508750915527344, G_Loss:5.016704082489014

iterator 3400, D_Loss:0.5701263546943665, G_Loss:5.453044414520264

iterator 3500, D_Loss:0.652885913848877, G_Loss:3.034996271133423

iterator 3600, D_Loss:0.5004281997680664, G_Loss:3.8465726375579834

iterator 3700, D_Loss:0.46587520837783813, G_Loss:2.9884541034698486

iterator 3800, D_Loss:0.5024530291557312, G_Loss:2.0624020099639893

iterator 3900, D_Loss:0.4526486396789551, G_Loss:4.478006839752197

iterator 4000, D_Loss:0.46652546525001526, G_Loss:4.719071865081787

iterator 4100, D_Loss:1.048265814781189, G_Loss:5.301687717437744

iterator 4200, D_Loss:1.083948016166687, G_Loss:5.670549392700195

iterator 4300, D_Loss:0.5112639665603638, G_Loss:3.015177011489868

iterator 4400, D_Loss:0.478505402803421, G_Loss:6.846465587615967

iterator 4500, D_Loss:0.5996811389923096, G_Loss:4.867865085601807

iterator 4600, D_Loss:0.4873703122138977, G_Loss:8.658733367919922

iterator 4700, D_Loss:0.5533577799797058, G_Loss:3.8259992599487305

iterator 4800, D_Loss:0.8802183866500854, G_Loss:4.730563163757324

iterator 4900, D_Loss:0.658661425113678, G_Loss:4.809155464172363

iterator 5000, D_Loss:0.4753524363040924, G_Loss:3.0278477668762207

-----------Epoch 3-----------
iterator 100, D_Loss:0.780574381351471, G_Loss:7.984884738922119

iterator 200, D_Loss:0.45972883701324463, G_Loss:5.877589225769043

iterator 300, D_Loss:0.4441787302494049, G_Loss:7.3914899826049805

iterator 400, D_Loss:0.9188694953918457, G_Loss:7.111305236816406

iterator 500, D_Loss:0.7775689959526062, G_Loss:2.326158046722412

iterator 600, D_Loss:0.5300187468528748, G_Loss:4.21541690826416

iterator 700, D_Loss:0.5760429501533508, G_Loss:8.488776206970215

iterator 800, D_Loss:0.4750872552394867, G_Loss:5.398589611053467

iterator 900, D_Loss:0.7932592034339905, G_Loss:7.249098777770996

iterator 1000, D_Loss:0.46783140301704407, G_Loss:8.371014595031738

iterator 1100, D_Loss:0.5591095685958862, G_Loss:5.866613864898682

iterator 1200, D_Loss:0.4508117437362671, G_Loss:6.695340633392334

iterator 1300, D_Loss:0.45151305198669434, G_Loss:6.3875885009765625

iterator 1400, D_Loss:0.4378671944141388, G_Loss:5.0058913230896

iterator 1500, D_Loss:0.7518633604049683, G_Loss:7.72191047668457

iterator 1600, D_Loss:0.5698059797286987, G_Loss:6.188315391540527

iterator 1700, D_Loss:0.49222078919410706, G_Loss:5.58712911605835

iterator 1800, D_Loss:0.4524063169956207, G_Loss:2.81872820854187

iterator 1900, D_Loss:0.9394632577896118, G_Loss:6.48436975479126

iterator 2000, D_Loss:0.44240424036979675, G_Loss:7.7866363525390625

iterator 2100, D_Loss:0.5078760385513306, G_Loss:8.612473487854004

iterator 2200, D_Loss:0.6805914044380188, G_Loss:6.1998610496521

iterator 2300, D_Loss:0.4321240186691284, G_Loss:5.377317428588867

iterator 2400, D_Loss:0.45359504222869873, G_Loss:4.697414875030518

iterator 2500, D_Loss:0.4477066695690155, G_Loss:7.459671497344971

iterator 2600, D_Loss:0.4667413532733917, G_Loss:9.730487823486328

iterator 2700, D_Loss:0.45973387360572815, G_Loss:7.983429908752441

iterator 2800, D_Loss:0.40489354729652405, G_Loss:6.671165466308594

iterator 2900, D_Loss:0.7021670937538147, G_Loss:6.228146553039551

iterator 3000, D_Loss:0.4396008551120758, G_Loss:6.454020977020264

iterator 3100, D_Loss:0.4750767946243286, G_Loss:6.058501243591309

iterator 3200, D_Loss:0.43668949604034424, G_Loss:9.524824142456055

iterator 3300, D_Loss:0.4470020830631256, G_Loss:7.301764488220215

iterator 3400, D_Loss:0.4500640034675598, G_Loss:4.020818710327148

iterator 3500, D_Loss:0.4378412067890167, G_Loss:4.62063455581665

iterator 3600, D_Loss:0.4543130695819855, G_Loss:6.569539546966553

iterator 3700, D_Loss:0.4495317041873932, G_Loss:5.626978874206543

iterator 3800, D_Loss:0.4538506269454956, G_Loss:6.137492656707764

iterator 3900, D_Loss:0.42402514815330505, G_Loss:2.3676271438598633

iterator 4000, D_Loss:0.41526713967323303, G_Loss:9.810171127319336

iterator 4100, D_Loss:0.4306403696537018, G_Loss:9.435218811035156

iterator 4200, D_Loss:0.46732059121131897, G_Loss:7.758461952209473

iterator 4300, D_Loss:0.4414278268814087, G_Loss:10.009093284606934

iterator 4400, D_Loss:0.4757397770881653, G_Loss:8.213390350341797

iterator 4500, D_Loss:5.099824905395508, G_Loss:7.842797756195068

iterator 4600, D_Loss:0.4491439461708069, G_Loss:6.247759819030762

iterator 4700, D_Loss:0.4372299015522003, G_Loss:5.781008243560791

iterator 4800, D_Loss:0.41048192977905273, G_Loss:7.748978137969971

iterator 4900, D_Loss:0.4867455065250397, G_Loss:0.8551961183547974

iterator 5000, D_Loss:0.44658005237579346, G_Loss:1.8068978786468506

-----------Epoch 4-----------
iterator 100, D_Loss:0.4220665693283081, G_Loss:7.046939849853516

iterator 200, D_Loss:0.4931420087814331, G_Loss:8.622486114501953

iterator 300, D_Loss:0.4390330910682678, G_Loss:6.499323844909668

iterator 400, D_Loss:0.43641021847724915, G_Loss:8.092917442321777

iterator 500, D_Loss:0.5073376297950745, G_Loss:5.632350444793701

iterator 600, D_Loss:0.5389443635940552, G_Loss:8.170419692993164

iterator 700, D_Loss:0.4197217524051666, G_Loss:9.09516716003418

iterator 800, D_Loss:0.4673974812030792, G_Loss:6.473327159881592

iterator 900, D_Loss:0.4643057584762573, G_Loss:11.223008155822754

iterator 1000, D_Loss:0.42010244727134705, G_Loss:8.83119010925293

iterator 1100, D_Loss:0.4405083954334259, G_Loss:6.7069411277771

iterator 1200, D_Loss:0.4244072139263153, G_Loss:10.502567291259766

iterator 1300, D_Loss:0.45329707860946655, G_Loss:9.36069393157959

iterator 1400, D_Loss:0.46724554896354675, G_Loss:8.031194686889648

iterator 1500, D_Loss:0.6427028179168701, G_Loss:7.460603713989258

iterator 1600, D_Loss:0.4532155394554138, G_Loss:7.016613483428955

iterator 1700, D_Loss:0.4378678798675537, G_Loss:5.701622009277344

iterator 1800, D_Loss:0.482593297958374, G_Loss:3.6035046577453613

iterator 1900, D_Loss:0.5181546211242676, G_Loss:8.314862251281738

iterator 2000, D_Loss:0.4062322974205017, G_Loss:6.194636821746826

iterator 2100, D_Loss:0.4180077314376831, G_Loss:6.838512897491455

iterator 2200, D_Loss:0.4148810803890228, G_Loss:9.798766136169434

iterator 2300, D_Loss:0.4229535162448883, G_Loss:12.102311134338379

iterator 2400, D_Loss:0.8927673697471619, G_Loss:9.279645919799805

iterator 2500, D_Loss:0.44558146595954895, G_Loss:8.833500862121582

iterator 2600, D_Loss:0.4818533658981323, G_Loss:7.330066680908203

iterator 2700, D_Loss:0.45272332429885864, G_Loss:10.1725435256958

iterator 2800, D_Loss:0.4168410301208496, G_Loss:5.350518226623535

iterator 2900, D_Loss:0.5415218472480774, G_Loss:7.288626194000244

iterator 3000, D_Loss:0.4292581379413605, G_Loss:10.7318115234375

iterator 3100, D_Loss:0.43739092350006104, G_Loss:10.980419158935547

iterator 3200, D_Loss:0.4036732614040375, G_Loss:9.33796215057373

iterator 3300, D_Loss:0.41886988282203674, G_Loss:8.595380783081055

iterator 3400, D_Loss:0.42744648456573486, G_Loss:9.554707527160645

iterator 3500, D_Loss:0.4701457619667053, G_Loss:8.512348175048828

iterator 3600, D_Loss:0.45883306860923767, G_Loss:7.483339786529541

iterator 3700, D_Loss:0.44703608751296997, G_Loss:10.17879581451416

iterator 3800, D_Loss:0.43864870071411133, G_Loss:10.864419937133789

iterator 3900, D_Loss:0.47446757555007935, G_Loss:8.568078994750977

iterator 4000, D_Loss:0.4106864333152771, G_Loss:6.18909215927124

iterator 4100, D_Loss:0.43082544207572937, G_Loss:8.328396797180176

iterator 4200, D_Loss:0.424378365278244, G_Loss:7.429841995239258

iterator 4300, D_Loss:0.4171961545944214, G_Loss:6.6134138107299805

iterator 4400, D_Loss:0.8020963668823242, G_Loss:10.485244750976562

iterator 4500, D_Loss:1.2092057466506958, G_Loss:10.646255493164062

iterator 4600, D_Loss:0.41310879588127136, G_Loss:8.062536239624023

iterator 4700, D_Loss:0.42089590430259705, G_Loss:8.010286331176758

iterator 4800, D_Loss:0.4309413433074951, G_Loss:7.217849254608154

iterator 4900, D_Loss:0.4421108365058899, G_Loss:8.397573471069336

iterator 5000, D_Loss:0.3919273018836975, G_Loss:8.667625427246094

-----------Epoch 5-----------
iterator 100, D_Loss:0.42360919713974, G_Loss:5.450117111206055

iterator 200, D_Loss:0.40146878361701965, G_Loss:11.05156135559082

iterator 300, D_Loss:0.4402439296245575, G_Loss:9.237894058227539

iterator 400, D_Loss:0.4379664957523346, G_Loss:7.62461519241333

iterator 500, D_Loss:0.43512260913848877, G_Loss:9.151988983154297

iterator 600, D_Loss:0.44906651973724365, G_Loss:7.168173789978027

iterator 700, D_Loss:0.44752591848373413, G_Loss:9.069458961486816

iterator 800, D_Loss:0.43643254041671753, G_Loss:11.267609596252441

iterator 900, D_Loss:0.5919955968856812, G_Loss:7.3177642822265625

iterator 1000, D_Loss:0.4397374391555786, G_Loss:9.233080863952637

iterator 1100, D_Loss:0.4543018043041229, G_Loss:11.147907257080078

iterator 1200, D_Loss:0.43141788244247437, G_Loss:9.295018196105957

iterator 1300, D_Loss:0.45185038447380066, G_Loss:9.560806274414062

iterator 1400, D_Loss:0.4430924654006958, G_Loss:7.122873306274414

iterator 1500, D_Loss:0.43635502457618713, G_Loss:11.92975902557373

iterator 1600, D_Loss:0.41396254301071167, G_Loss:8.335919380187988

iterator 1700, D_Loss:0.4298184812068939, G_Loss:9.024975776672363

iterator 1800, D_Loss:0.4453956186771393, G_Loss:12.412858009338379

iterator 1900, D_Loss:0.42681485414505005, G_Loss:8.82205581665039

iterator 2000, D_Loss:0.41867807507514954, G_Loss:10.046232223510742

iterator 2100, D_Loss:0.44774767756462097, G_Loss:7.540551662445068

iterator 2200, D_Loss:0.4312511086463928, G_Loss:9.639633178710938

iterator 2300, D_Loss:0.43957850337028503, G_Loss:10.340420722961426

iterator 2400, D_Loss:0.4208190143108368, G_Loss:7.747218608856201

iterator 2500, D_Loss:0.42380982637405396, G_Loss:13.848520278930664

iterator 2600, D_Loss:0.4067896902561188, G_Loss:12.170646667480469

iterator 2700, D_Loss:0.4193938970565796, G_Loss:10.024713516235352

iterator 2800, D_Loss:0.4312690496444702, G_Loss:11.279563903808594

iterator 2900, D_Loss:0.44832107424736023, G_Loss:11.76344108581543

iterator 3000, D_Loss:0.4486731290817261, G_Loss:13.13835334777832

iterator 3100, D_Loss:0.43938973546028137, G_Loss:12.379265785217285

iterator 3200, D_Loss:0.4333473742008209, G_Loss:10.005958557128906

iterator 3300, D_Loss:0.4283636808395386, G_Loss:11.630634307861328

iterator 3400, D_Loss:0.43633243441581726, G_Loss:10.892802238464355

iterator 3500, D_Loss:0.43089982867240906, G_Loss:12.313246726989746

iterator 3600, D_Loss:0.4325658679008484, G_Loss:10.716804504394531

iterator 3700, D_Loss:0.41451576352119446, G_Loss:14.147015571594238

iterator 3800, D_Loss:0.40514877438545227, G_Loss:12.348201751708984

iterator 3900, D_Loss:0.4226883053779602, G_Loss:13.011371612548828

iterator 4000, D_Loss:0.4249895215034485, G_Loss:11.952791213989258

iterator 4100, D_Loss:0.4083038568496704, G_Loss:10.886960983276367

iterator 4200, D_Loss:0.42036205530166626, G_Loss:12.21162223815918

iterator 4300, D_Loss:0.42555782198905945, G_Loss:12.33413028717041

iterator 4400, D_Loss:0.4207616448402405, G_Loss:12.723876953125

iterator 4500, D_Loss:0.43287554383277893, G_Loss:14.769542694091797

iterator 4600, D_Loss:0.4190523028373718, G_Loss:15.600554466247559

iterator 4700, D_Loss:0.41342586278915405, G_Loss:14.339143753051758

iterator 4800, D_Loss:0.44790980219841003, G_Loss:12.424662590026855

iterator 4900, D_Loss:0.43760955333709717, G_Loss:13.554572105407715

iterator 5000, D_Loss:0.40197718143463135, G_Loss:14.352716445922852

-----------Epoch 6-----------
iterator 100, D_Loss:0.4239642024040222, G_Loss:17.270158767700195

iterator 200, D_Loss:0.3987109065055847, G_Loss:14.833211898803711

iterator 300, D_Loss:0.45763099193573, G_Loss:15.426071166992188

iterator 400, D_Loss:0.4289495050907135, G_Loss:15.943167686462402

iterator 500, D_Loss:0.4211689829826355, G_Loss:15.896385192871094

iterator 600, D_Loss:0.40403029322624207, G_Loss:13.697036743164062

iterator 700, D_Loss:0.42654895782470703, G_Loss:14.854816436767578

iterator 800, D_Loss:0.42845186591148376, G_Loss:15.237372398376465

iterator 900, D_Loss:0.4266551434993744, G_Loss:14.943270683288574

iterator 1000, D_Loss:0.40281516313552856, G_Loss:14.165750503540039

iterator 1100, D_Loss:0.43136584758758545, G_Loss:13.867656707763672

iterator 1200, D_Loss:0.4219090938568115, G_Loss:15.10875129699707

iterator 1300, D_Loss:0.3999817669391632, G_Loss:15.485107421875

iterator 1400, D_Loss:0.4292468726634979, G_Loss:14.75905704498291

iterator 1500, D_Loss:0.42988383769989014, G_Loss:13.691106796264648

iterator 1600, D_Loss:0.43844956159591675, G_Loss:15.475382804870605

iterator 1700, D_Loss:0.3966135084629059, G_Loss:11.047139167785645

iterator 1800, D_Loss:0.39547526836395264, G_Loss:14.043909072875977

iterator 1900, D_Loss:0.43829479813575745, G_Loss:14.76646614074707

iterator 2000, D_Loss:0.4349175989627838, G_Loss:15.584396362304688

iterator 2100, D_Loss:0.42960289120674133, G_Loss:13.881536483764648

iterator 2200, D_Loss:0.44000664353370667, G_Loss:15.471586227416992

iterator 2300, D_Loss:0.436441034078598, G_Loss:14.191401481628418

iterator 2400, D_Loss:0.4078561067581177, G_Loss:12.523008346557617

iterator 2500, D_Loss:0.4035760164260864, G_Loss:14.195077896118164

iterator 2600, D_Loss:0.4036049544811249, G_Loss:12.642975807189941

iterator 2700, D_Loss:0.3939458429813385, G_Loss:16.080690383911133

iterator 2800, D_Loss:0.43122631311416626, G_Loss:14.421730041503906

iterator 2900, D_Loss:0.42862939834594727, G_Loss:15.900074005126953

iterator 3000, D_Loss:0.4173103868961334, G_Loss:16.33039093017578

iterator 3100, D_Loss:0.3932393491268158, G_Loss:16.108041763305664

iterator 3200, D_Loss:0.4376768469810486, G_Loss:14.444940567016602

iterator 3300, D_Loss:0.4150882661342621, G_Loss:15.192963600158691

iterator 3400, D_Loss:0.4301322400569916, G_Loss:15.695728302001953

iterator 3500, D_Loss:0.4066293239593506, G_Loss:14.522622108459473

iterator 3600, D_Loss:0.4422401785850525, G_Loss:15.138201713562012

iterator 3700, D_Loss:0.40680885314941406, G_Loss:16.178794860839844

iterator 3800, D_Loss:0.42147985100746155, G_Loss:15.510252952575684

iterator 3900, D_Loss:0.4334523677825928, G_Loss:13.637676239013672

iterator 4000, D_Loss:0.4035409390926361, G_Loss:14.85732650756836

iterator 4100, D_Loss:0.4180760979652405, G_Loss:14.343559265136719

iterator 4200, D_Loss:0.4022004306316376, G_Loss:14.676568984985352

iterator 4300, D_Loss:0.4141749143600464, G_Loss:16.733604431152344

iterator 4400, D_Loss:0.4275960326194763, G_Loss:14.547492980957031

iterator 4500, D_Loss:0.42463672161102295, G_Loss:16.995515823364258

iterator 4600, D_Loss:0.4499601423740387, G_Loss:14.889708518981934

iterator 4700, D_Loss:0.43250200152397156, G_Loss:16.331104278564453

iterator 4800, D_Loss:0.4196137487888336, G_Loss:17.268064498901367

iterator 4900, D_Loss:0.46706464886665344, G_Loss:18.3443660736084

iterator 5000, D_Loss:0.4194205403327942, G_Loss:16.70159149169922

-----------Epoch 7-----------
iterator 100, D_Loss:0.428592711687088, G_Loss:17.11832046508789

iterator 200, D_Loss:0.4117211699485779, G_Loss:15.345444679260254

iterator 300, D_Loss:0.4029105007648468, G_Loss:15.988038063049316

iterator 400, D_Loss:0.4040115475654602, G_Loss:13.531415939331055

iterator 500, D_Loss:0.4306723177433014, G_Loss:17.584514617919922

iterator 600, D_Loss:0.4339371621608734, G_Loss:14.500770568847656

iterator 700, D_Loss:0.4509120583534241, G_Loss:13.74582576751709

iterator 800, D_Loss:0.4280587434768677, G_Loss:15.664587020874023

iterator 900, D_Loss:0.4201829135417938, G_Loss:17.05887794494629

iterator 1000, D_Loss:0.4192095994949341, G_Loss:14.818891525268555

iterator 1100, D_Loss:0.4393407106399536, G_Loss:15.344165802001953

iterator 1200, D_Loss:0.448411226272583, G_Loss:15.6497220993042

iterator 1300, D_Loss:0.4210410416126251, G_Loss:15.491928100585938

iterator 1400, D_Loss:0.41763538122177124, G_Loss:16.67790985107422

iterator 1500, D_Loss:0.41388070583343506, G_Loss:15.371602058410645

iterator 1600, D_Loss:0.41661420464515686, G_Loss:16.274700164794922

iterator 1700, D_Loss:0.4168093502521515, G_Loss:16.376970291137695

iterator 1800, D_Loss:0.42088422179222107, G_Loss:15.365056037902832

iterator 1900, D_Loss:0.42306381464004517, G_Loss:14.811882019042969

iterator 2000, D_Loss:0.40772369503974915, G_Loss:15.770198822021484

iterator 2100, D_Loss:0.4103555679321289, G_Loss:15.340587615966797

iterator 2200, D_Loss:0.4459081292152405, G_Loss:14.563338279724121

iterator 2300, D_Loss:0.427769273519516, G_Loss:14.530204772949219

iterator 2400, D_Loss:0.44476649165153503, G_Loss:10.832820892333984

iterator 2500, D_Loss:0.4259048402309418, G_Loss:16.138914108276367

iterator 2600, D_Loss:0.4405688941478729, G_Loss:14.470818519592285

iterator 2700, D_Loss:0.41905608773231506, G_Loss:17.124284744262695

iterator 2800, D_Loss:0.43115705251693726, G_Loss:13.786036491394043

iterator 2900, D_Loss:0.4410668611526489, G_Loss:14.275495529174805

iterator 3000, D_Loss:0.41433677077293396, G_Loss:13.172937393188477

iterator 3100, D_Loss:0.42693892121315, G_Loss:16.861045837402344

iterator 3200, D_Loss:0.4268869459629059, G_Loss:13.866500854492188

iterator 3300, D_Loss:0.4153077006340027, G_Loss:16.025232315063477

iterator 3400, D_Loss:0.40102478861808777, G_Loss:19.692855834960938

iterator 3500, D_Loss:0.43458834290504456, G_Loss:19.250619888305664

iterator 3600, D_Loss:0.4315260648727417, G_Loss:17.053556442260742

iterator 3700, D_Loss:0.4511491060256958, G_Loss:18.615697860717773

iterator 3800, D_Loss:0.4202519953250885, G_Loss:16.2344970703125

iterator 3900, D_Loss:0.45953884720802307, G_Loss:16.939664840698242

iterator 4000, D_Loss:0.4400774836540222, G_Loss:14.049178123474121

iterator 4100, D_Loss:0.4222481846809387, G_Loss:16.611148834228516

iterator 4200, D_Loss:0.4411582946777344, G_Loss:17.728357315063477

iterator 4300, D_Loss:0.4422507882118225, G_Loss:18.753705978393555

iterator 4400, D_Loss:0.4611835479736328, G_Loss:18.055845260620117

iterator 4500, D_Loss:0.41502752900123596, G_Loss:18.179508209228516

iterator 4600, D_Loss:0.42634502053260803, G_Loss:15.063322067260742

iterator 4700, D_Loss:0.4285659193992615, G_Loss:18.52712631225586

iterator 4800, D_Loss:0.4350758194923401, G_Loss:17.845012664794922

iterator 4900, D_Loss:0.4595474898815155, G_Loss:16.562763214111328

iterator 5000, D_Loss:0.41624778509140015, G_Loss:18.74118995666504

-----------Epoch 8-----------
iterator 100, D_Loss:0.44112101197242737, G_Loss:19.39168357849121

iterator 200, D_Loss:0.42013972997665405, G_Loss:18.352455139160156

iterator 300, D_Loss:0.41801348328590393, G_Loss:16.765209197998047

iterator 400, D_Loss:0.4140777885913849, G_Loss:16.953855514526367

iterator 500, D_Loss:0.45279374718666077, G_Loss:17.37745475769043

iterator 600, D_Loss:0.4213390350341797, G_Loss:17.38888168334961

iterator 700, D_Loss:0.41836822032928467, G_Loss:17.277509689331055

iterator 800, D_Loss:0.43278831243515015, G_Loss:17.049694061279297

iterator 900, D_Loss:0.4444762170314789, G_Loss:17.07697868347168

iterator 1000, D_Loss:0.42336443066596985, G_Loss:17.55609703063965

iterator 1100, D_Loss:0.3952895700931549, G_Loss:16.94098663330078

iterator 1200, D_Loss:0.45349550247192383, G_Loss:14.245941162109375

iterator 1300, D_Loss:0.4400901198387146, G_Loss:17.163801193237305

iterator 1400, D_Loss:0.4058965742588043, G_Loss:16.466482162475586

iterator 1500, D_Loss:0.4142581820487976, G_Loss:18.14447784423828

iterator 1600, D_Loss:0.42452165484428406, G_Loss:15.910470008850098

iterator 1700, D_Loss:0.4402267634868622, G_Loss:17.06789779663086

iterator 1800, D_Loss:0.4088623523712158, G_Loss:16.48335075378418

iterator 1900, D_Loss:0.41784727573394775, G_Loss:15.732669830322266

iterator 2000, D_Loss:0.4233635663986206, G_Loss:15.398263931274414

iterator 2100, D_Loss:0.40071341395378113, G_Loss:17.610881805419922

iterator 2200, D_Loss:0.44394317269325256, G_Loss:15.017900466918945

iterator 2300, D_Loss:0.43469732999801636, G_Loss:14.74267864227295

iterator 2400, D_Loss:0.42421114444732666, G_Loss:14.59083080291748

iterator 2500, D_Loss:0.4384021759033203, G_Loss:15.431440353393555

iterator 2600, D_Loss:0.40256184339523315, G_Loss:15.618535041809082

iterator 2700, D_Loss:0.41261836886405945, G_Loss:12.74330997467041

iterator 2800, D_Loss:0.4257473945617676, G_Loss:15.328506469726562

iterator 2900, D_Loss:0.43683311343193054, G_Loss:13.1038818359375

iterator 3000, D_Loss:0.4119580090045929, G_Loss:14.788453102111816

iterator 3100, D_Loss:0.4177308976650238, G_Loss:16.764789581298828

iterator 3200, D_Loss:0.41767066717147827, G_Loss:16.105375289916992

iterator 3300, D_Loss:0.4235454499721527, G_Loss:16.71642303466797

iterator 3400, D_Loss:0.41591230034828186, G_Loss:15.567870140075684

iterator 3500, D_Loss:0.4222073554992676, G_Loss:13.772686958312988

iterator 3600, D_Loss:0.4308425188064575, G_Loss:11.649160385131836

iterator 3700, D_Loss:0.4248766303062439, G_Loss:14.849154472351074

iterator 3800, D_Loss:0.4278210401535034, G_Loss:10.606867790222168

iterator 3900, D_Loss:0.40571004152297974, G_Loss:12.121915817260742

iterator 4000, D_Loss:0.4405015707015991, G_Loss:12.942325592041016

iterator 4100, D_Loss:0.43632298707962036, G_Loss:13.972999572753906

iterator 4200, D_Loss:0.4264482855796814, G_Loss:12.427234649658203

iterator 4300, D_Loss:0.42468923330307007, G_Loss:14.99062728881836

iterator 4400, D_Loss:0.44410985708236694, G_Loss:15.241717338562012

iterator 4500, D_Loss:0.43090859055519104, G_Loss:14.298870086669922

iterator 4600, D_Loss:0.4292954206466675, G_Loss:14.72406005859375

iterator 4700, D_Loss:0.4318966567516327, G_Loss:17.076730728149414

iterator 4800, D_Loss:0.3973958492279053, G_Loss:16.75341033935547

iterator 4900, D_Loss:0.4258057475090027, G_Loss:16.07529640197754

iterator 5000, D_Loss:0.4495749771595001, G_Loss:13.850235939025879

-----------Epoch 9-----------
iterator 100, D_Loss:0.4094772934913635, G_Loss:16.262290954589844

iterator 200, D_Loss:0.4205292761325836, G_Loss:11.299408912658691

iterator 300, D_Loss:0.40259018540382385, G_Loss:15.559301376342773

iterator 400, D_Loss:0.4101111888885498, G_Loss:15.3162841796875

iterator 500, D_Loss:0.4171372950077057, G_Loss:16.683469772338867

iterator 600, D_Loss:0.432620108127594, G_Loss:14.646345138549805

iterator 700, D_Loss:0.41952991485595703, G_Loss:14.2335844039917

iterator 800, D_Loss:0.40425756573677063, G_Loss:14.490767478942871

iterator 900, D_Loss:0.4496494233608246, G_Loss:13.855925559997559

iterator 1000, D_Loss:0.41633081436157227, G_Loss:12.642647743225098

iterator 1100, D_Loss:0.42448824644088745, G_Loss:12.888625144958496

iterator 1200, D_Loss:0.42162826657295227, G_Loss:16.882083892822266

iterator 1300, D_Loss:0.42032119631767273, G_Loss:16.50706672668457

iterator 1400, D_Loss:0.42236337065696716, G_Loss:15.276065826416016

iterator 1500, D_Loss:0.43839141726493835, G_Loss:15.74024486541748

iterator 1600, D_Loss:0.43054822087287903, G_Loss:16.589515686035156

iterator 1700, D_Loss:0.41746678948402405, G_Loss:14.363327026367188

iterator 1800, D_Loss:0.43746426701545715, G_Loss:13.353747367858887

iterator 1900, D_Loss:0.42065614461898804, G_Loss:14.861021041870117

iterator 2000, D_Loss:0.42921170592308044, G_Loss:15.892709732055664

iterator 2100, D_Loss:0.4183643162250519, G_Loss:16.923606872558594

iterator 2200, D_Loss:0.4074103534221649, G_Loss:16.128740310668945

iterator 2300, D_Loss:0.42814984917640686, G_Loss:16.064077377319336

iterator 2400, D_Loss:0.4205012917518616, G_Loss:15.543957710266113

iterator 2500, D_Loss:0.42210590839385986, G_Loss:14.846223831176758

iterator 2600, D_Loss:0.41630035638809204, G_Loss:15.30082893371582

iterator 2700, D_Loss:0.45101600885391235, G_Loss:14.179141998291016

iterator 2800, D_Loss:0.4157335162162781, G_Loss:14.728182792663574

iterator 2900, D_Loss:0.4364685118198395, G_Loss:18.003690719604492

iterator 3000, D_Loss:0.44292521476745605, G_Loss:15.394538879394531

iterator 3100, D_Loss:0.4432319700717926, G_Loss:15.730456352233887

iterator 3200, D_Loss:0.41538211703300476, G_Loss:15.716585159301758

iterator 3300, D_Loss:0.421770840883255, G_Loss:16.443111419677734

iterator 3400, D_Loss:0.39796432852745056, G_Loss:15.484430313110352

iterator 3500, D_Loss:0.41914793848991394, G_Loss:15.231649398803711

iterator 3600, D_Loss:0.44976192712783813, G_Loss:15.708970069885254

iterator 3700, D_Loss:0.45291048288345337, G_Loss:11.493252754211426

iterator 3800, D_Loss:0.4364597499370575, G_Loss:15.0225248336792

iterator 3900, D_Loss:0.41461795568466187, G_Loss:13.419182777404785

iterator 4000, D_Loss:0.4193250834941864, G_Loss:14.110777854919434

iterator 4100, D_Loss:0.4028732180595398, G_Loss:13.166054725646973

iterator 4200, D_Loss:0.43960973620414734, G_Loss:14.533059120178223

iterator 4300, D_Loss:0.4334172010421753, G_Loss:14.853714942932129

iterator 4400, D_Loss:0.45560920238494873, G_Loss:12.628535270690918

iterator 4500, D_Loss:0.43302205204963684, G_Loss:14.442304611206055

iterator 4600, D_Loss:0.40758076310157776, G_Loss:13.04853343963623

iterator 4700, D_Loss:0.41290605068206787, G_Loss:13.496082305908203

iterator 4800, D_Loss:0.42212074995040894, G_Loss:14.984495162963867

iterator 4900, D_Loss:0.41335615515708923, G_Loss:13.765342712402344

iterator 5000, D_Loss:0.44975438714027405, G_Loss:14.107461929321289

LGAN_generator(
  (LSTM): LSTMCell(300, 400)
  (gmfc00): Linear(in_features=200, out_features=1, bias=True)
  (gmfc01): Linear(in_features=200, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=200, bias=True)
  (gmfe00): Linear(in_features=400, out_features=200, bias=True)
  (gmfe01): Linear(in_features=400, out_features=200, bias=True)
  (fc10): Linear(in_features=200, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=200, bias=True)
  (fe1): Linear(in_features=400, out_features=200, bias=True)
  (gmfc20): Linear(in_features=200, out_features=1, bias=True)
  (gmfc21): Linear(in_features=200, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=200, bias=True)
  (gmfe20): Linear(in_features=400, out_features=200, bias=True)
  (gmfe21): Linear(in_features=400, out_features=200, bias=True)
  (fc30): Linear(in_features=200, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=200, bias=True)
  (fe3): Linear(in_features=400, out_features=200, bias=True)
  (gmfc40): Linear(in_features=200, out_features=1, bias=True)
  (gmfc41): Linear(in_features=200, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=200, bias=True)
  (gmfe40): Linear(in_features=400, out_features=200, bias=True)
  (gmfe41): Linear(in_features=400, out_features=200, bias=True)
  (fc50): Linear(in_features=200, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=200, bias=True)
  (fe5): Linear(in_features=400, out_features=200, bias=True)
  (fc60): Linear(in_features=200, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=200, bias=True)
  (fe6): Linear(in_features=400, out_features=200, bias=True)
  (fc70): Linear(in_features=200, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=200, bias=True)
  (fe7): Linear(in_features=400, out_features=200, bias=True)
  (fc80): Linear(in_features=200, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=200, bias=True)
  (fe8): Linear(in_features=400, out_features=200, bias=True)
  (fc90): Linear(in_features=200, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=200, bias=True)
  (fe9): Linear(in_features=400, out_features=200, bias=True)
  (gmfc100): Linear(in_features=200, out_features=1, bias=True)
  (gmfc101): Linear(in_features=200, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=200, bias=True)
  (gmfe100): Linear(in_features=400, out_features=200, bias=True)
  (gmfe101): Linear(in_features=400, out_features=200, bias=True)
  (gmfc110): Linear(in_features=200, out_features=1, bias=True)
  (gmfc111): Linear(in_features=200, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=200, bias=True)
  (gmfe110): Linear(in_features=400, out_features=200, bias=True)
  (gmfe111): Linear(in_features=400, out_features=200, bias=True)
  (gmfc120): Linear(in_features=200, out_features=1, bias=True)
  (gmfc121): Linear(in_features=200, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=200, bias=True)
  (gmfe120): Linear(in_features=400, out_features=200, bias=True)
  (gmfe121): Linear(in_features=400, out_features=200, bias=True)
  (fc130): Linear(in_features=200, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=200, bias=True)
  (fe13): Linear(in_features=400, out_features=200, bias=True)
  (fc140): Linear(in_features=200, out_features=2, bias=True)
  (fc141): Linear(in_features=2, out_features=200, bias=True)
  (fe14): Linear(in_features=400, out_features=200, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=200, bias=True)
  (inputbn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (bn0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=200, out_features=200, bias=True)
  (bn1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=200, out_features=200, bias=True)
  (bn2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=200, out_features=1, bias=True)
)
(0, False, 135)
-----------Epoch 0-----------
iterator 100, D_Loss:1.4175366163253784, G_Loss:0.9100823402404785

iterator 200, D_Loss:1.4006874561309814, G_Loss:0.9302290081977844

iterator 300, D_Loss:1.403992772102356, G_Loss:0.909889817237854

iterator 400, D_Loss:1.3939138650894165, G_Loss:0.8970764875411987

iterator 500, D_Loss:1.3753044605255127, G_Loss:0.9140807390213013

iterator 600, D_Loss:1.3817776441574097, G_Loss:0.9148368835449219

iterator 700, D_Loss:1.3966084718704224, G_Loss:0.9201776385307312

iterator 800, D_Loss:1.3766777515411377, G_Loss:0.9569007754325867

iterator 900, D_Loss:1.3697630167007446, G_Loss:0.9161176681518555

iterator 1000, D_Loss:1.3655059337615967, G_Loss:0.9037509560585022

iterator 1100, D_Loss:1.3628759384155273, G_Loss:0.9010748863220215

iterator 1200, D_Loss:1.3673592805862427, G_Loss:0.9027947783470154

iterator 1300, D_Loss:1.3771339654922485, G_Loss:0.9324120283126831

iterator 1400, D_Loss:1.3555407524108887, G_Loss:0.9403578042984009

iterator 1500, D_Loss:1.3411139249801636, G_Loss:0.9825583696365356

iterator 1600, D_Loss:1.376741886138916, G_Loss:0.9376775026321411

iterator 1700, D_Loss:1.3558812141418457, G_Loss:0.8830892443656921

iterator 1800, D_Loss:1.365173101425171, G_Loss:0.8929844498634338

iterator 1900, D_Loss:1.351198434829712, G_Loss:0.9587478637695312

iterator 2000, D_Loss:1.3694932460784912, G_Loss:0.9663682579994202

iterator 2100, D_Loss:1.3719477653503418, G_Loss:1.0086547136306763

iterator 2200, D_Loss:1.3683714866638184, G_Loss:0.9522867202758789

iterator 2300, D_Loss:1.3550410270690918, G_Loss:0.9594566822052002

iterator 2400, D_Loss:1.3602380752563477, G_Loss:0.9307226538658142

iterator 2500, D_Loss:1.3454197645187378, G_Loss:0.957044780254364

iterator 2600, D_Loss:1.3493733406066895, G_Loss:0.9298378825187683

iterator 2700, D_Loss:1.3663032054901123, G_Loss:0.9506601095199585

iterator 2800, D_Loss:1.3604947328567505, G_Loss:0.916123628616333

iterator 2900, D_Loss:1.3517231941223145, G_Loss:0.9474228024482727

iterator 3000, D_Loss:1.3584611415863037, G_Loss:0.9664936661720276

iterator 3100, D_Loss:1.3378723859786987, G_Loss:0.9561607837677002

iterator 3200, D_Loss:1.364050030708313, G_Loss:0.9294630289077759

iterator 3300, D_Loss:1.3435277938842773, G_Loss:0.9465374946594238

iterator 3400, D_Loss:1.3594437837600708, G_Loss:0.921588659286499

iterator 3500, D_Loss:1.3515417575836182, G_Loss:0.9792719483375549

iterator 3600, D_Loss:1.313464879989624, G_Loss:0.9718490242958069

iterator 3700, D_Loss:1.2852084636688232, G_Loss:1.0410183668136597

iterator 3800, D_Loss:1.299500584602356, G_Loss:1.1350657939910889

iterator 3900, D_Loss:1.2447681427001953, G_Loss:0.9985377788543701

iterator 4000, D_Loss:1.2087843418121338, G_Loss:1.165203332901001

iterator 4100, D_Loss:1.183337688446045, G_Loss:1.2954678535461426

iterator 4200, D_Loss:1.048187494277954, G_Loss:1.527374505996704

iterator 4300, D_Loss:0.9745728969573975, G_Loss:1.6913291215896606

iterator 4400, D_Loss:0.8222355842590332, G_Loss:1.8283194303512573

iterator 4500, D_Loss:0.9232117533683777, G_Loss:2.135159969329834

iterator 4600, D_Loss:0.8012478351593018, G_Loss:2.0826356410980225

iterator 4700, D_Loss:0.7778608798980713, G_Loss:2.2930335998535156

iterator 4800, D_Loss:0.6968842148780823, G_Loss:2.485438108444214

iterator 4900, D_Loss:0.6701375246047974, G_Loss:2.4269304275512695

iterator 5000, D_Loss:0.6453738212585449, G_Loss:2.2038819789886475

-----------Epoch 1-----------
iterator 100, D_Loss:0.6429426670074463, G_Loss:2.727766990661621

iterator 200, D_Loss:0.6476488709449768, G_Loss:2.6803762912750244

iterator 300, D_Loss:0.5820479989051819, G_Loss:3.0430238246917725

iterator 400, D_Loss:0.5942745208740234, G_Loss:2.9591903686523438

iterator 500, D_Loss:0.5916787385940552, G_Loss:2.896688461303711

iterator 600, D_Loss:0.5504229068756104, G_Loss:3.3805620670318604

iterator 700, D_Loss:0.546973466873169, G_Loss:3.411195755004883

iterator 800, D_Loss:0.5673552751541138, G_Loss:3.3716084957122803

iterator 900, D_Loss:1.4485939741134644, G_Loss:0.889382541179657

iterator 1000, D_Loss:1.1354098320007324, G_Loss:1.719609260559082

iterator 1100, D_Loss:0.7691531181335449, G_Loss:2.421196222305298

iterator 1200, D_Loss:1.0920385122299194, G_Loss:2.589637041091919

iterator 1300, D_Loss:0.6656997799873352, G_Loss:2.0748863220214844

iterator 1400, D_Loss:0.678946852684021, G_Loss:3.025108575820923

iterator 1500, D_Loss:0.8867994546890259, G_Loss:3.3007845878601074

iterator 1600, D_Loss:0.7134044766426086, G_Loss:2.0982909202575684

iterator 1700, D_Loss:0.7938413619995117, G_Loss:3.3918325901031494

iterator 1800, D_Loss:0.7334487438201904, G_Loss:2.105987071990967

iterator 1900, D_Loss:0.7216708064079285, G_Loss:3.091559410095215

iterator 2000, D_Loss:0.9894106388092041, G_Loss:2.7861616611480713

iterator 2100, D_Loss:0.5984856486320496, G_Loss:3.0980165004730225

iterator 2200, D_Loss:1.12345290184021, G_Loss:2.6080193519592285

iterator 2300, D_Loss:1.0976313352584839, G_Loss:2.202841281890869

iterator 2400, D_Loss:0.7669676542282104, G_Loss:3.0411264896392822

iterator 2500, D_Loss:1.073871374130249, G_Loss:1.109444260597229

iterator 2600, D_Loss:1.0810805559158325, G_Loss:1.5500670671463013

iterator 2700, D_Loss:0.9739264249801636, G_Loss:2.468313694000244

iterator 2800, D_Loss:0.9525397419929504, G_Loss:2.1038169860839844

iterator 2900, D_Loss:1.0503535270690918, G_Loss:2.175320625305176

iterator 3000, D_Loss:0.8976868391036987, G_Loss:1.9643912315368652

iterator 3100, D_Loss:1.0072827339172363, G_Loss:2.88360595703125

iterator 3200, D_Loss:1.0632662773132324, G_Loss:1.9671159982681274

iterator 3300, D_Loss:0.8966548442840576, G_Loss:2.637702226638794

iterator 3400, D_Loss:1.393218755722046, G_Loss:1.7017322778701782

iterator 3500, D_Loss:1.0512243509292603, G_Loss:2.38334584236145

iterator 3600, D_Loss:1.2410532236099243, G_Loss:2.4489893913269043

iterator 3700, D_Loss:0.8567215204238892, G_Loss:3.102134943008423

iterator 3800, D_Loss:0.6756059527397156, G_Loss:2.078505039215088

iterator 3900, D_Loss:0.825354278087616, G_Loss:1.260224461555481

iterator 4000, D_Loss:0.7828054428100586, G_Loss:3.0709750652313232

iterator 4100, D_Loss:0.9536893367767334, G_Loss:2.664241075515747

iterator 4200, D_Loss:0.9573918581008911, G_Loss:1.6576191186904907

iterator 4300, D_Loss:0.9919552803039551, G_Loss:2.1571829319000244

iterator 4400, D_Loss:0.9465873837471008, G_Loss:3.4645519256591797

iterator 4500, D_Loss:1.114363193511963, G_Loss:1.5204559564590454

iterator 4600, D_Loss:1.0132936239242554, G_Loss:2.4370229244232178

iterator 4700, D_Loss:0.7092134356498718, G_Loss:2.8046162128448486

iterator 4800, D_Loss:0.8565158247947693, G_Loss:2.304219961166382

iterator 4900, D_Loss:1.1410727500915527, G_Loss:3.1608142852783203

iterator 5000, D_Loss:1.003796100616455, G_Loss:1.4182398319244385

-----------Epoch 2-----------
iterator 100, D_Loss:0.8119779229164124, G_Loss:3.97306489944458

iterator 200, D_Loss:0.6894999742507935, G_Loss:1.7270736694335938

iterator 300, D_Loss:0.7916485071182251, G_Loss:1.6051065921783447

iterator 400, D_Loss:0.7951430082321167, G_Loss:2.366010904312134

iterator 500, D_Loss:0.8943004608154297, G_Loss:2.849682331085205

iterator 600, D_Loss:0.6790341138839722, G_Loss:2.487384796142578

iterator 700, D_Loss:0.6843075752258301, G_Loss:3.4293274879455566

iterator 800, D_Loss:0.8108463287353516, G_Loss:1.8493338823318481

iterator 900, D_Loss:0.5504568219184875, G_Loss:3.7394824028015137

iterator 1000, D_Loss:0.7986095547676086, G_Loss:3.3470184803009033

iterator 1100, D_Loss:0.6492457389831543, G_Loss:3.390390396118164

iterator 1200, D_Loss:0.6311742663383484, G_Loss:4.822926998138428

iterator 1300, D_Loss:0.9496380090713501, G_Loss:3.2811341285705566

iterator 1400, D_Loss:0.5759484767913818, G_Loss:4.028536319732666

iterator 1500, D_Loss:0.6534156799316406, G_Loss:3.563744068145752

iterator 1600, D_Loss:0.6171439290046692, G_Loss:3.979661703109741

iterator 1700, D_Loss:0.6661486625671387, G_Loss:3.1769516468048096

iterator 1800, D_Loss:0.6426123380661011, G_Loss:4.9264607429504395

iterator 1900, D_Loss:0.504668653011322, G_Loss:3.162707805633545

iterator 2000, D_Loss:0.5823488831520081, G_Loss:4.470288276672363

iterator 2100, D_Loss:0.5284121036529541, G_Loss:3.8396923542022705

iterator 2200, D_Loss:0.6272445321083069, G_Loss:3.4572439193725586

iterator 2300, D_Loss:0.5499218106269836, G_Loss:3.978083848953247

iterator 2400, D_Loss:0.5486025214195251, G_Loss:3.0852081775665283

iterator 2500, D_Loss:0.5886857509613037, G_Loss:3.7929000854492188

iterator 2600, D_Loss:0.5847759246826172, G_Loss:5.181208610534668

iterator 2700, D_Loss:0.5371277928352356, G_Loss:4.948864936828613

iterator 2800, D_Loss:0.8980105519294739, G_Loss:2.2581787109375

iterator 2900, D_Loss:1.0849907398223877, G_Loss:3.4552245140075684

iterator 3000, D_Loss:0.7610636353492737, G_Loss:5.520966053009033

iterator 3100, D_Loss:0.9404231905937195, G_Loss:2.5275487899780273

iterator 3200, D_Loss:0.7559068202972412, G_Loss:3.07728910446167

iterator 3300, D_Loss:0.8154281377792358, G_Loss:3.4484646320343018

iterator 3400, D_Loss:0.9380866885185242, G_Loss:3.4702212810516357

iterator 3500, D_Loss:0.6490228176116943, G_Loss:3.068718910217285

iterator 3600, D_Loss:0.6235300302505493, G_Loss:1.7446036338806152

iterator 3700, D_Loss:0.8052458763122559, G_Loss:3.305384397506714

iterator 3800, D_Loss:0.6477063894271851, G_Loss:2.145049571990967

iterator 3900, D_Loss:0.8209601640701294, G_Loss:3.5162148475646973

iterator 4000, D_Loss:1.2898876667022705, G_Loss:1.4664863348007202

iterator 4100, D_Loss:1.4099475145339966, G_Loss:1.6733014583587646

iterator 4200, D_Loss:1.3131866455078125, G_Loss:2.959975242614746

iterator 4300, D_Loss:0.7600319385528564, G_Loss:1.717429518699646

iterator 4400, D_Loss:0.6861210465431213, G_Loss:1.8987687826156616

iterator 4500, D_Loss:0.8834246397018433, G_Loss:1.873002290725708

iterator 4600, D_Loss:1.0421897172927856, G_Loss:2.6775476932525635

iterator 4700, D_Loss:0.7704373598098755, G_Loss:3.4697139263153076

iterator 4800, D_Loss:0.7921966910362244, G_Loss:2.5206727981567383

iterator 4900, D_Loss:0.6299939751625061, G_Loss:2.8279809951782227

iterator 5000, D_Loss:0.7109564542770386, G_Loss:3.39758038520813

-----------Epoch 3-----------
iterator 100, D_Loss:0.803192138671875, G_Loss:1.365453839302063

iterator 200, D_Loss:0.7209835052490234, G_Loss:1.9692566394805908

iterator 300, D_Loss:0.6075759530067444, G_Loss:3.3998918533325195

iterator 400, D_Loss:0.5843507647514343, G_Loss:3.635385513305664

iterator 500, D_Loss:1.1264963150024414, G_Loss:3.431583881378174

iterator 600, D_Loss:0.6820574998855591, G_Loss:3.841488838195801

iterator 700, D_Loss:0.6271827220916748, G_Loss:3.3687291145324707

iterator 800, D_Loss:0.7768612504005432, G_Loss:2.4119632244110107

iterator 900, D_Loss:0.6344498991966248, G_Loss:3.721466064453125

iterator 1000, D_Loss:0.647101879119873, G_Loss:5.351031303405762

iterator 1100, D_Loss:0.5734902620315552, G_Loss:4.359691619873047

iterator 1200, D_Loss:0.7265889048576355, G_Loss:3.9699149131774902

iterator 1300, D_Loss:0.8486226797103882, G_Loss:2.84710693359375

iterator 1400, D_Loss:0.5798043012619019, G_Loss:3.250910520553589

iterator 1500, D_Loss:0.6524976491928101, G_Loss:1.971706748008728

iterator 1600, D_Loss:0.5930737257003784, G_Loss:2.621868133544922

iterator 1700, D_Loss:0.9532674551010132, G_Loss:2.5359597206115723

iterator 1800, D_Loss:0.7058104276657104, G_Loss:1.8065919876098633

iterator 1900, D_Loss:0.587285041809082, G_Loss:1.9034509658813477

iterator 2000, D_Loss:0.9773807525634766, G_Loss:3.2579848766326904

iterator 2100, D_Loss:0.6829922199249268, G_Loss:2.854759454727173

iterator 2200, D_Loss:1.2628755569458008, G_Loss:2.9412572383880615

iterator 2300, D_Loss:0.892980694770813, G_Loss:1.6986289024353027

iterator 2400, D_Loss:1.0771080255508423, G_Loss:2.0879743099212646

iterator 2500, D_Loss:0.501388669013977, G_Loss:3.0910701751708984

iterator 2600, D_Loss:0.6397076845169067, G_Loss:4.033118724822998

iterator 2700, D_Loss:0.6015069484710693, G_Loss:2.1943411827087402

iterator 2800, D_Loss:0.5931617021560669, G_Loss:3.2607386112213135

iterator 2900, D_Loss:0.5406439900398254, G_Loss:2.9761006832122803

iterator 3000, D_Loss:0.5828859806060791, G_Loss:4.157270431518555

iterator 3100, D_Loss:0.9322130680084229, G_Loss:4.073070049285889

iterator 3200, D_Loss:0.5256782174110413, G_Loss:4.991545677185059

iterator 3300, D_Loss:0.7531392574310303, G_Loss:3.11763334274292

iterator 3400, D_Loss:0.5180065035820007, G_Loss:3.8924131393432617

iterator 3500, D_Loss:0.8280953764915466, G_Loss:3.3458411693573

iterator 3600, D_Loss:0.5717587471008301, G_Loss:5.037093162536621

iterator 3700, D_Loss:0.561650276184082, G_Loss:3.9652793407440186

iterator 3800, D_Loss:0.5016944408416748, G_Loss:3.953550338745117

iterator 3900, D_Loss:0.5348401665687561, G_Loss:4.774309158325195

iterator 4000, D_Loss:0.5386864542961121, G_Loss:4.652669906616211

iterator 4100, D_Loss:0.4684303104877472, G_Loss:4.75278377532959

iterator 4200, D_Loss:0.5557908415794373, G_Loss:4.01998233795166

iterator 4300, D_Loss:0.883535623550415, G_Loss:5.191104412078857

iterator 4400, D_Loss:0.5291476845741272, G_Loss:6.802577495574951

iterator 4500, D_Loss:0.4801900386810303, G_Loss:5.868749618530273

iterator 4600, D_Loss:0.4976588487625122, G_Loss:6.137145519256592

iterator 4700, D_Loss:0.505734920501709, G_Loss:5.41867208480835

iterator 4800, D_Loss:0.5006945133209229, G_Loss:5.796419143676758

iterator 4900, D_Loss:0.4978799819946289, G_Loss:4.7099928855896

iterator 5000, D_Loss:0.5034677982330322, G_Loss:5.59441614151001

-----------Epoch 4-----------
iterator 100, D_Loss:0.4732709228992462, G_Loss:5.5608720779418945

iterator 200, D_Loss:0.5141516327857971, G_Loss:4.35878324508667

iterator 300, D_Loss:0.5047723054885864, G_Loss:4.600318908691406

iterator 400, D_Loss:0.5396623611450195, G_Loss:4.639653205871582

iterator 500, D_Loss:0.46787989139556885, G_Loss:4.264264106750488

iterator 600, D_Loss:0.466754287481308, G_Loss:4.5038604736328125

iterator 700, D_Loss:0.4604375958442688, G_Loss:6.04315185546875

iterator 800, D_Loss:0.47611814737319946, G_Loss:5.420781135559082

iterator 900, D_Loss:0.4559618830680847, G_Loss:5.858978271484375

iterator 1000, D_Loss:0.5103689432144165, G_Loss:4.314924716949463

iterator 1100, D_Loss:0.5203811526298523, G_Loss:5.440839767456055

iterator 1200, D_Loss:0.47873643040657043, G_Loss:7.026919364929199

iterator 1300, D_Loss:0.4563499093055725, G_Loss:6.092601299285889

iterator 1400, D_Loss:0.4788617491722107, G_Loss:7.016569137573242

iterator 1500, D_Loss:0.45474255084991455, G_Loss:4.97149658203125

iterator 1600, D_Loss:0.671414852142334, G_Loss:5.885385036468506

iterator 1700, D_Loss:0.4748508930206299, G_Loss:7.547117233276367

iterator 1800, D_Loss:0.42173293232917786, G_Loss:7.773733139038086

iterator 1900, D_Loss:0.4387057423591614, G_Loss:6.653229236602783

iterator 2000, D_Loss:0.44468721747398376, G_Loss:6.98280668258667

iterator 2100, D_Loss:0.45481443405151367, G_Loss:7.736046314239502

iterator 2200, D_Loss:0.45195716619491577, G_Loss:8.570237159729004

iterator 2300, D_Loss:0.44325217604637146, G_Loss:6.815442085266113

iterator 2400, D_Loss:0.4519462287425995, G_Loss:6.864138126373291

iterator 2500, D_Loss:0.47518521547317505, G_Loss:6.732078552246094

iterator 2600, D_Loss:0.45541417598724365, G_Loss:7.009987831115723

iterator 2700, D_Loss:0.47163963317871094, G_Loss:8.115462303161621

iterator 2800, D_Loss:0.4708336889743805, G_Loss:7.696931838989258

iterator 2900, D_Loss:0.49455446004867554, G_Loss:8.422457695007324

iterator 3000, D_Loss:0.5900209546089172, G_Loss:5.843177795410156

iterator 3100, D_Loss:0.5214616060256958, G_Loss:5.550705909729004

iterator 3200, D_Loss:0.6935644149780273, G_Loss:7.5594482421875

iterator 3300, D_Loss:0.5477081537246704, G_Loss:6.952535629272461

iterator 3400, D_Loss:0.4971057176589966, G_Loss:4.815972328186035

iterator 3500, D_Loss:0.5646317601203918, G_Loss:8.906612396240234

iterator 3600, D_Loss:0.4623263478279114, G_Loss:8.968400955200195

iterator 3700, D_Loss:0.5480514168739319, G_Loss:7.523707389831543

iterator 3800, D_Loss:0.5346451997756958, G_Loss:7.801170349121094

iterator 3900, D_Loss:0.5394865870475769, G_Loss:7.793310642242432

iterator 4000, D_Loss:0.4794560670852661, G_Loss:9.673649787902832

iterator 4100, D_Loss:0.4493022859096527, G_Loss:8.917013168334961

iterator 4200, D_Loss:0.573797345161438, G_Loss:9.015878677368164

iterator 4300, D_Loss:0.4680441617965698, G_Loss:8.044198036193848

iterator 4400, D_Loss:0.46969112753868103, G_Loss:5.984192848205566

iterator 4500, D_Loss:0.532674252986908, G_Loss:6.736821174621582

iterator 4600, D_Loss:0.48144325613975525, G_Loss:6.680271148681641

iterator 4700, D_Loss:0.46813058853149414, G_Loss:6.054773807525635

iterator 4800, D_Loss:0.492969810962677, G_Loss:7.920830249786377

iterator 4900, D_Loss:0.49211385846138, G_Loss:8.03398323059082

iterator 5000, D_Loss:0.5032904148101807, G_Loss:7.3161516189575195

-----------Epoch 5-----------
iterator 100, D_Loss:0.45720425248146057, G_Loss:9.044709205627441

iterator 200, D_Loss:0.45099836587905884, G_Loss:8.761457443237305

iterator 300, D_Loss:0.46991339325904846, G_Loss:6.875891208648682

iterator 400, D_Loss:0.43754127621650696, G_Loss:8.547348976135254

iterator 500, D_Loss:0.49203574657440186, G_Loss:4.506381988525391

iterator 600, D_Loss:0.47518038749694824, G_Loss:9.538459777832031

iterator 700, D_Loss:0.48801979422569275, G_Loss:7.897297382354736

iterator 800, D_Loss:0.4771748483181, G_Loss:8.336929321289062

iterator 900, D_Loss:0.4828220009803772, G_Loss:6.871063232421875

iterator 1000, D_Loss:0.5477397441864014, G_Loss:3.452125072479248

iterator 1100, D_Loss:0.5150846838951111, G_Loss:5.735999584197998

iterator 1200, D_Loss:0.4798028767108917, G_Loss:8.322074890136719

iterator 1300, D_Loss:0.4865303337574005, G_Loss:9.555438995361328

iterator 1400, D_Loss:0.42990779876708984, G_Loss:10.853801727294922

iterator 1500, D_Loss:0.459795743227005, G_Loss:7.559237480163574

iterator 1600, D_Loss:0.47218817472457886, G_Loss:8.515926361083984

iterator 1700, D_Loss:0.44956690073013306, G_Loss:9.048624038696289

iterator 1800, D_Loss:0.4664129316806793, G_Loss:7.5954742431640625

iterator 1900, D_Loss:0.4401489794254303, G_Loss:8.062276840209961

iterator 2000, D_Loss:0.44234499335289, G_Loss:10.135687828063965

iterator 2100, D_Loss:0.4469439685344696, G_Loss:8.462615013122559

iterator 2200, D_Loss:0.46465790271759033, G_Loss:8.735700607299805

iterator 2300, D_Loss:0.4670058488845825, G_Loss:7.9210405349731445

iterator 2400, D_Loss:0.47593000531196594, G_Loss:7.298591613769531

iterator 2500, D_Loss:0.589670717716217, G_Loss:7.102288246154785

iterator 2600, D_Loss:0.5202808976173401, G_Loss:3.640441417694092

iterator 2700, D_Loss:0.475486695766449, G_Loss:5.063316345214844

iterator 2800, D_Loss:0.512930154800415, G_Loss:4.278130531311035

iterator 2900, D_Loss:0.49801361560821533, G_Loss:7.095888614654541

iterator 3000, D_Loss:0.5562005043029785, G_Loss:6.29506778717041

iterator 3100, D_Loss:0.46004700660705566, G_Loss:4.887120246887207

iterator 3200, D_Loss:0.4650508463382721, G_Loss:7.229167938232422

iterator 3300, D_Loss:0.5125642418861389, G_Loss:7.868457794189453

iterator 3400, D_Loss:0.7403647303581238, G_Loss:5.574660301208496

iterator 3500, D_Loss:0.5496631860733032, G_Loss:8.071558952331543

iterator 3600, D_Loss:0.5291338562965393, G_Loss:8.828926086425781

iterator 3700, D_Loss:0.7115370631217957, G_Loss:6.766417026519775

iterator 3800, D_Loss:0.5655410289764404, G_Loss:5.378687858581543

iterator 3900, D_Loss:0.7317745685577393, G_Loss:4.864683151245117

iterator 4000, D_Loss:0.5242143869400024, G_Loss:5.599756240844727

iterator 4100, D_Loss:0.4790836274623871, G_Loss:7.962733268737793

iterator 4200, D_Loss:0.704716145992279, G_Loss:4.095354080200195

iterator 4300, D_Loss:0.6276701092720032, G_Loss:4.548260688781738

iterator 4400, D_Loss:0.5041229724884033, G_Loss:9.373830795288086

iterator 4500, D_Loss:0.4492107331752777, G_Loss:6.107597351074219

iterator 4600, D_Loss:0.5532146096229553, G_Loss:7.862646102905273

iterator 4700, D_Loss:0.6237877011299133, G_Loss:6.557284832000732

iterator 4800, D_Loss:0.504326343536377, G_Loss:4.913493633270264

iterator 4900, D_Loss:0.4372432231903076, G_Loss:7.370795726776123

iterator 5000, D_Loss:0.48740047216415405, G_Loss:4.808315753936768

-----------Epoch 6-----------
iterator 100, D_Loss:0.4744167923927307, G_Loss:7.756107330322266

iterator 200, D_Loss:0.5312888622283936, G_Loss:3.2802257537841797

iterator 300, D_Loss:0.5725180506706238, G_Loss:7.316808700561523

iterator 400, D_Loss:0.5048518776893616, G_Loss:7.145334720611572

iterator 500, D_Loss:0.4534871578216553, G_Loss:4.03792667388916

iterator 600, D_Loss:0.531290590763092, G_Loss:4.630794048309326

iterator 700, D_Loss:0.509198009967804, G_Loss:6.682861804962158

iterator 800, D_Loss:0.5310469269752502, G_Loss:7.552798748016357

iterator 900, D_Loss:0.5020506978034973, G_Loss:4.281241416931152

iterator 1000, D_Loss:0.6000573635101318, G_Loss:5.160640716552734

iterator 1100, D_Loss:0.5202130079269409, G_Loss:6.59677791595459

iterator 1200, D_Loss:0.5378854870796204, G_Loss:4.694923400878906

iterator 1300, D_Loss:0.5599061846733093, G_Loss:6.616425037384033

iterator 1400, D_Loss:0.5973430275917053, G_Loss:2.6276602745056152

iterator 1500, D_Loss:0.9535856246948242, G_Loss:5.948748588562012

iterator 1600, D_Loss:0.5534719228744507, G_Loss:5.716278076171875

iterator 1700, D_Loss:0.7692633867263794, G_Loss:4.649036407470703

iterator 1800, D_Loss:0.5235366225242615, G_Loss:5.293130874633789

iterator 1900, D_Loss:0.5867074131965637, G_Loss:6.615628719329834

iterator 2000, D_Loss:0.6993073225021362, G_Loss:4.303993225097656

iterator 2100, D_Loss:0.6006261110305786, G_Loss:5.239743709564209

iterator 2200, D_Loss:0.4720136821269989, G_Loss:4.826788902282715

iterator 2300, D_Loss:0.6779246926307678, G_Loss:7.916801929473877

iterator 2400, D_Loss:0.48585525155067444, G_Loss:6.8278093338012695

iterator 2500, D_Loss:0.5268362760543823, G_Loss:5.6396484375

iterator 2600, D_Loss:0.47172147035598755, G_Loss:4.486730575561523

iterator 2700, D_Loss:0.5043966174125671, G_Loss:5.9542365074157715

iterator 2800, D_Loss:0.5574121475219727, G_Loss:4.979421615600586

iterator 2900, D_Loss:0.6762844920158386, G_Loss:7.377182483673096

iterator 3000, D_Loss:0.5254505276679993, G_Loss:5.824099540710449

iterator 3100, D_Loss:0.4886094629764557, G_Loss:6.319961071014404

iterator 3200, D_Loss:0.6436775922775269, G_Loss:5.72047233581543

iterator 3300, D_Loss:0.4943420886993408, G_Loss:5.195659637451172

iterator 3400, D_Loss:0.5343924760818481, G_Loss:6.427391529083252

iterator 3500, D_Loss:0.45037731528282166, G_Loss:4.135112285614014

iterator 3600, D_Loss:0.4872313439846039, G_Loss:5.086304664611816

iterator 3700, D_Loss:0.5443624258041382, G_Loss:5.07035493850708

iterator 3800, D_Loss:0.4753111004829407, G_Loss:5.909487724304199

iterator 3900, D_Loss:0.48019328713417053, G_Loss:8.102375030517578

iterator 4000, D_Loss:0.4676870107650757, G_Loss:7.693289756774902

iterator 4100, D_Loss:0.5514534115791321, G_Loss:6.708648204803467

iterator 4200, D_Loss:0.549017071723938, G_Loss:8.039841651916504

iterator 4300, D_Loss:0.5168262124061584, G_Loss:11.4174222946167

iterator 4400, D_Loss:0.4464426338672638, G_Loss:10.08140754699707

iterator 4500, D_Loss:0.49008452892303467, G_Loss:7.628934860229492

iterator 4600, D_Loss:0.49822285771369934, G_Loss:6.2361159324646

iterator 4700, D_Loss:0.4562041461467743, G_Loss:5.096689224243164

iterator 4800, D_Loss:0.46377792954444885, G_Loss:8.975743293762207

iterator 4900, D_Loss:0.4612337052822113, G_Loss:9.355657577514648

iterator 5000, D_Loss:0.46105802059173584, G_Loss:10.912858963012695

-----------Epoch 7-----------
iterator 100, D_Loss:0.4576980173587799, G_Loss:6.237226486206055

iterator 200, D_Loss:0.520946204662323, G_Loss:5.222218036651611

iterator 300, D_Loss:0.4722959101200104, G_Loss:6.169734001159668

iterator 400, D_Loss:0.44948866963386536, G_Loss:5.343051910400391

iterator 500, D_Loss:0.44259896874427795, G_Loss:4.489874839782715

iterator 600, D_Loss:0.4628761410713196, G_Loss:4.746794700622559

iterator 700, D_Loss:0.47289377450942993, G_Loss:6.674030303955078

iterator 800, D_Loss:0.5631123185157776, G_Loss:6.734066486358643

iterator 900, D_Loss:0.6372332572937012, G_Loss:7.292068958282471

iterator 1000, D_Loss:0.49468374252319336, G_Loss:5.541277885437012

iterator 1100, D_Loss:0.5166202187538147, G_Loss:7.001084804534912

iterator 1200, D_Loss:0.43024343252182007, G_Loss:8.49019718170166

iterator 1300, D_Loss:0.48449230194091797, G_Loss:8.338932037353516

iterator 1400, D_Loss:0.4513307511806488, G_Loss:7.480657577514648

iterator 1500, D_Loss:0.5316707491874695, G_Loss:6.968667507171631

iterator 1600, D_Loss:0.4655647277832031, G_Loss:6.016544818878174

iterator 1700, D_Loss:0.47613728046417236, G_Loss:7.6898345947265625

iterator 1800, D_Loss:0.49304357171058655, G_Loss:7.540034294128418

iterator 1900, D_Loss:0.44324833154678345, G_Loss:7.466097831726074

iterator 2000, D_Loss:0.45490264892578125, G_Loss:4.86019229888916

iterator 2100, D_Loss:0.4593033790588379, G_Loss:8.624363899230957

iterator 2200, D_Loss:0.46264851093292236, G_Loss:7.872453689575195

iterator 2300, D_Loss:0.5408950448036194, G_Loss:6.409074783325195

iterator 2400, D_Loss:0.44224584102630615, G_Loss:9.422587394714355

iterator 2500, D_Loss:0.5065422058105469, G_Loss:5.987508773803711

iterator 2600, D_Loss:0.491112619638443, G_Loss:5.595252990722656

iterator 2700, D_Loss:0.6435317993164062, G_Loss:7.281311988830566

iterator 2800, D_Loss:0.4711029529571533, G_Loss:5.927626132965088

iterator 2900, D_Loss:0.44914114475250244, G_Loss:7.11175012588501

iterator 3000, D_Loss:0.4384647607803345, G_Loss:6.31505012512207

iterator 3100, D_Loss:0.4735580086708069, G_Loss:6.563938140869141

iterator 3200, D_Loss:0.4592691957950592, G_Loss:8.735437393188477

iterator 3300, D_Loss:0.4582212269306183, G_Loss:6.273497581481934

iterator 3400, D_Loss:0.5172695517539978, G_Loss:4.689953327178955

iterator 3500, D_Loss:0.4693799614906311, G_Loss:8.16117000579834

iterator 3600, D_Loss:0.46078604459762573, G_Loss:8.945314407348633

iterator 3700, D_Loss:0.4279480278491974, G_Loss:8.85018539428711

iterator 3800, D_Loss:0.43486109375953674, G_Loss:7.051253318786621

iterator 3900, D_Loss:0.4725707769393921, G_Loss:5.603192329406738

iterator 4000, D_Loss:0.432765394449234, G_Loss:6.829905986785889

iterator 4100, D_Loss:0.4737076163291931, G_Loss:8.016388893127441

iterator 4200, D_Loss:0.5458989143371582, G_Loss:7.6780619621276855

iterator 4300, D_Loss:0.4510250687599182, G_Loss:8.284866333007812

iterator 4400, D_Loss:0.4620097875595093, G_Loss:5.071658611297607

iterator 4500, D_Loss:0.4537971615791321, G_Loss:11.175795555114746

iterator 4600, D_Loss:0.4541856348514557, G_Loss:7.559213638305664

iterator 4700, D_Loss:0.47085151076316833, G_Loss:8.826074600219727

iterator 4800, D_Loss:0.454102486371994, G_Loss:11.078653335571289

iterator 4900, D_Loss:0.45596954226493835, G_Loss:6.95826530456543

iterator 5000, D_Loss:0.6074633002281189, G_Loss:9.445212364196777

-----------Epoch 8-----------
iterator 100, D_Loss:0.4175388514995575, G_Loss:7.510900974273682

iterator 200, D_Loss:0.44019415974617004, G_Loss:6.410008907318115

iterator 300, D_Loss:0.4475683569908142, G_Loss:13.210193634033203

iterator 400, D_Loss:0.4523835778236389, G_Loss:10.145729064941406

iterator 500, D_Loss:0.44612058997154236, G_Loss:6.786866188049316

iterator 600, D_Loss:0.43717271089553833, G_Loss:8.030563354492188

iterator 700, D_Loss:0.481079638004303, G_Loss:7.646173477172852

iterator 800, D_Loss:0.5189159512519836, G_Loss:6.510067462921143

iterator 900, D_Loss:0.48526298999786377, G_Loss:6.561750888824463

iterator 1000, D_Loss:0.44462504982948303, G_Loss:10.212653160095215

iterator 1100, D_Loss:0.48249754309654236, G_Loss:5.014649391174316

iterator 1200, D_Loss:0.5606989860534668, G_Loss:5.833743095397949

iterator 1300, D_Loss:0.42813026905059814, G_Loss:5.8154497146606445

iterator 1400, D_Loss:0.4359760284423828, G_Loss:9.409193992614746

iterator 1500, D_Loss:0.4430096447467804, G_Loss:6.776790618896484

iterator 1600, D_Loss:0.4346943795681, G_Loss:7.787281036376953

iterator 1700, D_Loss:0.4473594129085541, G_Loss:5.963037967681885

iterator 1800, D_Loss:0.45157957077026367, G_Loss:10.979905128479004

iterator 1900, D_Loss:0.44420260190963745, G_Loss:10.411063194274902

iterator 2000, D_Loss:0.46868711709976196, G_Loss:9.006219863891602

iterator 2100, D_Loss:0.4304203689098358, G_Loss:8.521431922912598

iterator 2200, D_Loss:0.46225640177726746, G_Loss:10.413839340209961

iterator 2300, D_Loss:0.4906499981880188, G_Loss:7.765939712524414

iterator 2400, D_Loss:0.4530280530452728, G_Loss:6.519435882568359

iterator 2500, D_Loss:0.4550763964653015, G_Loss:9.06653118133545

iterator 2600, D_Loss:0.4451376795768738, G_Loss:9.658287048339844

iterator 2700, D_Loss:0.4823116064071655, G_Loss:10.096003532409668

iterator 2800, D_Loss:0.45914554595947266, G_Loss:9.820074081420898

iterator 2900, D_Loss:0.4289115071296692, G_Loss:9.890993118286133

iterator 3000, D_Loss:0.44153696298599243, G_Loss:7.856161594390869

iterator 3100, D_Loss:0.44851693511009216, G_Loss:10.950438499450684

iterator 3200, D_Loss:0.44145667552948, G_Loss:8.297898292541504

iterator 3300, D_Loss:0.46081849932670593, G_Loss:8.830366134643555

iterator 3400, D_Loss:0.452737033367157, G_Loss:9.8038330078125

iterator 3500, D_Loss:0.41679301857948303, G_Loss:10.860273361206055

iterator 3600, D_Loss:0.43415096402168274, G_Loss:8.625019073486328

iterator 3700, D_Loss:0.43857240676879883, G_Loss:8.359334945678711

iterator 3800, D_Loss:0.44361481070518494, G_Loss:11.91120719909668

iterator 3900, D_Loss:0.43999427556991577, G_Loss:10.590802192687988

iterator 4000, D_Loss:0.4525660276412964, G_Loss:13.714309692382812

iterator 4100, D_Loss:0.4366495609283447, G_Loss:11.062161445617676

iterator 4200, D_Loss:0.43989452719688416, G_Loss:11.764394760131836

iterator 4300, D_Loss:0.4439204931259155, G_Loss:15.850701332092285

iterator 4400, D_Loss:0.4511595070362091, G_Loss:14.718965530395508

iterator 4500, D_Loss:0.44218865036964417, G_Loss:15.260279655456543

iterator 4600, D_Loss:0.43149495124816895, G_Loss:13.841114044189453

iterator 4700, D_Loss:0.4233241379261017, G_Loss:14.749918937683105

iterator 4800, D_Loss:0.4733123183250427, G_Loss:14.41206169128418

iterator 4900, D_Loss:0.4674660563468933, G_Loss:12.425933837890625

iterator 5000, D_Loss:0.4252462387084961, G_Loss:12.245773315429688

-----------Epoch 9-----------
iterator 100, D_Loss:0.425527960062027, G_Loss:9.482057571411133

iterator 200, D_Loss:0.44195178151130676, G_Loss:14.17231559753418

iterator 300, D_Loss:0.45304936170578003, G_Loss:10.700310707092285

iterator 400, D_Loss:0.4245468080043793, G_Loss:13.552373886108398

iterator 500, D_Loss:0.4336016774177551, G_Loss:13.830302238464355

iterator 600, D_Loss:0.4631401300430298, G_Loss:13.237581253051758

iterator 700, D_Loss:0.48269516229629517, G_Loss:13.350409507751465

iterator 800, D_Loss:0.4549653232097626, G_Loss:15.548788070678711

iterator 900, D_Loss:0.4361950159072876, G_Loss:16.909181594848633

iterator 1000, D_Loss:0.41831308603286743, G_Loss:15.742927551269531

iterator 1100, D_Loss:0.4338557720184326, G_Loss:14.490263938903809

iterator 1200, D_Loss:0.4351477324962616, G_Loss:16.10974884033203

iterator 1300, D_Loss:0.43802610039711, G_Loss:15.317193031311035

iterator 1400, D_Loss:0.43905407190322876, G_Loss:17.468610763549805

iterator 1500, D_Loss:0.45904362201690674, G_Loss:15.003127098083496

iterator 1600, D_Loss:0.44916319847106934, G_Loss:15.74502182006836

iterator 1700, D_Loss:0.43558499217033386, G_Loss:18.637557983398438

iterator 1800, D_Loss:0.4175722599029541, G_Loss:18.604793548583984

iterator 1900, D_Loss:0.4255920648574829, G_Loss:19.059669494628906

iterator 2000, D_Loss:0.43296492099761963, G_Loss:19.0596866607666

iterator 2100, D_Loss:0.41832807660102844, G_Loss:18.274593353271484

iterator 2200, D_Loss:0.4430892765522003, G_Loss:19.5096435546875

iterator 2300, D_Loss:0.4361262321472168, G_Loss:22.581703186035156

iterator 2400, D_Loss:0.43747812509536743, G_Loss:20.75415802001953

iterator 2500, D_Loss:0.43587273359298706, G_Loss:20.39314842224121

iterator 2600, D_Loss:0.421529620885849, G_Loss:18.564266204833984

iterator 2700, D_Loss:0.42926937341690063, G_Loss:19.009458541870117

iterator 2800, D_Loss:0.44334831833839417, G_Loss:19.73516082763672

iterator 2900, D_Loss:0.4298925995826721, G_Loss:17.17681121826172

iterator 3000, D_Loss:0.4278974235057831, G_Loss:20.31855583190918

iterator 3100, D_Loss:0.4486294388771057, G_Loss:20.74120330810547

iterator 3200, D_Loss:0.4449114501476288, G_Loss:19.514904022216797

iterator 3300, D_Loss:0.4531736671924591, G_Loss:18.69581413269043

iterator 3400, D_Loss:0.4097350835800171, G_Loss:21.048583984375

iterator 3500, D_Loss:0.426522433757782, G_Loss:23.472890853881836

iterator 3600, D_Loss:0.44443371891975403, G_Loss:22.8553524017334

iterator 3700, D_Loss:0.4318401515483856, G_Loss:20.324966430664062

iterator 3800, D_Loss:0.43589431047439575, G_Loss:21.95815658569336

iterator 3900, D_Loss:0.4261745512485504, G_Loss:27.13892364501953

iterator 4000, D_Loss:0.42891398072242737, G_Loss:24.978008270263672

iterator 4100, D_Loss:0.43533578515052795, G_Loss:21.888622283935547

iterator 4200, D_Loss:0.444082111120224, G_Loss:21.321516036987305

iterator 4300, D_Loss:0.44562941789627075, G_Loss:18.658828735351562

iterator 4400, D_Loss:0.42427346110343933, G_Loss:17.643898010253906

iterator 4500, D_Loss:0.4259437024593353, G_Loss:20.525455474853516

iterator 4600, D_Loss:0.4419250786304474, G_Loss:16.789857864379883

iterator 4700, D_Loss:0.4565046727657318, G_Loss:17.69710922241211

iterator 4800, D_Loss:0.4264526963233948, G_Loss:16.58165740966797

iterator 4900, D_Loss:0.43542027473449707, G_Loss:20.00197982788086

iterator 5000, D_Loss:0.44073954224586487, G_Loss:19.173728942871094

train row : 30148
sample row: 30148
LGAN_generator(
  (LSTM): LSTMCell(800, 200)
  (gmfc00): Linear(in_features=400, out_features=1, bias=True)
  (gmfc01): Linear(in_features=400, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=400, bias=True)
  (gmfe00): Linear(in_features=200, out_features=400, bias=True)
  (gmfe01): Linear(in_features=200, out_features=400, bias=True)
  (fc10): Linear(in_features=400, out_features=1, bias=True)
  (fc11): Linear(in_features=1, out_features=400, bias=True)
  (fe1): Linear(in_features=200, out_features=400, bias=True)
  (gmfc20): Linear(in_features=400, out_features=1, bias=True)
  (gmfc21): Linear(in_features=400, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=400, bias=True)
  (gmfe20): Linear(in_features=200, out_features=400, bias=True)
  (gmfe21): Linear(in_features=200, out_features=400, bias=True)
  (fc30): Linear(in_features=400, out_features=1, bias=True)
  (fc31): Linear(in_features=1, out_features=400, bias=True)
  (fe3): Linear(in_features=200, out_features=400, bias=True)
  (gmfc40): Linear(in_features=400, out_features=1, bias=True)
  (gmfc41): Linear(in_features=400, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=400, bias=True)
  (gmfe40): Linear(in_features=200, out_features=400, bias=True)
  (gmfe41): Linear(in_features=200, out_features=400, bias=True)
  (fc50): Linear(in_features=400, out_features=1, bias=True)
  (fc51): Linear(in_features=1, out_features=400, bias=True)
  (fe5): Linear(in_features=200, out_features=400, bias=True)
  (fc60): Linear(in_features=400, out_features=1, bias=True)
  (fc61): Linear(in_features=1, out_features=400, bias=True)
  (fe6): Linear(in_features=200, out_features=400, bias=True)
  (fc70): Linear(in_features=400, out_features=1, bias=True)
  (fc71): Linear(in_features=1, out_features=400, bias=True)
  (fe7): Linear(in_features=200, out_features=400, bias=True)
  (fc80): Linear(in_features=400, out_features=1, bias=True)
  (fc81): Linear(in_features=1, out_features=400, bias=True)
  (fe8): Linear(in_features=200, out_features=400, bias=True)
  (fc90): Linear(in_features=400, out_features=1, bias=True)
  (fc91): Linear(in_features=1, out_features=400, bias=True)
  (fe9): Linear(in_features=200, out_features=400, bias=True)
  (gmfc100): Linear(in_features=400, out_features=1, bias=True)
  (gmfc101): Linear(in_features=400, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=400, bias=True)
  (gmfe100): Linear(in_features=200, out_features=400, bias=True)
  (gmfe101): Linear(in_features=200, out_features=400, bias=True)
  (gmfc110): Linear(in_features=400, out_features=1, bias=True)
  (gmfc111): Linear(in_features=400, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=400, bias=True)
  (gmfe110): Linear(in_features=200, out_features=400, bias=True)
  (gmfe111): Linear(in_features=200, out_features=400, bias=True)
  (gmfc120): Linear(in_features=400, out_features=1, bias=True)
  (gmfc121): Linear(in_features=400, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=400, bias=True)
  (gmfe120): Linear(in_features=200, out_features=400, bias=True)
  (gmfe121): Linear(in_features=200, out_features=400, bias=True)
  (fc130): Linear(in_features=400, out_features=1, bias=True)
  (fc131): Linear(in_features=1, out_features=400, bias=True)
  (fe13): Linear(in_features=200, out_features=400, bias=True)
  (fc140): Linear(in_features=400, out_features=1, bias=True)
  (fc141): Linear(in_features=1, out_features=400, bias=True)
  (fe14): Linear(in_features=200, out_features=400, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=45, out_features=100, bias=True)
  (inputbn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=100, out_features=1, bias=True)
)
(0, False, 45)
-----------Epoch 0-----------
iterator 100, D_Loss:1.380711317062378, G_Loss:1.0534448623657227

iterator 200, D_Loss:1.3612850904464722, G_Loss:0.9750094413757324

iterator 300, D_Loss:1.3590494394302368, G_Loss:1.1098887920379639

iterator 400, D_Loss:1.331087589263916, G_Loss:1.1556532382965088

iterator 500, D_Loss:1.3150174617767334, G_Loss:1.1351274251937866

iterator 600, D_Loss:1.2283217906951904, G_Loss:1.0486698150634766

iterator 700, D_Loss:1.148486852645874, G_Loss:1.2438218593597412

iterator 800, D_Loss:1.3013153076171875, G_Loss:1.1630308628082275

iterator 900, D_Loss:1.27739417552948, G_Loss:1.1094014644622803

iterator 1000, D_Loss:1.256017804145813, G_Loss:1.2494890689849854

iterator 1100, D_Loss:1.2813055515289307, G_Loss:1.2925143241882324

iterator 1200, D_Loss:1.2362912893295288, G_Loss:1.2125824689865112

iterator 1300, D_Loss:1.151642084121704, G_Loss:1.2831419706344604

iterator 1400, D_Loss:1.2037843465805054, G_Loss:1.336293339729309

iterator 1500, D_Loss:1.050750494003296, G_Loss:1.4740118980407715

iterator 1600, D_Loss:1.0402532815933228, G_Loss:1.3509434461593628

iterator 1700, D_Loss:1.0416052341461182, G_Loss:1.512539029121399

iterator 1800, D_Loss:1.0520190000534058, G_Loss:1.6906459331512451

iterator 1900, D_Loss:1.3301746845245361, G_Loss:1.4996154308319092

iterator 2000, D_Loss:1.2331857681274414, G_Loss:1.2095608711242676

iterator 2100, D_Loss:1.4332420825958252, G_Loss:1.4917869567871094

iterator 2200, D_Loss:1.1889312267303467, G_Loss:1.3159570693969727

iterator 2300, D_Loss:1.2228333950042725, G_Loss:1.281869649887085

iterator 2400, D_Loss:1.2168834209442139, G_Loss:1.3203999996185303

iterator 2500, D_Loss:1.3051406145095825, G_Loss:1.2995834350585938

iterator 2600, D_Loss:1.2543548345565796, G_Loss:1.2132368087768555

iterator 2700, D_Loss:1.3693702220916748, G_Loss:1.271417260169983

iterator 2800, D_Loss:1.228082299232483, G_Loss:1.1533801555633545

iterator 2900, D_Loss:1.3639795780181885, G_Loss:1.214431881904602

iterator 3000, D_Loss:1.3478137254714966, G_Loss:1.1910420656204224

iterator 3100, D_Loss:1.3810086250305176, G_Loss:1.147085189819336

iterator 3200, D_Loss:1.2849833965301514, G_Loss:1.1806578636169434

iterator 3300, D_Loss:1.3706203699111938, G_Loss:1.1352014541625977

iterator 3400, D_Loss:1.2309836149215698, G_Loss:1.253600835800171

iterator 3500, D_Loss:1.23881196975708, G_Loss:1.1547398567199707

iterator 3600, D_Loss:1.4099628925323486, G_Loss:1.2772737741470337

iterator 3700, D_Loss:1.359928846359253, G_Loss:1.2935810089111328

iterator 3800, D_Loss:1.3310065269470215, G_Loss:1.1356114149093628

iterator 3900, D_Loss:1.2638943195343018, G_Loss:1.2566022872924805

iterator 4000, D_Loss:1.2724053859710693, G_Loss:1.406359076499939

iterator 4100, D_Loss:1.3910455703735352, G_Loss:1.3007150888442993

iterator 4200, D_Loss:1.2179229259490967, G_Loss:1.3365389108657837

iterator 4300, D_Loss:1.2630881071090698, G_Loss:1.3856008052825928

iterator 4400, D_Loss:1.20158851146698, G_Loss:1.2873401641845703

iterator 4500, D_Loss:1.257920503616333, G_Loss:1.2797660827636719

iterator 4600, D_Loss:1.2607388496398926, G_Loss:1.265681266784668

iterator 4700, D_Loss:1.171352505683899, G_Loss:1.349295735359192

iterator 4800, D_Loss:1.3276067972183228, G_Loss:1.2515723705291748

iterator 4900, D_Loss:1.2428655624389648, G_Loss:1.303457260131836

iterator 5000, D_Loss:1.2098727226257324, G_Loss:1.2272698879241943

-----------Epoch 1-----------
iterator 100, D_Loss:1.2387391328811646, G_Loss:1.2456601858139038

iterator 200, D_Loss:1.2654736042022705, G_Loss:1.5649986267089844

iterator 300, D_Loss:1.3431587219238281, G_Loss:1.346039891242981

iterator 400, D_Loss:1.318743109703064, G_Loss:1.237776279449463

iterator 500, D_Loss:1.2589199542999268, G_Loss:1.365207552909851

iterator 600, D_Loss:1.3840402364730835, G_Loss:1.4228966236114502

iterator 700, D_Loss:1.2079704999923706, G_Loss:1.1119885444641113

iterator 800, D_Loss:1.2327327728271484, G_Loss:1.5785542726516724

iterator 900, D_Loss:1.2380834817886353, G_Loss:1.4073539972305298

iterator 1000, D_Loss:1.1311579942703247, G_Loss:1.5993621349334717

iterator 1100, D_Loss:1.3851466178894043, G_Loss:1.3948462009429932

iterator 1200, D_Loss:1.2277148962020874, G_Loss:1.2625737190246582

iterator 1300, D_Loss:1.4015074968338013, G_Loss:1.3078603744506836

iterator 1400, D_Loss:1.2375977039337158, G_Loss:1.3214060068130493

iterator 1500, D_Loss:1.1258262395858765, G_Loss:1.511927843093872

iterator 1600, D_Loss:1.2319910526275635, G_Loss:1.3571293354034424

iterator 1700, D_Loss:1.0649998188018799, G_Loss:1.6634159088134766

iterator 1800, D_Loss:1.2993316650390625, G_Loss:1.4050184488296509

iterator 1900, D_Loss:1.1241132020950317, G_Loss:1.3736802339553833

iterator 2000, D_Loss:1.1017537117004395, G_Loss:1.3212237358093262

iterator 2100, D_Loss:1.2419530153274536, G_Loss:1.6784374713897705

iterator 2200, D_Loss:1.2406196594238281, G_Loss:1.2519500255584717

iterator 2300, D_Loss:1.3355677127838135, G_Loss:1.2340049743652344

iterator 2400, D_Loss:1.2952113151550293, G_Loss:1.4158059358596802

iterator 2500, D_Loss:1.3179237842559814, G_Loss:1.3266127109527588

iterator 2600, D_Loss:1.2076780796051025, G_Loss:1.3302936553955078

iterator 2700, D_Loss:1.3020703792572021, G_Loss:1.5418683290481567

iterator 2800, D_Loss:1.0524280071258545, G_Loss:1.62736177444458

iterator 2900, D_Loss:1.0912692546844482, G_Loss:1.4855831861495972

iterator 3000, D_Loss:1.279704213142395, G_Loss:1.2843143939971924

iterator 3100, D_Loss:1.0382241010665894, G_Loss:1.374962568283081

iterator 3200, D_Loss:1.1162574291229248, G_Loss:1.3077380657196045

iterator 3300, D_Loss:1.1308281421661377, G_Loss:1.5219533443450928

iterator 3400, D_Loss:1.1619045734405518, G_Loss:1.5170103311538696

iterator 3500, D_Loss:1.1079530715942383, G_Loss:1.2834515571594238

iterator 3600, D_Loss:1.3578948974609375, G_Loss:1.4898782968521118

iterator 3700, D_Loss:1.5102218389511108, G_Loss:1.4259607791900635

iterator 3800, D_Loss:1.0583124160766602, G_Loss:1.252537488937378

iterator 3900, D_Loss:1.1592772006988525, G_Loss:1.7162845134735107

iterator 4000, D_Loss:1.1797138452529907, G_Loss:1.7718265056610107

iterator 4100, D_Loss:1.0911344289779663, G_Loss:1.5206807851791382

iterator 4200, D_Loss:1.1207084655761719, G_Loss:1.738499402999878

iterator 4300, D_Loss:1.0610963106155396, G_Loss:1.2267814874649048

iterator 4400, D_Loss:1.1245036125183105, G_Loss:1.478203296661377

iterator 4500, D_Loss:1.2221109867095947, G_Loss:1.645949363708496

iterator 4600, D_Loss:1.1275818347930908, G_Loss:1.507426142692566

iterator 4700, D_Loss:1.0434261560440063, G_Loss:1.5843561887741089

iterator 4800, D_Loss:1.197371482849121, G_Loss:1.5400235652923584

iterator 4900, D_Loss:1.1272668838500977, G_Loss:1.324997067451477

iterator 5000, D_Loss:0.975069522857666, G_Loss:1.7988839149475098

-----------Epoch 2-----------
iterator 100, D_Loss:1.1267529726028442, G_Loss:1.8133108615875244

iterator 200, D_Loss:0.9777952432632446, G_Loss:1.8294121026992798

iterator 300, D_Loss:1.0270755290985107, G_Loss:1.7798411846160889

iterator 400, D_Loss:1.0088348388671875, G_Loss:1.6376093626022339

iterator 500, D_Loss:1.3234775066375732, G_Loss:2.1544735431671143

iterator 600, D_Loss:1.401458740234375, G_Loss:1.2935385704040527

iterator 700, D_Loss:0.8359562158584595, G_Loss:2.351991653442383

iterator 800, D_Loss:1.056791067123413, G_Loss:1.8235126733779907

iterator 900, D_Loss:0.9523410797119141, G_Loss:2.6015114784240723

iterator 1000, D_Loss:1.4244592189788818, G_Loss:1.8851161003112793

iterator 1100, D_Loss:0.8696584701538086, G_Loss:1.888282299041748

iterator 1200, D_Loss:1.029353380203247, G_Loss:2.390270471572876

iterator 1300, D_Loss:0.975847065448761, G_Loss:1.7744019031524658

iterator 1400, D_Loss:0.9455267786979675, G_Loss:2.3828516006469727

iterator 1500, D_Loss:0.6952182054519653, G_Loss:2.2639284133911133

iterator 1600, D_Loss:0.9623547792434692, G_Loss:2.507891893386841

iterator 1700, D_Loss:0.9545893669128418, G_Loss:1.7567732334136963

iterator 1800, D_Loss:1.2063778638839722, G_Loss:1.6415666341781616

iterator 1900, D_Loss:0.8962886333465576, G_Loss:1.8635857105255127

iterator 2000, D_Loss:1.1043102741241455, G_Loss:1.6260050535202026

iterator 2100, D_Loss:1.2637525796890259, G_Loss:2.0109386444091797

iterator 2200, D_Loss:0.8237362504005432, G_Loss:1.7428946495056152

iterator 2300, D_Loss:1.080938696861267, G_Loss:1.6449739933013916

iterator 2400, D_Loss:0.8616921901702881, G_Loss:1.8884475231170654

iterator 2500, D_Loss:1.4376634359359741, G_Loss:1.9844456911087036

iterator 2600, D_Loss:1.0080335140228271, G_Loss:1.8538190126419067

iterator 2700, D_Loss:1.1704202890396118, G_Loss:1.8337621688842773

iterator 2800, D_Loss:1.065608024597168, G_Loss:1.4602160453796387

iterator 2900, D_Loss:0.8150269985198975, G_Loss:2.3319971561431885

iterator 3000, D_Loss:0.9600908756256104, G_Loss:2.0635907649993896

iterator 3100, D_Loss:0.8195492625236511, G_Loss:1.8931334018707275

iterator 3200, D_Loss:0.7871040105819702, G_Loss:1.8013572692871094

iterator 3300, D_Loss:0.9667676687240601, G_Loss:1.9423415660858154

iterator 3400, D_Loss:0.895035982131958, G_Loss:2.207620143890381

iterator 3500, D_Loss:0.978071928024292, G_Loss:2.2740697860717773

iterator 3600, D_Loss:0.8400661945343018, G_Loss:2.089729070663452

iterator 3700, D_Loss:1.3150845766067505, G_Loss:2.1080105304718018

iterator 3800, D_Loss:1.055832862854004, G_Loss:1.3901480436325073

iterator 3900, D_Loss:1.0958164930343628, G_Loss:1.83639395236969

iterator 4000, D_Loss:1.008525013923645, G_Loss:1.9771912097930908

iterator 4100, D_Loss:1.0825353860855103, G_Loss:1.5449916124343872

iterator 4200, D_Loss:1.4293103218078613, G_Loss:1.8232835531234741

iterator 4300, D_Loss:1.0654362440109253, G_Loss:1.4719505310058594

iterator 4400, D_Loss:1.0014299154281616, G_Loss:1.8174761533737183

iterator 4500, D_Loss:1.082887887954712, G_Loss:2.120033025741577

iterator 4600, D_Loss:0.8416411280632019, G_Loss:1.5199501514434814

iterator 4700, D_Loss:0.9308151602745056, G_Loss:1.9607293605804443

iterator 4800, D_Loss:1.7105865478515625, G_Loss:1.4902772903442383

iterator 4900, D_Loss:1.21612548828125, G_Loss:1.8483363389968872

iterator 5000, D_Loss:1.3826464414596558, G_Loss:1.3766049146652222

-----------Epoch 3-----------
iterator 100, D_Loss:1.1141064167022705, G_Loss:1.3737479448318481

iterator 200, D_Loss:0.9626944065093994, G_Loss:1.8552494049072266

iterator 300, D_Loss:0.9110952019691467, G_Loss:1.8874244689941406

iterator 400, D_Loss:1.1267738342285156, G_Loss:1.764350414276123

iterator 500, D_Loss:1.2142871618270874, G_Loss:2.34279465675354

iterator 600, D_Loss:1.5322319269180298, G_Loss:1.6906952857971191

iterator 700, D_Loss:1.1193383932113647, G_Loss:1.6019421815872192

iterator 800, D_Loss:1.0366085767745972, G_Loss:1.8492156267166138

iterator 900, D_Loss:1.0350720882415771, G_Loss:1.9142625331878662

iterator 1000, D_Loss:0.9808386564254761, G_Loss:1.8076874017715454

iterator 1100, D_Loss:0.6963454484939575, G_Loss:1.4444867372512817

iterator 1200, D_Loss:1.3277755975723267, G_Loss:1.683784008026123

iterator 1300, D_Loss:1.2115792036056519, G_Loss:1.636443853378296

iterator 1400, D_Loss:0.9583186507225037, G_Loss:1.510010004043579

iterator 1500, D_Loss:0.9220659732818604, G_Loss:2.138718843460083

iterator 1600, D_Loss:1.053784728050232, G_Loss:1.730349063873291

iterator 1700, D_Loss:0.8551007509231567, G_Loss:1.6468178033828735

iterator 1800, D_Loss:0.9745635986328125, G_Loss:1.8900089263916016

iterator 1900, D_Loss:1.0195542573928833, G_Loss:2.040891408920288

iterator 2000, D_Loss:1.3499107360839844, G_Loss:1.2411551475524902

iterator 2100, D_Loss:1.0900068283081055, G_Loss:2.470304250717163

iterator 2200, D_Loss:0.9069899320602417, G_Loss:1.6982601881027222

iterator 2300, D_Loss:0.9616760015487671, G_Loss:1.5415244102478027

iterator 2400, D_Loss:0.8839369416236877, G_Loss:1.6597145795822144

iterator 2500, D_Loss:1.4642127752304077, G_Loss:1.901544451713562

iterator 2600, D_Loss:0.8713644742965698, G_Loss:1.7241153717041016

iterator 2700, D_Loss:0.9660577774047852, G_Loss:1.7211436033248901

iterator 2800, D_Loss:0.7898141741752625, G_Loss:1.4735591411590576

iterator 2900, D_Loss:1.061730146408081, G_Loss:1.3503296375274658

iterator 3000, D_Loss:1.3831963539123535, G_Loss:1.8761329650878906

iterator 3100, D_Loss:1.2042375802993774, G_Loss:1.6235347986221313

iterator 3200, D_Loss:0.9107845425605774, G_Loss:1.8555477857589722

iterator 3300, D_Loss:0.8869098424911499, G_Loss:1.6492207050323486

iterator 3400, D_Loss:1.0502896308898926, G_Loss:1.8189072608947754

iterator 3500, D_Loss:0.8940994739532471, G_Loss:1.7940071821212769

iterator 3600, D_Loss:0.9596197605133057, G_Loss:2.1363024711608887

iterator 3700, D_Loss:1.5966360569000244, G_Loss:1.5807316303253174

iterator 3800, D_Loss:0.882024884223938, G_Loss:2.0598788261413574

iterator 3900, D_Loss:0.9189236164093018, G_Loss:1.6562199592590332

iterator 4000, D_Loss:1.0660672187805176, G_Loss:2.567023515701294

iterator 4100, D_Loss:0.9567069411277771, G_Loss:1.6739380359649658

iterator 4200, D_Loss:1.1542489528656006, G_Loss:2.445484161376953

iterator 4300, D_Loss:1.001295804977417, G_Loss:1.710221529006958

iterator 4400, D_Loss:0.9253058433532715, G_Loss:1.4714672565460205

iterator 4500, D_Loss:0.913608729839325, G_Loss:1.9243552684783936

iterator 4600, D_Loss:0.8985598087310791, G_Loss:2.4732837677001953

iterator 4700, D_Loss:0.7823017239570618, G_Loss:1.625204086303711

iterator 4800, D_Loss:2.0623526573181152, G_Loss:1.5684194564819336

iterator 4900, D_Loss:1.1260136365890503, G_Loss:1.8748078346252441

iterator 5000, D_Loss:1.2893702983856201, G_Loss:1.5223863124847412

-----------Epoch 4-----------
iterator 100, D_Loss:0.826197624206543, G_Loss:1.8455722332000732

iterator 200, D_Loss:1.1159850358963013, G_Loss:1.6561110019683838

iterator 300, D_Loss:0.8256630897521973, G_Loss:1.9230064153671265

iterator 400, D_Loss:0.7803201675415039, G_Loss:1.6685326099395752

iterator 500, D_Loss:1.1955366134643555, G_Loss:1.6028392314910889

iterator 600, D_Loss:1.746000051498413, G_Loss:1.6897462606430054

iterator 700, D_Loss:0.815123438835144, G_Loss:2.364457607269287

iterator 800, D_Loss:1.1345664262771606, G_Loss:1.8787437677383423

iterator 900, D_Loss:0.8607129454612732, G_Loss:2.5351407527923584

iterator 1000, D_Loss:0.8107150197029114, G_Loss:1.9515632390975952

iterator 1100, D_Loss:1.0463855266571045, G_Loss:1.8931208848953247

iterator 1200, D_Loss:1.3629662990570068, G_Loss:1.9939563274383545

iterator 1300, D_Loss:1.0045937299728394, G_Loss:1.7748188972473145

iterator 1400, D_Loss:1.043871521949768, G_Loss:1.4716533422470093

iterator 1500, D_Loss:0.832056999206543, G_Loss:2.8780875205993652

iterator 1600, D_Loss:1.0659403800964355, G_Loss:2.05145263671875

iterator 1700, D_Loss:0.6857315897941589, G_Loss:1.645554780960083

iterator 1800, D_Loss:0.9677848219871521, G_Loss:1.8668506145477295

iterator 1900, D_Loss:0.9492366909980774, G_Loss:2.5095982551574707

iterator 2000, D_Loss:0.9346702098846436, G_Loss:2.8355021476745605

iterator 2100, D_Loss:0.9492520093917847, G_Loss:2.439703941345215

iterator 2200, D_Loss:0.7772699594497681, G_Loss:2.7126388549804688

iterator 2300, D_Loss:0.6789081692695618, G_Loss:1.8822752237319946

iterator 2400, D_Loss:0.8808302879333496, G_Loss:2.168114185333252

iterator 2500, D_Loss:1.5563015937805176, G_Loss:2.0230090618133545

iterator 2600, D_Loss:0.8101662397384644, G_Loss:2.3546230792999268

iterator 2700, D_Loss:0.8406526446342468, G_Loss:1.4305973052978516

iterator 2800, D_Loss:0.7803357839584351, G_Loss:1.881324291229248

iterator 2900, D_Loss:0.805762529373169, G_Loss:2.0633938312530518

iterator 3000, D_Loss:1.3025187253952026, G_Loss:1.599324107170105

iterator 3100, D_Loss:1.0331531763076782, G_Loss:2.7983815670013428

iterator 3200, D_Loss:0.8626992702484131, G_Loss:2.467545747756958

iterator 3300, D_Loss:1.0626792907714844, G_Loss:2.1262850761413574

iterator 3400, D_Loss:0.9621289968490601, G_Loss:1.8357036113739014

iterator 3500, D_Loss:0.8928980827331543, G_Loss:2.123687505722046

iterator 3600, D_Loss:0.9286500215530396, G_Loss:2.3330740928649902

iterator 3700, D_Loss:1.733210563659668, G_Loss:1.4959222078323364

iterator 3800, D_Loss:0.7390032410621643, G_Loss:2.1576712131500244

iterator 3900, D_Loss:0.8254191279411316, G_Loss:2.0676109790802

iterator 4000, D_Loss:0.8832772970199585, G_Loss:2.0735979080200195

iterator 4100, D_Loss:0.9481704831123352, G_Loss:1.3457542657852173

iterator 4200, D_Loss:1.1891229152679443, G_Loss:1.8891006708145142

iterator 4300, D_Loss:0.9463706612586975, G_Loss:2.616121292114258

iterator 4400, D_Loss:0.6953775882720947, G_Loss:1.8338061571121216

iterator 4500, D_Loss:0.8604337573051453, G_Loss:3.2308967113494873

iterator 4600, D_Loss:0.7558481097221375, G_Loss:1.8733437061309814

iterator 4700, D_Loss:1.056828260421753, G_Loss:1.421583652496338

iterator 4800, D_Loss:2.13153338432312, G_Loss:2.047053098678589

iterator 4900, D_Loss:1.0580658912658691, G_Loss:2.0653023719787598

iterator 5000, D_Loss:1.1809040307998657, G_Loss:1.7929661273956299

-----------Epoch 5-----------
iterator 100, D_Loss:0.7290721535682678, G_Loss:3.006686210632324

iterator 200, D_Loss:0.804955244064331, G_Loss:2.0561540126800537

iterator 300, D_Loss:0.9771808385848999, G_Loss:3.3981757164001465

iterator 400, D_Loss:0.8621982336044312, G_Loss:1.9864606857299805

iterator 500, D_Loss:1.1554330587387085, G_Loss:3.2780051231384277

iterator 600, D_Loss:1.5453916788101196, G_Loss:2.7014567852020264

iterator 700, D_Loss:0.8233848810195923, G_Loss:2.647815465927124

iterator 800, D_Loss:0.8718929290771484, G_Loss:2.065094470977783

iterator 900, D_Loss:0.8160099983215332, G_Loss:2.613337755203247

iterator 1000, D_Loss:0.8811789751052856, G_Loss:3.3679349422454834

iterator 1100, D_Loss:0.8449118733406067, G_Loss:3.799686908721924

iterator 1200, D_Loss:1.2582268714904785, G_Loss:1.8800123929977417

iterator 1300, D_Loss:1.1118019819259644, G_Loss:2.9422190189361572

iterator 1400, D_Loss:0.8789554834365845, G_Loss:1.7543888092041016

iterator 1500, D_Loss:0.7524501085281372, G_Loss:2.2888681888580322

iterator 1600, D_Loss:1.0192320346832275, G_Loss:3.0428597927093506

iterator 1700, D_Loss:0.8907555937767029, G_Loss:2.4477379322052

iterator 1800, D_Loss:0.7556746602058411, G_Loss:2.012357234954834

iterator 1900, D_Loss:0.7838715314865112, G_Loss:2.7233715057373047

iterator 2000, D_Loss:0.7833364605903625, G_Loss:2.0667243003845215

iterator 2100, D_Loss:0.8547680974006653, G_Loss:2.497976303100586

iterator 2200, D_Loss:0.7546887397766113, G_Loss:2.191819906234741

iterator 2300, D_Loss:1.0795650482177734, G_Loss:2.4724955558776855

iterator 2400, D_Loss:0.8637566566467285, G_Loss:3.499675750732422

iterator 2500, D_Loss:1.1409940719604492, G_Loss:2.4637176990509033

iterator 2600, D_Loss:0.8650945425033569, G_Loss:1.6384748220443726

iterator 2700, D_Loss:0.8229511976242065, G_Loss:2.0752363204956055

iterator 2800, D_Loss:0.7866736650466919, G_Loss:1.9744036197662354

iterator 2900, D_Loss:0.8810641765594482, G_Loss:2.428513526916504

iterator 3000, D_Loss:0.9928330183029175, G_Loss:2.376173496246338

iterator 3100, D_Loss:0.8208370208740234, G_Loss:2.0440256595611572

iterator 3200, D_Loss:0.9527150392532349, G_Loss:2.367591381072998

iterator 3300, D_Loss:0.8541131615638733, G_Loss:2.9710702896118164

iterator 3400, D_Loss:0.9577391743659973, G_Loss:2.872486114501953

iterator 3500, D_Loss:0.9118590354919434, G_Loss:3.760767936706543

iterator 3600, D_Loss:0.87769615650177, G_Loss:2.985821485519409

iterator 3700, D_Loss:1.0725359916687012, G_Loss:2.765078544616699

iterator 3800, D_Loss:2.1492037773132324, G_Loss:2.749009847640991

iterator 3900, D_Loss:1.452717661857605, G_Loss:2.2311625480651855

iterator 4000, D_Loss:0.8611103296279907, G_Loss:2.6177620887756348

iterator 4100, D_Loss:0.850695013999939, G_Loss:2.7418787479400635

iterator 4200, D_Loss:1.085209608078003, G_Loss:2.7577998638153076

iterator 4300, D_Loss:0.7167961597442627, G_Loss:3.1176207065582275

iterator 4400, D_Loss:0.7295929789543152, G_Loss:2.550114154815674

iterator 4500, D_Loss:0.6479045152664185, G_Loss:3.3981924057006836

iterator 4600, D_Loss:0.842097818851471, G_Loss:2.763054847717285

iterator 4700, D_Loss:0.8293938040733337, G_Loss:2.51238751411438

iterator 4800, D_Loss:1.9929125308990479, G_Loss:2.9626054763793945

iterator 4900, D_Loss:0.955817699432373, G_Loss:2.0305066108703613

iterator 5000, D_Loss:0.8954511880874634, G_Loss:2.2744140625

-----------Epoch 6-----------
iterator 100, D_Loss:0.8274892568588257, G_Loss:3.2841556072235107

iterator 200, D_Loss:0.7149235010147095, G_Loss:2.8963706493377686

iterator 300, D_Loss:1.0187921524047852, G_Loss:2.0487682819366455

iterator 400, D_Loss:0.6994802951812744, G_Loss:2.4708240032196045

iterator 500, D_Loss:0.8329818248748779, G_Loss:2.5873565673828125

iterator 600, D_Loss:1.080993413925171, G_Loss:3.0581047534942627

iterator 700, D_Loss:0.805121123790741, G_Loss:3.3550868034362793

iterator 800, D_Loss:0.877133309841156, G_Loss:2.2175934314727783

iterator 900, D_Loss:0.857488751411438, G_Loss:3.798766613006592

iterator 1000, D_Loss:0.8268812298774719, G_Loss:3.4957993030548096

iterator 1100, D_Loss:1.2149547338485718, G_Loss:1.9097864627838135

iterator 1200, D_Loss:1.0000048875808716, G_Loss:2.6009435653686523

iterator 1300, D_Loss:0.9454967379570007, G_Loss:2.543166399002075

iterator 1400, D_Loss:0.7241398096084595, G_Loss:3.3699958324432373

iterator 1500, D_Loss:0.7263763546943665, G_Loss:2.3243069648742676

iterator 1600, D_Loss:1.0073235034942627, G_Loss:3.916524648666382

iterator 1700, D_Loss:0.7104619145393372, G_Loss:2.5302696228027344

iterator 1800, D_Loss:0.9938821792602539, G_Loss:2.0880379676818848

iterator 1900, D_Loss:0.771221399307251, G_Loss:2.6775012016296387

iterator 2000, D_Loss:0.8949849009513855, G_Loss:2.1148481369018555

iterator 2100, D_Loss:1.0119404792785645, G_Loss:3.254626512527466

iterator 2200, D_Loss:0.8370746970176697, G_Loss:3.222968578338623

iterator 2300, D_Loss:0.938345193862915, G_Loss:2.193037271499634

iterator 2400, D_Loss:0.7360613942146301, G_Loss:2.6376917362213135

iterator 2500, D_Loss:1.0525506734848022, G_Loss:2.8145105838775635

iterator 2600, D_Loss:0.72456294298172, G_Loss:3.453861713409424

iterator 2700, D_Loss:0.8121392726898193, G_Loss:2.2358345985412598

iterator 2800, D_Loss:0.8351503610610962, G_Loss:1.8626203536987305

iterator 2900, D_Loss:0.8825862407684326, G_Loss:3.2874062061309814

iterator 3000, D_Loss:1.3268983364105225, G_Loss:2.274973154067993

iterator 3100, D_Loss:1.0181796550750732, G_Loss:1.9404711723327637

iterator 3200, D_Loss:0.8671134114265442, G_Loss:1.587758183479309

iterator 3300, D_Loss:0.7629963159561157, G_Loss:1.557268500328064

iterator 3400, D_Loss:0.9537448287010193, G_Loss:2.351180076599121

iterator 3500, D_Loss:0.8221215009689331, G_Loss:2.7594170570373535

iterator 3600, D_Loss:0.7517620325088501, G_Loss:2.2514407634735107

iterator 3700, D_Loss:1.6074610948562622, G_Loss:1.6590018272399902

iterator 3800, D_Loss:0.7653313875198364, G_Loss:1.964034080505371

iterator 3900, D_Loss:0.808993399143219, G_Loss:2.6525702476501465

iterator 4000, D_Loss:1.0145196914672852, G_Loss:1.9654146432876587

iterator 4100, D_Loss:0.7669513821601868, G_Loss:2.306793689727783

iterator 4200, D_Loss:1.0502500534057617, G_Loss:1.746957778930664

iterator 4300, D_Loss:0.7785285711288452, G_Loss:2.559373617172241

iterator 4400, D_Loss:0.8291501998901367, G_Loss:1.9464471340179443

iterator 4500, D_Loss:0.7288480997085571, G_Loss:3.399813652038574

iterator 4600, D_Loss:0.8627529144287109, G_Loss:2.3822145462036133

iterator 4700, D_Loss:0.634902834892273, G_Loss:3.056802749633789

iterator 4800, D_Loss:1.9496488571166992, G_Loss:3.0023577213287354

iterator 4900, D_Loss:0.9801021814346313, G_Loss:2.158764600753784

iterator 5000, D_Loss:0.9899356365203857, G_Loss:1.9754550457000732

-----------Epoch 7-----------
iterator 100, D_Loss:0.7322372794151306, G_Loss:2.8026530742645264

iterator 200, D_Loss:0.8002368211746216, G_Loss:2.8339226245880127

iterator 300, D_Loss:0.8660138845443726, G_Loss:2.561969518661499

iterator 400, D_Loss:0.9266046285629272, G_Loss:2.475297689437866

iterator 500, D_Loss:1.0049116611480713, G_Loss:3.2881064414978027

iterator 600, D_Loss:1.6314663887023926, G_Loss:1.930624008178711

iterator 700, D_Loss:0.7049932479858398, G_Loss:3.107693672180176

iterator 800, D_Loss:0.720043957233429, G_Loss:2.558565378189087

iterator 900, D_Loss:0.8005942702293396, G_Loss:3.8373990058898926

iterator 1000, D_Loss:0.9526692032814026, G_Loss:2.9474971294403076

iterator 1100, D_Loss:0.8164306879043579, G_Loss:2.5306529998779297

iterator 1200, D_Loss:1.1468442678451538, G_Loss:2.099327564239502

iterator 1300, D_Loss:0.8525765538215637, G_Loss:3.3853275775909424

iterator 1400, D_Loss:0.7726601362228394, G_Loss:2.6602866649627686

iterator 1500, D_Loss:0.759733259677887, G_Loss:2.705078363418579

iterator 1600, D_Loss:1.214545488357544, G_Loss:3.776378631591797

iterator 1700, D_Loss:0.6547055244445801, G_Loss:2.37528920173645

iterator 1800, D_Loss:0.7081757187843323, G_Loss:2.1491055488586426

iterator 1900, D_Loss:1.120159387588501, G_Loss:3.0193169116973877

iterator 2000, D_Loss:0.8596689105033875, G_Loss:1.9998422861099243

iterator 2100, D_Loss:0.9210205078125, G_Loss:2.6115574836730957

iterator 2200, D_Loss:0.9633902311325073, G_Loss:2.5195436477661133

iterator 2300, D_Loss:0.8617696166038513, G_Loss:1.9034600257873535

iterator 2400, D_Loss:0.8141227960586548, G_Loss:2.9584407806396484

iterator 2500, D_Loss:0.8983578681945801, G_Loss:2.5171844959259033

iterator 2600, D_Loss:0.9222913980484009, G_Loss:3.0006823539733887

iterator 2700, D_Loss:1.0644619464874268, G_Loss:2.272029399871826

iterator 2800, D_Loss:0.9259493947029114, G_Loss:2.0940001010894775

iterator 2900, D_Loss:0.861782431602478, G_Loss:2.3046672344207764

iterator 3000, D_Loss:1.1644682884216309, G_Loss:3.1478044986724854

iterator 3100, D_Loss:0.7765247821807861, G_Loss:1.7242047786712646

iterator 3200, D_Loss:0.8385506868362427, G_Loss:1.8879287242889404

iterator 3300, D_Loss:0.8053716421127319, G_Loss:3.801845073699951

iterator 3400, D_Loss:0.8786640763282776, G_Loss:2.7873308658599854

iterator 3500, D_Loss:0.8263288736343384, G_Loss:2.8056750297546387

iterator 3600, D_Loss:0.9611179232597351, G_Loss:2.4977173805236816

iterator 3700, D_Loss:1.1914061307907104, G_Loss:2.6471309661865234

iterator 3800, D_Loss:0.7925657033920288, G_Loss:2.7855172157287598

iterator 3900, D_Loss:0.778083324432373, G_Loss:3.16517972946167

iterator 4000, D_Loss:0.8255255818367004, G_Loss:3.525012969970703

iterator 4100, D_Loss:0.6866012811660767, G_Loss:1.8203630447387695

iterator 4200, D_Loss:1.0859322547912598, G_Loss:2.0909500122070312

iterator 4300, D_Loss:0.8624216318130493, G_Loss:2.6124465465545654

iterator 4400, D_Loss:0.8207472562789917, G_Loss:2.49825119972229

iterator 4500, D_Loss:0.8154028654098511, G_Loss:2.7760329246520996

iterator 4600, D_Loss:0.7880657911300659, G_Loss:2.0597238540649414

iterator 4700, D_Loss:0.8359197974205017, G_Loss:2.7084426879882812

iterator 4800, D_Loss:2.0249595642089844, G_Loss:2.383910655975342

iterator 4900, D_Loss:0.9858960509300232, G_Loss:2.2639079093933105

iterator 5000, D_Loss:0.9017678499221802, G_Loss:2.785243272781372

-----------Epoch 8-----------
iterator 100, D_Loss:0.6666749119758606, G_Loss:2.9136385917663574

iterator 200, D_Loss:0.866852879524231, G_Loss:2.175757884979248

iterator 300, D_Loss:0.9091564416885376, G_Loss:3.42148756980896

iterator 400, D_Loss:0.6683328747749329, G_Loss:2.645282745361328

iterator 500, D_Loss:0.9400122761726379, G_Loss:2.670602321624756

iterator 600, D_Loss:1.9270250797271729, G_Loss:3.4412167072296143

iterator 700, D_Loss:0.9449888467788696, G_Loss:2.3452255725860596

iterator 800, D_Loss:0.8695720434188843, G_Loss:3.463893413543701

iterator 900, D_Loss:0.755459189414978, G_Loss:2.753697156906128

iterator 1000, D_Loss:0.9006245136260986, G_Loss:2.3299503326416016

iterator 1100, D_Loss:0.6963719129562378, G_Loss:3.777421474456787

iterator 1200, D_Loss:0.9822437763214111, G_Loss:2.638409376144409

iterator 1300, D_Loss:0.702190637588501, G_Loss:2.8764395713806152

iterator 1400, D_Loss:1.0109745264053345, G_Loss:3.4879493713378906

iterator 1500, D_Loss:0.7571065425872803, G_Loss:3.6365764141082764

iterator 1600, D_Loss:0.8670046329498291, G_Loss:2.0274736881256104

iterator 1700, D_Loss:0.6888774037361145, G_Loss:3.1681151390075684

iterator 1800, D_Loss:0.8546411395072937, G_Loss:2.250344753265381

iterator 1900, D_Loss:1.0387873649597168, G_Loss:2.6255247592926025

iterator 2000, D_Loss:0.9113662242889404, G_Loss:4.195449352264404

iterator 2100, D_Loss:0.9198369979858398, G_Loss:3.8786239624023438

iterator 2200, D_Loss:0.858872652053833, G_Loss:2.8786189556121826

iterator 2300, D_Loss:0.7606035470962524, G_Loss:3.434596538543701

iterator 2400, D_Loss:0.7850803136825562, G_Loss:1.753227710723877

iterator 2500, D_Loss:0.9281406402587891, G_Loss:2.359370231628418

iterator 2600, D_Loss:0.7337467670440674, G_Loss:2.8549318313598633

iterator 2700, D_Loss:0.9436818957328796, G_Loss:3.279134511947632

iterator 2800, D_Loss:0.8217654824256897, G_Loss:1.8610906600952148

iterator 2900, D_Loss:0.7856869697570801, G_Loss:2.7818338871002197

iterator 3000, D_Loss:1.2732640504837036, G_Loss:2.579376459121704

iterator 3100, D_Loss:0.8543314933776855, G_Loss:2.034407138824463

iterator 3200, D_Loss:0.6192654371261597, G_Loss:2.8600096702575684

iterator 3300, D_Loss:0.6797541379928589, G_Loss:2.7924392223358154

iterator 3400, D_Loss:1.2614325284957886, G_Loss:2.6172616481781006

iterator 3500, D_Loss:0.7917992472648621, G_Loss:2.4899370670318604

iterator 3600, D_Loss:0.8566436171531677, G_Loss:3.3905293941497803

iterator 3700, D_Loss:1.4111456871032715, G_Loss:2.2064530849456787

iterator 3800, D_Loss:0.7859416007995605, G_Loss:1.8822431564331055

iterator 3900, D_Loss:0.7878583073616028, G_Loss:2.341630458831787

iterator 4000, D_Loss:1.2127249240875244, G_Loss:2.405113697052002

iterator 4100, D_Loss:0.7132794260978699, G_Loss:1.547995924949646

iterator 4200, D_Loss:1.1448230743408203, G_Loss:1.8690390586853027

iterator 4300, D_Loss:1.046887993812561, G_Loss:2.5955934524536133

iterator 4400, D_Loss:0.9036552309989929, G_Loss:1.9932496547698975

iterator 4500, D_Loss:0.8612157106399536, G_Loss:2.345501661300659

iterator 4600, D_Loss:0.974236011505127, G_Loss:2.9278292655944824

iterator 4700, D_Loss:0.6026743650436401, G_Loss:3.6633963584899902

iterator 4800, D_Loss:2.212907314300537, G_Loss:2.95345139503479

iterator 4900, D_Loss:1.1139034032821655, G_Loss:2.4615001678466797

iterator 5000, D_Loss:1.0331661701202393, G_Loss:1.4878119230270386

-----------Epoch 9-----------
iterator 100, D_Loss:0.8244128227233887, G_Loss:2.2436840534210205

iterator 200, D_Loss:0.8010885715484619, G_Loss:3.25258731842041

iterator 300, D_Loss:0.7557982206344604, G_Loss:4.064516544342041

iterator 400, D_Loss:0.7093524932861328, G_Loss:3.4364078044891357

iterator 500, D_Loss:0.9818254709243774, G_Loss:2.1975443363189697

iterator 600, D_Loss:1.4489848613739014, G_Loss:3.0496249198913574

iterator 700, D_Loss:0.7521088123321533, G_Loss:1.8969848155975342

iterator 800, D_Loss:0.780560314655304, G_Loss:2.2196273803710938

iterator 900, D_Loss:0.8179046511650085, G_Loss:2.6571762561798096

iterator 1000, D_Loss:1.146268367767334, G_Loss:3.3992438316345215

iterator 1100, D_Loss:0.8266162276268005, G_Loss:2.2808949947357178

iterator 1200, D_Loss:0.9103199243545532, G_Loss:2.692974090576172

iterator 1300, D_Loss:0.8796893358230591, G_Loss:2.198347330093384

iterator 1400, D_Loss:0.9365307688713074, G_Loss:2.7669355869293213

iterator 1500, D_Loss:0.7997470498085022, G_Loss:2.247697353363037

iterator 1600, D_Loss:1.1986249685287476, G_Loss:2.202406644821167

iterator 1700, D_Loss:0.6034356951713562, G_Loss:3.6482431888580322

iterator 1800, D_Loss:0.857475757598877, G_Loss:2.938019275665283

iterator 1900, D_Loss:1.0353935956954956, G_Loss:3.0099568367004395

iterator 2000, D_Loss:0.8629962205886841, G_Loss:2.6468396186828613

iterator 2100, D_Loss:0.8534585237503052, G_Loss:2.334980010986328

iterator 2200, D_Loss:0.9649641513824463, G_Loss:2.679081439971924

iterator 2300, D_Loss:0.7546507120132446, G_Loss:3.6629467010498047

iterator 2400, D_Loss:0.660415768623352, G_Loss:3.2771875858306885

iterator 2500, D_Loss:0.8914434909820557, G_Loss:2.7588584423065186

iterator 2600, D_Loss:0.7391553521156311, G_Loss:2.365854024887085

iterator 2700, D_Loss:0.7427799701690674, G_Loss:2.0710597038269043

iterator 2800, D_Loss:0.6830070614814758, G_Loss:3.453343391418457

iterator 2900, D_Loss:0.7795286774635315, G_Loss:2.4515581130981445

iterator 3000, D_Loss:1.5069564580917358, G_Loss:3.3151679039001465

iterator 3100, D_Loss:0.8107687830924988, G_Loss:3.3786888122558594

iterator 3200, D_Loss:0.7363448143005371, G_Loss:2.177022695541382

iterator 3300, D_Loss:0.8483023047447205, G_Loss:2.931828498840332

iterator 3400, D_Loss:0.7238603234291077, G_Loss:4.162022590637207

iterator 3500, D_Loss:0.6707480549812317, G_Loss:2.616507053375244

iterator 3600, D_Loss:0.8746330142021179, G_Loss:3.0494141578674316

iterator 3700, D_Loss:1.7835148572921753, G_Loss:2.0947537422180176

iterator 3800, D_Loss:0.9192922115325928, G_Loss:2.6994292736053467

iterator 3900, D_Loss:0.7170470356941223, G_Loss:2.48323655128479

iterator 4000, D_Loss:0.6573460698127747, G_Loss:2.7269556522369385

iterator 4100, D_Loss:0.7393844127655029, G_Loss:2.4639859199523926

iterator 4200, D_Loss:0.8911426067352295, G_Loss:3.0996859073638916

iterator 4300, D_Loss:0.8455963730812073, G_Loss:2.5716123580932617

iterator 4400, D_Loss:0.7868614196777344, G_Loss:2.2503929138183594

iterator 4500, D_Loss:0.9303331971168518, G_Loss:3.974174737930298

iterator 4600, D_Loss:0.701414942741394, G_Loss:3.16269850730896

iterator 4700, D_Loss:0.8689768314361572, G_Loss:3.50419282913208

iterator 4800, D_Loss:1.6541825532913208, G_Loss:2.733236074447632

iterator 4900, D_Loss:1.1697429418563843, G_Loss:3.1503472328186035

iterator 5000, D_Loss:0.7353603839874268, G_Loss:3.002476692199707

LGAN_generator(
  (LSTM): LSTMCell(300, 500)
  (gmfc00): Linear(in_features=100, out_features=1, bias=True)
  (gmfc01): Linear(in_features=100, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=100, bias=True)
  (gmfe00): Linear(in_features=500, out_features=100, bias=True)
  (gmfe01): Linear(in_features=500, out_features=100, bias=True)
  (fc10): Linear(in_features=100, out_features=1, bias=True)
  (fc11): Linear(in_features=1, out_features=100, bias=True)
  (fe1): Linear(in_features=500, out_features=100, bias=True)
  (gmfc20): Linear(in_features=100, out_features=1, bias=True)
  (gmfc21): Linear(in_features=100, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=100, bias=True)
  (gmfe20): Linear(in_features=500, out_features=100, bias=True)
  (gmfe21): Linear(in_features=500, out_features=100, bias=True)
  (fc30): Linear(in_features=100, out_features=1, bias=True)
  (fc31): Linear(in_features=1, out_features=100, bias=True)
  (fe3): Linear(in_features=500, out_features=100, bias=True)
  (gmfc40): Linear(in_features=100, out_features=1, bias=True)
  (gmfc41): Linear(in_features=100, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=100, bias=True)
  (gmfe40): Linear(in_features=500, out_features=100, bias=True)
  (gmfe41): Linear(in_features=500, out_features=100, bias=True)
  (fc50): Linear(in_features=100, out_features=1, bias=True)
  (fc51): Linear(in_features=1, out_features=100, bias=True)
  (fe5): Linear(in_features=500, out_features=100, bias=True)
  (fc60): Linear(in_features=100, out_features=1, bias=True)
  (fc61): Linear(in_features=1, out_features=100, bias=True)
  (fe6): Linear(in_features=500, out_features=100, bias=True)
  (fc70): Linear(in_features=100, out_features=1, bias=True)
  (fc71): Linear(in_features=1, out_features=100, bias=True)
  (fe7): Linear(in_features=500, out_features=100, bias=True)
  (fc80): Linear(in_features=100, out_features=1, bias=True)
  (fc81): Linear(in_features=1, out_features=100, bias=True)
  (fe8): Linear(in_features=500, out_features=100, bias=True)
  (fc90): Linear(in_features=100, out_features=1, bias=True)
  (fc91): Linear(in_features=1, out_features=100, bias=True)
  (fe9): Linear(in_features=500, out_features=100, bias=True)
  (gmfc100): Linear(in_features=100, out_features=1, bias=True)
  (gmfc101): Linear(in_features=100, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=100, bias=True)
  (gmfe100): Linear(in_features=500, out_features=100, bias=True)
  (gmfe101): Linear(in_features=500, out_features=100, bias=True)
  (gmfc110): Linear(in_features=100, out_features=1, bias=True)
  (gmfc111): Linear(in_features=100, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=100, bias=True)
  (gmfe110): Linear(in_features=500, out_features=100, bias=True)
  (gmfe111): Linear(in_features=500, out_features=100, bias=True)
  (gmfc120): Linear(in_features=100, out_features=1, bias=True)
  (gmfc121): Linear(in_features=100, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=100, bias=True)
  (gmfe120): Linear(in_features=500, out_features=100, bias=True)
  (gmfe121): Linear(in_features=500, out_features=100, bias=True)
  (fc130): Linear(in_features=100, out_features=1, bias=True)
  (fc131): Linear(in_features=1, out_features=100, bias=True)
  (fe13): Linear(in_features=500, out_features=100, bias=True)
  (fc140): Linear(in_features=100, out_features=1, bias=True)
  (fc141): Linear(in_features=1, out_features=100, bias=True)
  (fe14): Linear(in_features=500, out_features=100, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=45, out_features=100, bias=True)
  (inputbn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=100, out_features=1, bias=True)
)
(0, False, 45)
-----------Epoch 0-----------
iterator 100, D_Loss:1.400888204574585, G_Loss:1.0004005432128906

iterator 200, D_Loss:1.3917291164398193, G_Loss:0.9788689613342285

iterator 300, D_Loss:1.3501958847045898, G_Loss:1.024251937866211

iterator 400, D_Loss:1.3843423128128052, G_Loss:1.112734317779541

iterator 500, D_Loss:1.32039475440979, G_Loss:1.075608730316162

iterator 600, D_Loss:1.3967775106430054, G_Loss:1.0070655345916748

iterator 700, D_Loss:1.337742805480957, G_Loss:0.9949581623077393

iterator 800, D_Loss:1.3178865909576416, G_Loss:1.0697015523910522

iterator 900, D_Loss:1.3369888067245483, G_Loss:1.3647602796554565

iterator 1000, D_Loss:1.2982676029205322, G_Loss:1.1807830333709717

iterator 1100, D_Loss:1.2392492294311523, G_Loss:1.2184933423995972

iterator 1200, D_Loss:1.2263938188552856, G_Loss:1.1514701843261719

iterator 1300, D_Loss:1.284577488899231, G_Loss:1.1900006532669067

iterator 1400, D_Loss:1.2044354677200317, G_Loss:1.0971972942352295

iterator 1500, D_Loss:1.2966639995574951, G_Loss:1.2045377492904663

iterator 1600, D_Loss:1.3001896142959595, G_Loss:1.197216510772705

iterator 1700, D_Loss:1.2283886671066284, G_Loss:1.2083486318588257

iterator 1800, D_Loss:1.243992805480957, G_Loss:1.2624773979187012

iterator 1900, D_Loss:1.2651598453521729, G_Loss:1.2091054916381836

iterator 2000, D_Loss:1.2922277450561523, G_Loss:1.1522923707962036

iterator 2100, D_Loss:1.2603428363800049, G_Loss:1.7250664234161377

iterator 2200, D_Loss:1.1802717447280884, G_Loss:1.1351706981658936

iterator 2300, D_Loss:1.2155134677886963, G_Loss:1.1869807243347168

iterator 2400, D_Loss:1.2083872556686401, G_Loss:1.1508418321609497

iterator 2500, D_Loss:1.1897112131118774, G_Loss:1.3347169160842896

iterator 2600, D_Loss:1.2650680541992188, G_Loss:1.0914263725280762

iterator 2700, D_Loss:1.2951228618621826, G_Loss:1.1822127103805542

iterator 2800, D_Loss:1.2855794429779053, G_Loss:1.2154223918914795

iterator 2900, D_Loss:1.3456284999847412, G_Loss:1.257966160774231

iterator 3000, D_Loss:1.3285212516784668, G_Loss:1.0381124019622803

iterator 3100, D_Loss:1.2241814136505127, G_Loss:1.1920769214630127

iterator 3200, D_Loss:1.2266427278518677, G_Loss:1.1540279388427734

iterator 3300, D_Loss:1.2424468994140625, G_Loss:1.1746101379394531

iterator 3400, D_Loss:1.2846840620040894, G_Loss:1.1854586601257324

iterator 3500, D_Loss:1.2690058946609497, G_Loss:1.247701644897461

iterator 3600, D_Loss:1.3341670036315918, G_Loss:1.3617056608200073

iterator 3700, D_Loss:1.2271367311477661, G_Loss:1.2191696166992188

iterator 3800, D_Loss:1.2470072507858276, G_Loss:1.0881106853485107

iterator 3900, D_Loss:1.352473258972168, G_Loss:1.055176854133606

iterator 4000, D_Loss:1.4085899591445923, G_Loss:1.3415641784667969

iterator 4100, D_Loss:1.3272111415863037, G_Loss:1.1724510192871094

iterator 4200, D_Loss:1.3179826736450195, G_Loss:1.2559266090393066

iterator 4300, D_Loss:1.2400867938995361, G_Loss:1.111457347869873

iterator 4400, D_Loss:1.2706079483032227, G_Loss:1.2009127140045166

iterator 4500, D_Loss:1.3433356285095215, G_Loss:1.2195672988891602

iterator 4600, D_Loss:1.3095512390136719, G_Loss:1.1980215311050415

iterator 4700, D_Loss:1.3246819972991943, G_Loss:1.1664835214614868

iterator 4800, D_Loss:1.3812150955200195, G_Loss:1.08576238155365

iterator 4900, D_Loss:1.2958743572235107, G_Loss:1.146919846534729

iterator 5000, D_Loss:1.2871352434158325, G_Loss:1.1102170944213867

-----------Epoch 1-----------
iterator 100, D_Loss:1.326906442642212, G_Loss:1.1595133543014526

iterator 200, D_Loss:1.3498510122299194, G_Loss:1.0319572687149048

iterator 300, D_Loss:1.29691481590271, G_Loss:1.0615429878234863

iterator 400, D_Loss:1.3203938007354736, G_Loss:1.199981451034546

iterator 500, D_Loss:1.3113113641738892, G_Loss:1.1251680850982666

iterator 600, D_Loss:1.3236926794052124, G_Loss:1.0553034543991089

iterator 700, D_Loss:1.3752846717834473, G_Loss:0.9832271933555603

iterator 800, D_Loss:1.3955543041229248, G_Loss:1.1502875089645386

iterator 900, D_Loss:1.3250728845596313, G_Loss:1.3834030628204346

iterator 1000, D_Loss:1.2916004657745361, G_Loss:1.255852222442627

iterator 1100, D_Loss:1.3161208629608154, G_Loss:1.1126747131347656

iterator 1200, D_Loss:1.3487060070037842, G_Loss:1.123655080795288

iterator 1300, D_Loss:1.2899878025054932, G_Loss:1.1078006029129028

iterator 1400, D_Loss:1.2939021587371826, G_Loss:1.017195224761963

iterator 1500, D_Loss:1.3665207624435425, G_Loss:1.1792705059051514

iterator 1600, D_Loss:1.3198977708816528, G_Loss:1.177704095840454

iterator 1700, D_Loss:1.3500652313232422, G_Loss:1.1178802251815796

iterator 1800, D_Loss:1.2954373359680176, G_Loss:1.192120909690857

iterator 1900, D_Loss:1.321923017501831, G_Loss:1.1622123718261719

iterator 2000, D_Loss:1.306030511856079, G_Loss:1.093358039855957

iterator 2100, D_Loss:1.3409838676452637, G_Loss:1.5321447849273682

iterator 2200, D_Loss:1.3077046871185303, G_Loss:1.1761350631713867

iterator 2300, D_Loss:1.3693511486053467, G_Loss:1.067123532295227

iterator 2400, D_Loss:1.3286031484603882, G_Loss:1.1279387474060059

iterator 2500, D_Loss:1.3070226907730103, G_Loss:1.2574529647827148

iterator 2600, D_Loss:1.2867196798324585, G_Loss:1.0342973470687866

iterator 2700, D_Loss:1.3517050743103027, G_Loss:1.13167405128479

iterator 2800, D_Loss:1.2904717922210693, G_Loss:1.140114665031433

iterator 2900, D_Loss:1.2928624153137207, G_Loss:1.1829047203063965

iterator 3000, D_Loss:1.313838243484497, G_Loss:1.1153411865234375

iterator 3100, D_Loss:1.3672912120819092, G_Loss:1.158547043800354

iterator 3200, D_Loss:1.2393521070480347, G_Loss:0.9966689348220825

iterator 3300, D_Loss:1.3284207582473755, G_Loss:1.029856562614441

iterator 3400, D_Loss:1.3699578046798706, G_Loss:1.189706802368164

iterator 3500, D_Loss:1.2567647695541382, G_Loss:1.1378626823425293

iterator 3600, D_Loss:1.389289379119873, G_Loss:1.2226365804672241

iterator 3700, D_Loss:1.2772278785705566, G_Loss:1.1442430019378662

iterator 3800, D_Loss:1.3363949060440063, G_Loss:1.0563774108886719

iterator 3900, D_Loss:1.2807514667510986, G_Loss:1.2212111949920654

iterator 4000, D_Loss:1.3084341287612915, G_Loss:1.26007080078125

iterator 4100, D_Loss:1.25469172000885, G_Loss:1.1710468530654907

iterator 4200, D_Loss:1.3390713930130005, G_Loss:1.1377085447311401

iterator 4300, D_Loss:1.3051095008850098, G_Loss:1.0961952209472656

iterator 4400, D_Loss:1.2956349849700928, G_Loss:1.136020302772522

iterator 4500, D_Loss:1.254625916481018, G_Loss:1.1119134426116943

iterator 4600, D_Loss:1.2967393398284912, G_Loss:1.1301913261413574

iterator 4700, D_Loss:1.2383018732070923, G_Loss:1.1700756549835205

iterator 4800, D_Loss:1.2874994277954102, G_Loss:1.1161233186721802

iterator 4900, D_Loss:1.294499158859253, G_Loss:1.172157883644104

iterator 5000, D_Loss:1.2619924545288086, G_Loss:1.1018829345703125

-----------Epoch 2-----------
iterator 100, D_Loss:1.336780071258545, G_Loss:1.1529152393341064

iterator 200, D_Loss:1.3261487483978271, G_Loss:1.0503473281860352

iterator 300, D_Loss:1.3656280040740967, G_Loss:1.07881760597229

iterator 400, D_Loss:1.328051209449768, G_Loss:1.2024418115615845

iterator 500, D_Loss:1.2908276319503784, G_Loss:1.1505722999572754

iterator 600, D_Loss:1.282629132270813, G_Loss:1.1131718158721924

iterator 700, D_Loss:1.304568886756897, G_Loss:1.0924357175827026

iterator 800, D_Loss:1.281042456626892, G_Loss:1.1874637603759766

iterator 900, D_Loss:1.321750283241272, G_Loss:1.4492528438568115

iterator 1000, D_Loss:1.3416342735290527, G_Loss:1.1894593238830566

iterator 1100, D_Loss:1.3530765771865845, G_Loss:1.195682168006897

iterator 1200, D_Loss:1.2985424995422363, G_Loss:1.2699391841888428

iterator 1300, D_Loss:1.3256134986877441, G_Loss:1.1645677089691162

iterator 1400, D_Loss:1.2826848030090332, G_Loss:1.144866704940796

iterator 1500, D_Loss:1.3099918365478516, G_Loss:1.0398353338241577

iterator 1600, D_Loss:1.3099751472473145, G_Loss:1.1955618858337402

iterator 1700, D_Loss:1.3115559816360474, G_Loss:1.149806261062622

iterator 1800, D_Loss:1.3323309421539307, G_Loss:1.1899358034133911

iterator 1900, D_Loss:1.373758316040039, G_Loss:1.16831636428833

iterator 2000, D_Loss:1.2931981086730957, G_Loss:1.1485471725463867

iterator 2100, D_Loss:1.3521792888641357, G_Loss:1.481955647468567

iterator 2200, D_Loss:1.2746089696884155, G_Loss:1.136202096939087

iterator 2300, D_Loss:1.3230767250061035, G_Loss:1.2341227531433105

iterator 2400, D_Loss:1.247103214263916, G_Loss:1.159528374671936

iterator 2500, D_Loss:1.2236953973770142, G_Loss:1.3156824111938477

iterator 2600, D_Loss:1.3050165176391602, G_Loss:1.1549413204193115

iterator 2700, D_Loss:1.3119547367095947, G_Loss:1.1969223022460938

iterator 2800, D_Loss:1.2574663162231445, G_Loss:1.105675220489502

iterator 2900, D_Loss:1.3069987297058105, G_Loss:1.2207040786743164

iterator 3000, D_Loss:1.3377660512924194, G_Loss:1.1072626113891602

iterator 3100, D_Loss:1.330467700958252, G_Loss:1.1403802633285522

iterator 3200, D_Loss:1.26808500289917, G_Loss:1.0686309337615967

iterator 3300, D_Loss:1.2419843673706055, G_Loss:1.1021344661712646

iterator 3400, D_Loss:1.2671904563903809, G_Loss:1.2603880167007446

iterator 3500, D_Loss:1.233173131942749, G_Loss:1.2064080238342285

iterator 3600, D_Loss:1.3297014236450195, G_Loss:1.2832179069519043

iterator 3700, D_Loss:1.2955039739608765, G_Loss:1.1363962888717651

iterator 3800, D_Loss:1.346483826637268, G_Loss:1.0602558851242065

iterator 3900, D_Loss:1.3184601068496704, G_Loss:1.2099833488464355

iterator 4000, D_Loss:1.339151382446289, G_Loss:1.2659144401550293

iterator 4100, D_Loss:1.3148422241210938, G_Loss:1.1939195394515991

iterator 4200, D_Loss:1.2493072748184204, G_Loss:1.19701087474823

iterator 4300, D_Loss:1.276946783065796, G_Loss:1.1482762098312378

iterator 4400, D_Loss:1.2985869646072388, G_Loss:1.1302425861358643

iterator 4500, D_Loss:1.301238775253296, G_Loss:1.159751534461975

iterator 4600, D_Loss:1.2836958169937134, G_Loss:1.1685711145401

iterator 4700, D_Loss:1.238511562347412, G_Loss:1.123918056488037

iterator 4800, D_Loss:1.2511347532272339, G_Loss:1.2746481895446777

iterator 4900, D_Loss:1.261521339416504, G_Loss:1.2285655736923218

iterator 5000, D_Loss:1.179486870765686, G_Loss:1.3157047033309937

-----------Epoch 3-----------
iterator 100, D_Loss:1.2216041088104248, G_Loss:1.2493540048599243

iterator 200, D_Loss:1.2182042598724365, G_Loss:1.0152369737625122

iterator 300, D_Loss:1.2862672805786133, G_Loss:1.057361364364624

iterator 400, D_Loss:1.2825865745544434, G_Loss:1.2169753313064575

iterator 500, D_Loss:1.331347942352295, G_Loss:1.1519485712051392

iterator 600, D_Loss:1.357837200164795, G_Loss:1.079947590827942

iterator 700, D_Loss:1.3312678337097168, G_Loss:0.9842539429664612

iterator 800, D_Loss:1.2393763065338135, G_Loss:1.162407398223877

iterator 900, D_Loss:1.2841029167175293, G_Loss:1.5492218732833862

iterator 1000, D_Loss:1.311091423034668, G_Loss:1.225477695465088

iterator 1100, D_Loss:1.3778820037841797, G_Loss:1.263935923576355

iterator 1200, D_Loss:1.294939398765564, G_Loss:1.1946642398834229

iterator 1300, D_Loss:1.3359527587890625, G_Loss:1.1344616413116455

iterator 1400, D_Loss:1.3197684288024902, G_Loss:1.112823486328125

iterator 1500, D_Loss:1.294898509979248, G_Loss:1.1870248317718506

iterator 1600, D_Loss:1.333688735961914, G_Loss:1.225213646888733

iterator 1700, D_Loss:1.2738707065582275, G_Loss:1.1992371082305908

iterator 1800, D_Loss:1.4033684730529785, G_Loss:1.1167926788330078

iterator 1900, D_Loss:1.4038171768188477, G_Loss:1.09298837184906

iterator 2000, D_Loss:1.2535399198532104, G_Loss:1.0869755744934082

iterator 2100, D_Loss:1.4426809549331665, G_Loss:1.492316484451294

iterator 2200, D_Loss:1.3148164749145508, G_Loss:1.1872460842132568

iterator 2300, D_Loss:1.3219072818756104, G_Loss:1.0819202661514282

iterator 2400, D_Loss:1.278898000717163, G_Loss:1.1492599248886108

iterator 2500, D_Loss:1.331291913986206, G_Loss:1.2656755447387695

iterator 2600, D_Loss:1.3083252906799316, G_Loss:1.0850781202316284

iterator 2700, D_Loss:1.2163563966751099, G_Loss:1.1430574655532837

iterator 2800, D_Loss:1.2224600315093994, G_Loss:1.162067174911499

iterator 2900, D_Loss:1.339667558670044, G_Loss:1.2585293054580688

iterator 3000, D_Loss:1.314408779144287, G_Loss:1.033381462097168

iterator 3100, D_Loss:1.236480951309204, G_Loss:1.2592995166778564

iterator 3200, D_Loss:1.2741048336029053, G_Loss:1.049420714378357

iterator 3300, D_Loss:1.2333660125732422, G_Loss:1.0765740871429443

iterator 3400, D_Loss:1.222015380859375, G_Loss:1.1915826797485352

iterator 3500, D_Loss:1.2496289014816284, G_Loss:1.0990502834320068

iterator 3600, D_Loss:1.3820066452026367, G_Loss:1.350483775138855

iterator 3700, D_Loss:1.273925542831421, G_Loss:1.2426416873931885

iterator 3800, D_Loss:1.2714694738388062, G_Loss:1.02631413936615

iterator 3900, D_Loss:1.3013279438018799, G_Loss:1.2987942695617676

iterator 4000, D_Loss:1.2861731052398682, G_Loss:1.3227308988571167

iterator 4100, D_Loss:1.3215296268463135, G_Loss:1.1462770700454712

iterator 4200, D_Loss:1.3559776544570923, G_Loss:1.114087700843811

iterator 4300, D_Loss:1.3514530658721924, G_Loss:1.0898176431655884

iterator 4400, D_Loss:1.2717983722686768, G_Loss:1.1280145645141602

iterator 4500, D_Loss:1.3376364707946777, G_Loss:1.1637054681777954

iterator 4600, D_Loss:1.3170130252838135, G_Loss:1.1098037958145142

iterator 4700, D_Loss:1.3444758653640747, G_Loss:1.0867093801498413

iterator 4800, D_Loss:1.344101071357727, G_Loss:1.1315953731536865

iterator 4900, D_Loss:1.293703556060791, G_Loss:1.0823194980621338

iterator 5000, D_Loss:1.3159282207489014, G_Loss:1.1267057657241821

-----------Epoch 4-----------
iterator 100, D_Loss:1.3659963607788086, G_Loss:1.0723676681518555

iterator 200, D_Loss:1.2206135988235474, G_Loss:1.118713140487671

iterator 300, D_Loss:1.3056999444961548, G_Loss:1.12697434425354

iterator 400, D_Loss:1.1945290565490723, G_Loss:1.2456434965133667

iterator 500, D_Loss:1.2534971237182617, G_Loss:1.158963918685913

iterator 600, D_Loss:1.2533178329467773, G_Loss:1.1945523023605347

iterator 700, D_Loss:1.2438489198684692, G_Loss:1.123329520225525

iterator 800, D_Loss:1.2097973823547363, G_Loss:1.3080668449401855

iterator 900, D_Loss:1.3153369426727295, G_Loss:1.2901721000671387

iterator 1000, D_Loss:1.3476896286010742, G_Loss:1.2406656742095947

iterator 1100, D_Loss:1.2767176628112793, G_Loss:1.119502067565918

iterator 1200, D_Loss:1.2615017890930176, G_Loss:1.156948447227478

iterator 1300, D_Loss:1.2787718772888184, G_Loss:1.2776215076446533

iterator 1400, D_Loss:1.24283766746521, G_Loss:1.077314853668213

iterator 1500, D_Loss:1.3307100534439087, G_Loss:1.238364338874817

iterator 1600, D_Loss:1.3298451900482178, G_Loss:1.2795754671096802

iterator 1700, D_Loss:1.34173583984375, G_Loss:1.1957595348358154

iterator 1800, D_Loss:1.3403887748718262, G_Loss:1.2009855508804321

iterator 1900, D_Loss:1.4391142129898071, G_Loss:1.1918805837631226

iterator 2000, D_Loss:1.2643463611602783, G_Loss:1.2543855905532837

iterator 2100, D_Loss:1.320314645767212, G_Loss:1.6254924535751343

iterator 2200, D_Loss:1.3216123580932617, G_Loss:1.1580755710601807

iterator 2300, D_Loss:1.3697082996368408, G_Loss:1.0751093626022339

iterator 2400, D_Loss:1.3019707202911377, G_Loss:1.2291598320007324

iterator 2500, D_Loss:1.2879724502563477, G_Loss:1.241295337677002

iterator 2600, D_Loss:1.2362028360366821, G_Loss:1.1354621648788452

iterator 2700, D_Loss:1.3154081106185913, G_Loss:1.2128593921661377

iterator 2800, D_Loss:1.2819364070892334, G_Loss:1.2393200397491455

iterator 2900, D_Loss:1.2592355012893677, G_Loss:1.1490460634231567

iterator 3000, D_Loss:1.336174726486206, G_Loss:1.1032506227493286

iterator 3100, D_Loss:1.3044931888580322, G_Loss:1.1993203163146973

iterator 3200, D_Loss:1.299687147140503, G_Loss:1.0466994047164917

iterator 3300, D_Loss:1.2782208919525146, G_Loss:1.0996427536010742

iterator 3400, D_Loss:1.2971643209457397, G_Loss:1.2726856470108032

iterator 3500, D_Loss:1.3343071937561035, G_Loss:1.2085213661193848

iterator 3600, D_Loss:1.3727447986602783, G_Loss:1.2567459344863892

iterator 3700, D_Loss:1.234151005744934, G_Loss:1.195886492729187

iterator 3800, D_Loss:1.2753651142120361, G_Loss:1.1567580699920654

iterator 3900, D_Loss:1.2588624954223633, G_Loss:1.2608861923217773

iterator 4000, D_Loss:1.3099145889282227, G_Loss:1.2246992588043213

iterator 4100, D_Loss:1.2899054288864136, G_Loss:1.252358078956604

iterator 4200, D_Loss:1.3248589038848877, G_Loss:1.1870092153549194

iterator 4300, D_Loss:1.3238693475723267, G_Loss:1.0988678932189941

iterator 4400, D_Loss:1.3341120481491089, G_Loss:1.1513350009918213

iterator 4500, D_Loss:1.2772738933563232, G_Loss:1.173239827156067

iterator 4600, D_Loss:1.4234960079193115, G_Loss:1.1645745038986206

iterator 4700, D_Loss:1.2667375802993774, G_Loss:1.1577237844467163

iterator 4800, D_Loss:1.3633315563201904, G_Loss:1.234266996383667

iterator 4900, D_Loss:1.3171849250793457, G_Loss:1.2166521549224854

iterator 5000, D_Loss:1.2054367065429688, G_Loss:1.0982298851013184

-----------Epoch 5-----------
iterator 100, D_Loss:1.3134877681732178, G_Loss:1.1462568044662476

iterator 200, D_Loss:1.2642369270324707, G_Loss:0.9915726184844971

iterator 300, D_Loss:1.2547094821929932, G_Loss:1.2071727514266968

iterator 400, D_Loss:1.289167046546936, G_Loss:1.1617469787597656

iterator 500, D_Loss:1.2235355377197266, G_Loss:1.1984678506851196

iterator 600, D_Loss:1.3168418407440186, G_Loss:1.139910101890564

iterator 700, D_Loss:1.318954586982727, G_Loss:1.1496827602386475

iterator 800, D_Loss:1.2650038003921509, G_Loss:1.2063840627670288

iterator 900, D_Loss:1.312698245048523, G_Loss:1.295712947845459

iterator 1000, D_Loss:1.3174042701721191, G_Loss:1.1967393159866333

iterator 1100, D_Loss:1.3508574962615967, G_Loss:1.150391697883606

iterator 1200, D_Loss:1.3375556468963623, G_Loss:1.257440447807312

iterator 1300, D_Loss:1.2651095390319824, G_Loss:1.2754125595092773

iterator 1400, D_Loss:1.2445837259292603, G_Loss:1.197245478630066

iterator 1500, D_Loss:1.3278027772903442, G_Loss:1.3208439350128174

iterator 1600, D_Loss:1.3610742092132568, G_Loss:1.2464574575424194

iterator 1700, D_Loss:1.3476049900054932, G_Loss:1.4144554138183594

iterator 1800, D_Loss:1.2731987237930298, G_Loss:1.2071181535720825

iterator 1900, D_Loss:1.3052364587783813, G_Loss:1.1625820398330688

iterator 2000, D_Loss:1.297571063041687, G_Loss:1.256668210029602

iterator 2100, D_Loss:1.3537874221801758, G_Loss:1.7585967779159546

iterator 2200, D_Loss:1.3626959323883057, G_Loss:1.1565426588058472

iterator 2300, D_Loss:1.326350212097168, G_Loss:1.1173852682113647

iterator 2400, D_Loss:1.2681690454483032, G_Loss:1.0832951068878174

iterator 2500, D_Loss:1.3330215215682983, G_Loss:1.2214335203170776

iterator 2600, D_Loss:1.3464889526367188, G_Loss:1.2602814435958862

iterator 2700, D_Loss:1.3294622898101807, G_Loss:1.096997857093811

iterator 2800, D_Loss:1.2431560754776, G_Loss:1.2249411344528198

iterator 2900, D_Loss:1.296292781829834, G_Loss:1.1258009672164917

iterator 3000, D_Loss:1.2652060985565186, G_Loss:0.9641284346580505

iterator 3100, D_Loss:1.3144081830978394, G_Loss:1.0267277956008911

iterator 3200, D_Loss:1.3546421527862549, G_Loss:1.1222047805786133

iterator 3300, D_Loss:1.328244924545288, G_Loss:1.0322009325027466

iterator 3400, D_Loss:1.2370935678482056, G_Loss:1.2626194953918457

iterator 3500, D_Loss:1.2603402137756348, G_Loss:1.1766992807388306

iterator 3600, D_Loss:1.3889896869659424, G_Loss:1.3372222185134888

iterator 3700, D_Loss:1.2578580379486084, G_Loss:1.1068406105041504

iterator 3800, D_Loss:1.259474754333496, G_Loss:1.1576498746871948

iterator 3900, D_Loss:1.2588149309158325, G_Loss:1.1728074550628662

iterator 4000, D_Loss:1.3290762901306152, G_Loss:1.2129936218261719

iterator 4100, D_Loss:1.3136534690856934, G_Loss:1.1801061630249023

iterator 4200, D_Loss:1.322497844696045, G_Loss:1.1873574256896973

iterator 4300, D_Loss:1.381642460823059, G_Loss:1.257061243057251

iterator 4400, D_Loss:1.3285253047943115, G_Loss:1.1598434448242188

iterator 4500, D_Loss:1.3240407705307007, G_Loss:1.1095672845840454

iterator 4600, D_Loss:1.4030234813690186, G_Loss:1.1641931533813477

iterator 4700, D_Loss:1.3441214561462402, G_Loss:1.196663498878479

iterator 4800, D_Loss:1.2886161804199219, G_Loss:1.1557631492614746

iterator 4900, D_Loss:1.2497481107711792, G_Loss:1.0869438648223877

iterator 5000, D_Loss:1.3567650318145752, G_Loss:1.0321308374404907

-----------Epoch 6-----------
iterator 100, D_Loss:1.315056562423706, G_Loss:1.1115835905075073

iterator 200, D_Loss:1.2592239379882812, G_Loss:1.122999906539917

iterator 300, D_Loss:1.2882280349731445, G_Loss:1.0280872583389282

iterator 400, D_Loss:1.2913203239440918, G_Loss:1.22990882396698

iterator 500, D_Loss:1.184077501296997, G_Loss:1.136434555053711

iterator 600, D_Loss:1.3567404747009277, G_Loss:1.15615713596344

iterator 700, D_Loss:1.2600973844528198, G_Loss:1.02671217918396

iterator 800, D_Loss:1.2516834735870361, G_Loss:1.1297459602355957

iterator 900, D_Loss:1.230461597442627, G_Loss:1.3378338813781738

iterator 1000, D_Loss:1.3097050189971924, G_Loss:1.3909401893615723

iterator 1100, D_Loss:1.3224622011184692, G_Loss:1.2100090980529785

iterator 1200, D_Loss:1.296238899230957, G_Loss:1.197493076324463

iterator 1300, D_Loss:1.3333181142807007, G_Loss:1.2926697731018066

iterator 1400, D_Loss:1.3464492559432983, G_Loss:1.0033667087554932

iterator 1500, D_Loss:1.286205768585205, G_Loss:1.2268146276474

iterator 1600, D_Loss:1.343601942062378, G_Loss:1.2463301420211792

iterator 1700, D_Loss:1.3123416900634766, G_Loss:1.1415679454803467

iterator 1800, D_Loss:1.352062463760376, G_Loss:1.2182329893112183

iterator 1900, D_Loss:1.3724472522735596, G_Loss:1.136325716972351

iterator 2000, D_Loss:1.2088745832443237, G_Loss:1.3382281064987183

iterator 2100, D_Loss:1.3301445245742798, G_Loss:1.5893275737762451

iterator 2200, D_Loss:1.298384189605713, G_Loss:1.2143629789352417

iterator 2300, D_Loss:1.3515528440475464, G_Loss:1.0469164848327637

iterator 2400, D_Loss:1.2305408716201782, G_Loss:1.1501657962799072

iterator 2500, D_Loss:1.3895587921142578, G_Loss:1.2359062433242798

iterator 2600, D_Loss:1.2640326023101807, G_Loss:1.1103020906448364

iterator 2700, D_Loss:1.3503937721252441, G_Loss:1.228657841682434

iterator 2800, D_Loss:1.2101233005523682, G_Loss:1.2646108865737915

iterator 2900, D_Loss:1.3382606506347656, G_Loss:1.2380645275115967

iterator 3000, D_Loss:1.1965259313583374, G_Loss:1.155630350112915

iterator 3100, D_Loss:1.1554460525512695, G_Loss:1.216805338859558

iterator 3200, D_Loss:1.338836908340454, G_Loss:1.0610015392303467

iterator 3300, D_Loss:1.233323335647583, G_Loss:1.111595630645752

iterator 3400, D_Loss:1.320055603981018, G_Loss:1.2211390733718872

iterator 3500, D_Loss:1.3616470098495483, G_Loss:1.162018895149231

iterator 3600, D_Loss:1.3075082302093506, G_Loss:1.3431103229522705

iterator 3700, D_Loss:1.3302156925201416, G_Loss:1.172522783279419

iterator 3800, D_Loss:1.2820026874542236, G_Loss:1.1305686235427856

iterator 3900, D_Loss:1.2618327140808105, G_Loss:1.2647041082382202

iterator 4000, D_Loss:1.297173023223877, G_Loss:1.315662145614624

iterator 4100, D_Loss:1.2081869840621948, G_Loss:1.0835176706314087

iterator 4200, D_Loss:1.3258039951324463, G_Loss:1.110491156578064

iterator 4300, D_Loss:1.3610584735870361, G_Loss:1.1277995109558105

iterator 4400, D_Loss:1.3664616346359253, G_Loss:1.2670040130615234

iterator 4500, D_Loss:1.2838852405548096, G_Loss:1.2404881715774536

iterator 4600, D_Loss:1.4275343418121338, G_Loss:1.2911787033081055

iterator 4700, D_Loss:1.3781449794769287, G_Loss:1.145112156867981

iterator 4800, D_Loss:1.2971980571746826, G_Loss:1.2576494216918945

iterator 4900, D_Loss:1.366948127746582, G_Loss:1.2739704847335815

iterator 5000, D_Loss:1.2412450313568115, G_Loss:1.1466234922409058

-----------Epoch 7-----------
iterator 100, D_Loss:1.3341596126556396, G_Loss:1.1257977485656738

iterator 200, D_Loss:1.3125874996185303, G_Loss:1.0478599071502686

iterator 300, D_Loss:1.305692195892334, G_Loss:1.1950373649597168

iterator 400, D_Loss:1.2922192811965942, G_Loss:1.1883654594421387

iterator 500, D_Loss:1.3061323165893555, G_Loss:1.1478453874588013

iterator 600, D_Loss:1.2972379922866821, G_Loss:1.1080127954483032

iterator 700, D_Loss:1.312288761138916, G_Loss:1.1644152402877808

iterator 800, D_Loss:1.3519024848937988, G_Loss:1.0939667224884033

iterator 900, D_Loss:1.2813189029693604, G_Loss:1.2909479141235352

iterator 1000, D_Loss:1.3253222703933716, G_Loss:1.106748104095459

iterator 1100, D_Loss:1.3182268142700195, G_Loss:1.1899207830429077

iterator 1200, D_Loss:1.3618037700653076, G_Loss:1.0592647790908813

iterator 1300, D_Loss:1.3621717691421509, G_Loss:1.1082319021224976

iterator 1400, D_Loss:1.2540538311004639, G_Loss:1.0949859619140625

iterator 1500, D_Loss:1.340782642364502, G_Loss:1.1151800155639648

iterator 1600, D_Loss:1.2732782363891602, G_Loss:1.241532564163208

iterator 1700, D_Loss:1.2927030324935913, G_Loss:1.2619644403457642

iterator 1800, D_Loss:1.3811196088790894, G_Loss:1.1582310199737549

iterator 1900, D_Loss:1.3511803150177002, G_Loss:1.1394292116165161

iterator 2000, D_Loss:1.369882345199585, G_Loss:1.138883352279663

iterator 2100, D_Loss:1.4360871315002441, G_Loss:1.4946238994598389

iterator 2200, D_Loss:1.2895958423614502, G_Loss:1.2467808723449707

iterator 2300, D_Loss:1.3360127210617065, G_Loss:1.1029752492904663

iterator 2400, D_Loss:1.2908530235290527, G_Loss:1.142713189125061

iterator 2500, D_Loss:1.351487636566162, G_Loss:1.2425062656402588

iterator 2600, D_Loss:1.339905023574829, G_Loss:1.0440565347671509

iterator 2700, D_Loss:1.3208715915679932, G_Loss:1.1928232908248901

iterator 2800, D_Loss:1.2768230438232422, G_Loss:1.0824568271636963

iterator 2900, D_Loss:1.3864299058914185, G_Loss:1.1307650804519653

iterator 3000, D_Loss:1.2738704681396484, G_Loss:0.9944623708724976

iterator 3100, D_Loss:1.2485620975494385, G_Loss:1.1143059730529785

iterator 3200, D_Loss:1.2300362586975098, G_Loss:1.0603489875793457

iterator 3300, D_Loss:1.2592369318008423, G_Loss:1.0259509086608887

iterator 3400, D_Loss:1.3482989072799683, G_Loss:1.2281934022903442

iterator 3500, D_Loss:1.3465499877929688, G_Loss:1.1493226289749146

iterator 3600, D_Loss:1.3852843046188354, G_Loss:1.2811148166656494

iterator 3700, D_Loss:1.3774770498275757, G_Loss:1.1657353639602661

iterator 3800, D_Loss:1.248898983001709, G_Loss:1.0989079475402832

iterator 3900, D_Loss:1.2582745552062988, G_Loss:1.1059329509735107

iterator 4000, D_Loss:1.3366687297821045, G_Loss:1.1431292295455933

iterator 4100, D_Loss:1.2983524799346924, G_Loss:1.1626676321029663

iterator 4200, D_Loss:1.3484280109405518, G_Loss:1.155655860900879

iterator 4300, D_Loss:1.368351697921753, G_Loss:1.0883498191833496

iterator 4400, D_Loss:1.304783582687378, G_Loss:1.0897433757781982

iterator 4500, D_Loss:1.3464138507843018, G_Loss:1.3249225616455078

iterator 4600, D_Loss:1.3548967838287354, G_Loss:1.1179327964782715

iterator 4700, D_Loss:1.3313050270080566, G_Loss:1.0626524686813354

iterator 4800, D_Loss:1.3016737699508667, G_Loss:1.0889554023742676

iterator 4900, D_Loss:1.4145517349243164, G_Loss:1.1181857585906982

iterator 5000, D_Loss:1.3450698852539062, G_Loss:1.0438042879104614

-----------Epoch 8-----------
iterator 100, D_Loss:1.2750005722045898, G_Loss:1.160529375076294

iterator 200, D_Loss:1.395624041557312, G_Loss:1.1030220985412598

iterator 300, D_Loss:1.3101122379302979, G_Loss:1.144819974899292

iterator 400, D_Loss:1.3176720142364502, G_Loss:1.193884015083313

iterator 500, D_Loss:1.265046238899231, G_Loss:1.2169219255447388

iterator 600, D_Loss:1.2958457469940186, G_Loss:1.0777583122253418

iterator 700, D_Loss:1.304503083229065, G_Loss:1.0402277708053589

iterator 800, D_Loss:1.3654334545135498, G_Loss:1.1468396186828613

iterator 900, D_Loss:1.3112767934799194, G_Loss:1.3805229663848877

iterator 1000, D_Loss:1.2595524787902832, G_Loss:1.2692387104034424

iterator 1100, D_Loss:1.3133039474487305, G_Loss:1.1522667407989502

iterator 1200, D_Loss:1.3471802473068237, G_Loss:1.1362605094909668

iterator 1300, D_Loss:1.3083107471466064, G_Loss:1.1003292798995972

iterator 1400, D_Loss:1.2313754558563232, G_Loss:1.1255449056625366

iterator 1500, D_Loss:1.3270187377929688, G_Loss:1.084446907043457

iterator 1600, D_Loss:1.2899940013885498, G_Loss:1.1515703201293945

iterator 1700, D_Loss:1.308934211730957, G_Loss:1.2032997608184814

iterator 1800, D_Loss:1.2931602001190186, G_Loss:1.1369514465332031

iterator 1900, D_Loss:1.3703241348266602, G_Loss:1.0631294250488281

iterator 2000, D_Loss:1.258624792098999, G_Loss:1.1246747970581055

iterator 2100, D_Loss:1.3848986625671387, G_Loss:1.6953718662261963

iterator 2200, D_Loss:1.4037408828735352, G_Loss:1.12030029296875

iterator 2300, D_Loss:1.2708855867385864, G_Loss:1.4323641061782837

iterator 2400, D_Loss:1.340017557144165, G_Loss:1.105823278427124

iterator 2500, D_Loss:1.4200286865234375, G_Loss:1.304661512374878

iterator 2600, D_Loss:1.2845046520233154, G_Loss:1.1563031673431396

iterator 2700, D_Loss:1.2743141651153564, G_Loss:1.3005982637405396

iterator 2800, D_Loss:1.3001502752304077, G_Loss:1.0774956941604614

iterator 2900, D_Loss:1.4512501955032349, G_Loss:1.0929135084152222

iterator 3000, D_Loss:1.2879806756973267, G_Loss:1.0794979333877563

iterator 3100, D_Loss:1.34920072555542, G_Loss:1.3495056629180908

iterator 3200, D_Loss:1.2887945175170898, G_Loss:1.1462873220443726

iterator 3300, D_Loss:1.2918941974639893, G_Loss:1.1494066715240479

iterator 3400, D_Loss:1.3132086992263794, G_Loss:1.1959549188613892

iterator 3500, D_Loss:1.25631582736969, G_Loss:1.2446105480194092

iterator 3600, D_Loss:1.3602406978607178, G_Loss:1.2599327564239502

iterator 3700, D_Loss:1.2463017702102661, G_Loss:1.2789649963378906

iterator 3800, D_Loss:1.2517399787902832, G_Loss:1.1230779886245728

iterator 3900, D_Loss:1.2317991256713867, G_Loss:1.4328771829605103

iterator 4000, D_Loss:1.3327727317810059, G_Loss:1.2556544542312622

iterator 4100, D_Loss:1.3144006729125977, G_Loss:1.161189079284668

iterator 4200, D_Loss:1.3222506046295166, G_Loss:1.0782771110534668

iterator 4300, D_Loss:1.3469631671905518, G_Loss:0.9988621473312378

iterator 4400, D_Loss:1.2674622535705566, G_Loss:1.2000763416290283

iterator 4500, D_Loss:1.3809239864349365, G_Loss:1.3747375011444092

iterator 4600, D_Loss:1.330119013786316, G_Loss:1.1673405170440674

iterator 4700, D_Loss:1.2796337604522705, G_Loss:1.1990313529968262

iterator 4800, D_Loss:1.2930446863174438, G_Loss:1.054029941558838

iterator 4900, D_Loss:1.2909003496170044, G_Loss:1.0752943754196167

iterator 5000, D_Loss:1.325344204902649, G_Loss:1.05293607711792

-----------Epoch 9-----------
iterator 100, D_Loss:1.354762315750122, G_Loss:1.0511720180511475

iterator 200, D_Loss:1.230879545211792, G_Loss:1.083490014076233

iterator 300, D_Loss:1.2983763217926025, G_Loss:1.11225426197052

iterator 400, D_Loss:1.304610252380371, G_Loss:1.1118320226669312

iterator 500, D_Loss:1.2895928621292114, G_Loss:1.1392076015472412

iterator 600, D_Loss:1.389389157295227, G_Loss:1.0659929513931274

iterator 700, D_Loss:1.3165380954742432, G_Loss:1.0866612195968628

iterator 800, D_Loss:1.2961301803588867, G_Loss:1.1773626804351807

iterator 900, D_Loss:1.2543058395385742, G_Loss:1.4054111242294312

iterator 1000, D_Loss:1.2764774560928345, G_Loss:1.1478610038757324

iterator 1100, D_Loss:1.3652195930480957, G_Loss:1.1863514184951782

iterator 1200, D_Loss:1.304145336151123, G_Loss:1.1487808227539062

iterator 1300, D_Loss:1.320958137512207, G_Loss:1.2393522262573242

iterator 1400, D_Loss:1.369411587715149, G_Loss:1.051139235496521

iterator 1500, D_Loss:1.3356194496154785, G_Loss:1.1754584312438965

iterator 1600, D_Loss:1.3753750324249268, G_Loss:1.111954689025879

iterator 1700, D_Loss:1.3123910427093506, G_Loss:1.1813294887542725

iterator 1800, D_Loss:1.2290713787078857, G_Loss:1.2265139818191528

iterator 1900, D_Loss:1.3861234188079834, G_Loss:1.1742210388183594

iterator 2000, D_Loss:1.321885108947754, G_Loss:1.1095365285873413

iterator 2100, D_Loss:1.3795156478881836, G_Loss:1.477876901626587

iterator 2200, D_Loss:1.3934240341186523, G_Loss:1.1026649475097656

iterator 2300, D_Loss:1.3385536670684814, G_Loss:1.1486791372299194

iterator 2400, D_Loss:1.2531391382217407, G_Loss:1.1063581705093384

iterator 2500, D_Loss:1.399817943572998, G_Loss:1.2248495817184448

iterator 2600, D_Loss:1.318838357925415, G_Loss:1.0781093835830688

iterator 2700, D_Loss:1.2923732995986938, G_Loss:1.2164663076400757

iterator 2800, D_Loss:1.2532873153686523, G_Loss:1.118945837020874

iterator 2900, D_Loss:1.3553727865219116, G_Loss:1.195169448852539

iterator 3000, D_Loss:1.3634555339813232, G_Loss:1.0857044458389282

iterator 3100, D_Loss:1.2850615978240967, G_Loss:1.160865068435669

iterator 3200, D_Loss:1.3364710807800293, G_Loss:1.0233547687530518

iterator 3300, D_Loss:1.3290998935699463, G_Loss:1.0891104936599731

iterator 3400, D_Loss:1.3106846809387207, G_Loss:1.185960292816162

iterator 3500, D_Loss:1.2593705654144287, G_Loss:1.2303980588912964

iterator 3600, D_Loss:1.3811999559402466, G_Loss:1.2488396167755127

iterator 3700, D_Loss:1.2752248048782349, G_Loss:1.1794499158859253

iterator 3800, D_Loss:1.3284955024719238, G_Loss:1.1692028045654297

iterator 3900, D_Loss:1.2873632907867432, G_Loss:1.1657791137695312

iterator 4000, D_Loss:1.3474228382110596, G_Loss:1.1803979873657227

iterator 4100, D_Loss:1.3091633319854736, G_Loss:1.2023286819458008

iterator 4200, D_Loss:1.315319538116455, G_Loss:1.2169190645217896

iterator 4300, D_Loss:1.3825023174285889, G_Loss:1.0479527711868286

iterator 4400, D_Loss:1.307875156402588, G_Loss:1.186143159866333

iterator 4500, D_Loss:1.3152968883514404, G_Loss:1.0793933868408203

iterator 4600, D_Loss:1.3879772424697876, G_Loss:1.1081926822662354

iterator 4700, D_Loss:1.3467642068862915, G_Loss:1.0878334045410156

iterator 4800, D_Loss:1.329367756843567, G_Loss:1.1483591794967651

iterator 4900, D_Loss:1.3645282983779907, G_Loss:1.0902117490768433

iterator 5000, D_Loss:1.2171372175216675, G_Loss:1.0716177225112915

train row : 30148
sample row: 30148
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [192,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [193,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [194,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [195,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [196,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [197,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [198,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [199,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [96,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [97,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [98,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [99,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [100,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [101,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [102,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [103,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [104,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [105,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [106,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [107,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [108,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [109,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [110,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [111,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [112,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [113,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [114,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [115,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [116,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [117,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [118,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [119,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [120,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [121,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [122,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [123,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [124,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [125,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [126,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [127,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [64,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [65,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [66,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [67,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [68,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [69,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [70,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [71,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [72,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [73,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [74,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [75,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [76,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [77,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [78,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [79,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [80,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [81,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [82,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [83,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [84,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [85,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [86,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [87,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [88,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [89,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [90,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [91,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [92,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [93,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [94,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [95,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [0,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [1,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [2,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [3,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [4,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [5,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [6,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [7,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [8,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [9,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [10,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [11,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [12,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [13,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [14,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [15,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [16,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [17,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [18,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [19,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [20,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [21,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [22,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [23,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [24,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [25,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [26,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [27,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [28,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [29,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [30,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [31,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [128,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [129,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [130,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [131,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [132,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [133,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [134,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [135,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [136,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [137,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [138,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [139,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [140,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [141,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [142,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [143,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [144,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [145,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [146,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [147,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [148,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [149,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [150,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [151,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [152,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [153,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [154,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [155,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [156,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [157,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [158,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [159,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [32,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [33,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [34,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [35,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [36,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [37,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [38,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [39,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [40,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [41,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [42,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [43,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [44,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [45,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [46,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [47,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [48,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [49,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [50,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [51,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [52,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [53,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [54,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [55,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [56,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [57,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [58,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [59,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [60,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [61,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [62,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [63,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [160,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [161,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [162,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [163,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [164,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [165,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [166,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [167,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [168,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [169,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [170,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [171,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [172,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [173,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [174,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [175,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [176,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [177,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [178,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [179,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [180,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [181,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [182,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [183,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [184,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [185,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [186,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [187,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [188,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [189,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [190,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [191,0,0] Assertion `input >= 0. && input <= 1.` failed.
LGAN_generator(
  (LSTM): LSTMCell(500, 300)
  (fc00): Linear(in_features=300, out_features=1, bias=True)
  (fc01): Linear(in_features=1, out_features=300, bias=True)
  (fe0): Linear(in_features=300, out_features=300, bias=True)
  (fc10): Linear(in_features=300, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=300, bias=True)
  (fe1): Linear(in_features=300, out_features=300, bias=True)
  (fc20): Linear(in_features=300, out_features=1, bias=True)
  (fc21): Linear(in_features=1, out_features=300, bias=True)
  (fe2): Linear(in_features=300, out_features=300, bias=True)
  (fc30): Linear(in_features=300, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=300, bias=True)
  (fe3): Linear(in_features=300, out_features=300, bias=True)
  (fc40): Linear(in_features=300, out_features=1, bias=True)
  (fc41): Linear(in_features=1, out_features=300, bias=True)
  (fe4): Linear(in_features=300, out_features=300, bias=True)
  (fc50): Linear(in_features=300, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=300, bias=True)
  (fe5): Linear(in_features=300, out_features=300, bias=True)
  (fc60): Linear(in_features=300, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=300, bias=True)
  (fe6): Linear(in_features=300, out_features=300, bias=True)
  (fc70): Linear(in_features=300, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=300, bias=True)
  (fe7): Linear(in_features=300, out_features=300, bias=True)
  (fc80): Linear(in_features=300, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=300, bias=True)
  (fe8): Linear(in_features=300, out_features=300, bias=True)
  (fc90): Linear(in_features=300, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=300, bias=True)
  (fe9): Linear(in_features=300, out_features=300, bias=True)
  (fc100): Linear(in_features=300, out_features=1, bias=True)
  (fc101): Linear(in_features=1, out_features=300, bias=True)
  (fe10): Linear(in_features=300, out_features=300, bias=True)
  (fc110): Linear(in_features=300, out_features=1, bias=True)
  (fc111): Linear(in_features=1, out_features=300, bias=True)
  (fe11): Linear(in_features=300, out_features=300, bias=True)
  (fc120): Linear(in_features=300, out_features=1, bias=True)
  (fc121): Linear(in_features=1, out_features=300, bias=True)
  (fe12): Linear(in_features=300, out_features=300, bias=True)
  (fc130): Linear(in_features=300, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=300, bias=True)
  (fe13): Linear(in_features=300, out_features=300, bias=True)
  (fc140): Linear(in_features=300, out_features=2, bias=True)
  (fc141): Linear(in_features=2, out_features=300, bias=True)
  (fe14): Linear(in_features=300, out_features=300, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=105, out_features=200, bias=True)
  (inputbn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (bn0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=200, out_features=200, bias=True)
  (bn1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=200, out_features=200, bias=True)
  (bn2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=200, out_features=200, bias=True)
  (bn3): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc4): Linear(in_features=200, out_features=200, bias=True)
  (bn4): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=200, out_features=1, bias=True)
)
(0, False, 105)
-----------Epoch 0-----------
iterator 100, D_Loss:1.3722243309020996, G_Loss:0.922204315662384

iterator 200, D_Loss:1.3087289333343506, G_Loss:1.0238591432571411

iterator 300, D_Loss:1.4011528491973877, G_Loss:1.4708003997802734

iterator 400, D_Loss:0.9650695323944092, G_Loss:3.070857048034668

iterator 500, D_Loss:0.5283440947532654, G_Loss:4.639966011047363

iterator 600, D_Loss:0.5843802690505981, G_Loss:4.583647727966309

iterator 700, D_Loss:0.5695471167564392, G_Loss:6.963426113128662

iterator 800, D_Loss:0.45790666341781616, G_Loss:6.902676105499268

iterator 900, D_Loss:0.5618245601654053, G_Loss:8.121264457702637

iterator 1000, D_Loss:0.4646333158016205, G_Loss:8.810216903686523

iterator 1100, D_Loss:0.435977041721344, G_Loss:8.720613479614258

iterator 1200, D_Loss:0.43596720695495605, G_Loss:8.70491886138916

iterator 1300, D_Loss:0.4231970012187958, G_Loss:8.57485294342041

iterator 1400, D_Loss:0.4454236924648285, G_Loss:8.18047046661377

iterator 1500, D_Loss:0.4341040849685669, G_Loss:8.897146224975586

iterator 1600, D_Loss:0.42517346143722534, G_Loss:9.033829689025879

iterator 1700, D_Loss:0.43940162658691406, G_Loss:7.27019739151001

iterator 1800, D_Loss:0.4344668686389923, G_Loss:10.89578628540039

iterator 1900, D_Loss:0.42522314190864563, G_Loss:10.976834297180176

iterator 2000, D_Loss:0.42500221729278564, G_Loss:10.8712158203125

iterator 2100, D_Loss:0.4099697172641754, G_Loss:11.991971969604492

iterator 2200, D_Loss:0.4202265739440918, G_Loss:11.431625366210938

iterator 2300, D_Loss:0.45083749294281006, G_Loss:11.677543640136719

iterator 2400, D_Loss:0.433358371257782, G_Loss:11.056794166564941

iterator 2500, D_Loss:0.41603171825408936, G_Loss:12.471746444702148

iterator 2600, D_Loss:0.4185904860496521, G_Loss:10.408394813537598

iterator 2700, D_Loss:0.4321743845939636, G_Loss:11.160882949829102

iterator 2800, D_Loss:0.4084201157093048, G_Loss:12.250998497009277

iterator 2900, D_Loss:0.4299485385417938, G_Loss:11.982220649719238

iterator 3000, D_Loss:0.43437790870666504, G_Loss:11.70692253112793

iterator 3100, D_Loss:0.43082937598228455, G_Loss:11.626261711120605

iterator 3200, D_Loss:0.4376431703567505, G_Loss:10.729402542114258

iterator 3300, D_Loss:0.43414148688316345, G_Loss:17.144641876220703

iterator 3400, D_Loss:0.43222159147262573, G_Loss:14.658702850341797

iterator 3500, D_Loss:0.4011547565460205, G_Loss:16.977792739868164

iterator 3600, D_Loss:0.4280233085155487, G_Loss:14.790362358093262

iterator 3700, D_Loss:0.4317045509815216, G_Loss:14.298158645629883

iterator 3800, D_Loss:0.42004281282424927, G_Loss:15.807640075683594

iterator 3900, D_Loss:0.41996896266937256, G_Loss:13.439781188964844

iterator 4000, D_Loss:0.41634219884872437, G_Loss:14.559795379638672

iterator 4100, D_Loss:0.42893078923225403, G_Loss:9.49160385131836

iterator 4200, D_Loss:0.42315778136253357, G_Loss:11.348116874694824

iterator 4300, D_Loss:0.40770062804222107, G_Loss:15.22986888885498

iterator 4400, D_Loss:0.44177407026290894, G_Loss:13.677127838134766

iterator 4500, D_Loss:0.4289554953575134, G_Loss:14.196582794189453

iterator 4600, D_Loss:0.44466859102249146, G_Loss:15.668455123901367

iterator 4700, D_Loss:0.4255184531211853, G_Loss:14.493562698364258

iterator 4800, D_Loss:0.42768594622612, G_Loss:14.749604225158691

iterator 4900, D_Loss:0.44231799244880676, G_Loss:18.863605499267578

iterator 5000, D_Loss:0.4122862219810486, G_Loss:20.876720428466797

-----------Epoch 1-----------
iterator 100, D_Loss:0.4318810999393463, G_Loss:18.074344635009766

iterator 200, D_Loss:0.4287228584289551, G_Loss:22.07369613647461

iterator 300, D_Loss:0.43338119983673096, G_Loss:21.87102699279785

iterator 400, D_Loss:0.4221577048301697, G_Loss:21.305604934692383

iterator 500, D_Loss:0.4223126769065857, G_Loss:18.595317840576172

iterator 600, D_Loss:0.4312972128391266, G_Loss:23.409778594970703

iterator 700, D_Loss:0.43584567308425903, G_Loss:24.426063537597656

iterator 800, D_Loss:0.4177936017513275, G_Loss:25.881134033203125

iterator 900, D_Loss:0.4490298330783844, G_Loss:21.21390724182129

iterator 1000, D_Loss:0.4161292612552643, G_Loss:17.519271850585938

iterator 1100, D_Loss:0.4195423424243927, G_Loss:20.5141658782959

iterator 1200, D_Loss:0.43758824467658997, G_Loss:20.4805850982666

iterator 1300, D_Loss:0.4212266206741333, G_Loss:21.837656021118164

iterator 1400, D_Loss:0.4177877902984619, G_Loss:22.638038635253906

iterator 1500, D_Loss:0.42477500438690186, G_Loss:26.00371742248535

iterator 1600, D_Loss:0.40894463658332825, G_Loss:21.043792724609375

iterator 1700, D_Loss:0.40921032428741455, G_Loss:23.494491577148438

iterator 1800, D_Loss:0.4315051734447479, G_Loss:21.253009796142578

iterator 1900, D_Loss:0.4257962703704834, G_Loss:21.0660400390625

iterator 2000, D_Loss:0.4109717905521393, G_Loss:22.799129486083984

iterator 2100, D_Loss:0.42834240198135376, G_Loss:22.059412002563477

iterator 2200, D_Loss:0.42071712017059326, G_Loss:22.037187576293945

iterator 2300, D_Loss:0.424932599067688, G_Loss:24.278919219970703

iterator 2400, D_Loss:0.41469651460647583, G_Loss:22.12779998779297

iterator 2500, D_Loss:0.43114611506462097, G_Loss:22.315589904785156

iterator 2600, D_Loss:0.4162677228450775, G_Loss:22.847698211669922

iterator 2700, D_Loss:0.41812819242477417, G_Loss:24.688417434692383

iterator 2800, D_Loss:0.43177518248558044, G_Loss:23.500513076782227

iterator 2900, D_Loss:0.4173891544342041, G_Loss:23.85281753540039

iterator 3000, D_Loss:0.43066152930259705, G_Loss:21.799619674682617

iterator 3100, D_Loss:0.4127517640590668, G_Loss:21.473247528076172

iterator 3200, D_Loss:0.4293009638786316, G_Loss:22.65851402282715

iterator 3300, D_Loss:0.4174714982509613, G_Loss:25.193143844604492

iterator 3400, D_Loss:0.42188897728919983, G_Loss:25.010456085205078

iterator 3500, D_Loss:0.4037526249885559, G_Loss:23.05000114440918

iterator 3600, D_Loss:0.4111851155757904, G_Loss:23.90924835205078

iterator 3700, D_Loss:0.4050373136997223, G_Loss:23.468875885009766

iterator 3800, D_Loss:0.43956100940704346, G_Loss:24.29617691040039

iterator 3900, D_Loss:0.4117209017276764, G_Loss:23.26659393310547

iterator 4000, D_Loss:0.4273524582386017, G_Loss:22.690597534179688

iterator 4100, D_Loss:0.4232712388038635, G_Loss:22.63192367553711

iterator 4200, D_Loss:0.4148295819759369, G_Loss:21.62356948852539

iterator 4300, D_Loss:0.4187855124473572, G_Loss:25.327810287475586

iterator 4400, D_Loss:0.416508287191391, G_Loss:22.076269149780273

iterator 4500, D_Loss:0.4281792938709259, G_Loss:25.96017837524414

iterator 4600, D_Loss:0.41353654861450195, G_Loss:25.94019889831543

iterator 4700, D_Loss:0.41671207547187805, G_Loss:23.28752899169922

iterator 4800, D_Loss:0.42863816022872925, G_Loss:24.4930419921875

iterator 4900, D_Loss:0.4262382388114929, G_Loss:23.75725555419922

iterator 5000, D_Loss:0.4163181185722351, G_Loss:25.152572631835938

-----------Epoch 2-----------
iterator 100, D_Loss:0.432341068983078, G_Loss:23.84888458251953

iterator 200, D_Loss:0.41415679454803467, G_Loss:26.428848266601562

iterator 300, D_Loss:0.41417011618614197, G_Loss:24.04228973388672

iterator 400, D_Loss:0.42381182312965393, G_Loss:26.814586639404297

iterator 500, D_Loss:0.41480499505996704, G_Loss:25.47686767578125

iterator 600, D_Loss:0.4249473512172699, G_Loss:24.53293800354004

iterator 700, D_Loss:0.41473835706710815, G_Loss:24.3125057220459

iterator 800, D_Loss:0.4303334951400757, G_Loss:26.464174270629883

iterator 900, D_Loss:0.44065383076667786, G_Loss:24.89940643310547

iterator 1000, D_Loss:0.4054486155509949, G_Loss:22.14266586303711

iterator 1100, D_Loss:0.43789219856262207, G_Loss:23.88713836669922

iterator 1200, D_Loss:0.4236679971218109, G_Loss:23.0634708404541

iterator 1300, D_Loss:0.4245539903640747, G_Loss:22.43527603149414

iterator 1400, D_Loss:0.4330623745918274, G_Loss:22.50225830078125

iterator 1500, D_Loss:0.4274674952030182, G_Loss:21.642492294311523

iterator 1600, D_Loss:0.4239652752876282, G_Loss:25.003692626953125

iterator 1700, D_Loss:0.42649638652801514, G_Loss:23.192882537841797

iterator 1800, D_Loss:0.41233476996421814, G_Loss:22.975582122802734

iterator 1900, D_Loss:0.4232487380504608, G_Loss:22.138526916503906

iterator 2000, D_Loss:0.42268747091293335, G_Loss:22.020584106445312

iterator 2100, D_Loss:0.42867597937583923, G_Loss:24.193729400634766

iterator 2200, D_Loss:0.42337870597839355, G_Loss:24.1146240234375

iterator 2300, D_Loss:0.4157213270664215, G_Loss:22.620685577392578

iterator 2400, D_Loss:0.4162869155406952, G_Loss:23.512405395507812

iterator 2500, D_Loss:0.4276334345340729, G_Loss:23.561744689941406

iterator 2600, D_Loss:0.44064465165138245, G_Loss:22.54075813293457

iterator 2700, D_Loss:0.4170747399330139, G_Loss:22.720630645751953

iterator 2800, D_Loss:0.4491310715675354, G_Loss:21.815773010253906

iterator 2900, D_Loss:0.4323177635669708, G_Loss:21.86858367919922

iterator 3000, D_Loss:0.42736274003982544, G_Loss:21.162689208984375

iterator 3100, D_Loss:0.4183765947818756, G_Loss:23.16611671447754

iterator 3200, D_Loss:0.41422343254089355, G_Loss:20.58086585998535

iterator 3300, D_Loss:0.4220760762691498, G_Loss:22.238563537597656

iterator 3400, D_Loss:0.4116346836090088, G_Loss:22.057483673095703

iterator 3500, D_Loss:0.4146910309791565, G_Loss:22.564895629882812

iterator 3600, D_Loss:0.42646199464797974, G_Loss:23.188413619995117

iterator 3700, D_Loss:0.43093377351760864, G_Loss:23.49694061279297

iterator 3800, D_Loss:0.42607393860816956, G_Loss:21.404056549072266

iterator 3900, D_Loss:0.43061837553977966, G_Loss:23.84274673461914

iterator 4000, D_Loss:0.4471661150455475, G_Loss:23.824684143066406

iterator 4100, D_Loss:0.40362346172332764, G_Loss:21.393606185913086

iterator 4200, D_Loss:0.4217173159122467, G_Loss:20.493202209472656

iterator 4300, D_Loss:0.40672287344932556, G_Loss:19.799171447753906

iterator 4400, D_Loss:0.415738046169281, G_Loss:17.51458168029785

iterator 4500, D_Loss:0.4338024854660034, G_Loss:14.546102523803711

iterator 4600, D_Loss:0.43352288007736206, G_Loss:12.612771034240723

iterator 4700, D_Loss:0.4407784938812256, G_Loss:14.841235160827637

iterator 4800, D_Loss:0.41215720772743225, G_Loss:13.597188949584961

iterator 4900, D_Loss:0.4250011742115021, G_Loss:14.363455772399902

iterator 5000, D_Loss:0.4413435757160187, G_Loss:16.270009994506836

-----------Epoch 3-----------
iterator 100, D_Loss:0.4336071014404297, G_Loss:15.43610954284668

iterator 200, D_Loss:0.4198746085166931, G_Loss:14.130436897277832

iterator 300, D_Loss:0.42412620782852173, G_Loss:16.627269744873047

iterator 400, D_Loss:0.4133097529411316, G_Loss:15.292278289794922

iterator 500, D_Loss:0.41711583733558655, G_Loss:18.912321090698242

iterator 600, D_Loss:0.41400495171546936, G_Loss:19.73879623413086

iterator 700, D_Loss:0.440112441778183, G_Loss:17.484533309936523

iterator 800, D_Loss:0.43250739574432373, G_Loss:17.41204833984375

iterator 900, D_Loss:0.42415693402290344, G_Loss:17.526065826416016

iterator 1000, D_Loss:0.42216503620147705, G_Loss:17.744873046875

iterator 1100, D_Loss:0.4194273352622986, G_Loss:18.463600158691406

iterator 1200, D_Loss:0.42795291543006897, G_Loss:16.372055053710938

iterator 1300, D_Loss:0.4174274802207947, G_Loss:17.492294311523438

iterator 1400, D_Loss:0.42021095752716064, G_Loss:16.127187728881836

iterator 1500, D_Loss:0.4274786710739136, G_Loss:15.774969100952148

iterator 1600, D_Loss:0.4345373809337616, G_Loss:19.222633361816406

iterator 1700, D_Loss:0.42709454894065857, G_Loss:18.782365798950195

iterator 1800, D_Loss:0.42052552103996277, G_Loss:19.451635360717773

iterator 1900, D_Loss:0.4284057915210724, G_Loss:16.041397094726562

iterator 2000, D_Loss:0.4210953712463379, G_Loss:16.188716888427734

iterator 2100, D_Loss:0.42970606684684753, G_Loss:17.090768814086914

iterator 2200, D_Loss:0.4298870861530304, G_Loss:15.758810043334961

iterator 2300, D_Loss:0.4124217927455902, G_Loss:15.00692367553711

iterator 2400, D_Loss:0.41204479336738586, G_Loss:14.928869247436523

iterator 2500, D_Loss:0.43220365047454834, G_Loss:16.524465560913086

iterator 2600, D_Loss:0.4263337254524231, G_Loss:16.8145809173584

iterator 2700, D_Loss:0.41330474615097046, G_Loss:17.1984806060791

iterator 2800, D_Loss:0.4235231280326843, G_Loss:19.138582229614258

iterator 2900, D_Loss:0.4294375479221344, G_Loss:18.915542602539062

iterator 3000, D_Loss:0.40295571088790894, G_Loss:19.720169067382812

iterator 3100, D_Loss:0.4109329879283905, G_Loss:17.981189727783203

iterator 3200, D_Loss:0.43832099437713623, G_Loss:19.450626373291016

iterator 3300, D_Loss:0.40498819947242737, G_Loss:20.0653076171875

iterator 3400, D_Loss:0.40902450680732727, G_Loss:19.407024383544922

iterator 3500, D_Loss:0.42584824562072754, G_Loss:20.013916015625

iterator 3600, D_Loss:0.44071832299232483, G_Loss:21.32438087463379

iterator 3700, D_Loss:0.4148588478565216, G_Loss:18.59847640991211

iterator 3800, D_Loss:0.41832026839256287, G_Loss:18.13798713684082

iterator 3900, D_Loss:0.4172850549221039, G_Loss:17.22402572631836

iterator 4000, D_Loss:0.4237278699874878, G_Loss:17.208696365356445

iterator 4100, D_Loss:0.40985575318336487, G_Loss:18.010984420776367

iterator 4200, D_Loss:0.4276157021522522, G_Loss:18.566743850708008

iterator 4300, D_Loss:0.4324784278869629, G_Loss:18.666860580444336

iterator 4400, D_Loss:0.4293496906757355, G_Loss:20.31184196472168

iterator 4500, D_Loss:0.41514015197753906, G_Loss:20.74872589111328

iterator 4600, D_Loss:0.4212001860141754, G_Loss:20.182422637939453

iterator 4700, D_Loss:0.4211563766002655, G_Loss:20.3571834564209

iterator 4800, D_Loss:0.4332748353481293, G_Loss:20.238605499267578

iterator 4900, D_Loss:0.4242846965789795, G_Loss:20.3565673828125

iterator 5000, D_Loss:0.4201031029224396, G_Loss:19.93220329284668

-----------Epoch 4-----------
iterator 100, D_Loss:0.4185345768928528, G_Loss:20.943317413330078

iterator 200, D_Loss:0.40706154704093933, G_Loss:22.875442504882812

iterator 300, D_Loss:0.41814374923706055, G_Loss:22.054332733154297

iterator 400, D_Loss:0.42550796270370483, G_Loss:20.995948791503906

iterator 500, D_Loss:0.4154815375804901, G_Loss:20.29720687866211

iterator 600, D_Loss:0.418535053730011, G_Loss:20.57207489013672

iterator 700, D_Loss:0.41104745864868164, G_Loss:19.10096549987793

iterator 800, D_Loss:0.4331064820289612, G_Loss:20.509023666381836

iterator 900, D_Loss:0.41292518377304077, G_Loss:18.783449172973633

iterator 1000, D_Loss:0.4224459230899811, G_Loss:18.676227569580078

iterator 1100, D_Loss:0.42456290125846863, G_Loss:18.583961486816406

iterator 1200, D_Loss:0.43198516964912415, G_Loss:19.276762008666992

iterator 1300, D_Loss:0.4255419373512268, G_Loss:18.78701400756836

iterator 1400, D_Loss:0.4265602231025696, G_Loss:18.65658187866211

iterator 1500, D_Loss:0.4149729609489441, G_Loss:18.039520263671875

iterator 1600, D_Loss:0.41261136531829834, G_Loss:18.361238479614258

iterator 1700, D_Loss:0.44142499566078186, G_Loss:18.030004501342773

iterator 1800, D_Loss:0.39834171533584595, G_Loss:17.073776245117188

iterator 1900, D_Loss:0.41734904050827026, G_Loss:17.033082962036133

iterator 2000, D_Loss:1.1929981708526611, G_Loss:15.043978691101074

iterator 2100, D_Loss:0.4320194125175476, G_Loss:17.73398208618164

iterator 2200, D_Loss:0.4230327308177948, G_Loss:18.079641342163086

iterator 2300, D_Loss:0.4036370813846588, G_Loss:14.746420860290527

iterator 2400, D_Loss:0.4255627393722534, G_Loss:14.479287147521973

iterator 2500, D_Loss:0.4539920687675476, G_Loss:15.797776222229004

iterator 2600, D_Loss:0.4257883131504059, G_Loss:14.106791496276855

iterator 2700, D_Loss:0.4367951452732086, G_Loss:14.579212188720703

iterator 2800, D_Loss:0.4378429353237152, G_Loss:15.491795539855957

iterator 2900, D_Loss:0.4248926341533661, G_Loss:12.928647994995117

iterator 3000, D_Loss:0.44232621788978577, G_Loss:13.458922386169434

iterator 3100, D_Loss:0.4119436740875244, G_Loss:12.986438751220703

iterator 3200, D_Loss:0.41691842675209045, G_Loss:14.301130294799805

iterator 3300, D_Loss:0.4209734797477722, G_Loss:13.685431480407715

iterator 3400, D_Loss:0.4117005169391632, G_Loss:15.540771484375

iterator 3500, D_Loss:0.4477512538433075, G_Loss:16.626052856445312

iterator 3600, D_Loss:0.410372257232666, G_Loss:18.046239852905273

iterator 3700, D_Loss:0.42232102155685425, G_Loss:18.232837677001953

iterator 3800, D_Loss:0.41156601905822754, G_Loss:16.826480865478516

iterator 3900, D_Loss:0.4145262837409973, G_Loss:15.868582725524902

iterator 4000, D_Loss:0.42654916644096375, G_Loss:19.72156524658203

iterator 4100, D_Loss:0.4074132740497589, G_Loss:17.356679916381836

iterator 4200, D_Loss:0.4186832308769226, G_Loss:17.645008087158203

iterator 4300, D_Loss:0.4192325472831726, G_Loss:17.223922729492188

iterator 4400, D_Loss:0.4257490336894989, G_Loss:16.1091251373291

iterator 4500, D_Loss:0.4254516065120697, G_Loss:15.694486618041992

iterator 4600, D_Loss:0.42467814683914185, G_Loss:13.567962646484375

iterator 4700, D_Loss:0.43249624967575073, G_Loss:15.683158874511719

iterator 4800, D_Loss:0.40978339314460754, G_Loss:13.511516571044922

iterator 4900, D_Loss:0.42328375577926636, G_Loss:16.553665161132812

iterator 5000, D_Loss:0.4677030146121979, G_Loss:17.117013931274414

-----------Epoch 5-----------
iterator 100, D_Loss:0.4248798191547394, G_Loss:17.62096405029297

iterator 200, D_Loss:0.4191942811012268, G_Loss:18.618553161621094

iterator 300, D_Loss:0.4151002764701843, G_Loss:17.578659057617188

iterator 400, D_Loss:0.4199446439743042, G_Loss:17.640459060668945

iterator 500, D_Loss:0.4156200885772705, G_Loss:15.912187576293945

iterator 600, D_Loss:0.4293663799762726, G_Loss:15.89488697052002

iterator 700, D_Loss:0.43153369426727295, G_Loss:16.205989837646484

iterator 800, D_Loss:0.43502309918403625, G_Loss:15.908957481384277

iterator 900, D_Loss:0.43590646982192993, G_Loss:16.890121459960938

iterator 1000, D_Loss:0.4433310627937317, G_Loss:16.87429428100586

iterator 1100, D_Loss:0.429823100566864, G_Loss:15.883617401123047

iterator 1200, D_Loss:0.4088142514228821, G_Loss:14.074968338012695

iterator 1300, D_Loss:0.4420650601387024, G_Loss:15.735031127929688

iterator 1400, D_Loss:0.40408429503440857, G_Loss:10.283183097839355

iterator 1500, D_Loss:0.42270874977111816, G_Loss:17.753816604614258

iterator 1600, D_Loss:0.42719048261642456, G_Loss:17.781326293945312

iterator 1700, D_Loss:0.4283300042152405, G_Loss:18.727252960205078

iterator 1800, D_Loss:0.42508938908576965, G_Loss:18.406055450439453

iterator 1900, D_Loss:0.42126694321632385, G_Loss:18.106975555419922

iterator 2000, D_Loss:0.4184505343437195, G_Loss:16.314483642578125

iterator 2100, D_Loss:0.42193254828453064, G_Loss:14.356918334960938

iterator 2200, D_Loss:0.43069136142730713, G_Loss:15.321939468383789

iterator 2300, D_Loss:0.4440085291862488, G_Loss:17.224971771240234

iterator 2400, D_Loss:0.4233129918575287, G_Loss:17.0123291015625

iterator 2500, D_Loss:0.4309116005897522, G_Loss:17.179489135742188

iterator 2600, D_Loss:0.43550512194633484, G_Loss:18.037395477294922

iterator 2700, D_Loss:0.4244039058685303, G_Loss:16.39393424987793

iterator 2800, D_Loss:0.42509928345680237, G_Loss:16.369037628173828

iterator 2900, D_Loss:0.4276869595050812, G_Loss:15.688440322875977

iterator 3000, D_Loss:0.4362267851829529, G_Loss:17.007503509521484

iterator 3100, D_Loss:0.40071555972099304, G_Loss:17.01127815246582

iterator 3200, D_Loss:0.4387965202331543, G_Loss:19.843381881713867

iterator 3300, D_Loss:0.42967167496681213, G_Loss:18.907800674438477

iterator 3400, D_Loss:0.423350989818573, G_Loss:18.35139274597168

iterator 3500, D_Loss:0.4169234037399292, G_Loss:17.721837997436523

iterator 3600, D_Loss:0.41984373331069946, G_Loss:17.717866897583008

iterator 3700, D_Loss:0.44342973828315735, G_Loss:17.84990882873535

iterator 3800, D_Loss:0.43485286831855774, G_Loss:15.935750961303711

iterator 3900, D_Loss:0.40728670358657837, G_Loss:18.234975814819336

iterator 4000, D_Loss:0.42324331402778625, G_Loss:18.49376678466797

iterator 4100, D_Loss:0.425756573677063, G_Loss:18.683998107910156

iterator 4200, D_Loss:0.4365474581718445, G_Loss:19.07390594482422

iterator 4300, D_Loss:0.4264448285102844, G_Loss:18.857181549072266

iterator 4400, D_Loss:0.4351930022239685, G_Loss:15.133723258972168

iterator 4500, D_Loss:0.4004611074924469, G_Loss:18.72132682800293

iterator 4600, D_Loss:0.41656574606895447, G_Loss:17.913978576660156

iterator 4700, D_Loss:0.41963207721710205, G_Loss:18.25279998779297

iterator 4800, D_Loss:0.42792820930480957, G_Loss:18.704652786254883

iterator 4900, D_Loss:0.41314461827278137, G_Loss:18.424537658691406

iterator 5000, D_Loss:0.42398178577423096, G_Loss:17.364604949951172

-----------Epoch 6-----------
iterator 100, D_Loss:0.4210380017757416, G_Loss:17.43263816833496

iterator 200, D_Loss:0.4200270473957062, G_Loss:17.423168182373047

iterator 300, D_Loss:0.441332072019577, G_Loss:16.83606719970703

iterator 400, D_Loss:0.43613430857658386, G_Loss:15.360267639160156

iterator 500, D_Loss:0.41760873794555664, G_Loss:15.178451538085938

iterator 600, D_Loss:0.41039609909057617, G_Loss:15.087422370910645

iterator 700, D_Loss:0.41759979724884033, G_Loss:16.9539737701416

iterator 800, D_Loss:0.4471956193447113, G_Loss:14.884495735168457

iterator 900, D_Loss:0.433838427066803, G_Loss:16.042068481445312

iterator 1000, D_Loss:0.4383210837841034, G_Loss:15.972309112548828

iterator 1100, D_Loss:0.44062134623527527, G_Loss:14.691094398498535

iterator 1200, D_Loss:0.43373534083366394, G_Loss:15.189183235168457

iterator 1300, D_Loss:0.42986229062080383, G_Loss:14.851116180419922

iterator 1400, D_Loss:0.42663809657096863, G_Loss:13.506097793579102

iterator 1500, D_Loss:0.4202757477760315, G_Loss:14.261917114257812

iterator 1600, D_Loss:0.41777244210243225, G_Loss:14.038529396057129

iterator 1700, D_Loss:0.4089851975440979, G_Loss:13.104930877685547

iterator 1800, D_Loss:0.42611730098724365, G_Loss:13.552000045776367

iterator 1900, D_Loss:0.4418080747127533, G_Loss:13.879612922668457

iterator 2000, D_Loss:0.4107009470462799, G_Loss:13.740944862365723

iterator 2100, D_Loss:0.43324434757232666, G_Loss:13.653822898864746

iterator 2200, D_Loss:0.4168930947780609, G_Loss:13.517494201660156

iterator 2300, D_Loss:0.4241115152835846, G_Loss:13.77775764465332

iterator 2400, D_Loss:0.41845422983169556, G_Loss:13.252243041992188

iterator 2500, D_Loss:0.4263831675052643, G_Loss:13.438929557800293

iterator 2600, D_Loss:0.40701431035995483, G_Loss:13.887372970581055

iterator 2700, D_Loss:0.40699949860572815, G_Loss:13.359550476074219

iterator 2800, D_Loss:0.41458025574684143, G_Loss:14.282441139221191

iterator 2900, D_Loss:0.42745545506477356, G_Loss:13.702167510986328

iterator 3000, D_Loss:0.42988356947898865, G_Loss:16.589519500732422

iterator 3100, D_Loss:0.40837639570236206, G_Loss:18.040407180786133

iterator 3200, D_Loss:0.42477110028266907, G_Loss:17.61008071899414

iterator 3300, D_Loss:0.43286755681037903, G_Loss:15.728719711303711

iterator 3400, D_Loss:0.4364643394947052, G_Loss:13.123608589172363

iterator 3500, D_Loss:0.4205458462238312, G_Loss:14.022378921508789

iterator 3600, D_Loss:0.4429946839809418, G_Loss:12.104976654052734

iterator 3700, D_Loss:0.4260439872741699, G_Loss:16.21135711669922

iterator 3800, D_Loss:0.4222354590892792, G_Loss:16.655452728271484

iterator 3900, D_Loss:0.4195939600467682, G_Loss:17.000858306884766

iterator 4000, D_Loss:0.40132156014442444, G_Loss:15.696521759033203

iterator 4100, D_Loss:0.41400307416915894, G_Loss:16.4786319732666

iterator 4200, D_Loss:0.4283333122730255, G_Loss:16.571136474609375

iterator 4300, D_Loss:0.4276735484600067, G_Loss:19.671287536621094

iterator 4400, D_Loss:0.41959959268569946, G_Loss:19.235397338867188

iterator 4500, D_Loss:0.4388779401779175, G_Loss:19.537981033325195

iterator 4600, D_Loss:0.4303710460662842, G_Loss:21.70199203491211

iterator 4700, D_Loss:0.4307457208633423, G_Loss:21.038105010986328

iterator 4800, D_Loss:0.4321082830429077, G_Loss:23.251962661743164

iterator 4900, D_Loss:0.43574783205986023, G_Loss:20.86048126220703

Process Process-45:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 141, in thread_run
    V_Train(search, path, sample_it, gen, dis, config["n_epochs"], param["lr"], train_it, param["z_dim"], dataset, col_type, sample_times,itertimes = 100, steps_per_epoch = config["steps_per_epoch"],GPU=GPU,KL=KL)
  File "/home/youran/Daisy/Daisy/synthesizer/train.py", line 113, in V_Train
    D_Loss2 = F.binary_cross_entropy(y_fake, fake_label)
  File "/usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/8.3.0-10.1.243/openmpi/3.1.4/pytorch/1.4.0-python-3.7.4/lib/python3.7/site-packages/torch/nn/functional.py", line 2077, in binary_cross_entropy
    input, target, weight, reduction_enum)
RuntimeError: reduce failed to synchronize: cudaErrorAssert: device-side assert triggered
LGAN_generator(
  (LSTM): LSTMCell(300, 300)
  (fc00): Linear(in_features=200, out_features=1, bias=True)
  (fc01): Linear(in_features=1, out_features=200, bias=True)
  (fe0): Linear(in_features=300, out_features=200, bias=True)
  (fc10): Linear(in_features=200, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=200, bias=True)
  (fe1): Linear(in_features=300, out_features=200, bias=True)
  (fc20): Linear(in_features=200, out_features=1, bias=True)
  (fc21): Linear(in_features=1, out_features=200, bias=True)
  (fe2): Linear(in_features=300, out_features=200, bias=True)
  (fc30): Linear(in_features=200, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=200, bias=True)
  (fe3): Linear(in_features=300, out_features=200, bias=True)
  (fc40): Linear(in_features=200, out_features=1, bias=True)
  (fc41): Linear(in_features=1, out_features=200, bias=True)
  (fe4): Linear(in_features=300, out_features=200, bias=True)
  (fc50): Linear(in_features=200, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=200, bias=True)
  (fe5): Linear(in_features=300, out_features=200, bias=True)
  (fc60): Linear(in_features=200, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=200, bias=True)
  (fe6): Linear(in_features=300, out_features=200, bias=True)
  (fc70): Linear(in_features=200, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=200, bias=True)
  (fe7): Linear(in_features=300, out_features=200, bias=True)
  (fc80): Linear(in_features=200, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=200, bias=True)
  (fe8): Linear(in_features=300, out_features=200, bias=True)
  (fc90): Linear(in_features=200, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=200, bias=True)
  (fe9): Linear(in_features=300, out_features=200, bias=True)
  (fc100): Linear(in_features=200, out_features=1, bias=True)
  (fc101): Linear(in_features=1, out_features=200, bias=True)
  (fe10): Linear(in_features=300, out_features=200, bias=True)
  (fc110): Linear(in_features=200, out_features=1, bias=True)
  (fc111): Linear(in_features=1, out_features=200, bias=True)
  (fe11): Linear(in_features=300, out_features=200, bias=True)
  (fc120): Linear(in_features=200, out_features=1, bias=True)
  (fc121): Linear(in_features=1, out_features=200, bias=True)
  (fe12): Linear(in_features=300, out_features=200, bias=True)
  (fc130): Linear(in_features=200, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=200, bias=True)
  (fe13): Linear(in_features=300, out_features=200, bias=True)
  (fc140): Linear(in_features=200, out_features=2, bias=True)
  (fc141): Linear(in_features=2, out_features=200, bias=True)
  (fe14): Linear(in_features=300, out_features=200, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=105, out_features=400, bias=True)
  (inputbn): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=400, out_features=400, bias=True)
  (bn0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=400, bias=True)
  (bn1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=400, out_features=400, bias=True)
  (bn2): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=400, out_features=400, bias=True)
  (bn3): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=400, out_features=1, bias=True)
)
(0, False, 105)
-----------Epoch 0-----------
iterator 100, D_Loss:1.4162781238555908, G_Loss:0.9271424412727356

iterator 200, D_Loss:1.377925157546997, G_Loss:0.9812499284744263

iterator 300, D_Loss:1.3930253982543945, G_Loss:0.9690947532653809

iterator 400, D_Loss:1.4168989658355713, G_Loss:0.9440276026725769

iterator 500, D_Loss:1.4165012836456299, G_Loss:0.9376480579376221

iterator 600, D_Loss:1.4057849645614624, G_Loss:0.9995362758636475

iterator 700, D_Loss:1.4173798561096191, G_Loss:0.9880850911140442

iterator 800, D_Loss:1.3769237995147705, G_Loss:0.964372992515564

iterator 900, D_Loss:1.3790249824523926, G_Loss:0.9367819428443909

iterator 1000, D_Loss:1.3548221588134766, G_Loss:0.9614446759223938

iterator 1100, D_Loss:1.3792364597320557, G_Loss:0.9720858931541443

iterator 1200, D_Loss:1.3685933351516724, G_Loss:0.9887625575065613

iterator 1300, D_Loss:1.3547605276107788, G_Loss:0.995773196220398

iterator 1400, D_Loss:1.343907356262207, G_Loss:0.9874732494354248

iterator 1500, D_Loss:1.3589084148406982, G_Loss:0.9195044636726379

iterator 1600, D_Loss:1.3955440521240234, G_Loss:0.9420644640922546

iterator 1700, D_Loss:1.322502613067627, G_Loss:0.9590774774551392

iterator 1800, D_Loss:1.2814112901687622, G_Loss:1.0485308170318604

iterator 1900, D_Loss:1.2684147357940674, G_Loss:1.128300666809082

iterator 2000, D_Loss:1.2041809558868408, G_Loss:1.1891353130340576

iterator 2100, D_Loss:1.1895004510879517, G_Loss:1.1197240352630615

iterator 2200, D_Loss:1.1037087440490723, G_Loss:1.230499267578125

iterator 2300, D_Loss:1.0839197635650635, G_Loss:1.3617651462554932

iterator 2400, D_Loss:1.0834742784500122, G_Loss:1.341199517250061

iterator 2500, D_Loss:1.001071572303772, G_Loss:1.5371776819229126

iterator 2600, D_Loss:0.9704875349998474, G_Loss:1.3884303569793701

iterator 2700, D_Loss:0.8744977712631226, G_Loss:1.4781302213668823

iterator 2800, D_Loss:0.81032395362854, G_Loss:2.010436773300171

iterator 2900, D_Loss:0.7580614686012268, G_Loss:2.1766462326049805

iterator 3000, D_Loss:0.8680828809738159, G_Loss:1.8662371635437012

iterator 3100, D_Loss:0.7395260334014893, G_Loss:2.446693181991577

iterator 3200, D_Loss:0.7832014560699463, G_Loss:2.417125701904297

iterator 3300, D_Loss:0.8001828789710999, G_Loss:2.3288896083831787

iterator 3400, D_Loss:0.8288777470588684, G_Loss:2.5359246730804443

iterator 3500, D_Loss:0.7300840616226196, G_Loss:3.027240514755249

iterator 3600, D_Loss:0.7220007181167603, G_Loss:3.4125022888183594

iterator 3700, D_Loss:0.6064928770065308, G_Loss:2.8996875286102295

iterator 3800, D_Loss:0.6470324993133545, G_Loss:2.2563209533691406

iterator 3900, D_Loss:0.634760320186615, G_Loss:2.6757712364196777

iterator 4000, D_Loss:0.7707080245018005, G_Loss:3.45782470703125

iterator 4100, D_Loss:0.6871006488800049, G_Loss:3.2365171909332275

iterator 4200, D_Loss:0.5977334380149841, G_Loss:3.7222795486450195

iterator 4300, D_Loss:0.6150422096252441, G_Loss:3.376417398452759

iterator 4400, D_Loss:0.6533645391464233, G_Loss:2.770625591278076

iterator 4500, D_Loss:0.7712974548339844, G_Loss:2.6597352027893066

iterator 4600, D_Loss:0.7226250171661377, G_Loss:4.025312423706055

iterator 4700, D_Loss:1.1129655838012695, G_Loss:3.5204155445098877

iterator 4800, D_Loss:0.8099280595779419, G_Loss:3.497018575668335

iterator 4900, D_Loss:0.5209437012672424, G_Loss:3.887415885925293

iterator 5000, D_Loss:0.5802297592163086, G_Loss:3.4304332733154297

-----------Epoch 1-----------
iterator 100, D_Loss:0.5376092791557312, G_Loss:4.295324325561523

iterator 200, D_Loss:0.639274001121521, G_Loss:2.8344109058380127

iterator 300, D_Loss:0.6269413232803345, G_Loss:4.281894207000732

iterator 400, D_Loss:0.7770587205886841, G_Loss:4.188111782073975

iterator 500, D_Loss:0.564109742641449, G_Loss:4.706323623657227

iterator 600, D_Loss:0.5674927234649658, G_Loss:3.4280741214752197

iterator 700, D_Loss:0.7416365146636963, G_Loss:2.966817855834961

iterator 800, D_Loss:0.7607702016830444, G_Loss:4.255824089050293

iterator 900, D_Loss:0.558841347694397, G_Loss:3.814269542694092

iterator 1000, D_Loss:0.5289223790168762, G_Loss:4.198271751403809

iterator 1100, D_Loss:0.9491357803344727, G_Loss:5.499306678771973

iterator 1200, D_Loss:0.5489410758018494, G_Loss:5.249819755554199

iterator 1300, D_Loss:0.6676229238510132, G_Loss:4.731053829193115

iterator 1400, D_Loss:0.5255210399627686, G_Loss:4.637434482574463

iterator 1500, D_Loss:0.5295785665512085, G_Loss:3.780050277709961

iterator 1600, D_Loss:1.001152753829956, G_Loss:2.6217501163482666

iterator 1700, D_Loss:0.5919995307922363, G_Loss:4.296930313110352

iterator 1800, D_Loss:0.6002411246299744, G_Loss:3.5648107528686523

iterator 1900, D_Loss:1.3010196685791016, G_Loss:5.063090801239014

iterator 2000, D_Loss:0.4683467149734497, G_Loss:3.95405650138855

iterator 2100, D_Loss:0.5218228697776794, G_Loss:4.846292972564697

iterator 2200, D_Loss:0.5852195024490356, G_Loss:4.142923355102539

iterator 2300, D_Loss:0.6027912497520447, G_Loss:3.4815261363983154

iterator 2400, D_Loss:0.4574694037437439, G_Loss:4.911203384399414

iterator 2500, D_Loss:0.656462550163269, G_Loss:4.08128547668457

iterator 2600, D_Loss:0.4517907500267029, G_Loss:3.2155394554138184

iterator 2700, D_Loss:1.178659200668335, G_Loss:5.071755886077881

iterator 2800, D_Loss:0.5710586905479431, G_Loss:6.049681186676025

iterator 2900, D_Loss:0.525465726852417, G_Loss:4.6906280517578125

iterator 3000, D_Loss:0.6258029341697693, G_Loss:3.921420097351074

iterator 3100, D_Loss:0.6261480450630188, G_Loss:5.211714744567871

iterator 3200, D_Loss:0.8971815705299377, G_Loss:5.125250816345215

iterator 3300, D_Loss:0.7540695667266846, G_Loss:3.946168899536133

iterator 3400, D_Loss:0.5822110176086426, G_Loss:4.983119487762451

iterator 3500, D_Loss:0.8894961476325989, G_Loss:3.3905575275421143

iterator 3600, D_Loss:1.3475489616394043, G_Loss:4.979590892791748

iterator 3700, D_Loss:0.536906898021698, G_Loss:4.2371416091918945

iterator 3800, D_Loss:0.7556772828102112, G_Loss:2.7548413276672363

iterator 3900, D_Loss:0.4979220926761627, G_Loss:4.633430004119873

iterator 4000, D_Loss:0.5872146487236023, G_Loss:4.229656219482422

iterator 4100, D_Loss:0.7405824661254883, G_Loss:4.700713634490967

iterator 4200, D_Loss:0.5496002435684204, G_Loss:3.2452690601348877

iterator 4300, D_Loss:0.5908093452453613, G_Loss:6.048666477203369

iterator 4400, D_Loss:0.6781368255615234, G_Loss:4.076448917388916

iterator 4500, D_Loss:0.609445333480835, G_Loss:4.692741394042969

iterator 4600, D_Loss:0.6351893544197083, G_Loss:3.544757843017578

iterator 4700, D_Loss:0.5747189521789551, G_Loss:3.6643733978271484

iterator 4800, D_Loss:0.8874495029449463, G_Loss:5.09003210067749

iterator 4900, D_Loss:0.5394629836082458, G_Loss:3.310788154602051

iterator 5000, D_Loss:1.158521294593811, G_Loss:3.925766944885254

-----------Epoch 2-----------
iterator 100, D_Loss:0.5468630194664001, G_Loss:5.749030113220215

iterator 200, D_Loss:0.6807247996330261, G_Loss:5.507285118103027

iterator 300, D_Loss:0.48902907967567444, G_Loss:4.973556995391846

iterator 400, D_Loss:0.8028736710548401, G_Loss:4.003162384033203

iterator 500, D_Loss:0.4692446291446686, G_Loss:3.570122003555298

iterator 600, D_Loss:0.5929535627365112, G_Loss:6.324626922607422

iterator 700, D_Loss:0.6237872838973999, G_Loss:6.058619022369385

iterator 800, D_Loss:0.7197064161300659, G_Loss:4.138144493103027

iterator 900, D_Loss:0.5679481625556946, G_Loss:5.275927543640137

iterator 1000, D_Loss:0.5077835321426392, G_Loss:3.1017580032348633

iterator 1100, D_Loss:0.4658737778663635, G_Loss:5.187211036682129

iterator 1200, D_Loss:0.4661102890968323, G_Loss:6.845738887786865

iterator 1300, D_Loss:0.4402937889099121, G_Loss:6.545055389404297

iterator 1400, D_Loss:0.4591039717197418, G_Loss:4.276987552642822

iterator 1500, D_Loss:0.5095739960670471, G_Loss:3.445483922958374

iterator 1600, D_Loss:0.6125710010528564, G_Loss:6.505168914794922

iterator 1700, D_Loss:0.5067250728607178, G_Loss:5.570794582366943

iterator 1800, D_Loss:0.5395071506500244, G_Loss:7.104893684387207

iterator 1900, D_Loss:1.053497076034546, G_Loss:4.189334869384766

iterator 2000, D_Loss:0.5065495371818542, G_Loss:5.746181011199951

iterator 2100, D_Loss:1.3295366764068604, G_Loss:6.593973159790039

iterator 2200, D_Loss:0.774917483329773, G_Loss:5.97575569152832

iterator 2300, D_Loss:0.5167436003684998, G_Loss:6.028855323791504

iterator 2400, D_Loss:0.5211970210075378, G_Loss:6.118438243865967

iterator 2500, D_Loss:1.0710158348083496, G_Loss:3.1041955947875977

iterator 2600, D_Loss:0.4711034893989563, G_Loss:7.295187950134277

iterator 2700, D_Loss:0.5268855690956116, G_Loss:3.3184661865234375

iterator 2800, D_Loss:0.806731104850769, G_Loss:3.2920968532562256

iterator 2900, D_Loss:0.46583762764930725, G_Loss:6.466810703277588

iterator 3000, D_Loss:0.5912614464759827, G_Loss:5.268647193908691

iterator 3100, D_Loss:0.45564162731170654, G_Loss:6.969813823699951

iterator 3200, D_Loss:0.5454339981079102, G_Loss:4.008679389953613

iterator 3300, D_Loss:0.5241118669509888, G_Loss:3.188077449798584

iterator 3400, D_Loss:0.5195193886756897, G_Loss:6.2741899490356445

iterator 3500, D_Loss:0.4767383635044098, G_Loss:5.08477258682251

iterator 3600, D_Loss:0.48964670300483704, G_Loss:7.279064178466797

iterator 3700, D_Loss:0.4365570843219757, G_Loss:4.453708648681641

iterator 3800, D_Loss:0.4994492828845978, G_Loss:2.721554756164551

iterator 3900, D_Loss:0.6353744864463806, G_Loss:3.286067008972168

iterator 4000, D_Loss:0.45858219265937805, G_Loss:4.280034065246582

iterator 4100, D_Loss:0.4523014724254608, G_Loss:5.061399459838867

iterator 4200, D_Loss:0.5523781776428223, G_Loss:5.517190933227539

iterator 4300, D_Loss:0.47735169529914856, G_Loss:4.805421352386475

iterator 4400, D_Loss:0.5476787090301514, G_Loss:6.316684722900391

iterator 4500, D_Loss:0.4770491421222687, G_Loss:5.234610557556152

iterator 4600, D_Loss:0.5178943872451782, G_Loss:4.929868221282959

iterator 4700, D_Loss:0.48203137516975403, G_Loss:4.990068435668945

iterator 4800, D_Loss:0.4328826367855072, G_Loss:4.27208137512207

iterator 4900, D_Loss:0.5018808841705322, G_Loss:8.011573791503906

iterator 5000, D_Loss:0.4740947484970093, G_Loss:4.681600093841553

-----------Epoch 3-----------
iterator 100, D_Loss:0.44149819016456604, G_Loss:5.19338846206665

iterator 200, D_Loss:0.45360517501831055, G_Loss:6.854446887969971

iterator 300, D_Loss:0.5072993636131287, G_Loss:6.848679065704346

iterator 400, D_Loss:0.4366626739501953, G_Loss:7.06246280670166

iterator 500, D_Loss:0.4623994529247284, G_Loss:8.3590087890625

iterator 600, D_Loss:0.42627233266830444, G_Loss:8.819147109985352

iterator 700, D_Loss:0.4649321436882019, G_Loss:6.764001369476318

iterator 800, D_Loss:0.43938741087913513, G_Loss:6.941950798034668

iterator 900, D_Loss:0.4625454843044281, G_Loss:7.088874340057373

iterator 1000, D_Loss:0.446405827999115, G_Loss:4.442505836486816

iterator 1100, D_Loss:0.482976496219635, G_Loss:8.32540225982666

iterator 1200, D_Loss:0.46682146191596985, G_Loss:5.187873840332031

iterator 1300, D_Loss:0.4416821002960205, G_Loss:9.078964233398438

iterator 1400, D_Loss:0.43386662006378174, G_Loss:8.671525955200195

iterator 1500, D_Loss:0.4741870164871216, G_Loss:7.6283111572265625

iterator 1600, D_Loss:0.49707627296447754, G_Loss:5.283782005310059

iterator 1700, D_Loss:0.4510107636451721, G_Loss:7.7972917556762695

iterator 1800, D_Loss:0.44017839431762695, G_Loss:4.841928482055664

iterator 1900, D_Loss:0.41349607706069946, G_Loss:6.152968883514404

iterator 2000, D_Loss:0.44534939527511597, G_Loss:7.833186149597168

iterator 2100, D_Loss:0.46294718980789185, G_Loss:9.0145845413208

iterator 2200, D_Loss:0.43909475207328796, G_Loss:7.685827732086182

iterator 2300, D_Loss:0.4365585446357727, G_Loss:9.723234176635742

iterator 2400, D_Loss:0.4854065477848053, G_Loss:8.459553718566895

iterator 2500, D_Loss:0.4619336426258087, G_Loss:7.964861869812012

iterator 2600, D_Loss:0.46455103158950806, G_Loss:7.319751739501953

iterator 2700, D_Loss:0.44644856452941895, G_Loss:6.895578384399414

iterator 2800, D_Loss:0.40987664461135864, G_Loss:6.757041931152344

iterator 2900, D_Loss:0.4510582387447357, G_Loss:9.68008041381836

iterator 3000, D_Loss:0.4529734253883362, G_Loss:7.861476898193359

iterator 3100, D_Loss:0.45273256301879883, G_Loss:10.500109672546387

iterator 3200, D_Loss:0.4302971363067627, G_Loss:8.76989459991455

iterator 3300, D_Loss:0.4804117679595947, G_Loss:4.588238716125488

iterator 3400, D_Loss:0.4473710060119629, G_Loss:7.810365676879883

iterator 3500, D_Loss:0.4776563346385956, G_Loss:9.616096496582031

iterator 3600, D_Loss:0.43793338537216187, G_Loss:9.099135398864746

iterator 3700, D_Loss:0.459850013256073, G_Loss:7.628593921661377

iterator 3800, D_Loss:0.43557679653167725, G_Loss:7.275683403015137

iterator 3900, D_Loss:0.42353183031082153, G_Loss:7.640148639678955

iterator 4000, D_Loss:0.6048300862312317, G_Loss:8.25051212310791

iterator 4100, D_Loss:0.4317053556442261, G_Loss:8.3967924118042

iterator 4200, D_Loss:0.4630267918109894, G_Loss:9.3865327835083

iterator 4300, D_Loss:0.42575666308403015, G_Loss:9.25705623626709

iterator 4400, D_Loss:0.4464472830295563, G_Loss:9.711007118225098

iterator 4500, D_Loss:0.41833075881004333, G_Loss:8.157032012939453

iterator 4600, D_Loss:0.4628618657588959, G_Loss:6.713661193847656

iterator 4700, D_Loss:0.4406639337539673, G_Loss:7.877967357635498

iterator 4800, D_Loss:0.4142356812953949, G_Loss:6.736713409423828

iterator 4900, D_Loss:0.4511888325214386, G_Loss:7.891796588897705

iterator 5000, D_Loss:0.4354454278945923, G_Loss:8.037446975708008

-----------Epoch 4-----------
iterator 100, D_Loss:0.42433005571365356, G_Loss:9.246247291564941

iterator 200, D_Loss:0.4397725462913513, G_Loss:8.601749420166016

iterator 300, D_Loss:0.41739702224731445, G_Loss:7.898210525512695

iterator 400, D_Loss:0.4353957772254944, G_Loss:9.114836692810059

iterator 500, D_Loss:0.4443467855453491, G_Loss:9.46812915802002

iterator 600, D_Loss:0.4102969169616699, G_Loss:8.83676528930664

iterator 700, D_Loss:0.4166383743286133, G_Loss:9.166155815124512

iterator 800, D_Loss:0.46050235629081726, G_Loss:10.013699531555176

iterator 900, D_Loss:0.4410878121852875, G_Loss:7.4177751541137695

iterator 1000, D_Loss:0.41252902150154114, G_Loss:9.563194274902344

iterator 1100, D_Loss:0.4241447448730469, G_Loss:9.50994873046875

iterator 1200, D_Loss:0.47488823533058167, G_Loss:6.765329360961914

iterator 1300, D_Loss:0.4496746361255646, G_Loss:9.196455001831055

iterator 1400, D_Loss:0.4247009754180908, G_Loss:9.34512996673584

iterator 1500, D_Loss:0.47190648317337036, G_Loss:3.8526525497436523

iterator 1600, D_Loss:0.6541605591773987, G_Loss:4.084366798400879

iterator 1700, D_Loss:0.41513749957084656, G_Loss:8.92795467376709

iterator 1800, D_Loss:0.4341048300266266, G_Loss:6.604060649871826

iterator 1900, D_Loss:0.4338012933731079, G_Loss:6.134902477264404

iterator 2000, D_Loss:0.407685786485672, G_Loss:8.117191314697266

iterator 2100, D_Loss:0.4203721880912781, G_Loss:5.464140892028809

iterator 2200, D_Loss:0.41509729623794556, G_Loss:11.051286697387695

iterator 2300, D_Loss:0.4219711124897003, G_Loss:10.680646896362305

iterator 2400, D_Loss:0.4265797734260559, G_Loss:10.98568344116211

iterator 2500, D_Loss:0.4482004642486572, G_Loss:8.408329010009766

iterator 2600, D_Loss:0.41945576667785645, G_Loss:11.526063919067383

iterator 2700, D_Loss:0.4473915100097656, G_Loss:10.070109367370605

iterator 2800, D_Loss:0.4076099693775177, G_Loss:9.250330924987793

iterator 2900, D_Loss:0.4384705722332001, G_Loss:9.130350112915039

iterator 3000, D_Loss:0.4395834803581238, G_Loss:9.028398513793945

iterator 3100, D_Loss:0.4363819658756256, G_Loss:9.919818878173828

iterator 3200, D_Loss:0.41735604405403137, G_Loss:10.9647798538208

iterator 3300, D_Loss:0.4294636845588684, G_Loss:11.107444763183594

iterator 3400, D_Loss:0.4124240577220917, G_Loss:8.277316093444824

iterator 3500, D_Loss:0.462019681930542, G_Loss:12.62403678894043

iterator 3600, D_Loss:0.43197381496429443, G_Loss:11.248078346252441

iterator 3700, D_Loss:0.449562132358551, G_Loss:11.07900619506836

iterator 3800, D_Loss:0.4392443001270294, G_Loss:11.2247953414917

iterator 3900, D_Loss:0.47361060976982117, G_Loss:10.94444465637207

iterator 4000, D_Loss:0.4093863070011139, G_Loss:8.996025085449219

iterator 4100, D_Loss:0.43101948499679565, G_Loss:9.881402015686035

iterator 4200, D_Loss:0.41336020827293396, G_Loss:10.81006145477295

iterator 4300, D_Loss:0.4277437925338745, G_Loss:9.83325481414795

iterator 4400, D_Loss:0.4391430616378784, G_Loss:11.672385215759277

iterator 4500, D_Loss:0.4201897978782654, G_Loss:10.436524391174316

iterator 4600, D_Loss:0.4116118252277374, G_Loss:9.066543579101562

iterator 4700, D_Loss:0.4242492914199829, G_Loss:9.369009971618652

iterator 4800, D_Loss:0.42286038398742676, G_Loss:7.582522392272949

iterator 4900, D_Loss:0.44855964183807373, G_Loss:9.23404312133789

iterator 5000, D_Loss:0.4043795168399811, G_Loss:11.458442687988281

-----------Epoch 5-----------
iterator 100, D_Loss:0.41915273666381836, G_Loss:8.348626136779785

iterator 200, D_Loss:0.4022819697856903, G_Loss:12.397825241088867

iterator 300, D_Loss:0.43268293142318726, G_Loss:11.238072395324707

iterator 400, D_Loss:0.42755207419395447, G_Loss:11.17261791229248

iterator 500, D_Loss:0.426057368516922, G_Loss:11.722145080566406

iterator 600, D_Loss:0.45458632707595825, G_Loss:10.96149730682373

iterator 700, D_Loss:0.44091832637786865, G_Loss:11.307159423828125

iterator 800, D_Loss:0.4308842718601227, G_Loss:11.028732299804688

iterator 900, D_Loss:0.4247564375400543, G_Loss:10.206088066101074

iterator 1000, D_Loss:0.4364407956600189, G_Loss:11.941691398620605

iterator 1100, D_Loss:0.4488883316516876, G_Loss:11.579398155212402

iterator 1200, D_Loss:0.4258994460105896, G_Loss:13.852645874023438

iterator 1300, D_Loss:0.45105841755867004, G_Loss:11.551088333129883

iterator 1400, D_Loss:0.43000662326812744, G_Loss:11.708576202392578

iterator 1500, D_Loss:0.4266197681427002, G_Loss:10.935147285461426

iterator 1600, D_Loss:0.4189249277114868, G_Loss:10.23587417602539

iterator 1700, D_Loss:0.42721059918403625, G_Loss:11.128488540649414

iterator 1800, D_Loss:0.4441072344779968, G_Loss:12.477009773254395

iterator 1900, D_Loss:0.4176621437072754, G_Loss:12.879819869995117

iterator 2000, D_Loss:0.4177273213863373, G_Loss:10.547426223754883

iterator 2100, D_Loss:0.4412679672241211, G_Loss:11.822933197021484

iterator 2200, D_Loss:0.42381611466407776, G_Loss:11.786799430847168

iterator 2300, D_Loss:0.44044920802116394, G_Loss:10.666059494018555

iterator 2400, D_Loss:0.408963143825531, G_Loss:13.30057144165039

iterator 2500, D_Loss:0.4177086353302002, G_Loss:11.834425926208496

iterator 2600, D_Loss:0.40873607993125916, G_Loss:12.462803840637207

iterator 2700, D_Loss:0.41896599531173706, G_Loss:12.210209846496582

iterator 2800, D_Loss:0.4343826174736023, G_Loss:11.30140209197998

iterator 2900, D_Loss:0.44729089736938477, G_Loss:11.992073059082031

iterator 3000, D_Loss:0.4478306174278259, G_Loss:11.863238334655762

iterator 3100, D_Loss:0.436959832906723, G_Loss:12.536860466003418

iterator 3200, D_Loss:0.431264728307724, G_Loss:11.969482421875

iterator 3300, D_Loss:0.43010011315345764, G_Loss:11.500758171081543

iterator 3400, D_Loss:0.4352821111679077, G_Loss:12.6968994140625

iterator 3500, D_Loss:0.4280602037906647, G_Loss:13.556722640991211

iterator 3600, D_Loss:0.43512284755706787, G_Loss:12.351258277893066

iterator 3700, D_Loss:0.41935038566589355, G_Loss:12.411797523498535

iterator 3800, D_Loss:0.405952125787735, G_Loss:12.386747360229492

iterator 3900, D_Loss:0.42648181319236755, G_Loss:11.715339660644531

iterator 4000, D_Loss:0.429666131734848, G_Loss:13.801061630249023

iterator 4100, D_Loss:0.40624767541885376, G_Loss:13.140240669250488

iterator 4200, D_Loss:0.41845619678497314, G_Loss:14.038005828857422

iterator 4300, D_Loss:0.4257481098175049, G_Loss:14.884478569030762

iterator 4400, D_Loss:0.42313921451568604, G_Loss:12.556314468383789

iterator 4500, D_Loss:0.4368870258331299, G_Loss:11.857137680053711

iterator 4600, D_Loss:0.4211905002593994, G_Loss:12.852938652038574

iterator 4700, D_Loss:0.4190898835659027, G_Loss:12.458381652832031

iterator 4800, D_Loss:0.4488142430782318, G_Loss:13.224773406982422

iterator 4900, D_Loss:0.434957355260849, G_Loss:11.891094207763672

iterator 5000, D_Loss:0.4054499566555023, G_Loss:11.56210994720459

-----------Epoch 6-----------
iterator 100, D_Loss:0.4244253635406494, G_Loss:11.227816581726074

iterator 200, D_Loss:0.3966417908668518, G_Loss:11.859313011169434

iterator 300, D_Loss:0.46168628334999084, G_Loss:12.981834411621094

iterator 400, D_Loss:0.4294484257698059, G_Loss:7.0450263023376465

iterator 500, D_Loss:0.4223318099975586, G_Loss:11.787346839904785

iterator 600, D_Loss:0.40960559248924255, G_Loss:13.17922306060791

iterator 700, D_Loss:0.4388739764690399, G_Loss:14.977503776550293

iterator 800, D_Loss:0.4295099675655365, G_Loss:13.272028923034668

iterator 900, D_Loss:0.4278692901134491, G_Loss:13.14198112487793

iterator 1000, D_Loss:0.4046717882156372, G_Loss:11.658329010009766

iterator 1100, D_Loss:0.4293577969074249, G_Loss:11.432171821594238

iterator 1200, D_Loss:0.42767980694770813, G_Loss:13.84036922454834

iterator 1300, D_Loss:0.3978273272514343, G_Loss:12.70212173461914

iterator 1400, D_Loss:0.4260423183441162, G_Loss:13.037097930908203

iterator 1500, D_Loss:0.4298112094402313, G_Loss:13.662737846374512

iterator 1600, D_Loss:0.4432901442050934, G_Loss:16.202669143676758

iterator 1700, D_Loss:0.395987331867218, G_Loss:15.547637939453125

iterator 1800, D_Loss:0.399554044008255, G_Loss:13.672301292419434

iterator 1900, D_Loss:0.44219955801963806, G_Loss:13.54187297821045

iterator 2000, D_Loss:0.4351048767566681, G_Loss:13.899190902709961

iterator 2100, D_Loss:0.42485982179641724, G_Loss:15.669588088989258

iterator 2200, D_Loss:0.43882524967193604, G_Loss:15.639763832092285

iterator 2300, D_Loss:0.43725576996803284, G_Loss:14.731012344360352

iterator 2400, D_Loss:0.40992140769958496, G_Loss:15.58810806274414

iterator 2500, D_Loss:0.40254148840904236, G_Loss:12.619906425476074

iterator 2600, D_Loss:0.40807318687438965, G_Loss:13.882146835327148

iterator 2700, D_Loss:0.39848607778549194, G_Loss:17.5454044342041

iterator 2800, D_Loss:0.4323517680168152, G_Loss:14.56546401977539

iterator 2900, D_Loss:0.42776086926460266, G_Loss:14.842048645019531

iterator 3000, D_Loss:0.41600775718688965, G_Loss:16.2302188873291

iterator 3100, D_Loss:0.39688363671302795, G_Loss:13.901659965515137

iterator 3200, D_Loss:0.4349023699760437, G_Loss:15.578330993652344

iterator 3300, D_Loss:0.4189872145652771, G_Loss:17.081541061401367

iterator 3400, D_Loss:0.43224555253982544, G_Loss:16.060644149780273

iterator 3500, D_Loss:0.4100155532360077, G_Loss:15.4818696975708

iterator 3600, D_Loss:0.44316795468330383, G_Loss:14.123828887939453

iterator 3700, D_Loss:0.41101229190826416, G_Loss:17.93754768371582

iterator 3800, D_Loss:0.4246433973312378, G_Loss:17.613109588623047

iterator 3900, D_Loss:0.43255871534347534, G_Loss:16.960201263427734

iterator 4000, D_Loss:0.4056818187236786, G_Loss:15.495352745056152

iterator 4100, D_Loss:0.4196827709674835, G_Loss:17.32355499267578

iterator 4200, D_Loss:0.40059658885002136, G_Loss:16.54429817199707

iterator 4300, D_Loss:0.416338711977005, G_Loss:15.298592567443848

iterator 4400, D_Loss:0.4335632026195526, G_Loss:15.805475234985352

iterator 4500, D_Loss:0.42630481719970703, G_Loss:15.829217910766602

iterator 4600, D_Loss:0.44923385977745056, G_Loss:14.177949905395508

iterator 4700, D_Loss:0.4327644407749176, G_Loss:14.712614059448242

iterator 4800, D_Loss:0.4223298728466034, G_Loss:15.731793403625488

iterator 4900, D_Loss:0.4651043713092804, G_Loss:14.689760208129883

iterator 5000, D_Loss:0.4224144518375397, G_Loss:15.294883728027344

-----------Epoch 7-----------
iterator 100, D_Loss:0.4309757649898529, G_Loss:14.014155387878418

iterator 200, D_Loss:0.4095326066017151, G_Loss:14.405231475830078

iterator 300, D_Loss:0.40456974506378174, G_Loss:16.337833404541016

iterator 400, D_Loss:0.4030778706073761, G_Loss:15.370418548583984

iterator 500, D_Loss:0.41833797097206116, G_Loss:13.687896728515625

iterator 600, D_Loss:0.43705540895462036, G_Loss:15.727076530456543

iterator 700, D_Loss:0.44801440834999084, G_Loss:14.551141738891602

iterator 800, D_Loss:0.4265522360801697, G_Loss:13.61987018585205

iterator 900, D_Loss:0.42344188690185547, G_Loss:15.533788681030273

iterator 1000, D_Loss:0.42026907205581665, G_Loss:14.5497465133667

iterator 1100, D_Loss:0.43758419156074524, G_Loss:13.936439514160156

iterator 1200, D_Loss:0.44828981161117554, G_Loss:12.920614242553711

iterator 1300, D_Loss:0.4235992729663849, G_Loss:15.918256759643555

iterator 1400, D_Loss:0.41372308135032654, G_Loss:15.743647575378418

iterator 1500, D_Loss:0.41265445947647095, G_Loss:15.897141456604004

iterator 1600, D_Loss:0.41908910870552063, G_Loss:17.32090187072754

iterator 1700, D_Loss:0.41588330268859863, G_Loss:15.375935554504395

iterator 1800, D_Loss:0.4213208556175232, G_Loss:18.336328506469727

iterator 1900, D_Loss:0.4250316917896271, G_Loss:15.068233489990234

iterator 2000, D_Loss:0.4090542495250702, G_Loss:16.012622833251953

iterator 2100, D_Loss:0.4097974896430969, G_Loss:17.2216796875

iterator 2200, D_Loss:0.44545117020606995, G_Loss:14.632878303527832

iterator 2300, D_Loss:0.4273325800895691, G_Loss:16.672576904296875

iterator 2400, D_Loss:0.4466642737388611, G_Loss:17.191650390625

iterator 2500, D_Loss:0.4220302700996399, G_Loss:17.61043357849121

iterator 2600, D_Loss:0.42184847593307495, G_Loss:16.93450355529785

iterator 2700, D_Loss:0.41802555322647095, G_Loss:16.726469039916992

iterator 2800, D_Loss:0.43030011653900146, G_Loss:16.766752243041992

iterator 2900, D_Loss:0.4012802541255951, G_Loss:14.025053024291992

iterator 3000, D_Loss:0.4135311245918274, G_Loss:17.209590911865234

iterator 3100, D_Loss:0.4287180006504059, G_Loss:15.185060501098633

iterator 3200, D_Loss:0.4293151795864105, G_Loss:16.231918334960938

iterator 3300, D_Loss:0.41462740302085876, G_Loss:16.070314407348633

iterator 3400, D_Loss:0.39785459637641907, G_Loss:16.742027282714844

iterator 3500, D_Loss:0.4345199465751648, G_Loss:15.44459342956543

iterator 3600, D_Loss:0.43279746174812317, G_Loss:17.222740173339844

iterator 3700, D_Loss:0.4535170793533325, G_Loss:16.386564254760742

iterator 3800, D_Loss:0.42183780670166016, G_Loss:17.144786834716797

iterator 3900, D_Loss:0.45091012120246887, G_Loss:17.127965927124023

iterator 4000, D_Loss:0.434754341840744, G_Loss:17.763774871826172

iterator 4100, D_Loss:0.42649415135383606, G_Loss:16.533601760864258

iterator 4200, D_Loss:0.4408477544784546, G_Loss:17.43865203857422

iterator 4300, D_Loss:0.43967005610466003, G_Loss:17.612319946289062

iterator 4400, D_Loss:0.4605657756328583, G_Loss:15.325798988342285

iterator 4500, D_Loss:0.4158627390861511, G_Loss:16.9528751373291

iterator 4600, D_Loss:0.4267592132091522, G_Loss:17.02767562866211

iterator 4700, D_Loss:0.42651548981666565, G_Loss:15.154892921447754

iterator 4800, D_Loss:0.43432578444480896, G_Loss:15.85238265991211

iterator 4900, D_Loss:0.46466392278671265, G_Loss:16.586894989013672

iterator 5000, D_Loss:0.4164712727069855, G_Loss:15.752349853515625

-----------Epoch 8-----------
iterator 100, D_Loss:0.4440571367740631, G_Loss:16.049072265625

iterator 200, D_Loss:0.42208826541900635, G_Loss:16.975425720214844

iterator 300, D_Loss:0.41692259907722473, G_Loss:15.880218505859375

iterator 400, D_Loss:0.41534483432769775, G_Loss:15.31235408782959

iterator 500, D_Loss:0.4539981484413147, G_Loss:16.662837982177734

iterator 600, D_Loss:0.4218008816242218, G_Loss:14.958230972290039

iterator 700, D_Loss:0.41857990622520447, G_Loss:15.207324028015137

iterator 800, D_Loss:0.4280378222465515, G_Loss:16.416770935058594

iterator 900, D_Loss:0.4424262046813965, G_Loss:16.627473831176758

iterator 1000, D_Loss:0.42045390605926514, G_Loss:19.06316566467285

iterator 1100, D_Loss:0.3938799798488617, G_Loss:16.750768661499023

iterator 1200, D_Loss:0.4554019570350647, G_Loss:15.077493667602539

iterator 1300, D_Loss:0.4424566626548767, G_Loss:15.40816593170166

iterator 1400, D_Loss:0.4070262610912323, G_Loss:5.605574607849121

iterator 1500, D_Loss:0.4151790738105774, G_Loss:15.594883918762207

iterator 1600, D_Loss:0.42638513445854187, G_Loss:16.29782485961914

iterator 1700, D_Loss:0.4401218593120575, G_Loss:15.271200180053711

iterator 1800, D_Loss:0.410992294549942, G_Loss:14.966106414794922

iterator 1900, D_Loss:0.41841331124305725, G_Loss:16.151506423950195

iterator 2000, D_Loss:0.4262504279613495, G_Loss:15.219450950622559

iterator 2100, D_Loss:0.39995071291923523, G_Loss:15.467547416687012

iterator 2200, D_Loss:0.44808343052864075, G_Loss:15.150113105773926

iterator 2300, D_Loss:0.4353577792644501, G_Loss:14.703868865966797

iterator 2400, D_Loss:0.42584115266799927, G_Loss:16.079702377319336

iterator 2500, D_Loss:0.43835386633872986, G_Loss:14.996295928955078

iterator 2600, D_Loss:0.4033862352371216, G_Loss:14.389289855957031

iterator 2700, D_Loss:0.40913498401641846, G_Loss:13.886445999145508

iterator 2800, D_Loss:0.4293265640735626, G_Loss:14.294431686401367

iterator 2900, D_Loss:0.4345165491104126, G_Loss:15.612114906311035

iterator 3000, D_Loss:0.4137062728404999, G_Loss:18.06492805480957

iterator 3100, D_Loss:0.4209405481815338, G_Loss:20.028642654418945

iterator 3200, D_Loss:0.42267096042633057, G_Loss:17.368545532226562

iterator 3300, D_Loss:0.42189326882362366, G_Loss:19.41769027709961

iterator 3400, D_Loss:0.41869044303894043, G_Loss:18.525041580200195

iterator 3500, D_Loss:0.4230313003063202, G_Loss:18.12339210510254

iterator 3600, D_Loss:0.42984527349472046, G_Loss:16.549732208251953

iterator 3700, D_Loss:0.42601490020751953, G_Loss:19.130374908447266

iterator 3800, D_Loss:0.4277939200401306, G_Loss:19.337005615234375

iterator 3900, D_Loss:0.40771010518074036, G_Loss:18.06552505493164

iterator 4000, D_Loss:0.44209352135658264, G_Loss:16.268035888671875

iterator 4100, D_Loss:0.4360174834728241, G_Loss:18.945711135864258

iterator 4200, D_Loss:0.4254443645477295, G_Loss:17.151731491088867

iterator 4300, D_Loss:0.411123663187027, G_Loss:19.64117431640625

iterator 4400, D_Loss:0.43133506178855896, G_Loss:19.789377212524414

iterator 4500, D_Loss:0.4413112699985504, G_Loss:17.173498153686523

iterator 4600, D_Loss:0.4311261475086212, G_Loss:20.723674774169922

iterator 4700, D_Loss:0.4332953095436096, G_Loss:20.586292266845703

iterator 4800, D_Loss:0.3970761001110077, G_Loss:21.477785110473633

iterator 4900, D_Loss:0.4270784854888916, G_Loss:21.51143455505371

iterator 5000, D_Loss:0.4476773738861084, G_Loss:21.974742889404297

-----------Epoch 9-----------
iterator 100, D_Loss:0.409271776676178, G_Loss:23.241985321044922

iterator 200, D_Loss:0.42050936818122864, G_Loss:18.717588424682617

iterator 300, D_Loss:0.40041816234588623, G_Loss:24.56616973876953

iterator 400, D_Loss:0.4095277786254883, G_Loss:24.903636932373047

iterator 500, D_Loss:0.41425496339797974, G_Loss:23.232126235961914

iterator 600, D_Loss:0.4320646822452545, G_Loss:24.512767791748047

iterator 700, D_Loss:0.4157390594482422, G_Loss:20.602718353271484

iterator 800, D_Loss:0.4054715931415558, G_Loss:20.647708892822266

iterator 900, D_Loss:0.4493313729763031, G_Loss:17.87161636352539

iterator 1000, D_Loss:0.41420549154281616, G_Loss:21.55493927001953

iterator 1100, D_Loss:0.425991952419281, G_Loss:20.440303802490234

iterator 1200, D_Loss:0.4246458411216736, G_Loss:21.76708221435547

iterator 1300, D_Loss:0.41995152831077576, G_Loss:21.07523536682129

iterator 1400, D_Loss:0.4219103157520294, G_Loss:21.942699432373047

iterator 1500, D_Loss:0.4358142018318176, G_Loss:21.283611297607422

iterator 1600, D_Loss:0.4282694160938263, G_Loss:19.9237060546875

iterator 1700, D_Loss:0.4180510640144348, G_Loss:22.13090705871582

iterator 1800, D_Loss:0.4357505142688751, G_Loss:22.70079803466797

iterator 1900, D_Loss:0.4219660460948944, G_Loss:22.51261329650879

iterator 2000, D_Loss:0.43006274104118347, G_Loss:19.434595108032227

iterator 2100, D_Loss:0.4194093644618988, G_Loss:20.627655029296875

iterator 2200, D_Loss:0.4101887345314026, G_Loss:19.878833770751953

iterator 2300, D_Loss:0.4283609688282013, G_Loss:19.60089111328125

iterator 2400, D_Loss:0.419975221157074, G_Loss:19.582901000976562

iterator 2500, D_Loss:0.42049577832221985, G_Loss:18.879892349243164

iterator 2600, D_Loss:0.4152372181415558, G_Loss:19.719520568847656

iterator 2700, D_Loss:0.45158281922340393, G_Loss:19.85360336303711

iterator 2800, D_Loss:0.4139496684074402, G_Loss:20.752002716064453

iterator 2900, D_Loss:0.4373743236064911, G_Loss:18.839353561401367

iterator 3000, D_Loss:0.44247445464134216, G_Loss:20.20232391357422

iterator 3100, D_Loss:0.44394296407699585, G_Loss:19.456314086914062

iterator 3200, D_Loss:0.4167144298553467, G_Loss:19.54657745361328

iterator 3300, D_Loss:0.4224488437175751, G_Loss:19.862760543823242

iterator 3400, D_Loss:0.3989880084991455, G_Loss:19.811389923095703

iterator 3500, D_Loss:0.418552964925766, G_Loss:20.99359130859375

iterator 3600, D_Loss:0.4496782124042511, G_Loss:20.022357940673828

iterator 3700, D_Loss:0.4580620527267456, G_Loss:19.62859344482422

iterator 3800, D_Loss:0.43821001052856445, G_Loss:19.229068756103516

iterator 3900, D_Loss:0.41270896792411804, G_Loss:17.89177131652832

iterator 4000, D_Loss:0.42120224237442017, G_Loss:19.373485565185547

iterator 4100, D_Loss:0.40590187907218933, G_Loss:18.818626403808594

iterator 4200, D_Loss:0.44047462940216064, G_Loss:15.91720962524414

iterator 4300, D_Loss:0.4359104633331299, G_Loss:17.632862091064453

iterator 4400, D_Loss:0.4532161056995392, G_Loss:17.81064224243164

iterator 4500, D_Loss:0.4351561367511749, G_Loss:19.46512794494629

iterator 4600, D_Loss:0.40873339772224426, G_Loss:17.785245895385742

iterator 4700, D_Loss:0.41114550828933716, G_Loss:19.67816734313965

iterator 4800, D_Loss:0.4217245280742645, G_Loss:19.4305362701416

iterator 4900, D_Loss:0.4131450057029724, G_Loss:18.853723526000977

iterator 5000, D_Loss:0.44999203085899353, G_Loss:17.199430465698242

train row : 30148
sample row: 30148
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [96,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [97,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [98,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [99,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [32,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [33,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [34,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [35,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [36,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [37,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [38,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [39,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [40,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [41,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [42,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [43,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [44,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [45,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [46,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [47,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [48,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [49,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [50,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [51,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [52,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [53,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [54,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [55,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [56,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [57,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [58,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [59,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [60,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [61,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [62,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [63,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [0,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [1,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [2,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [3,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [4,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [5,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [6,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [7,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [8,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [9,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [10,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [11,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [12,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [13,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [14,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [15,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [16,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [17,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [18,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [19,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [20,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [21,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [22,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [23,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [24,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [25,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [26,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [27,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [28,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [29,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [30,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [31,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [64,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [65,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [66,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [67,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [68,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [69,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [70,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [71,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [72,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [73,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [74,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [75,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [76,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [77,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [78,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [79,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [80,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [81,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [82,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [83,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [84,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [85,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [86,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [87,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [88,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [89,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [90,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [91,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [92,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [93,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [94,0,0] Assertion `input >= 0. && input <= 1.` failed.
/usr/local/easybuild-2019/easybuild/build/PyTorch/1.4.0/fosscuda-2019b-Python-3.7.4/pytorch-1.4.0/aten/src/THCUNN/BCECriterion.cu:42: Acctype bce_functor<Dtype, Acctype>::operator()(Tuple) [with Tuple = thrust::detail::tuple_of_iterator_references<thrust::device_reference<float>, thrust::device_reference<float>, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type, thrust::null_type>, Dtype = float, Acctype = float]: block: [0,0,0], thread: [95,0,0] Assertion `input >= 0. && input <= 1.` failed.
LGAN_generator(
  (LSTM): LSTMCell(250, 500)
  (fc00): Linear(in_features=200, out_features=1, bias=True)
  (fc01): Linear(in_features=1, out_features=200, bias=True)
  (fe0): Linear(in_features=500, out_features=200, bias=True)
  (fc10): Linear(in_features=200, out_features=1, bias=True)
  (fc11): Linear(in_features=1, out_features=200, bias=True)
  (fe1): Linear(in_features=500, out_features=200, bias=True)
  (fc20): Linear(in_features=200, out_features=1, bias=True)
  (fc21): Linear(in_features=1, out_features=200, bias=True)
  (fe2): Linear(in_features=500, out_features=200, bias=True)
  (fc30): Linear(in_features=200, out_features=1, bias=True)
  (fc31): Linear(in_features=1, out_features=200, bias=True)
  (fe3): Linear(in_features=500, out_features=200, bias=True)
  (fc40): Linear(in_features=200, out_features=1, bias=True)
  (fc41): Linear(in_features=1, out_features=200, bias=True)
  (fe4): Linear(in_features=500, out_features=200, bias=True)
  (fc50): Linear(in_features=200, out_features=1, bias=True)
  (fc51): Linear(in_features=1, out_features=200, bias=True)
  (fe5): Linear(in_features=500, out_features=200, bias=True)
  (fc60): Linear(in_features=200, out_features=1, bias=True)
  (fc61): Linear(in_features=1, out_features=200, bias=True)
  (fe6): Linear(in_features=500, out_features=200, bias=True)
  (fc70): Linear(in_features=200, out_features=1, bias=True)
  (fc71): Linear(in_features=1, out_features=200, bias=True)
  (fe7): Linear(in_features=500, out_features=200, bias=True)
  (fc80): Linear(in_features=200, out_features=1, bias=True)
  (fc81): Linear(in_features=1, out_features=200, bias=True)
  (fe8): Linear(in_features=500, out_features=200, bias=True)
  (fc90): Linear(in_features=200, out_features=1, bias=True)
  (fc91): Linear(in_features=1, out_features=200, bias=True)
  (fe9): Linear(in_features=500, out_features=200, bias=True)
  (fc100): Linear(in_features=200, out_features=1, bias=True)
  (fc101): Linear(in_features=1, out_features=200, bias=True)
  (fe10): Linear(in_features=500, out_features=200, bias=True)
  (fc110): Linear(in_features=200, out_features=1, bias=True)
  (fc111): Linear(in_features=1, out_features=200, bias=True)
  (fe11): Linear(in_features=500, out_features=200, bias=True)
  (fc120): Linear(in_features=200, out_features=1, bias=True)
  (fc121): Linear(in_features=1, out_features=200, bias=True)
  (fe12): Linear(in_features=500, out_features=200, bias=True)
  (fc130): Linear(in_features=200, out_features=1, bias=True)
  (fc131): Linear(in_features=1, out_features=200, bias=True)
  (fe13): Linear(in_features=500, out_features=200, bias=True)
  (fc140): Linear(in_features=200, out_features=1, bias=True)
  (fc141): Linear(in_features=1, out_features=200, bias=True)
  (fe14): Linear(in_features=500, out_features=200, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=15, out_features=200, bias=True)
  (inputbn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (bn0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=200, out_features=200, bias=True)
  (bn1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=200, out_features=200, bias=True)
  (bn2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=200, out_features=200, bias=True)
  (bn3): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc4): Linear(in_features=200, out_features=200, bias=True)
  (bn4): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=200, out_features=1, bias=True)
)
(0, False, 15)
-----------Epoch 0-----------
iterator 100, D_Loss:1.4227170944213867, G_Loss:0.8860251903533936

iterator 200, D_Loss:1.3999888896942139, G_Loss:0.8686384558677673

iterator 300, D_Loss:1.3540440797805786, G_Loss:0.8664714097976685

iterator 400, D_Loss:1.3516789674758911, G_Loss:0.8455531597137451

iterator 500, D_Loss:1.3809497356414795, G_Loss:0.8842948079109192

iterator 600, D_Loss:1.3495068550109863, G_Loss:0.8681343197822571

iterator 700, D_Loss:1.3667619228363037, G_Loss:0.8512327075004578

iterator 800, D_Loss:1.3365068435668945, G_Loss:0.8459919691085815

iterator 900, D_Loss:1.4054927825927734, G_Loss:0.7974804043769836

iterator 1000, D_Loss:1.3149800300598145, G_Loss:0.9406688213348389

iterator 1100, D_Loss:1.2376418113708496, G_Loss:1.051734209060669

iterator 1200, D_Loss:1.2145233154296875, G_Loss:1.1594858169555664

iterator 1300, D_Loss:1.0651322603225708, G_Loss:1.2557090520858765

iterator 1400, D_Loss:1.0928744077682495, G_Loss:1.4063982963562012

iterator 1500, D_Loss:1.1513831615447998, G_Loss:1.6409167051315308

iterator 1600, D_Loss:0.8192692995071411, G_Loss:1.7928539514541626

iterator 1700, D_Loss:0.8188121318817139, G_Loss:1.7560733556747437

iterator 1800, D_Loss:0.8576077222824097, G_Loss:2.1280014514923096

iterator 1900, D_Loss:0.7039369940757751, G_Loss:2.02546763420105

iterator 2000, D_Loss:0.696125328540802, G_Loss:2.764366865158081

iterator 2100, D_Loss:1.0093531608581543, G_Loss:1.5314037799835205

iterator 2200, D_Loss:0.5958172678947449, G_Loss:3.182485580444336

iterator 2300, D_Loss:0.6648961901664734, G_Loss:2.977109670639038

iterator 2400, D_Loss:0.5094491243362427, G_Loss:2.5276787281036377

iterator 2500, D_Loss:0.5185314416885376, G_Loss:3.4259719848632812

iterator 2600, D_Loss:0.569847583770752, G_Loss:3.3006319999694824

iterator 2700, D_Loss:0.5623329281806946, G_Loss:3.2365078926086426

iterator 2800, D_Loss:0.4953914284706116, G_Loss:3.4272522926330566

iterator 2900, D_Loss:0.5135153532028198, G_Loss:4.362703323364258

iterator 3000, D_Loss:0.48976433277130127, G_Loss:3.581916570663452

iterator 3100, D_Loss:0.5415007472038269, G_Loss:4.956967830657959

iterator 3200, D_Loss:0.4708118438720703, G_Loss:4.609066486358643

iterator 3300, D_Loss:0.48757970333099365, G_Loss:4.934838771820068

iterator 3400, D_Loss:0.4569677412509918, G_Loss:3.9848854541778564

iterator 3500, D_Loss:0.47088623046875, G_Loss:4.104551792144775

iterator 3600, D_Loss:0.5586265921592712, G_Loss:5.326773643493652

iterator 3700, D_Loss:0.44344621896743774, G_Loss:5.275381565093994

iterator 3800, D_Loss:0.4333302080631256, G_Loss:5.663330554962158

iterator 3900, D_Loss:0.46980684995651245, G_Loss:6.373317718505859

iterator 4000, D_Loss:0.47414422035217285, G_Loss:6.473599910736084

iterator 4100, D_Loss:0.48221924901008606, G_Loss:6.3727707862854

iterator 4200, D_Loss:0.4164787530899048, G_Loss:6.3259501457214355

iterator 4300, D_Loss:0.445278525352478, G_Loss:6.621135234832764

iterator 4400, D_Loss:0.4498002529144287, G_Loss:6.311712265014648

iterator 4500, D_Loss:0.4657334089279175, G_Loss:6.077330112457275

iterator 4600, D_Loss:0.496621698141098, G_Loss:6.653641223907471

iterator 4700, D_Loss:0.46231210231781006, G_Loss:6.830451011657715

iterator 4800, D_Loss:0.4556695520877838, G_Loss:6.634830951690674

iterator 4900, D_Loss:0.45843246579170227, G_Loss:6.071702480316162

iterator 5000, D_Loss:0.4318823218345642, G_Loss:5.57893180847168

-----------Epoch 1-----------
iterator 100, D_Loss:0.4384135603904724, G_Loss:4.972778797149658

iterator 200, D_Loss:0.44511955976486206, G_Loss:4.077486515045166

iterator 300, D_Loss:0.4714048504829407, G_Loss:6.874112606048584

iterator 400, D_Loss:0.4478762149810791, G_Loss:6.458705902099609

iterator 500, D_Loss:0.45483675599098206, G_Loss:6.952706813812256

iterator 600, D_Loss:0.4614150822162628, G_Loss:6.905120372772217

iterator 700, D_Loss:0.4579598307609558, G_Loss:6.772772789001465

iterator 800, D_Loss:0.452910453081131, G_Loss:6.1720476150512695

iterator 900, D_Loss:0.4532682001590729, G_Loss:5.256882190704346

iterator 1000, D_Loss:0.4625642001628876, G_Loss:5.923008441925049

iterator 1100, D_Loss:0.4237273335456848, G_Loss:4.999361991882324

iterator 1200, D_Loss:0.47665783762931824, G_Loss:5.355359077453613

iterator 1300, D_Loss:0.46550989151000977, G_Loss:5.933292388916016

iterator 1400, D_Loss:0.4585539698600769, G_Loss:6.0357794761657715

iterator 1500, D_Loss:0.4311884641647339, G_Loss:5.575831413269043

iterator 1600, D_Loss:0.45053771138191223, G_Loss:6.861457347869873

iterator 1700, D_Loss:0.448181688785553, G_Loss:7.304406642913818

iterator 1800, D_Loss:0.42639636993408203, G_Loss:7.282741069793701

iterator 1900, D_Loss:0.43542590737342834, G_Loss:7.930159091949463

iterator 2000, D_Loss:0.41186898946762085, G_Loss:6.2114410400390625

iterator 2100, D_Loss:0.4282962381839752, G_Loss:8.611405372619629

iterator 2200, D_Loss:0.4314500689506531, G_Loss:8.221209526062012

iterator 2300, D_Loss:0.4537599980831146, G_Loss:7.896692276000977

iterator 2400, D_Loss:0.427404522895813, G_Loss:8.286635398864746

iterator 2500, D_Loss:0.42119598388671875, G_Loss:8.35665225982666

iterator 2600, D_Loss:0.4283756911754608, G_Loss:7.8996782302856445

iterator 2700, D_Loss:0.44583919644355774, G_Loss:8.253787994384766

iterator 2800, D_Loss:0.424394428730011, G_Loss:0.6830575466156006

iterator 2900, D_Loss:0.4476388096809387, G_Loss:8.393383979797363

iterator 3000, D_Loss:0.4321480095386505, G_Loss:8.912322044372559

iterator 3100, D_Loss:0.4337315261363983, G_Loss:8.314066886901855

iterator 3200, D_Loss:0.41703927516937256, G_Loss:9.537198066711426

iterator 3300, D_Loss:0.4123625159263611, G_Loss:8.122440338134766

iterator 3400, D_Loss:0.4231412410736084, G_Loss:8.151592254638672

iterator 3500, D_Loss:0.4029427766799927, G_Loss:7.430411338806152

iterator 3600, D_Loss:0.4026365578174591, G_Loss:9.005633354187012

iterator 3700, D_Loss:0.41746267676353455, G_Loss:7.92747688293457

iterator 3800, D_Loss:0.4493516981601715, G_Loss:8.99710750579834

iterator 3900, D_Loss:0.42443329095840454, G_Loss:8.77252197265625

iterator 4000, D_Loss:0.46679553389549255, G_Loss:8.0060396194458

Process Process-52:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 141, in thread_run
    V_Train(search, path, sample_it, gen, dis, config["n_epochs"], param["lr"], train_it, param["z_dim"], dataset, col_type, sample_times,itertimes = 100, steps_per_epoch = config["steps_per_epoch"],GPU=GPU,KL=KL)
  File "/home/youran/Daisy/Daisy/synthesizer/train.py", line 113, in V_Train
    D_Loss2 = F.binary_cross_entropy(y_fake, fake_label)
  File "/usr/local/easybuild-2019/easybuild/software/mpi/gcc-cuda/8.3.0-10.1.243/openmpi/3.1.4/pytorch/1.4.0-python-3.7.4/lib/python3.7/site-packages/torch/nn/functional.py", line 2077, in binary_cross_entropy
    input, target, weight, reduction_enum)
RuntimeError: reduce failed to synchronize: cudaErrorAssert: device-side assert triggered
LGAN_generator(
  (LSTM): LSTMCell(900, 300)
  (fc00): Linear(in_features=500, out_features=1, bias=True)
  (fc01): Linear(in_features=1, out_features=500, bias=True)
  (fe0): Linear(in_features=300, out_features=500, bias=True)
  (fc10): Linear(in_features=500, out_features=1, bias=True)
  (fc11): Linear(in_features=1, out_features=500, bias=True)
  (fe1): Linear(in_features=300, out_features=500, bias=True)
  (fc20): Linear(in_features=500, out_features=1, bias=True)
  (fc21): Linear(in_features=1, out_features=500, bias=True)
  (fe2): Linear(in_features=300, out_features=500, bias=True)
  (fc30): Linear(in_features=500, out_features=1, bias=True)
  (fc31): Linear(in_features=1, out_features=500, bias=True)
  (fe3): Linear(in_features=300, out_features=500, bias=True)
  (fc40): Linear(in_features=500, out_features=1, bias=True)
  (fc41): Linear(in_features=1, out_features=500, bias=True)
  (fe4): Linear(in_features=300, out_features=500, bias=True)
  (fc50): Linear(in_features=500, out_features=1, bias=True)
  (fc51): Linear(in_features=1, out_features=500, bias=True)
  (fe5): Linear(in_features=300, out_features=500, bias=True)
  (fc60): Linear(in_features=500, out_features=1, bias=True)
  (fc61): Linear(in_features=1, out_features=500, bias=True)
  (fe6): Linear(in_features=300, out_features=500, bias=True)
  (fc70): Linear(in_features=500, out_features=1, bias=True)
  (fc71): Linear(in_features=1, out_features=500, bias=True)
  (fe7): Linear(in_features=300, out_features=500, bias=True)
  (fc80): Linear(in_features=500, out_features=1, bias=True)
  (fc81): Linear(in_features=1, out_features=500, bias=True)
  (fe8): Linear(in_features=300, out_features=500, bias=True)
  (fc90): Linear(in_features=500, out_features=1, bias=True)
  (fc91): Linear(in_features=1, out_features=500, bias=True)
  (fe9): Linear(in_features=300, out_features=500, bias=True)
  (fc100): Linear(in_features=500, out_features=1, bias=True)
  (fc101): Linear(in_features=1, out_features=500, bias=True)
  (fe10): Linear(in_features=300, out_features=500, bias=True)
  (fc110): Linear(in_features=500, out_features=1, bias=True)
  (fc111): Linear(in_features=1, out_features=500, bias=True)
  (fe11): Linear(in_features=300, out_features=500, bias=True)
  (fc120): Linear(in_features=500, out_features=1, bias=True)
  (fc121): Linear(in_features=1, out_features=500, bias=True)
  (fe12): Linear(in_features=300, out_features=500, bias=True)
  (fc130): Linear(in_features=500, out_features=1, bias=True)
  (fc131): Linear(in_features=1, out_features=500, bias=True)
  (fe13): Linear(in_features=300, out_features=500, bias=True)
  (fc140): Linear(in_features=500, out_features=1, bias=True)
  (fc141): Linear(in_features=1, out_features=500, bias=True)
  (fe14): Linear(in_features=300, out_features=500, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=15, out_features=100, bias=True)
  (inputbn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=100, out_features=100, bias=True)
  (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=100, out_features=100, bias=True)
  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=100, out_features=100, bias=True)
  (bn3): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=100, out_features=1, bias=True)
)
(0, False, 15)
-----------Epoch 0-----------
iterator 100, D_Loss:1.413510799407959, G_Loss:0.7920998930931091

iterator 200, D_Loss:1.420274019241333, G_Loss:0.8797985315322876

iterator 300, D_Loss:1.4134972095489502, G_Loss:0.8829971551895142

iterator 400, D_Loss:1.3919785022735596, G_Loss:0.8476954102516174

iterator 500, D_Loss:1.3689062595367432, G_Loss:0.8505034446716309

iterator 600, D_Loss:1.3557214736938477, G_Loss:0.8827369809150696

iterator 700, D_Loss:1.3826141357421875, G_Loss:0.8740583062171936

iterator 800, D_Loss:1.3818610906600952, G_Loss:0.8560287952423096

iterator 900, D_Loss:1.3692408800125122, G_Loss:0.8665452599525452

iterator 1000, D_Loss:1.3639631271362305, G_Loss:0.8697972297668457

iterator 1100, D_Loss:1.3546233177185059, G_Loss:0.8676216006278992

iterator 1200, D_Loss:1.3956725597381592, G_Loss:0.8712084293365479

iterator 1300, D_Loss:1.3535289764404297, G_Loss:0.8601858615875244

iterator 1400, D_Loss:1.365099310874939, G_Loss:0.8628026843070984

iterator 1500, D_Loss:1.3771029710769653, G_Loss:0.879701554775238

iterator 1600, D_Loss:1.368931770324707, G_Loss:0.8867639899253845

iterator 1700, D_Loss:1.3987486362457275, G_Loss:0.8017688989639282

iterator 1800, D_Loss:1.3767013549804688, G_Loss:0.8123047351837158

iterator 1900, D_Loss:1.374596118927002, G_Loss:0.8130686283111572

iterator 2000, D_Loss:1.376990795135498, G_Loss:0.8283516764640808

iterator 2100, D_Loss:1.385230541229248, G_Loss:0.829607367515564

iterator 2200, D_Loss:1.374363899230957, G_Loss:0.834820032119751

iterator 2300, D_Loss:1.369728684425354, G_Loss:0.8674737811088562

iterator 2400, D_Loss:1.325605869293213, G_Loss:0.8545243144035339

iterator 2500, D_Loss:1.299781322479248, G_Loss:0.9275535345077515

iterator 2600, D_Loss:1.3120558261871338, G_Loss:0.8487517833709717

iterator 2700, D_Loss:1.279586911201477, G_Loss:0.9289466142654419

iterator 2800, D_Loss:1.2678391933441162, G_Loss:0.9413691163063049

iterator 2900, D_Loss:1.249396800994873, G_Loss:1.1149564981460571

iterator 3000, D_Loss:1.2304936647415161, G_Loss:1.132684350013733

iterator 3100, D_Loss:1.1327342987060547, G_Loss:1.1373894214630127

iterator 3200, D_Loss:1.0939491987228394, G_Loss:1.236761212348938

iterator 3300, D_Loss:1.311280369758606, G_Loss:1.3353183269500732

iterator 3400, D_Loss:1.0882495641708374, G_Loss:1.2970037460327148

iterator 3500, D_Loss:1.0642268657684326, G_Loss:1.4084935188293457

iterator 3600, D_Loss:1.0934486389160156, G_Loss:1.3985090255737305

iterator 3700, D_Loss:1.0340750217437744, G_Loss:1.5484803915023804

iterator 3800, D_Loss:0.9749289751052856, G_Loss:1.59975004196167

iterator 3900, D_Loss:0.8975728750228882, G_Loss:1.5417324304580688

iterator 4000, D_Loss:0.9302967190742493, G_Loss:1.7718627452850342

iterator 4100, D_Loss:0.9526119232177734, G_Loss:1.7197009325027466

iterator 4200, D_Loss:0.8911131620407104, G_Loss:1.7082895040512085

iterator 4300, D_Loss:0.904080867767334, G_Loss:1.4993685483932495

iterator 4400, D_Loss:1.5555453300476074, G_Loss:0.8433486223220825

iterator 4500, D_Loss:1.0311237573623657, G_Loss:1.7463035583496094

iterator 4600, D_Loss:0.921040952205658, G_Loss:1.3867918252944946

iterator 4700, D_Loss:1.179520845413208, G_Loss:1.369950532913208

iterator 4800, D_Loss:1.1038579940795898, G_Loss:0.9859155416488647

iterator 4900, D_Loss:0.9350239038467407, G_Loss:1.671162724494934

iterator 5000, D_Loss:0.8942258358001709, G_Loss:1.5720324516296387

-----------Epoch 1-----------
iterator 100, D_Loss:0.8562098145484924, G_Loss:1.7700456380844116

iterator 200, D_Loss:0.9880732893943787, G_Loss:2.066291570663452

iterator 300, D_Loss:0.8320356607437134, G_Loss:1.6576744318008423

iterator 400, D_Loss:1.0519853830337524, G_Loss:2.132685899734497

iterator 500, D_Loss:0.790751039981842, G_Loss:1.5367872714996338

iterator 600, D_Loss:0.929282546043396, G_Loss:1.788011074066162

iterator 700, D_Loss:0.8075584173202515, G_Loss:1.5488238334655762

iterator 800, D_Loss:0.8904617428779602, G_Loss:1.3055708408355713

iterator 900, D_Loss:1.129783034324646, G_Loss:1.3431174755096436

iterator 1000, D_Loss:0.9928345680236816, G_Loss:1.9818753004074097

iterator 1100, D_Loss:1.0777757167816162, G_Loss:1.4034247398376465

iterator 1200, D_Loss:1.3229649066925049, G_Loss:1.1689574718475342

iterator 1300, D_Loss:1.4653542041778564, G_Loss:0.7928380370140076

iterator 1400, D_Loss:1.083451509475708, G_Loss:1.1873652935028076

iterator 1500, D_Loss:1.0869168043136597, G_Loss:1.5859932899475098

iterator 1600, D_Loss:1.3632032871246338, G_Loss:1.7566511631011963

iterator 1700, D_Loss:1.119417667388916, G_Loss:1.7985986471176147

iterator 1800, D_Loss:0.667496383190155, G_Loss:1.9870983362197876

iterator 1900, D_Loss:1.2652411460876465, G_Loss:1.151963472366333

iterator 2000, D_Loss:1.1645784378051758, G_Loss:1.345758080482483

iterator 2100, D_Loss:1.2767070531845093, G_Loss:1.4289392232894897

iterator 2200, D_Loss:0.7600240707397461, G_Loss:1.5327259302139282

iterator 2300, D_Loss:0.7853390574455261, G_Loss:1.3816990852355957

iterator 2400, D_Loss:1.0303395986557007, G_Loss:1.7699127197265625

iterator 2500, D_Loss:0.8124340176582336, G_Loss:1.42197847366333

iterator 2600, D_Loss:0.958917498588562, G_Loss:1.7635681629180908

iterator 2700, D_Loss:0.8428005576133728, G_Loss:2.2791593074798584

iterator 2800, D_Loss:0.6344183683395386, G_Loss:1.4852045774459839

iterator 2900, D_Loss:0.7383393049240112, G_Loss:2.9122495651245117

iterator 3000, D_Loss:0.8838634490966797, G_Loss:2.890266180038452

iterator 3100, D_Loss:0.6376491189002991, G_Loss:2.784827947616577

iterator 3200, D_Loss:0.6850136518478394, G_Loss:2.930251121520996

iterator 3300, D_Loss:1.856808066368103, G_Loss:2.7377443313598633

iterator 3400, D_Loss:0.7580878734588623, G_Loss:2.5396039485931396

iterator 3500, D_Loss:0.5753377676010132, G_Loss:2.259770154953003

iterator 3600, D_Loss:0.5868893265724182, G_Loss:2.791600227355957

iterator 3700, D_Loss:0.5705774426460266, G_Loss:1.384406328201294

iterator 3800, D_Loss:0.547498345375061, G_Loss:3.111539602279663

iterator 3900, D_Loss:0.728476345539093, G_Loss:3.34769344329834

iterator 4000, D_Loss:0.597148597240448, G_Loss:1.832971453666687

iterator 4100, D_Loss:0.5940909385681152, G_Loss:2.5041091442108154

iterator 4200, D_Loss:0.7653161287307739, G_Loss:2.5126752853393555

iterator 4300, D_Loss:0.5229621529579163, G_Loss:3.4560904502868652

iterator 4400, D_Loss:0.5757454037666321, G_Loss:3.5217409133911133

iterator 4500, D_Loss:0.6428162455558777, G_Loss:3.2366156578063965

iterator 4600, D_Loss:0.5774335861206055, G_Loss:3.3473150730133057

iterator 4700, D_Loss:0.5001526474952698, G_Loss:3.563466787338257

iterator 4800, D_Loss:0.566068708896637, G_Loss:3.671907901763916

iterator 4900, D_Loss:0.5040619969367981, G_Loss:4.195622444152832

iterator 5000, D_Loss:0.5182697772979736, G_Loss:4.370391845703125

-----------Epoch 2-----------
iterator 100, D_Loss:0.5167800188064575, G_Loss:2.35976243019104

iterator 200, D_Loss:0.5762418508529663, G_Loss:3.3726084232330322

iterator 300, D_Loss:0.7460322380065918, G_Loss:3.2005865573883057

iterator 400, D_Loss:0.835332453250885, G_Loss:4.250228404998779

iterator 500, D_Loss:0.50680011510849, G_Loss:3.9516994953155518

iterator 600, D_Loss:0.5309922695159912, G_Loss:3.8674187660217285

iterator 700, D_Loss:0.521251916885376, G_Loss:3.6340179443359375

iterator 800, D_Loss:0.49604475498199463, G_Loss:4.243793964385986

iterator 900, D_Loss:0.555724024772644, G_Loss:4.087785720825195

iterator 1000, D_Loss:0.4880000948905945, G_Loss:3.6034135818481445

iterator 1100, D_Loss:0.49422687292099, G_Loss:4.821694374084473

iterator 1200, D_Loss:0.484986811876297, G_Loss:4.516016006469727

iterator 1300, D_Loss:0.5109308958053589, G_Loss:3.644200325012207

iterator 1400, D_Loss:0.5112634897232056, G_Loss:4.621170520782471

iterator 1500, D_Loss:0.5036147832870483, G_Loss:4.6030964851379395

iterator 1600, D_Loss:0.5566369295120239, G_Loss:4.7948455810546875

iterator 1700, D_Loss:0.45430973172187805, G_Loss:5.335205554962158

iterator 1800, D_Loss:0.4887581765651703, G_Loss:4.713705062866211

iterator 1900, D_Loss:0.491526335477829, G_Loss:4.101308822631836

iterator 2000, D_Loss:0.5320285558700562, G_Loss:4.030824661254883

iterator 2100, D_Loss:0.5194852948188782, G_Loss:4.268548011779785

iterator 2200, D_Loss:0.4609435200691223, G_Loss:4.478801727294922

iterator 2300, D_Loss:0.5242370963096619, G_Loss:4.266961574554443

iterator 2400, D_Loss:0.4660537540912628, G_Loss:4.485696315765381

iterator 2500, D_Loss:0.4798367917537689, G_Loss:5.754096031188965

iterator 2600, D_Loss:0.4598226547241211, G_Loss:4.638859272003174

iterator 2700, D_Loss:0.47173550724983215, G_Loss:5.7091217041015625

iterator 2800, D_Loss:0.5473695993423462, G_Loss:5.623318672180176

iterator 2900, D_Loss:0.5339087247848511, G_Loss:5.347149848937988

iterator 3000, D_Loss:0.4998718202114105, G_Loss:4.990294933319092

iterator 3100, D_Loss:0.4585246741771698, G_Loss:3.9644722938537598

iterator 3200, D_Loss:0.5030467510223389, G_Loss:5.834721565246582

iterator 3300, D_Loss:1.4301295280456543, G_Loss:5.0039873123168945

iterator 3400, D_Loss:0.47885310649871826, G_Loss:5.578112602233887

iterator 3500, D_Loss:0.4942493438720703, G_Loss:5.333817958831787

iterator 3600, D_Loss:0.4718964397907257, G_Loss:5.948399066925049

iterator 3700, D_Loss:0.4665415585041046, G_Loss:5.490478038787842

iterator 3800, D_Loss:0.47847530245780945, G_Loss:5.333840847015381

iterator 3900, D_Loss:0.4354846179485321, G_Loss:5.4327850341796875

iterator 4000, D_Loss:0.4650910198688507, G_Loss:5.010119438171387

iterator 4100, D_Loss:0.4677049517631531, G_Loss:5.1842241287231445

iterator 4200, D_Loss:0.48506882786750793, G_Loss:5.272334098815918

iterator 4300, D_Loss:0.46339941024780273, G_Loss:6.161977767944336

iterator 4400, D_Loss:0.48510169982910156, G_Loss:5.5424113273620605

iterator 4500, D_Loss:0.481269508600235, G_Loss:5.7014384269714355

iterator 4600, D_Loss:0.57090824842453, G_Loss:4.444876670837402

iterator 4700, D_Loss:0.5097985863685608, G_Loss:4.858100414276123

iterator 4800, D_Loss:0.46147847175598145, G_Loss:4.946338176727295

iterator 4900, D_Loss:0.4698880612850189, G_Loss:5.798689365386963

iterator 5000, D_Loss:0.4778173267841339, G_Loss:5.633523464202881

-----------Epoch 3-----------
iterator 100, D_Loss:0.45278945565223694, G_Loss:5.3390116691589355

iterator 200, D_Loss:0.5764711499214172, G_Loss:6.791399002075195

iterator 300, D_Loss:0.44593527913093567, G_Loss:4.771780490875244

iterator 400, D_Loss:0.5176568031311035, G_Loss:6.408384323120117

iterator 500, D_Loss:0.4822940230369568, G_Loss:7.486372470855713

iterator 600, D_Loss:0.4502975344657898, G_Loss:6.983701705932617

iterator 700, D_Loss:0.4543576240539551, G_Loss:7.6277337074279785

iterator 800, D_Loss:0.4482212960720062, G_Loss:6.915923595428467

iterator 900, D_Loss:0.46654343605041504, G_Loss:6.4161834716796875

iterator 1000, D_Loss:0.48248130083084106, G_Loss:6.065191745758057

iterator 1100, D_Loss:0.44003185629844666, G_Loss:6.596594333648682

iterator 1200, D_Loss:0.4527824819087982, G_Loss:5.997664928436279

iterator 1300, D_Loss:0.4421239495277405, G_Loss:6.532849311828613

iterator 1400, D_Loss:0.47662055492401123, G_Loss:5.404547214508057

iterator 1500, D_Loss:0.46958407759666443, G_Loss:4.891714572906494

iterator 1600, D_Loss:0.4745884835720062, G_Loss:5.023799419403076

iterator 1700, D_Loss:0.46397489309310913, G_Loss:5.627105712890625

iterator 1800, D_Loss:0.44906720519065857, G_Loss:6.428974151611328

iterator 1900, D_Loss:0.4462662935256958, G_Loss:6.334536075592041

iterator 2000, D_Loss:0.44785240292549133, G_Loss:6.170174598693848

iterator 2100, D_Loss:0.47474920749664307, G_Loss:5.877740383148193

iterator 2200, D_Loss:0.4444240927696228, G_Loss:6.3563232421875

iterator 2300, D_Loss:0.450564980506897, G_Loss:7.239072799682617

iterator 2400, D_Loss:0.46196699142456055, G_Loss:7.090454578399658

iterator 2500, D_Loss:0.4464603066444397, G_Loss:7.047863006591797

iterator 2600, D_Loss:0.4867625832557678, G_Loss:6.268111705780029

iterator 2700, D_Loss:0.44992873072624207, G_Loss:7.2392659187316895

iterator 2800, D_Loss:0.41300418972969055, G_Loss:7.610357761383057

iterator 2900, D_Loss:0.45981869101524353, G_Loss:7.5286149978637695

iterator 3000, D_Loss:0.4530314803123474, G_Loss:6.045609951019287

iterator 3100, D_Loss:0.4507714807987213, G_Loss:7.613877773284912

iterator 3200, D_Loss:0.4457777738571167, G_Loss:6.3445048332214355

iterator 3300, D_Loss:1.2588016986846924, G_Loss:5.126059532165527

iterator 3400, D_Loss:0.4711909294128418, G_Loss:6.07803201675415

iterator 3500, D_Loss:0.42967984080314636, G_Loss:6.501742362976074

iterator 3600, D_Loss:0.44780105352401733, G_Loss:7.385327339172363

iterator 3700, D_Loss:0.4467409551143646, G_Loss:7.215826034545898

iterator 3800, D_Loss:0.4396989643573761, G_Loss:7.820487022399902

iterator 3900, D_Loss:0.43433302640914917, G_Loss:7.564642429351807

iterator 4000, D_Loss:0.4047906994819641, G_Loss:6.992224216461182

iterator 4100, D_Loss:0.46038639545440674, G_Loss:6.932754039764404

iterator 4200, D_Loss:0.4810313284397125, G_Loss:8.363298416137695

iterator 4300, D_Loss:0.43680763244628906, G_Loss:6.4695844650268555

iterator 4400, D_Loss:0.4701746106147766, G_Loss:7.463862895965576

iterator 4500, D_Loss:0.43788081407546997, G_Loss:7.869727611541748

iterator 4600, D_Loss:0.4630568325519562, G_Loss:7.575437545776367

iterator 4700, D_Loss:0.43653586506843567, G_Loss:7.612386703491211

iterator 4800, D_Loss:0.45417168736457825, G_Loss:7.213133335113525

iterator 4900, D_Loss:0.4560031592845917, G_Loss:5.928025722503662

iterator 5000, D_Loss:0.4526961147785187, G_Loss:7.2599778175354

-----------Epoch 4-----------
iterator 100, D_Loss:0.5174534320831299, G_Loss:8.339521408081055

iterator 200, D_Loss:1.0495662689208984, G_Loss:5.941093921661377

iterator 300, D_Loss:0.43767234683036804, G_Loss:8.146326065063477

iterator 400, D_Loss:0.48010504245758057, G_Loss:7.6651201248168945

iterator 500, D_Loss:0.4513965845108032, G_Loss:8.195236206054688

iterator 600, D_Loss:0.40961626172065735, G_Loss:8.623260498046875

iterator 700, D_Loss:0.42564457654953003, G_Loss:8.266077041625977

iterator 800, D_Loss:0.47329258918762207, G_Loss:8.515275001525879

iterator 900, D_Loss:0.4465090334415436, G_Loss:6.894935131072998

iterator 1000, D_Loss:0.41967472434043884, G_Loss:7.7734808921813965

iterator 1100, D_Loss:0.432762086391449, G_Loss:9.252243995666504

iterator 1200, D_Loss:0.46020030975341797, G_Loss:8.068586349487305

iterator 1300, D_Loss:0.4696665108203888, G_Loss:8.299845695495605

iterator 1400, D_Loss:0.4290405213832855, G_Loss:7.293740749359131

iterator 1500, D_Loss:0.450025737285614, G_Loss:8.327706336975098

iterator 1600, D_Loss:0.4413905441761017, G_Loss:6.584941387176514

iterator 1700, D_Loss:0.42195186018943787, G_Loss:8.147263526916504

iterator 1800, D_Loss:0.43308475613594055, G_Loss:7.5396952629089355

iterator 1900, D_Loss:0.4432356059551239, G_Loss:6.704818248748779

iterator 2000, D_Loss:0.41658613085746765, G_Loss:7.697847366333008

iterator 2100, D_Loss:0.41807714104652405, G_Loss:8.174217224121094

iterator 2200, D_Loss:0.4257604479789734, G_Loss:7.622610569000244

iterator 2300, D_Loss:0.4505116045475006, G_Loss:8.242056846618652

iterator 2400, D_Loss:0.42153871059417725, G_Loss:7.442197799682617

iterator 2500, D_Loss:0.4534456729888916, G_Loss:8.368398666381836

iterator 2600, D_Loss:0.43213221430778503, G_Loss:8.531949043273926

iterator 2700, D_Loss:0.4520197808742523, G_Loss:7.982888221740723

iterator 2800, D_Loss:0.4254430830478668, G_Loss:7.760690212249756

iterator 2900, D_Loss:0.4463336169719696, G_Loss:9.344369888305664

iterator 3000, D_Loss:0.43178504705429077, G_Loss:8.594217300415039

iterator 3100, D_Loss:0.4759621024131775, G_Loss:8.252046585083008

iterator 3200, D_Loss:0.40671369433403015, G_Loss:8.821686744689941

iterator 3300, D_Loss:0.43627458810806274, G_Loss:8.808712005615234

iterator 3400, D_Loss:0.41798606514930725, G_Loss:6.912023544311523

iterator 3500, D_Loss:0.4558540880680084, G_Loss:8.970881462097168

iterator 3600, D_Loss:0.43951496481895447, G_Loss:7.393110752105713

iterator 3700, D_Loss:0.45499321818351746, G_Loss:7.306721210479736

iterator 3800, D_Loss:0.4385563135147095, G_Loss:8.883009910583496

iterator 3900, D_Loss:0.47912880778312683, G_Loss:8.243118286132812

iterator 4000, D_Loss:0.4109530746936798, G_Loss:8.99706745147705

iterator 4100, D_Loss:0.43324801325798035, G_Loss:8.284533500671387

iterator 4200, D_Loss:0.4230317771434784, G_Loss:9.320110321044922

iterator 4300, D_Loss:0.4331953823566437, G_Loss:4.864927768707275

iterator 4400, D_Loss:0.4439827799797058, G_Loss:8.701460838317871

iterator 4500, D_Loss:0.43324023485183716, G_Loss:9.472784996032715

iterator 4600, D_Loss:0.4164672791957855, G_Loss:8.5570650100708

iterator 4700, D_Loss:0.4274413585662842, G_Loss:9.042202949523926

iterator 4800, D_Loss:0.432196706533432, G_Loss:9.23916244506836

iterator 4900, D_Loss:0.4331272542476654, G_Loss:9.342516899108887

iterator 5000, D_Loss:0.4031124413013458, G_Loss:9.60757827758789

-----------Epoch 5-----------
iterator 100, D_Loss:0.4834352135658264, G_Loss:9.014742851257324

iterator 200, D_Loss:1.462835669517517, G_Loss:7.452979564666748

iterator 300, D_Loss:0.4644944965839386, G_Loss:8.57386589050293

iterator 400, D_Loss:0.5059848427772522, G_Loss:8.894756317138672

iterator 500, D_Loss:0.43287378549575806, G_Loss:7.042693614959717

iterator 600, D_Loss:0.44895076751708984, G_Loss:11.86816120147705

iterator 700, D_Loss:0.45164328813552856, G_Loss:9.60457992553711

iterator 800, D_Loss:0.43997272849082947, G_Loss:8.664424896240234

iterator 900, D_Loss:0.4453383684158325, G_Loss:9.087677955627441

iterator 1000, D_Loss:0.4401003122329712, G_Loss:8.152902603149414

iterator 1100, D_Loss:0.46300798654556274, G_Loss:8.828465461730957

iterator 1200, D_Loss:0.43634480237960815, G_Loss:8.363987922668457

iterator 1300, D_Loss:0.4817650318145752, G_Loss:9.265451431274414

iterator 1400, D_Loss:0.4356676936149597, G_Loss:9.244319915771484

iterator 1500, D_Loss:0.4348585307598114, G_Loss:9.626335144042969

iterator 1600, D_Loss:0.418239951133728, G_Loss:10.616264343261719

iterator 1700, D_Loss:0.444784015417099, G_Loss:9.328961372375488

iterator 1800, D_Loss:0.45295560359954834, G_Loss:8.677035331726074

iterator 1900, D_Loss:0.4287618100643158, G_Loss:8.580713272094727

iterator 2000, D_Loss:0.42295464873313904, G_Loss:8.009955406188965

iterator 2100, D_Loss:0.44821563363075256, G_Loss:8.455412864685059

iterator 2200, D_Loss:0.4294593930244446, G_Loss:10.055895805358887

iterator 2300, D_Loss:0.4487546384334564, G_Loss:8.400369644165039

iterator 2400, D_Loss:0.41536206007003784, G_Loss:9.840770721435547

iterator 2500, D_Loss:0.4193746745586395, G_Loss:9.892254829406738

iterator 2600, D_Loss:0.4131033718585968, G_Loss:9.078765869140625

iterator 2700, D_Loss:0.42600828409194946, G_Loss:8.140986442565918

iterator 2800, D_Loss:0.4389100968837738, G_Loss:8.45728588104248

iterator 2900, D_Loss:0.45290058851242065, G_Loss:9.646485328674316

iterator 3000, D_Loss:0.452912837266922, G_Loss:9.61977767944336

iterator 3100, D_Loss:0.4404735863208771, G_Loss:7.279901027679443

iterator 3200, D_Loss:0.43650713562965393, G_Loss:9.171936988830566

iterator 3300, D_Loss:0.7603769898414612, G_Loss:7.49500846862793

iterator 3400, D_Loss:0.5202413201332092, G_Loss:8.33265209197998

iterator 3500, D_Loss:0.4583251476287842, G_Loss:7.445619583129883

iterator 3600, D_Loss:0.4694375693798065, G_Loss:7.061558723449707

iterator 3700, D_Loss:0.46061959862709045, G_Loss:8.28974723815918

iterator 3800, D_Loss:0.43729040026664734, G_Loss:10.794931411743164

iterator 3900, D_Loss:0.4326551854610443, G_Loss:8.838235855102539

iterator 4000, D_Loss:0.43869549036026, G_Loss:11.8861083984375

iterator 4100, D_Loss:0.4218606650829315, G_Loss:10.845590591430664

iterator 4200, D_Loss:0.43678516149520874, G_Loss:10.1763334274292

iterator 4300, D_Loss:0.4655097424983978, G_Loss:8.597369194030762

iterator 4400, D_Loss:0.43366900086402893, G_Loss:9.11711311340332

iterator 4500, D_Loss:0.4751659333705902, G_Loss:8.912698745727539

iterator 4600, D_Loss:0.4504905343055725, G_Loss:9.135191917419434

iterator 4700, D_Loss:0.4216066300868988, G_Loss:6.561341762542725

iterator 4800, D_Loss:0.47339916229248047, G_Loss:7.442416191101074

iterator 4900, D_Loss:0.4713689982891083, G_Loss:8.239656448364258

iterator 5000, D_Loss:0.4257517158985138, G_Loss:9.904108047485352

-----------Epoch 6-----------
iterator 100, D_Loss:0.44433149695396423, G_Loss:5.418857574462891

iterator 200, D_Loss:0.4319092333316803, G_Loss:6.612235069274902

iterator 300, D_Loss:0.5259504318237305, G_Loss:9.122176170349121

iterator 400, D_Loss:0.510576605796814, G_Loss:7.4161810874938965

iterator 500, D_Loss:0.42767882347106934, G_Loss:9.7130126953125

iterator 600, D_Loss:0.4187334477901459, G_Loss:9.514810562133789

iterator 700, D_Loss:0.4479159712791443, G_Loss:10.461119651794434

iterator 800, D_Loss:0.43736255168914795, G_Loss:8.913579940795898

iterator 900, D_Loss:0.4417872428894043, G_Loss:8.30843734741211

iterator 1000, D_Loss:0.4098598062992096, G_Loss:9.905327796936035

iterator 1100, D_Loss:0.43655645847320557, G_Loss:10.07291316986084

iterator 1200, D_Loss:0.4463217556476593, G_Loss:10.348299980163574

iterator 1300, D_Loss:0.40973448753356934, G_Loss:10.1336030960083

iterator 1400, D_Loss:0.43747562170028687, G_Loss:9.932938575744629

iterator 1500, D_Loss:0.4302414655685425, G_Loss:9.384411811828613

iterator 1600, D_Loss:0.43834009766578674, G_Loss:10.006397247314453

iterator 1700, D_Loss:0.4136650562286377, G_Loss:10.21663761138916

iterator 1800, D_Loss:0.40930572152137756, G_Loss:10.146836280822754

iterator 1900, D_Loss:0.4524904489517212, G_Loss:9.91354751586914

iterator 2000, D_Loss:0.441768616437912, G_Loss:10.700077056884766

iterator 2100, D_Loss:0.4378834366798401, G_Loss:11.493494033813477

iterator 2200, D_Loss:0.44168633222579956, G_Loss:11.337815284729004

iterator 2300, D_Loss:0.45089665055274963, G_Loss:11.481380462646484

iterator 2400, D_Loss:0.4170231819152832, G_Loss:11.476144790649414

iterator 2500, D_Loss:0.40949031710624695, G_Loss:10.85226821899414

iterator 2600, D_Loss:0.4125768542289734, G_Loss:9.68221664428711

iterator 2700, D_Loss:0.3990691304206848, G_Loss:10.859720230102539

iterator 2800, D_Loss:0.4322546720504761, G_Loss:10.654624938964844

iterator 2900, D_Loss:0.44680339097976685, G_Loss:10.341657638549805

iterator 3000, D_Loss:0.4457136392593384, G_Loss:10.653212547302246

iterator 3100, D_Loss:0.4007456302642822, G_Loss:8.762262344360352

iterator 3200, D_Loss:0.4335573613643646, G_Loss:11.359421730041504

iterator 3300, D_Loss:0.4693566858768463, G_Loss:11.586467742919922

iterator 3400, D_Loss:0.4347841441631317, G_Loss:12.440138816833496

iterator 3500, D_Loss:0.4152267575263977, G_Loss:10.782598495483398

iterator 3600, D_Loss:0.44474905729293823, G_Loss:10.405433654785156

iterator 3700, D_Loss:0.4169408082962036, G_Loss:10.10538387298584

iterator 3800, D_Loss:0.4293743073940277, G_Loss:10.467877388000488

iterator 3900, D_Loss:0.43305379152297974, G_Loss:11.015364646911621

iterator 4000, D_Loss:0.40741196274757385, G_Loss:10.971047401428223

iterator 4100, D_Loss:0.4260841906070709, G_Loss:11.0007905960083

iterator 4200, D_Loss:0.40592169761657715, G_Loss:10.021622657775879

iterator 4300, D_Loss:0.41778063774108887, G_Loss:10.481571197509766

iterator 4400, D_Loss:0.43370145559310913, G_Loss:9.66639518737793

iterator 4500, D_Loss:0.42521047592163086, G_Loss:9.05471420288086

iterator 4600, D_Loss:0.45710596442222595, G_Loss:8.734970092773438

iterator 4700, D_Loss:0.4383305609226227, G_Loss:11.66370964050293

iterator 4800, D_Loss:0.4277609884738922, G_Loss:11.138930320739746

iterator 4900, D_Loss:0.46698179841041565, G_Loss:10.722046852111816

iterator 5000, D_Loss:0.4271436631679535, G_Loss:9.040901184082031

-----------Epoch 7-----------
iterator 100, D_Loss:0.43509310483932495, G_Loss:10.902750015258789

iterator 200, D_Loss:0.4270104467868805, G_Loss:13.306894302368164

iterator 300, D_Loss:0.41806480288505554, G_Loss:8.923954010009766

iterator 400, D_Loss:0.4118814170360565, G_Loss:11.44764518737793

iterator 500, D_Loss:0.4223076105117798, G_Loss:14.580414772033691

iterator 600, D_Loss:0.4401744306087494, G_Loss:11.650287628173828

iterator 700, D_Loss:0.4537065327167511, G_Loss:13.87309455871582

iterator 800, D_Loss:0.4323679804801941, G_Loss:11.90855598449707

iterator 900, D_Loss:0.42263370752334595, G_Loss:13.13025188446045

iterator 1000, D_Loss:0.4249384105205536, G_Loss:11.990294456481934

iterator 1100, D_Loss:0.4422772526741028, G_Loss:12.528292655944824

iterator 1200, D_Loss:0.45031997561454773, G_Loss:12.742539405822754

iterator 1300, D_Loss:0.42685315012931824, G_Loss:13.22368049621582

iterator 1400, D_Loss:0.41750288009643555, G_Loss:11.140135765075684

iterator 1500, D_Loss:0.41701018810272217, G_Loss:10.932783126831055

iterator 1600, D_Loss:0.42351987957954407, G_Loss:12.120197296142578

iterator 1700, D_Loss:0.41839203238487244, G_Loss:11.421948432922363

iterator 1800, D_Loss:0.4221537113189697, G_Loss:12.577115058898926

iterator 1900, D_Loss:0.43042874336242676, G_Loss:11.015796661376953

iterator 2000, D_Loss:0.40875959396362305, G_Loss:10.144601821899414

iterator 2100, D_Loss:0.41422006487846375, G_Loss:11.995265007019043

iterator 2200, D_Loss:0.4465843141078949, G_Loss:12.316619873046875

iterator 2300, D_Loss:0.4350765645503998, G_Loss:12.410981178283691

iterator 2400, D_Loss:0.445565402507782, G_Loss:11.147992134094238

iterator 2500, D_Loss:0.43073949217796326, G_Loss:11.610482215881348

iterator 2600, D_Loss:0.4249948263168335, G_Loss:12.454148292541504

iterator 2700, D_Loss:0.4212992191314697, G_Loss:12.25145149230957

iterator 2800, D_Loss:0.4323713183403015, G_Loss:12.722794532775879

iterator 2900, D_Loss:0.41051071882247925, G_Loss:13.007694244384766

iterator 3000, D_Loss:0.41861316561698914, G_Loss:12.953011512756348

iterator 3100, D_Loss:0.43195343017578125, G_Loss:12.322929382324219

iterator 3200, D_Loss:0.42961522936820984, G_Loss:12.036689758300781

iterator 3300, D_Loss:0.6152532696723938, G_Loss:13.214630126953125

iterator 3400, D_Loss:0.4002339243888855, G_Loss:11.324250221252441

iterator 3500, D_Loss:0.44023531675338745, G_Loss:11.692540168762207

iterator 3600, D_Loss:0.4344356656074524, G_Loss:12.161423683166504

iterator 3700, D_Loss:0.45312175154685974, G_Loss:11.85557746887207

iterator 3800, D_Loss:0.42821016907691956, G_Loss:13.277260780334473

iterator 3900, D_Loss:0.4523460865020752, G_Loss:13.425410270690918

iterator 4000, D_Loss:0.4484739303588867, G_Loss:13.778486251831055

iterator 4100, D_Loss:0.4352666735649109, G_Loss:10.194724082946777

iterator 4200, D_Loss:0.4446379840373993, G_Loss:12.435402870178223

iterator 4300, D_Loss:0.4442918598651886, G_Loss:10.3340482711792

iterator 4400, D_Loss:0.46571114659309387, G_Loss:12.634464263916016

iterator 4500, D_Loss:0.41664257645606995, G_Loss:12.278895378112793

iterator 4600, D_Loss:0.4320219159126282, G_Loss:11.164205551147461

iterator 4700, D_Loss:0.4426737129688263, G_Loss:10.482304573059082

iterator 4800, D_Loss:0.4626257121562958, G_Loss:7.5624566078186035

iterator 4900, D_Loss:0.4644421339035034, G_Loss:9.272313117980957

iterator 5000, D_Loss:0.4191400706768036, G_Loss:10.109549522399902

-----------Epoch 8-----------
iterator 100, D_Loss:0.4521101117134094, G_Loss:10.198885917663574

iterator 200, D_Loss:0.4412832260131836, G_Loss:10.16861343383789

iterator 300, D_Loss:0.42496737837791443, G_Loss:10.582741737365723

iterator 400, D_Loss:0.4240310788154602, G_Loss:1.7364720106124878

iterator 500, D_Loss:0.46746042370796204, G_Loss:11.67773723602295

iterator 600, D_Loss:0.42428407073020935, G_Loss:12.476134300231934

iterator 700, D_Loss:0.42785900831222534, G_Loss:10.215873718261719

iterator 800, D_Loss:0.43442636728286743, G_Loss:11.415836334228516

iterator 900, D_Loss:0.4454919099807739, G_Loss:10.84290885925293

iterator 1000, D_Loss:0.4302598834037781, G_Loss:9.199864387512207

iterator 1100, D_Loss:0.4047214388847351, G_Loss:10.258650779724121

iterator 1200, D_Loss:0.45927852392196655, G_Loss:10.748446464538574

iterator 1300, D_Loss:0.45951783657073975, G_Loss:11.670197486877441

iterator 1400, D_Loss:0.4100497364997864, G_Loss:11.525970458984375

iterator 1500, D_Loss:0.4200250208377838, G_Loss:10.218718528747559

iterator 1600, D_Loss:0.42706188559532166, G_Loss:13.067426681518555

iterator 1700, D_Loss:0.45171409845352173, G_Loss:12.237361907958984

iterator 1800, D_Loss:0.4146500527858734, G_Loss:10.791435241699219

iterator 1900, D_Loss:0.4219912588596344, G_Loss:11.788407325744629

iterator 2000, D_Loss:0.4286697506904602, G_Loss:10.319304466247559

iterator 2100, D_Loss:0.40680816769599915, G_Loss:11.519268035888672

iterator 2200, D_Loss:0.4492931365966797, G_Loss:11.879559516906738

iterator 2300, D_Loss:0.4388921856880188, G_Loss:12.676623344421387

iterator 2400, D_Loss:0.43150943517684937, G_Loss:11.321854591369629

iterator 2500, D_Loss:0.4397068917751312, G_Loss:11.983508110046387

iterator 2600, D_Loss:0.4052824079990387, G_Loss:11.551098823547363

iterator 2700, D_Loss:0.4087197482585907, G_Loss:11.295622825622559

iterator 2800, D_Loss:0.4259348511695862, G_Loss:12.62153434753418

iterator 2900, D_Loss:0.43802422285079956, G_Loss:11.686258316040039

iterator 3000, D_Loss:0.4152870178222656, G_Loss:13.330941200256348

iterator 3100, D_Loss:0.4174419045448303, G_Loss:13.957688331604004

iterator 3200, D_Loss:0.4235590994358063, G_Loss:13.64468765258789

iterator 3300, D_Loss:0.47175803780555725, G_Loss:13.74172592163086

iterator 3400, D_Loss:0.4225800037384033, G_Loss:12.66584587097168

iterator 3500, D_Loss:0.4236127734184265, G_Loss:13.092052459716797

iterator 3600, D_Loss:0.4303463399410248, G_Loss:11.970549583435059

iterator 3700, D_Loss:0.4322907626628876, G_Loss:12.551383018493652

iterator 3800, D_Loss:0.43226826190948486, G_Loss:11.886792182922363

iterator 3900, D_Loss:0.4089907705783844, G_Loss:13.230365753173828

iterator 4000, D_Loss:0.45134398341178894, G_Loss:12.437169075012207

iterator 4100, D_Loss:0.4403478801250458, G_Loss:12.145986557006836

iterator 4200, D_Loss:0.4273695647716522, G_Loss:11.545618057250977

iterator 4300, D_Loss:0.42050257325172424, G_Loss:13.78106689453125

iterator 4400, D_Loss:0.4272342920303345, G_Loss:11.950796127319336

iterator 4500, D_Loss:0.43160995841026306, G_Loss:12.30774211883545

iterator 4600, D_Loss:0.4319453835487366, G_Loss:13.977311134338379

iterator 4700, D_Loss:0.435234397649765, G_Loss:12.825159072875977

iterator 4800, D_Loss:0.4003284275531769, G_Loss:13.821045875549316

iterator 4900, D_Loss:0.42772457003593445, G_Loss:12.847994804382324

iterator 5000, D_Loss:0.44802528619766235, G_Loss:12.49513053894043

-----------Epoch 9-----------
iterator 100, D_Loss:0.40936732292175293, G_Loss:13.63105583190918

iterator 200, D_Loss:0.4471290409564972, G_Loss:12.711438179016113

iterator 300, D_Loss:0.40750613808631897, G_Loss:14.134272575378418

iterator 400, D_Loss:0.4143659472465515, G_Loss:12.433448791503906

iterator 500, D_Loss:0.4166269302368164, G_Loss:12.03233528137207

iterator 600, D_Loss:0.43976327776908875, G_Loss:13.181279182434082

iterator 700, D_Loss:0.4241657853126526, G_Loss:10.851361274719238

iterator 800, D_Loss:0.41157692670822144, G_Loss:14.564020156860352

iterator 900, D_Loss:0.4505707025527954, G_Loss:12.404854774475098

iterator 1000, D_Loss:0.41828683018684387, G_Loss:11.899571418762207

iterator 1100, D_Loss:0.4255213737487793, G_Loss:12.505821228027344

iterator 1200, D_Loss:0.42438334226608276, G_Loss:11.678813934326172

iterator 1300, D_Loss:0.4255538582801819, G_Loss:11.530810356140137

iterator 1400, D_Loss:0.4247139096260071, G_Loss:8.910787582397461

iterator 1500, D_Loss:0.4437403082847595, G_Loss:12.568378448486328

iterator 1600, D_Loss:0.4318132996559143, G_Loss:11.97895622253418

iterator 1700, D_Loss:0.42405232787132263, G_Loss:12.919934272766113

iterator 1800, D_Loss:0.4374435245990753, G_Loss:12.571920394897461

iterator 1900, D_Loss:0.42027658224105835, G_Loss:12.539443016052246

iterator 2000, D_Loss:0.43636244535446167, G_Loss:11.668682098388672

iterator 2100, D_Loss:0.423734575510025, G_Loss:11.869518280029297

iterator 2200, D_Loss:0.4090641736984253, G_Loss:12.612171173095703

iterator 2300, D_Loss:0.43011510372161865, G_Loss:12.829920768737793

iterator 2400, D_Loss:0.4241221249103546, G_Loss:12.33439826965332

iterator 2500, D_Loss:0.4383479654788971, G_Loss:12.280097961425781

iterator 2600, D_Loss:0.4176080822944641, G_Loss:11.2846040725708

iterator 2700, D_Loss:0.45034894347190857, G_Loss:11.182845115661621

iterator 2800, D_Loss:0.4416550099849701, G_Loss:11.376840591430664

iterator 2900, D_Loss:0.4415363371372223, G_Loss:13.830348014831543

iterator 3000, D_Loss:0.44640639424324036, G_Loss:11.562212944030762

iterator 3100, D_Loss:0.4471486806869507, G_Loss:10.687030792236328

iterator 3200, D_Loss:0.41655752062797546, G_Loss:11.831068992614746

iterator 3300, D_Loss:0.5837727785110474, G_Loss:12.147770881652832

iterator 3400, D_Loss:0.41547155380249023, G_Loss:11.385136604309082

iterator 3500, D_Loss:0.4246101379394531, G_Loss:11.418465614318848

iterator 3600, D_Loss:0.4597022235393524, G_Loss:12.066201210021973

iterator 3700, D_Loss:0.46340516209602356, G_Loss:10.904723167419434

iterator 3800, D_Loss:0.4389277994632721, G_Loss:11.515641212463379

iterator 3900, D_Loss:0.41355979442596436, G_Loss:11.246769905090332

iterator 4000, D_Loss:0.4253239333629608, G_Loss:12.353775978088379

iterator 4100, D_Loss:0.4094138443470001, G_Loss:10.53886604309082

iterator 4200, D_Loss:0.4406745135784149, G_Loss:11.264853477478027

iterator 4300, D_Loss:0.44040924310684204, G_Loss:10.785229682922363

iterator 4400, D_Loss:0.455644816160202, G_Loss:11.473433494567871

iterator 4500, D_Loss:0.43596941232681274, G_Loss:10.062350273132324

iterator 4600, D_Loss:0.4072796106338501, G_Loss:11.381233215332031

iterator 4700, D_Loss:0.4179787337779999, G_Loss:11.877860069274902

iterator 4800, D_Loss:0.42540353536605835, G_Loss:11.328627586364746

iterator 4900, D_Loss:0.42272457480430603, G_Loss:9.597363471984863

iterator 5000, D_Loss:0.45217081904411316, G_Loss:12.933123588562012

train row : 30148
sample row: 30148
LGAN_generator(
  (LSTM): LSTMCell(402, 100)
  (gmfc00): Linear(in_features=200, out_features=1, bias=True)
  (gmfc01): Linear(in_features=200, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=200, bias=True)
  (gmfe00): Linear(in_features=100, out_features=200, bias=True)
  (gmfe01): Linear(in_features=100, out_features=200, bias=True)
  (fc10): Linear(in_features=200, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=200, bias=True)
  (fe1): Linear(in_features=100, out_features=200, bias=True)
  (gmfc20): Linear(in_features=200, out_features=1, bias=True)
  (gmfc21): Linear(in_features=200, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=200, bias=True)
  (gmfe20): Linear(in_features=100, out_features=200, bias=True)
  (gmfe21): Linear(in_features=100, out_features=200, bias=True)
  (fc30): Linear(in_features=200, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=200, bias=True)
  (fe3): Linear(in_features=100, out_features=200, bias=True)
  (gmfc40): Linear(in_features=200, out_features=1, bias=True)
  (gmfc41): Linear(in_features=200, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=200, bias=True)
  (gmfe40): Linear(in_features=100, out_features=200, bias=True)
  (gmfe41): Linear(in_features=100, out_features=200, bias=True)
  (fc50): Linear(in_features=200, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=200, bias=True)
  (fe5): Linear(in_features=100, out_features=200, bias=True)
  (fc60): Linear(in_features=200, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=200, bias=True)
  (fe6): Linear(in_features=100, out_features=200, bias=True)
  (fc70): Linear(in_features=200, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=200, bias=True)
  (fe7): Linear(in_features=100, out_features=200, bias=True)
  (fc80): Linear(in_features=200, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=200, bias=True)
  (fe8): Linear(in_features=100, out_features=200, bias=True)
  (fc90): Linear(in_features=200, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=200, bias=True)
  (fe9): Linear(in_features=100, out_features=200, bias=True)
  (gmfc100): Linear(in_features=200, out_features=1, bias=True)
  (gmfc101): Linear(in_features=200, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=200, bias=True)
  (gmfe100): Linear(in_features=100, out_features=200, bias=True)
  (gmfe101): Linear(in_features=100, out_features=200, bias=True)
  (gmfc110): Linear(in_features=200, out_features=1, bias=True)
  (gmfc111): Linear(in_features=200, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=200, bias=True)
  (gmfe110): Linear(in_features=100, out_features=200, bias=True)
  (gmfe111): Linear(in_features=100, out_features=200, bias=True)
  (gmfc120): Linear(in_features=200, out_features=1, bias=True)
  (gmfc121): Linear(in_features=200, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=200, bias=True)
  (gmfe120): Linear(in_features=100, out_features=200, bias=True)
  (gmfe121): Linear(in_features=100, out_features=200, bias=True)
  (fc130): Linear(in_features=200, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=200, bias=True)
  (fe13): Linear(in_features=100, out_features=200, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=100, bias=True)
  (inputbn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=100, out_features=100, bias=True)
  (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=100, out_features=100, bias=True)
  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=100, out_features=100, bias=True)
  (bn3): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=100, out_features=1, bias=True)
)
(2, True, 133)
(30148, 2)
-----------Epoch 0-----------
iterator 0, D_Loss:1.4532897472381592, G_Loss:13.32984447479248

iterator 100, D_Loss:1.3964014053344727, G_Loss:1.7617123126983643

iterator 200, D_Loss:1.3706594705581665, G_Loss:1.4959046840667725

iterator 300, D_Loss:1.3779072761535645, G_Loss:1.580679178237915

iterator 400, D_Loss:1.391062617301941, G_Loss:1.1796941757202148

iterator 500, D_Loss:1.3833712339401245, G_Loss:1.0381428003311157

iterator 600, D_Loss:1.3577454090118408, G_Loss:0.9747720956802368

iterator 700, D_Loss:1.361480712890625, G_Loss:0.9443444013595581

iterator 800, D_Loss:1.3638789653778076, G_Loss:0.9580855965614319

iterator 900, D_Loss:1.350208044052124, G_Loss:0.9629808664321899

iterator 1000, D_Loss:1.3644492626190186, G_Loss:0.9732345342636108

iterator 1100, D_Loss:1.3388216495513916, G_Loss:1.006913185119629

iterator 1200, D_Loss:1.350966215133667, G_Loss:1.0131586790084839

iterator 1300, D_Loss:1.3552274703979492, G_Loss:0.9452303647994995

iterator 1400, D_Loss:1.2969753742218018, G_Loss:1.0343390703201294

iterator 1500, D_Loss:1.245180606842041, G_Loss:1.2010471820831299

iterator 1600, D_Loss:1.1936511993408203, G_Loss:1.3412495851516724

iterator 1700, D_Loss:1.315484881401062, G_Loss:1.2099987268447876

iterator 1800, D_Loss:1.1390892267227173, G_Loss:1.201094150543213

iterator 1900, D_Loss:1.213760256767273, G_Loss:0.9584944248199463

iterator 2000, D_Loss:1.0699056386947632, G_Loss:1.3356174230575562

iterator 2100, D_Loss:1.2179034948349, G_Loss:1.3857141733169556

iterator 2200, D_Loss:1.1202651262283325, G_Loss:1.092054009437561

iterator 2300, D_Loss:1.3486253023147583, G_Loss:1.2982906103134155

iterator 2400, D_Loss:1.4515905380249023, G_Loss:0.7934404015541077

iterator 2500, D_Loss:1.3680740594863892, G_Loss:1.41171395778656

iterator 2600, D_Loss:1.2906882762908936, G_Loss:0.8474664092063904

iterator 2700, D_Loss:1.2615256309509277, G_Loss:1.239013910293579

iterator 2800, D_Loss:1.2931902408599854, G_Loss:1.4915955066680908

iterator 2900, D_Loss:1.266097903251648, G_Loss:1.0587928295135498

iterator 3000, D_Loss:1.183800220489502, G_Loss:0.920335054397583

iterator 3100, D_Loss:1.1829962730407715, G_Loss:1.7948684692382812

iterator 3200, D_Loss:0.9745184183120728, G_Loss:1.4116621017456055

iterator 3300, D_Loss:0.9454147219657898, G_Loss:1.8857271671295166

iterator 3400, D_Loss:0.9083025455474854, G_Loss:1.162460207939148

iterator 3500, D_Loss:0.7914872169494629, G_Loss:2.189255714416504

iterator 3600, D_Loss:0.7615750432014465, G_Loss:1.8688645362854004

iterator 3700, D_Loss:0.9377005100250244, G_Loss:2.45573353767395

iterator 3800, D_Loss:0.79115891456604, G_Loss:2.6456634998321533

iterator 3900, D_Loss:0.731081485748291, G_Loss:2.703188896179199

iterator 4000, D_Loss:0.7942337989807129, G_Loss:3.7526419162750244

iterator 4100, D_Loss:0.6403429508209229, G_Loss:3.4577994346618652

iterator 4200, D_Loss:0.6599757075309753, G_Loss:3.701706647872925

iterator 4300, D_Loss:0.70653235912323, G_Loss:4.019824504852295

iterator 4400, D_Loss:0.5981895327568054, G_Loss:3.984074354171753

iterator 4500, D_Loss:0.5806961059570312, G_Loss:3.621643543243408

iterator 4600, D_Loss:0.6217759847640991, G_Loss:3.669832706451416

iterator 4700, D_Loss:1.586162805557251, G_Loss:0.876697838306427

iterator 4800, D_Loss:0.6350951790809631, G_Loss:4.035494327545166

iterator 4900, D_Loss:0.5958208441734314, G_Loss:2.6248676776885986

-----------Epoch 1-----------
iterator 0, D_Loss:0.685990571975708, G_Loss:2.6786489486694336

iterator 100, D_Loss:0.619367241859436, G_Loss:3.4539577960968018

iterator 200, D_Loss:0.8455445766448975, G_Loss:3.8789877891540527

iterator 300, D_Loss:0.5776947736740112, G_Loss:3.9050278663635254

iterator 400, D_Loss:0.6128984689712524, G_Loss:4.291102409362793

iterator 500, D_Loss:0.5784984827041626, G_Loss:4.531003475189209

iterator 600, D_Loss:0.583613932132721, G_Loss:4.0096025466918945

iterator 700, D_Loss:0.594880223274231, G_Loss:3.369224786758423

iterator 800, D_Loss:0.5596319437026978, G_Loss:4.510982513427734

iterator 900, D_Loss:0.5559306740760803, G_Loss:4.208689212799072

iterator 1000, D_Loss:0.5684021711349487, G_Loss:4.315190315246582

iterator 1100, D_Loss:0.5479574203491211, G_Loss:4.639476776123047

iterator 1200, D_Loss:0.5503931641578674, G_Loss:5.434913158416748

iterator 1300, D_Loss:0.5290024876594543, G_Loss:5.624201774597168

iterator 1400, D_Loss:0.49504995346069336, G_Loss:5.104852199554443

iterator 1500, D_Loss:0.536248505115509, G_Loss:5.981171131134033

iterator 1600, D_Loss:0.5163689851760864, G_Loss:3.171287775039673

iterator 1700, D_Loss:0.5465265512466431, G_Loss:6.113759994506836

iterator 1800, D_Loss:0.5027378797531128, G_Loss:5.268004417419434

iterator 1900, D_Loss:0.5156750679016113, G_Loss:5.926634788513184

iterator 2000, D_Loss:0.5084742307662964, G_Loss:5.849119663238525

iterator 2100, D_Loss:0.4986336827278137, G_Loss:5.624195098876953

iterator 2200, D_Loss:0.48345503211021423, G_Loss:6.462858200073242

iterator 2300, D_Loss:0.48938894271850586, G_Loss:5.998440742492676

iterator 2400, D_Loss:0.47578707337379456, G_Loss:5.234652996063232

iterator 2500, D_Loss:0.4878615438938141, G_Loss:6.642731666564941

iterator 2600, D_Loss:0.6630828380584717, G_Loss:7.292951583862305

iterator 2700, D_Loss:0.4841855764389038, G_Loss:7.238749980926514

iterator 2800, D_Loss:0.5123163461685181, G_Loss:6.148270130157471

iterator 2900, D_Loss:0.47255292534828186, G_Loss:3.584493637084961

iterator 3000, D_Loss:0.4901125431060791, G_Loss:5.284536361694336

iterator 3100, D_Loss:0.466608464717865, G_Loss:7.168336868286133

iterator 3200, D_Loss:0.4620721638202667, G_Loss:7.699548721313477

iterator 3300, D_Loss:0.44483596086502075, G_Loss:6.712818145751953

iterator 3400, D_Loss:0.4742851257324219, G_Loss:4.861532688140869

iterator 3500, D_Loss:0.4710555970668793, G_Loss:5.6121649742126465

iterator 3600, D_Loss:0.5432934165000916, G_Loss:2.1789026260375977

iterator 3700, D_Loss:0.48884114623069763, G_Loss:4.586319923400879

iterator 3800, D_Loss:0.5748184323310852, G_Loss:6.587513446807861

iterator 3900, D_Loss:0.4520895779132843, G_Loss:8.267752647399902

iterator 4000, D_Loss:0.4686156213283539, G_Loss:7.863589763641357

iterator 4100, D_Loss:0.4718545377254486, G_Loss:8.332428932189941

iterator 4200, D_Loss:0.455327570438385, G_Loss:8.997490882873535

iterator 4300, D_Loss:0.4676032066345215, G_Loss:7.498936653137207

iterator 4400, D_Loss:0.4327961504459381, G_Loss:6.23167610168457

iterator 4500, D_Loss:0.5344669818878174, G_Loss:6.76280403137207

iterator 4600, D_Loss:0.4875752329826355, G_Loss:6.918454170227051

iterator 4700, D_Loss:0.4464307427406311, G_Loss:9.222813606262207

iterator 4800, D_Loss:0.44947952032089233, G_Loss:8.151588439941406

iterator 4900, D_Loss:0.4636266529560089, G_Loss:6.449780464172363

-----------Epoch 2-----------
iterator 0, D_Loss:0.43673887848854065, G_Loss:7.892131805419922

iterator 100, D_Loss:0.43713244795799255, G_Loss:7.314418792724609

iterator 200, D_Loss:0.469377726316452, G_Loss:7.25605583190918

iterator 300, D_Loss:0.49492332339286804, G_Loss:7.421976566314697

iterator 400, D_Loss:0.4816669523715973, G_Loss:7.636037349700928

iterator 500, D_Loss:0.5843573808670044, G_Loss:9.492888450622559

iterator 600, D_Loss:0.47951528429985046, G_Loss:6.251108646392822

iterator 700, D_Loss:0.45506420731544495, G_Loss:8.141115188598633

iterator 800, D_Loss:0.4436158239841461, G_Loss:8.474870681762695

iterator 900, D_Loss:0.4268147051334381, G_Loss:8.131144523620605

iterator 1000, D_Loss:0.46190205216407776, G_Loss:9.228466033935547

iterator 1100, D_Loss:0.43223872780799866, G_Loss:9.065384864807129

iterator 1200, D_Loss:0.4324638545513153, G_Loss:9.584297180175781

iterator 1300, D_Loss:0.4304281175136566, G_Loss:10.132589340209961

iterator 1400, D_Loss:0.45057734847068787, G_Loss:8.040745735168457

iterator 1500, D_Loss:0.6254792809486389, G_Loss:8.639328956604004

iterator 1600, D_Loss:0.4334558844566345, G_Loss:11.389093399047852

iterator 1700, D_Loss:0.41688787937164307, G_Loss:10.809450149536133

iterator 1800, D_Loss:0.4323793947696686, G_Loss:9.900041580200195

iterator 1900, D_Loss:0.42804914712905884, G_Loss:9.814990043640137

iterator 2000, D_Loss:0.4490346610546112, G_Loss:10.26341438293457

iterator 2100, D_Loss:0.43109071254730225, G_Loss:8.795040130615234

iterator 2200, D_Loss:0.45428621768951416, G_Loss:8.072026252746582

iterator 2300, D_Loss:0.45585834980010986, G_Loss:10.67327880859375

iterator 2400, D_Loss:0.4312828779220581, G_Loss:10.374296188354492

iterator 2500, D_Loss:0.46635255217552185, G_Loss:12.681089401245117

iterator 2600, D_Loss:0.43559131026268005, G_Loss:11.44056224822998

iterator 2700, D_Loss:0.43662312626838684, G_Loss:8.415987968444824

iterator 2800, D_Loss:0.42573606967926025, G_Loss:10.26659107208252

iterator 2900, D_Loss:0.4252850413322449, G_Loss:9.706018447875977

iterator 3000, D_Loss:0.6284629106521606, G_Loss:9.165894508361816

iterator 3100, D_Loss:0.44619300961494446, G_Loss:10.47856330871582

iterator 3200, D_Loss:0.4194191098213196, G_Loss:11.562271118164062

iterator 3300, D_Loss:0.42124873399734497, G_Loss:10.505126953125

iterator 3400, D_Loss:0.4386385679244995, G_Loss:9.520021438598633

iterator 3500, D_Loss:0.4248408377170563, G_Loss:10.315166473388672

iterator 3600, D_Loss:0.4438384771347046, G_Loss:11.231587409973145

iterator 3700, D_Loss:0.41995909810066223, G_Loss:7.438253402709961

iterator 3800, D_Loss:0.42776310443878174, G_Loss:8.917960166931152

iterator 3900, D_Loss:0.442532479763031, G_Loss:10.341279029846191

iterator 4000, D_Loss:0.4301467537879944, G_Loss:11.055261611938477

iterator 4100, D_Loss:0.4288646876811981, G_Loss:8.028759956359863

iterator 4200, D_Loss:0.4419808089733124, G_Loss:11.001147270202637

iterator 4300, D_Loss:0.432607501745224, G_Loss:11.72037410736084

iterator 4400, D_Loss:0.4300042390823364, G_Loss:11.36011028289795

iterator 4500, D_Loss:0.4253982603549957, G_Loss:10.84499740600586

iterator 4600, D_Loss:0.45569702982902527, G_Loss:9.714579582214355

iterator 4700, D_Loss:0.4424439072608948, G_Loss:11.491695404052734

iterator 4800, D_Loss:0.4750765264034271, G_Loss:10.625385284423828

iterator 4900, D_Loss:0.4889404773712158, G_Loss:10.89128303527832

-----------Epoch 3-----------
iterator 0, D_Loss:0.45483794808387756, G_Loss:11.003849983215332

iterator 100, D_Loss:0.4405834972858429, G_Loss:13.389091491699219

iterator 200, D_Loss:0.4647410809993744, G_Loss:12.943092346191406

iterator 300, D_Loss:0.45724213123321533, G_Loss:10.899650573730469

iterator 400, D_Loss:0.4717515707015991, G_Loss:11.875802993774414

iterator 500, D_Loss:0.4591350257396698, G_Loss:11.944171905517578

iterator 600, D_Loss:0.4430099427700043, G_Loss:9.422947883605957

iterator 700, D_Loss:3.580739974975586, G_Loss:12.675580978393555

iterator 800, D_Loss:0.45903366804122925, G_Loss:9.598055839538574

iterator 900, D_Loss:0.4970291256904602, G_Loss:12.600213050842285

iterator 1000, D_Loss:0.4448387026786804, G_Loss:7.919595718383789

iterator 1100, D_Loss:0.44141820073127747, G_Loss:9.859789848327637

iterator 1200, D_Loss:0.5158109664916992, G_Loss:9.956295013427734

iterator 1300, D_Loss:0.4616921544075012, G_Loss:6.634653091430664

iterator 1400, D_Loss:0.47326889634132385, G_Loss:9.994197845458984

iterator 1500, D_Loss:0.9229357242584229, G_Loss:8.216669082641602

iterator 1600, D_Loss:0.48942944407463074, G_Loss:8.230525016784668

iterator 1700, D_Loss:0.42813223600387573, G_Loss:11.47551441192627

iterator 1800, D_Loss:0.47326916456222534, G_Loss:7.856108665466309

iterator 1900, D_Loss:0.45012927055358887, G_Loss:10.970602035522461

iterator 2000, D_Loss:0.436880886554718, G_Loss:9.84215259552002

iterator 2100, D_Loss:0.4636407792568207, G_Loss:13.138935089111328

iterator 2200, D_Loss:0.43859127163887024, G_Loss:11.774545669555664

iterator 2300, D_Loss:0.43126600980758667, G_Loss:7.167727470397949

iterator 2400, D_Loss:0.43110302090644836, G_Loss:10.614969253540039

iterator 2500, D_Loss:0.41626614332199097, G_Loss:8.494036674499512

iterator 2600, D_Loss:0.429025262594223, G_Loss:8.759486198425293

iterator 2700, D_Loss:0.43067944049835205, G_Loss:9.683489799499512

iterator 2800, D_Loss:0.4649062752723694, G_Loss:13.092720985412598

iterator 2900, D_Loss:0.47568967938423157, G_Loss:12.92792797088623

iterator 3000, D_Loss:0.4212535321712494, G_Loss:10.776325225830078

iterator 3100, D_Loss:0.43674957752227783, G_Loss:9.382672309875488

iterator 3200, D_Loss:0.4338045120239258, G_Loss:12.435968399047852

iterator 3300, D_Loss:0.42758363485336304, G_Loss:12.417052268981934

iterator 3400, D_Loss:0.4445205628871918, G_Loss:9.386133193969727

iterator 3500, D_Loss:0.4277299642562866, G_Loss:11.702335357666016

iterator 3600, D_Loss:0.432643324136734, G_Loss:13.544452667236328

iterator 3700, D_Loss:0.43648409843444824, G_Loss:13.655173301696777

iterator 3800, D_Loss:0.4335322976112366, G_Loss:11.258122444152832

iterator 3900, D_Loss:0.42190396785736084, G_Loss:8.686103820800781

iterator 4000, D_Loss:0.4420356750488281, G_Loss:11.878877639770508

iterator 4100, D_Loss:0.43663835525512695, G_Loss:13.058127403259277

iterator 4200, D_Loss:0.43820083141326904, G_Loss:13.050394058227539

iterator 4300, D_Loss:0.4439893662929535, G_Loss:13.745430946350098

iterator 4400, D_Loss:0.41710299253463745, G_Loss:12.462227821350098

iterator 4500, D_Loss:0.4295908510684967, G_Loss:13.980522155761719

iterator 4600, D_Loss:0.42982080578804016, G_Loss:12.610112190246582

iterator 4700, D_Loss:0.4198409616947174, G_Loss:11.427730560302734

iterator 4800, D_Loss:0.4467165768146515, G_Loss:10.004195213317871

iterator 4900, D_Loss:0.4351724684238434, G_Loss:9.89992904663086

-----------Epoch 4-----------
iterator 0, D_Loss:0.45128485560417175, G_Loss:7.392778396606445

iterator 100, D_Loss:0.4386626183986664, G_Loss:12.013359069824219

iterator 200, D_Loss:0.4303516745567322, G_Loss:11.350225448608398

iterator 300, D_Loss:0.4283005893230438, G_Loss:11.3853120803833

iterator 400, D_Loss:0.4343349039554596, G_Loss:14.346756935119629

iterator 500, D_Loss:0.4164029061794281, G_Loss:10.056888580322266

iterator 600, D_Loss:5.160161972045898, G_Loss:14.477300643920898

iterator 700, D_Loss:0.43601348996162415, G_Loss:11.35007095336914

iterator 800, D_Loss:0.4255659878253937, G_Loss:9.9453763961792

iterator 900, D_Loss:0.4450523257255554, G_Loss:11.996808052062988

iterator 1000, D_Loss:0.4132115840911865, G_Loss:12.008369445800781

iterator 1100, D_Loss:0.42953982949256897, G_Loss:11.689443588256836

iterator 1200, D_Loss:0.4315846562385559, G_Loss:10.920587539672852

iterator 1300, D_Loss:0.4326152205467224, G_Loss:13.309006690979004

iterator 1400, D_Loss:0.4315672218799591, G_Loss:10.804868698120117

iterator 1500, D_Loss:0.4094066619873047, G_Loss:12.931242942810059

iterator 1600, D_Loss:0.4286615550518036, G_Loss:12.805920600891113

iterator 1700, D_Loss:0.43046560883522034, G_Loss:10.438072204589844

iterator 1800, D_Loss:0.43517032265663147, G_Loss:10.352391242980957

iterator 1900, D_Loss:0.4254443943500519, G_Loss:12.31067180633545

iterator 2000, D_Loss:0.4299250841140747, G_Loss:11.566461563110352

iterator 2100, D_Loss:0.4072727560997009, G_Loss:12.39763069152832

iterator 2200, D_Loss:0.4180534780025482, G_Loss:13.60400676727295

iterator 2300, D_Loss:0.41402682662010193, G_Loss:10.437151908874512

iterator 2400, D_Loss:0.4407564699649811, G_Loss:11.105389595031738

iterator 2500, D_Loss:0.41457220911979675, G_Loss:12.44760799407959

iterator 2600, D_Loss:0.4414244592189789, G_Loss:10.78597354888916

iterator 2700, D_Loss:0.43614158034324646, G_Loss:10.41531753540039

iterator 2800, D_Loss:0.3953671157360077, G_Loss:11.078047752380371

iterator 2900, D_Loss:0.4285098612308502, G_Loss:12.298003196716309

iterator 3000, D_Loss:0.4175485074520111, G_Loss:11.508825302124023

iterator 3100, D_Loss:0.4206481873989105, G_Loss:12.774955749511719

iterator 3200, D_Loss:0.4392104744911194, G_Loss:12.474164009094238

iterator 3300, D_Loss:0.4142475724220276, G_Loss:11.753392219543457

iterator 3400, D_Loss:0.4263125956058502, G_Loss:13.797914505004883

iterator 3500, D_Loss:0.41541460156440735, G_Loss:14.422908782958984

iterator 3600, D_Loss:0.41940316557884216, G_Loss:14.683267593383789

iterator 3700, D_Loss:0.41611427068710327, G_Loss:10.078032493591309

iterator 3800, D_Loss:0.43021342158317566, G_Loss:13.057093620300293

iterator 3900, D_Loss:0.4338989853858948, G_Loss:13.181138038635254

iterator 4000, D_Loss:0.42191752791404724, G_Loss:6.008443832397461

iterator 4100, D_Loss:0.4324277341365814, G_Loss:12.588451385498047

iterator 4200, D_Loss:0.4302752614021301, G_Loss:10.244590759277344

iterator 4300, D_Loss:0.4121105372905731, G_Loss:11.70777416229248

iterator 4400, D_Loss:0.44768020510673523, G_Loss:14.20953369140625

iterator 4500, D_Loss:0.41913244128227234, G_Loss:13.897695541381836

iterator 4600, D_Loss:0.43251222372055054, G_Loss:14.655346870422363

iterator 4700, D_Loss:0.42562952637672424, G_Loss:12.773615837097168

iterator 4800, D_Loss:0.41845226287841797, G_Loss:11.41518497467041

iterator 4900, D_Loss:0.4301324486732483, G_Loss:12.083285331726074

-----------Epoch 5-----------
iterator 0, D_Loss:0.4244011640548706, G_Loss:9.653048515319824

iterator 100, D_Loss:0.4290587604045868, G_Loss:13.444009780883789

iterator 200, D_Loss:0.43326666951179504, G_Loss:12.660130500793457

iterator 300, D_Loss:0.4292752742767334, G_Loss:11.889071464538574

iterator 400, D_Loss:0.4203304350376129, G_Loss:13.628254890441895

iterator 500, D_Loss:0.41206759214401245, G_Loss:13.173542022705078

iterator 600, D_Loss:0.4116174280643463, G_Loss:7.856537342071533

iterator 700, D_Loss:0.4202826917171478, G_Loss:10.542651176452637

iterator 800, D_Loss:0.4086979925632477, G_Loss:11.21738338470459

iterator 900, D_Loss:0.4254451096057892, G_Loss:12.72028923034668

iterator 1000, D_Loss:0.41603824496269226, G_Loss:8.768719673156738

iterator 1100, D_Loss:0.4201069474220276, G_Loss:12.784375190734863

iterator 1200, D_Loss:0.4373811185359955, G_Loss:10.789983749389648

iterator 1300, D_Loss:0.428739458322525, G_Loss:10.54046630859375

iterator 1400, D_Loss:0.4227377474308014, G_Loss:13.151994705200195

iterator 1500, D_Loss:0.4166732132434845, G_Loss:11.428580284118652

iterator 1600, D_Loss:0.42527058720588684, G_Loss:8.758773803710938

iterator 1700, D_Loss:0.4239780902862549, G_Loss:13.505024909973145

iterator 1800, D_Loss:0.41937699913978577, G_Loss:11.568066596984863

iterator 1900, D_Loss:0.4407331049442291, G_Loss:10.937716484069824

iterator 2000, D_Loss:0.4251444637775421, G_Loss:10.90782642364502

iterator 2100, D_Loss:0.4401686191558838, G_Loss:10.745759010314941

iterator 2200, D_Loss:0.423452764749527, G_Loss:12.63668441772461

iterator 2300, D_Loss:0.4188568890094757, G_Loss:9.57713508605957

iterator 2400, D_Loss:0.4437013268470764, G_Loss:11.069686889648438

iterator 2500, D_Loss:0.4249548614025116, G_Loss:12.671381950378418

iterator 2600, D_Loss:0.42210865020751953, G_Loss:10.74415397644043

iterator 2700, D_Loss:0.4355360269546509, G_Loss:11.871110916137695

iterator 2800, D_Loss:0.42495036125183105, G_Loss:11.805581092834473

iterator 2900, D_Loss:0.4435923099517822, G_Loss:13.137391090393066

iterator 3000, D_Loss:0.43310683965682983, G_Loss:11.539687156677246

iterator 3100, D_Loss:0.42025816440582275, G_Loss:11.564447402954102

iterator 3200, D_Loss:0.4428083002567291, G_Loss:13.009669303894043

iterator 3300, D_Loss:0.4096004068851471, G_Loss:12.10268783569336

iterator 3400, D_Loss:0.42059949040412903, G_Loss:11.385594367980957

iterator 3500, D_Loss:0.4281201958656311, G_Loss:12.90640640258789

iterator 3600, D_Loss:0.41973575949668884, G_Loss:9.157562255859375

iterator 3700, D_Loss:0.407953679561615, G_Loss:12.824767112731934

iterator 3800, D_Loss:0.41218680143356323, G_Loss:7.800396919250488

iterator 3900, D_Loss:0.4217607080936432, G_Loss:12.059961318969727

iterator 4000, D_Loss:0.41407597064971924, G_Loss:12.897597312927246

iterator 4100, D_Loss:0.4647523760795593, G_Loss:12.024640083312988

iterator 4200, D_Loss:0.4303676187992096, G_Loss:14.539051055908203

iterator 4300, D_Loss:0.4355279207229614, G_Loss:12.572469711303711

iterator 4400, D_Loss:0.420159250497818, G_Loss:12.633844375610352

iterator 4500, D_Loss:0.4396360218524933, G_Loss:11.108461380004883

iterator 4600, D_Loss:0.42885664105415344, G_Loss:13.778122901916504

iterator 4700, D_Loss:0.4245206415653229, G_Loss:9.980496406555176

iterator 4800, D_Loss:0.41676151752471924, G_Loss:14.96685791015625

iterator 4900, D_Loss:0.5817252397537231, G_Loss:4.099832057952881

-----------Epoch 6-----------
iterator 0, D_Loss:0.4220965802669525, G_Loss:14.111294746398926

iterator 100, D_Loss:0.4116516709327698, G_Loss:12.760906219482422

iterator 200, D_Loss:0.45591768622398376, G_Loss:9.854168891906738

iterator 300, D_Loss:0.43511471152305603, G_Loss:5.423883438110352

iterator 400, D_Loss:0.4223261773586273, G_Loss:12.228975296020508

iterator 500, D_Loss:0.42876818776130676, G_Loss:14.034921646118164

iterator 600, D_Loss:0.4450294077396393, G_Loss:13.229347229003906

iterator 700, D_Loss:0.8471859693527222, G_Loss:16.88552474975586

iterator 800, D_Loss:0.44951894879341125, G_Loss:12.069644927978516

iterator 900, D_Loss:0.43384087085723877, G_Loss:13.965707778930664

iterator 1000, D_Loss:0.4437468349933624, G_Loss:13.164613723754883

iterator 1100, D_Loss:0.43916642665863037, G_Loss:12.116196632385254

iterator 1200, D_Loss:0.4386594891548157, G_Loss:11.046379089355469

iterator 1300, D_Loss:0.4371547996997833, G_Loss:11.888652801513672

iterator 1400, D_Loss:0.43614083528518677, G_Loss:12.794378280639648

iterator 1500, D_Loss:0.447857528924942, G_Loss:9.574758529663086

iterator 1600, D_Loss:0.4234788715839386, G_Loss:12.08836555480957

iterator 1700, D_Loss:0.44433432817459106, G_Loss:14.410788536071777

iterator 1800, D_Loss:0.43030408024787903, G_Loss:15.216399192810059

iterator 1900, D_Loss:0.4130823314189911, G_Loss:14.377239227294922

iterator 2000, D_Loss:0.4211086332798004, G_Loss:13.126856803894043

iterator 2100, D_Loss:0.4342597424983978, G_Loss:13.016243934631348

iterator 2200, D_Loss:0.42706725001335144, G_Loss:11.084321022033691

iterator 2300, D_Loss:0.4112367630004883, G_Loss:14.218079566955566

iterator 2400, D_Loss:0.5102888345718384, G_Loss:11.260101318359375

iterator 2500, D_Loss:0.4246298372745514, G_Loss:12.406600952148438

iterator 2600, D_Loss:0.4275359511375427, G_Loss:11.06769847869873

iterator 2700, D_Loss:0.42546388506889343, G_Loss:10.26323127746582

iterator 2800, D_Loss:0.4325175881385803, G_Loss:10.313997268676758

iterator 2900, D_Loss:0.4377344250679016, G_Loss:10.741252899169922

iterator 3000, D_Loss:0.4133647382259369, G_Loss:11.017253875732422

iterator 3100, D_Loss:0.4400146007537842, G_Loss:10.966782569885254

iterator 3200, D_Loss:0.41532665491104126, G_Loss:10.92257308959961

iterator 3300, D_Loss:0.4517018496990204, G_Loss:11.40112018585205

iterator 3400, D_Loss:0.4233824610710144, G_Loss:9.462657928466797

iterator 3500, D_Loss:0.4192948043346405, G_Loss:11.267585754394531

iterator 3600, D_Loss:0.42875176668167114, G_Loss:10.782687187194824

iterator 3700, D_Loss:0.42495566606521606, G_Loss:7.861278533935547

iterator 3800, D_Loss:0.4430070221424103, G_Loss:11.178730964660645

iterator 3900, D_Loss:0.42477792501449585, G_Loss:10.502440452575684

iterator 4000, D_Loss:0.43035513162612915, G_Loss:10.65143871307373

iterator 4100, D_Loss:0.4363476037979126, G_Loss:12.166512489318848

iterator 4200, D_Loss:0.4234374761581421, G_Loss:11.587004661560059

iterator 4300, D_Loss:0.44087255001068115, G_Loss:10.163102149963379

iterator 4400, D_Loss:0.43552157282829285, G_Loss:11.528584480285645

iterator 4500, D_Loss:0.4245932400226593, G_Loss:12.199422836303711

iterator 4600, D_Loss:0.4300398528575897, G_Loss:10.889951705932617

iterator 4700, D_Loss:0.41083234548568726, G_Loss:11.253190994262695

iterator 4800, D_Loss:0.4269197881221771, G_Loss:12.082880973815918

iterator 4900, D_Loss:0.41881299018859863, G_Loss:12.790761947631836

-----------Epoch 7-----------
iterator 0, D_Loss:0.4348495900630951, G_Loss:11.50903034210205

iterator 100, D_Loss:0.4073728322982788, G_Loss:8.82672119140625

iterator 200, D_Loss:0.4341837763786316, G_Loss:11.657771110534668

iterator 300, D_Loss:0.4244554340839386, G_Loss:11.282163619995117

iterator 400, D_Loss:0.4130431115627289, G_Loss:9.49220085144043

iterator 500, D_Loss:0.418234258890152, G_Loss:10.173308372497559

iterator 600, D_Loss:0.4657241404056549, G_Loss:12.993820190429688

iterator 700, D_Loss:0.4599296748638153, G_Loss:14.641474723815918

iterator 800, D_Loss:0.42635345458984375, G_Loss:12.651705741882324

iterator 900, D_Loss:0.41696831583976746, G_Loss:9.018177032470703

iterator 1000, D_Loss:0.44348013401031494, G_Loss:12.451080322265625

iterator 1100, D_Loss:0.430418998003006, G_Loss:14.054990768432617

iterator 1200, D_Loss:0.4545532464981079, G_Loss:14.198637962341309

iterator 1300, D_Loss:1.289800763130188, G_Loss:14.826557159423828

iterator 1400, D_Loss:0.42750120162963867, G_Loss:13.068902969360352

iterator 1500, D_Loss:0.42787402868270874, G_Loss:12.351664543151855

iterator 1600, D_Loss:0.4320050776004791, G_Loss:11.503134727478027

iterator 1700, D_Loss:0.42950326204299927, G_Loss:11.885048866271973

iterator 1800, D_Loss:0.430459201335907, G_Loss:12.723520278930664

iterator 1900, D_Loss:0.42189353704452515, G_Loss:13.871758460998535

iterator 2000, D_Loss:0.43009763956069946, G_Loss:10.227294921875

iterator 2100, D_Loss:0.4264804422855377, G_Loss:12.515040397644043

iterator 2200, D_Loss:0.4362516403198242, G_Loss:11.770994186401367

iterator 2300, D_Loss:0.4284120202064514, G_Loss:10.651172637939453

iterator 2400, D_Loss:0.5204464197158813, G_Loss:11.937658309936523

iterator 2500, D_Loss:0.4232195317745209, G_Loss:11.923152923583984

iterator 2600, D_Loss:0.43617600202560425, G_Loss:11.969789505004883

iterator 2700, D_Loss:0.4413886070251465, G_Loss:11.585902214050293

iterator 2800, D_Loss:0.4441031515598297, G_Loss:13.02364730834961

iterator 2900, D_Loss:0.42301687598228455, G_Loss:11.147764205932617

iterator 3000, D_Loss:0.42449650168418884, G_Loss:10.853443145751953

iterator 3100, D_Loss:0.4340631067752838, G_Loss:11.557779312133789

iterator 3200, D_Loss:0.41817647218704224, G_Loss:11.409843444824219

iterator 3300, D_Loss:0.4062572121620178, G_Loss:12.226383209228516

iterator 3400, D_Loss:0.4316008687019348, G_Loss:10.137774467468262

iterator 3500, D_Loss:0.5617947578430176, G_Loss:12.669071197509766

iterator 3600, D_Loss:0.425598680973053, G_Loss:11.465588569641113

iterator 3700, D_Loss:0.42043933272361755, G_Loss:11.352052688598633

iterator 3800, D_Loss:0.42198845744132996, G_Loss:13.324955940246582

iterator 3900, D_Loss:0.4232965409755707, G_Loss:9.523725509643555

iterator 4000, D_Loss:0.46248093247413635, G_Loss:14.138877868652344

iterator 4100, D_Loss:0.4265527129173279, G_Loss:12.785054206848145

iterator 4200, D_Loss:0.4231712520122528, G_Loss:13.194438934326172

iterator 4300, D_Loss:0.43385833501815796, G_Loss:13.311073303222656

iterator 4400, D_Loss:0.45171239972114563, G_Loss:8.939501762390137

iterator 4500, D_Loss:0.42199456691741943, G_Loss:13.001818656921387

iterator 4600, D_Loss:0.42745649814605713, G_Loss:11.794567108154297

iterator 4700, D_Loss:0.4311254024505615, G_Loss:15.07295036315918

iterator 4800, D_Loss:0.433031290769577, G_Loss:13.685856819152832

iterator 4900, D_Loss:0.4405195116996765, G_Loss:14.66067886352539

-----------Epoch 8-----------
iterator 0, D_Loss:0.4364033043384552, G_Loss:12.075803756713867

iterator 100, D_Loss:0.4155750572681427, G_Loss:10.953211784362793

iterator 200, D_Loss:0.4264870285987854, G_Loss:11.90684700012207

iterator 300, D_Loss:0.41923418641090393, G_Loss:11.840846061706543

iterator 400, D_Loss:0.4441167712211609, G_Loss:13.024942398071289

iterator 500, D_Loss:0.43965381383895874, G_Loss:11.6814603805542

iterator 600, D_Loss:0.4322894513607025, G_Loss:11.351214408874512

iterator 700, D_Loss:0.43967729806900024, G_Loss:10.146852493286133

iterator 800, D_Loss:0.4295087456703186, G_Loss:12.315807342529297

iterator 900, D_Loss:0.43418070673942566, G_Loss:11.128952980041504

iterator 1000, D_Loss:0.43363142013549805, G_Loss:11.38093376159668

iterator 1100, D_Loss:0.44263753294944763, G_Loss:11.755636215209961

iterator 1200, D_Loss:0.42122602462768555, G_Loss:11.483744621276855

iterator 1300, D_Loss:0.4077340066432953, G_Loss:11.920743942260742

iterator 1400, D_Loss:0.4208250939846039, G_Loss:12.37983512878418

iterator 1500, D_Loss:0.45171070098876953, G_Loss:11.5426607131958

iterator 1600, D_Loss:0.4400345981121063, G_Loss:5.305727958679199

iterator 1700, D_Loss:0.404683381319046, G_Loss:11.118674278259277

iterator 1800, D_Loss:0.42577776312828064, G_Loss:11.136518478393555

iterator 1900, D_Loss:0.42944860458374023, G_Loss:11.420500755310059

iterator 2000, D_Loss:0.41492578387260437, G_Loss:11.51357650756836

iterator 2100, D_Loss:0.420933336019516, G_Loss:11.466683387756348

iterator 2200, D_Loss:0.4219179153442383, G_Loss:9.71399211883545

iterator 2300, D_Loss:0.40808606147766113, G_Loss:10.031511306762695

iterator 2400, D_Loss:0.4249880015850067, G_Loss:9.93027400970459

iterator 2500, D_Loss:0.4345857501029968, G_Loss:14.287454605102539

iterator 2600, D_Loss:0.4277021884918213, G_Loss:13.001254081726074

iterator 2700, D_Loss:0.4138050675392151, G_Loss:13.188480377197266

iterator 2800, D_Loss:0.42898374795913696, G_Loss:12.975020408630371

iterator 2900, D_Loss:0.4164872169494629, G_Loss:12.234966278076172

iterator 3000, D_Loss:0.4232095777988434, G_Loss:12.322371482849121

iterator 3100, D_Loss:0.42817431688308716, G_Loss:11.719866752624512

iterator 3200, D_Loss:0.41776689887046814, G_Loss:11.775875091552734

iterator 3300, D_Loss:0.4274938106536865, G_Loss:12.723580360412598

iterator 3400, D_Loss:0.43971699476242065, G_Loss:11.837784767150879

iterator 3500, D_Loss:0.4366319477558136, G_Loss:11.090538024902344

iterator 3600, D_Loss:0.43473461270332336, G_Loss:11.28317642211914

iterator 3700, D_Loss:0.44081002473831177, G_Loss:12.107403755187988

iterator 3800, D_Loss:0.42337271571159363, G_Loss:11.637665748596191

iterator 3900, D_Loss:0.4292333126068115, G_Loss:11.246774673461914

iterator 4000, D_Loss:0.4147752523422241, G_Loss:12.493724822998047

iterator 4100, D_Loss:0.4255005121231079, G_Loss:11.451142311096191

iterator 4200, D_Loss:0.41893869638442993, G_Loss:9.53464126586914

iterator 4300, D_Loss:0.4133635461330414, G_Loss:10.182168006896973

iterator 4400, D_Loss:0.4203557074069977, G_Loss:11.659858703613281

iterator 4500, D_Loss:0.4259817600250244, G_Loss:11.849959373474121

iterator 4600, D_Loss:0.42262542247772217, G_Loss:10.621495246887207

iterator 4700, D_Loss:0.4108130931854248, G_Loss:11.222772598266602

iterator 4800, D_Loss:0.4347657859325409, G_Loss:10.97840404510498

iterator 4900, D_Loss:0.4284215569496155, G_Loss:11.848573684692383

-----------Epoch 9-----------
iterator 0, D_Loss:0.4208764433860779, G_Loss:11.380703926086426

iterator 100, D_Loss:0.4268505871295929, G_Loss:11.489842414855957

iterator 200, D_Loss:0.40132585167884827, G_Loss:13.255874633789062

iterator 300, D_Loss:0.43158045411109924, G_Loss:14.816911697387695

iterator 400, D_Loss:0.4054501950740814, G_Loss:12.715438842773438

iterator 500, D_Loss:0.4445568919181824, G_Loss:12.165215492248535

iterator 600, D_Loss:0.4193023443222046, G_Loss:13.581008911132812

iterator 700, D_Loss:0.421377956867218, G_Loss:16.80660629272461

iterator 800, D_Loss:0.4461545944213867, G_Loss:14.617956161499023

iterator 900, D_Loss:0.4765256345272064, G_Loss:13.060415267944336

iterator 1000, D_Loss:1.1945688724517822, G_Loss:16.724414825439453

iterator 1100, D_Loss:0.4422331750392914, G_Loss:14.305008888244629

iterator 1200, D_Loss:0.40762537717819214, G_Loss:12.133880615234375

iterator 1300, D_Loss:0.4312314987182617, G_Loss:12.23638916015625

iterator 1400, D_Loss:1.1440081596374512, G_Loss:12.122299194335938

iterator 1500, D_Loss:0.42323872447013855, G_Loss:13.289559364318848

iterator 1600, D_Loss:0.4213923215866089, G_Loss:11.660205841064453

iterator 1700, D_Loss:0.44080621004104614, G_Loss:11.222042083740234

iterator 1800, D_Loss:0.4356940686702728, G_Loss:10.776461601257324

iterator 1900, D_Loss:0.41422051191329956, G_Loss:11.374252319335938

iterator 2000, D_Loss:0.4165024161338806, G_Loss:12.542484283447266

iterator 2100, D_Loss:0.41592442989349365, G_Loss:12.553621292114258

iterator 2200, D_Loss:0.4268256723880768, G_Loss:12.809430122375488

iterator 2300, D_Loss:0.4033389687538147, G_Loss:11.88166618347168

iterator 2400, D_Loss:0.4365043640136719, G_Loss:13.00696086883545

iterator 2500, D_Loss:0.43049249053001404, G_Loss:13.417913436889648

iterator 2600, D_Loss:0.42209622263908386, G_Loss:13.069815635681152

iterator 2700, D_Loss:0.424342542886734, G_Loss:12.255898475646973

iterator 2800, D_Loss:0.4236111342906952, G_Loss:12.408487319946289

iterator 2900, D_Loss:0.42281779646873474, G_Loss:11.739198684692383

iterator 3000, D_Loss:0.44059327244758606, G_Loss:10.461925506591797

iterator 3100, D_Loss:0.4389812648296356, G_Loss:10.784645080566406

iterator 3200, D_Loss:0.4274165630340576, G_Loss:11.802702903747559

iterator 3300, D_Loss:0.42624926567077637, G_Loss:12.298781394958496

iterator 3400, D_Loss:0.42827460169792175, G_Loss:12.20146369934082

iterator 3500, D_Loss:0.4203140139579773, G_Loss:11.722090721130371

iterator 3600, D_Loss:0.43151170015335083, G_Loss:11.714454650878906

iterator 3700, D_Loss:0.4305976629257202, G_Loss:13.824821472167969

iterator 3800, D_Loss:0.42169857025146484, G_Loss:12.928374290466309

iterator 3900, D_Loss:0.4293631613254547, G_Loss:12.019569396972656

iterator 4000, D_Loss:0.42026591300964355, G_Loss:11.378140449523926

iterator 4100, D_Loss:0.42935705184936523, G_Loss:11.520577430725098

iterator 4200, D_Loss:0.41398531198501587, G_Loss:12.996520042419434

iterator 4300, D_Loss:0.43734997510910034, G_Loss:12.31261157989502

iterator 4400, D_Loss:0.4352070093154907, G_Loss:10.790339469909668

iterator 4500, D_Loss:0.45414894819259644, G_Loss:10.214700698852539

iterator 4600, D_Loss:0.4127116799354553, G_Loss:12.493408203125

iterator 4700, D_Loss:0.4212810695171356, G_Loss:12.036279678344727

iterator 4800, D_Loss:0.4193815588951111, G_Loss:11.503402709960938

iterator 4900, D_Loss:0.41781988739967346, G_Loss:12.66853141784668

LGAN_generator(
  (LSTM): LSTMCell(602, 300)
  (gmfc00): Linear(in_features=200, out_features=1, bias=True)
  (gmfc01): Linear(in_features=200, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=200, bias=True)
  (gmfe00): Linear(in_features=300, out_features=200, bias=True)
  (gmfe01): Linear(in_features=300, out_features=200, bias=True)
  (fc10): Linear(in_features=200, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=200, bias=True)
  (fe1): Linear(in_features=300, out_features=200, bias=True)
  (gmfc20): Linear(in_features=200, out_features=1, bias=True)
  (gmfc21): Linear(in_features=200, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=200, bias=True)
  (gmfe20): Linear(in_features=300, out_features=200, bias=True)
  (gmfe21): Linear(in_features=300, out_features=200, bias=True)
  (fc30): Linear(in_features=200, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=200, bias=True)
  (fe3): Linear(in_features=300, out_features=200, bias=True)
  (gmfc40): Linear(in_features=200, out_features=1, bias=True)
  (gmfc41): Linear(in_features=200, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=200, bias=True)
  (gmfe40): Linear(in_features=300, out_features=200, bias=True)
  (gmfe41): Linear(in_features=300, out_features=200, bias=True)
  (fc50): Linear(in_features=200, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=200, bias=True)
  (fe5): Linear(in_features=300, out_features=200, bias=True)
  (fc60): Linear(in_features=200, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=200, bias=True)
  (fe6): Linear(in_features=300, out_features=200, bias=True)
  (fc70): Linear(in_features=200, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=200, bias=True)
  (fe7): Linear(in_features=300, out_features=200, bias=True)
  (fc80): Linear(in_features=200, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=200, bias=True)
  (fe8): Linear(in_features=300, out_features=200, bias=True)
  (fc90): Linear(in_features=200, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=200, bias=True)
  (fe9): Linear(in_features=300, out_features=200, bias=True)
  (gmfc100): Linear(in_features=200, out_features=1, bias=True)
  (gmfc101): Linear(in_features=200, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=200, bias=True)
  (gmfe100): Linear(in_features=300, out_features=200, bias=True)
  (gmfe101): Linear(in_features=300, out_features=200, bias=True)
  (gmfc110): Linear(in_features=200, out_features=1, bias=True)
  (gmfc111): Linear(in_features=200, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=200, bias=True)
  (gmfe110): Linear(in_features=300, out_features=200, bias=True)
  (gmfe111): Linear(in_features=300, out_features=200, bias=True)
  (gmfc120): Linear(in_features=200, out_features=1, bias=True)
  (gmfc121): Linear(in_features=200, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=200, bias=True)
  (gmfe120): Linear(in_features=300, out_features=200, bias=True)
  (gmfe121): Linear(in_features=300, out_features=200, bias=True)
  (fc130): Linear(in_features=200, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=200, bias=True)
  (fe13): Linear(in_features=300, out_features=200, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=500, bias=True)
  (inputbn): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=500, out_features=500, bias=True)
  (bn0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=500, out_features=500, bias=True)
  (bn1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=500, out_features=500, bias=True)
  (bn2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=500, out_features=500, bias=True)
  (bn3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc4): Linear(in_features=500, out_features=500, bias=True)
  (bn4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=500, out_features=1, bias=True)
)
(2, True, 133)
(30148, 2)
-----------Epoch 0-----------
iterator 0, D_Loss:1.4644038677215576, G_Loss:9.716032981872559

iterator 100, D_Loss:1.3935743570327759, G_Loss:1.8752198219299316

iterator 200, D_Loss:1.4246183633804321, G_Loss:1.4786021709442139

iterator 300, D_Loss:1.3726952075958252, G_Loss:1.5243794918060303

iterator 400, D_Loss:1.3641862869262695, G_Loss:1.6800765991210938

iterator 500, D_Loss:1.3776495456695557, G_Loss:1.7188829183578491

iterator 600, D_Loss:1.3827475309371948, G_Loss:1.1924006938934326

iterator 700, D_Loss:1.3843541145324707, G_Loss:1.1597222089767456

iterator 800, D_Loss:1.3772939443588257, G_Loss:1.0885955095291138

iterator 900, D_Loss:1.4008145332336426, G_Loss:1.1027050018310547

iterator 1000, D_Loss:1.3872406482696533, G_Loss:1.0749218463897705

iterator 1100, D_Loss:1.3863009214401245, G_Loss:1.033519983291626

iterator 1200, D_Loss:1.3798680305480957, G_Loss:1.0002248287200928

iterator 1300, D_Loss:1.3649077415466309, G_Loss:0.9807761311531067

iterator 1400, D_Loss:1.3847525119781494, G_Loss:1.0047112703323364

iterator 1500, D_Loss:1.371555209159851, G_Loss:1.0189800262451172

iterator 1600, D_Loss:1.3636512756347656, G_Loss:1.001094102859497

iterator 1700, D_Loss:1.3719825744628906, G_Loss:1.181331753730774

iterator 1800, D_Loss:1.354404091835022, G_Loss:1.0842721462249756

iterator 1900, D_Loss:1.3545703887939453, G_Loss:1.0724761486053467

iterator 2000, D_Loss:1.351902723312378, G_Loss:1.0425875186920166

iterator 2100, D_Loss:1.3581223487854004, G_Loss:1.038718581199646

iterator 2200, D_Loss:1.349668264389038, G_Loss:1.0931509733200073

iterator 2300, D_Loss:1.3608975410461426, G_Loss:1.1037176847457886

iterator 2400, D_Loss:1.303464651107788, G_Loss:1.1587777137756348

iterator 2500, D_Loss:1.3045945167541504, G_Loss:1.059678554534912

iterator 2600, D_Loss:1.333279013633728, G_Loss:1.1901029348373413

iterator 2700, D_Loss:1.2177809476852417, G_Loss:1.4720215797424316

iterator 2800, D_Loss:1.2049003839492798, G_Loss:1.349299430847168

iterator 2900, D_Loss:1.0824379920959473, G_Loss:1.5896692276000977

iterator 3000, D_Loss:1.2038055658340454, G_Loss:1.5638630390167236

iterator 3100, D_Loss:1.105558156967163, G_Loss:1.760938048362732

iterator 3200, D_Loss:0.830994725227356, G_Loss:2.0468478202819824

iterator 3300, D_Loss:0.8774596452713013, G_Loss:1.8880515098571777

iterator 3400, D_Loss:0.7096840739250183, G_Loss:2.1804428100585938

iterator 3500, D_Loss:0.7942874431610107, G_Loss:1.7923980951309204

iterator 3600, D_Loss:0.8776019811630249, G_Loss:2.0400891304016113

iterator 3700, D_Loss:1.3473381996154785, G_Loss:2.448762893676758

iterator 3800, D_Loss:0.6717000007629395, G_Loss:2.1260509490966797

iterator 3900, D_Loss:1.3802237510681152, G_Loss:2.418238639831543

iterator 4000, D_Loss:0.6244039535522461, G_Loss:2.1358869075775146

iterator 4100, D_Loss:1.1351248025894165, G_Loss:2.8076295852661133

iterator 4200, D_Loss:1.106156349182129, G_Loss:1.711107850074768

iterator 4300, D_Loss:0.9179482460021973, G_Loss:2.1916844844818115

iterator 4400, D_Loss:0.707832932472229, G_Loss:1.7385201454162598

iterator 4500, D_Loss:0.6476254463195801, G_Loss:3.247616767883301

iterator 4600, D_Loss:0.741958737373352, G_Loss:2.7344212532043457

iterator 4700, D_Loss:1.2524470090866089, G_Loss:3.494356155395508

iterator 4800, D_Loss:0.7663336396217346, G_Loss:3.482489585876465

iterator 4900, D_Loss:0.6531111598014832, G_Loss:3.448162794113159

-----------Epoch 1-----------
iterator 0, D_Loss:0.7993250489234924, G_Loss:1.4387630224227905

iterator 100, D_Loss:0.5418688058853149, G_Loss:3.221014976501465

iterator 200, D_Loss:0.572108268737793, G_Loss:3.0496344566345215

iterator 300, D_Loss:1.590442180633545, G_Loss:2.8979434967041016

iterator 400, D_Loss:0.5993214249610901, G_Loss:3.13691782951355

iterator 500, D_Loss:0.6892702579498291, G_Loss:3.9234979152679443

iterator 600, D_Loss:0.7523230314254761, G_Loss:3.5281405448913574

iterator 700, D_Loss:0.7702150940895081, G_Loss:2.4545016288757324

iterator 800, D_Loss:0.8704910278320312, G_Loss:3.204223155975342

iterator 900, D_Loss:1.005985975265503, G_Loss:2.7663397789001465

iterator 1000, D_Loss:1.1207728385925293, G_Loss:3.742823600769043

iterator 1100, D_Loss:0.586584746837616, G_Loss:3.8832318782806396

iterator 1200, D_Loss:0.7566736936569214, G_Loss:3.604365110397339

iterator 1300, D_Loss:0.6941919922828674, G_Loss:3.345728874206543

iterator 1400, D_Loss:1.0903918743133545, G_Loss:3.8881983757019043

iterator 1500, D_Loss:0.5622609257698059, G_Loss:4.024312973022461

iterator 1600, D_Loss:0.6182379126548767, G_Loss:2.8619847297668457

iterator 1700, D_Loss:1.5324045419692993, G_Loss:1.979418158531189

iterator 1800, D_Loss:0.805343747138977, G_Loss:3.613802909851074

iterator 1900, D_Loss:0.6569530963897705, G_Loss:3.4786930084228516

iterator 2000, D_Loss:0.6891323328018188, G_Loss:4.4056396484375

iterator 2100, D_Loss:0.5053117871284485, G_Loss:4.199833869934082

iterator 2200, D_Loss:1.4349932670593262, G_Loss:1.0849521160125732

iterator 2300, D_Loss:1.0636764764785767, G_Loss:1.9639382362365723

iterator 2400, D_Loss:1.5061469078063965, G_Loss:3.011338949203491

iterator 2500, D_Loss:0.6892510056495667, G_Loss:4.606131076812744

iterator 2600, D_Loss:0.5611280798912048, G_Loss:3.9075729846954346

iterator 2700, D_Loss:0.5904626846313477, G_Loss:3.5263805389404297

iterator 2800, D_Loss:1.1073987483978271, G_Loss:3.2690200805664062

iterator 2900, D_Loss:0.4986611604690552, G_Loss:2.379279851913452

iterator 3000, D_Loss:0.773398756980896, G_Loss:1.9873030185699463

iterator 3100, D_Loss:0.6586306095123291, G_Loss:4.518852710723877

iterator 3200, D_Loss:0.6534000039100647, G_Loss:3.530700445175171

iterator 3300, D_Loss:0.4838751256465912, G_Loss:3.15697979927063

iterator 3400, D_Loss:0.612231969833374, G_Loss:2.651482105255127

iterator 3500, D_Loss:0.4846019148826599, G_Loss:3.0841050148010254

iterator 3600, D_Loss:0.6807073354721069, G_Loss:2.3488030433654785

iterator 3700, D_Loss:0.5317381024360657, G_Loss:2.1941323280334473

iterator 3800, D_Loss:2.271570920944214, G_Loss:4.89370584487915

iterator 3900, D_Loss:0.5987122058868408, G_Loss:3.598015308380127

iterator 4000, D_Loss:0.5456925630569458, G_Loss:2.4896554946899414

iterator 4100, D_Loss:1.401232123374939, G_Loss:5.046456336975098

iterator 4200, D_Loss:1.604352593421936, G_Loss:3.441026449203491

iterator 4300, D_Loss:0.5178044438362122, G_Loss:4.494423866271973

iterator 4400, D_Loss:0.4755808711051941, G_Loss:3.192152976989746

iterator 4500, D_Loss:0.6698728799819946, G_Loss:5.128743648529053

iterator 4600, D_Loss:0.5992130637168884, G_Loss:2.4448647499084473

iterator 4700, D_Loss:0.7939742803573608, G_Loss:5.772032260894775

iterator 4800, D_Loss:0.6946711540222168, G_Loss:5.0067291259765625

iterator 4900, D_Loss:0.7074406743049622, G_Loss:1.5237607955932617

-----------Epoch 2-----------
iterator 0, D_Loss:0.49199798703193665, G_Loss:5.355096340179443

iterator 100, D_Loss:0.5083134174346924, G_Loss:1.7307178974151611

iterator 200, D_Loss:0.5438037514686584, G_Loss:3.6317200660705566

iterator 300, D_Loss:0.7359035015106201, G_Loss:2.97137451171875

iterator 400, D_Loss:0.6632388234138489, G_Loss:3.538984775543213

iterator 500, D_Loss:0.47541195154190063, G_Loss:4.028189659118652

iterator 600, D_Loss:0.6252431273460388, G_Loss:4.263006210327148

iterator 700, D_Loss:0.5415716767311096, G_Loss:3.0850675106048584

iterator 800, D_Loss:3.0566775798797607, G_Loss:5.380743026733398

iterator 900, D_Loss:0.592677652835846, G_Loss:4.878292560577393

iterator 1000, D_Loss:0.7494757175445557, G_Loss:3.92437744140625

iterator 1100, D_Loss:0.6053227186203003, G_Loss:2.862112522125244

iterator 1200, D_Loss:0.5093078017234802, G_Loss:4.766500473022461

iterator 1300, D_Loss:0.5719844698905945, G_Loss:3.815025568008423

iterator 1400, D_Loss:0.49149203300476074, G_Loss:4.797379493713379

iterator 1500, D_Loss:0.44675081968307495, G_Loss:4.995295524597168

iterator 1600, D_Loss:0.5479896068572998, G_Loss:4.796800136566162

iterator 1700, D_Loss:0.6818180084228516, G_Loss:3.855105400085449

iterator 1800, D_Loss:0.5122344493865967, G_Loss:3.450784683227539

iterator 1900, D_Loss:0.5009974837303162, G_Loss:5.682929992675781

iterator 2000, D_Loss:0.4864247441291809, G_Loss:4.527352333068848

iterator 2100, D_Loss:0.5348958373069763, G_Loss:5.029200553894043

iterator 2200, D_Loss:0.49418583512306213, G_Loss:6.601651191711426

iterator 2300, D_Loss:0.4667339324951172, G_Loss:2.3848488330841064

iterator 2400, D_Loss:0.49694734811782837, G_Loss:4.321857452392578

iterator 2500, D_Loss:0.5139561295509338, G_Loss:4.566735744476318

iterator 2600, D_Loss:0.5517019629478455, G_Loss:2.5126121044158936

iterator 2700, D_Loss:0.7860686182975769, G_Loss:1.397183895111084

iterator 2800, D_Loss:0.4744332432746887, G_Loss:4.151322841644287

iterator 2900, D_Loss:0.5754192471504211, G_Loss:3.6130149364471436

iterator 3000, D_Loss:0.49578261375427246, G_Loss:4.160518169403076

iterator 3100, D_Loss:0.49291548132896423, G_Loss:3.750136375427246

iterator 3200, D_Loss:0.4722025692462921, G_Loss:6.258041858673096

iterator 3300, D_Loss:0.5646501779556274, G_Loss:4.658503532409668

iterator 3400, D_Loss:0.4976547658443451, G_Loss:5.243155002593994

iterator 3500, D_Loss:0.5103529691696167, G_Loss:4.711847305297852

iterator 3600, D_Loss:0.4397355020046234, G_Loss:3.918271541595459

iterator 3700, D_Loss:0.5663046836853027, G_Loss:6.796955585479736

iterator 3800, D_Loss:0.6247785091400146, G_Loss:4.121760368347168

iterator 3900, D_Loss:0.4951096177101135, G_Loss:4.173461437225342

iterator 4000, D_Loss:2.1829190254211426, G_Loss:3.7054178714752197

iterator 4100, D_Loss:0.4660429358482361, G_Loss:3.2874417304992676

iterator 4200, D_Loss:0.6576752662658691, G_Loss:4.235027313232422

iterator 4300, D_Loss:0.5630772113800049, G_Loss:3.8085060119628906

iterator 4400, D_Loss:0.5400571823120117, G_Loss:5.07600736618042

iterator 4500, D_Loss:0.4777470529079437, G_Loss:3.9612679481506348

iterator 4600, D_Loss:0.5149634480476379, G_Loss:5.940918922424316

iterator 4700, D_Loss:0.972521185874939, G_Loss:5.481412887573242

iterator 4800, D_Loss:0.4758968651294708, G_Loss:3.8058853149414062

iterator 4900, D_Loss:0.5351970195770264, G_Loss:5.854094505310059

-----------Epoch 3-----------
iterator 0, D_Loss:0.46044671535491943, G_Loss:4.16847038269043

iterator 100, D_Loss:1.0533573627471924, G_Loss:3.3710451126098633

iterator 200, D_Loss:0.5277560353279114, G_Loss:3.8779191970825195

iterator 300, D_Loss:0.6163768172264099, G_Loss:5.137398719787598

iterator 400, D_Loss:0.5078639388084412, G_Loss:5.055474281311035

iterator 500, D_Loss:0.5557124614715576, G_Loss:5.414007663726807

iterator 600, D_Loss:0.5088011622428894, G_Loss:5.653363227844238

iterator 700, D_Loss:0.4933278560638428, G_Loss:5.445876121520996

iterator 800, D_Loss:0.47069022059440613, G_Loss:3.964127779006958

iterator 900, D_Loss:0.4788907766342163, G_Loss:6.340090751647949

iterator 1000, D_Loss:0.4726581871509552, G_Loss:4.586345195770264

iterator 1100, D_Loss:0.4437062740325928, G_Loss:5.28732967376709

iterator 1200, D_Loss:0.6174451112747192, G_Loss:5.975006103515625

iterator 1300, D_Loss:0.4595002830028534, G_Loss:5.217025279998779

iterator 1400, D_Loss:0.8354799747467041, G_Loss:3.733308792114258

iterator 1500, D_Loss:0.4991983473300934, G_Loss:5.565825462341309

iterator 1600, D_Loss:0.48340192437171936, G_Loss:4.676974773406982

iterator 1700, D_Loss:0.497205913066864, G_Loss:5.369391441345215

iterator 1800, D_Loss:0.444161981344223, G_Loss:6.254255294799805

iterator 1900, D_Loss:0.5814359188079834, G_Loss:5.303627967834473

iterator 2000, D_Loss:0.73496413230896, G_Loss:5.512479305267334

iterator 2100, D_Loss:0.47902238368988037, G_Loss:5.512607574462891

iterator 2200, D_Loss:0.4749034345149994, G_Loss:6.723749160766602

iterator 2300, D_Loss:0.4561484754085541, G_Loss:4.179308891296387

iterator 2400, D_Loss:0.5735076665878296, G_Loss:6.0668230056762695

iterator 2500, D_Loss:0.4527626931667328, G_Loss:5.920774459838867

iterator 2600, D_Loss:0.49718010425567627, G_Loss:1.9588605165481567

iterator 2700, D_Loss:0.5666193962097168, G_Loss:5.5978288650512695

iterator 2800, D_Loss:0.5115431547164917, G_Loss:5.2599711418151855

iterator 2900, D_Loss:0.4421202838420868, G_Loss:3.5310378074645996

iterator 3000, D_Loss:0.44626620411872864, G_Loss:4.947720527648926

iterator 3100, D_Loss:0.4712430238723755, G_Loss:7.00506067276001

iterator 3200, D_Loss:0.5500891804695129, G_Loss:2.8511908054351807

iterator 3300, D_Loss:0.5146624445915222, G_Loss:6.491336822509766

iterator 3400, D_Loss:0.45266711711883545, G_Loss:3.828251361846924

iterator 3500, D_Loss:1.1155787706375122, G_Loss:3.20957612991333

iterator 3600, D_Loss:0.6719712615013123, G_Loss:7.308219909667969

iterator 3700, D_Loss:0.6826772093772888, G_Loss:7.048131942749023

iterator 3800, D_Loss:0.6523227095603943, G_Loss:3.9849965572357178

iterator 3900, D_Loss:0.47263404726982117, G_Loss:6.9671630859375

iterator 4000, D_Loss:0.48556697368621826, G_Loss:5.534873962402344

iterator 4100, D_Loss:0.502668559551239, G_Loss:5.160582542419434

iterator 4200, D_Loss:0.42487195134162903, G_Loss:5.802618026733398

iterator 4300, D_Loss:0.46529942750930786, G_Loss:6.243067741394043

iterator 4400, D_Loss:0.4556887149810791, G_Loss:6.154139041900635

iterator 4500, D_Loss:0.4595896601676941, G_Loss:7.134941101074219

iterator 4600, D_Loss:0.45870786905288696, G_Loss:7.007238388061523

iterator 4700, D_Loss:0.4737548232078552, G_Loss:4.3481764793396

iterator 4800, D_Loss:0.6234256625175476, G_Loss:6.096432685852051

iterator 4900, D_Loss:0.8985646963119507, G_Loss:7.646814823150635

-----------Epoch 4-----------
iterator 0, D_Loss:0.4554079473018646, G_Loss:5.711610794067383

iterator 100, D_Loss:0.7795108556747437, G_Loss:5.67426872253418

iterator 200, D_Loss:0.43810132145881653, G_Loss:5.65507698059082

iterator 300, D_Loss:0.44612258672714233, G_Loss:6.944977760314941

iterator 400, D_Loss:0.4705922603607178, G_Loss:7.182570457458496

iterator 500, D_Loss:0.48629963397979736, G_Loss:5.235997200012207

iterator 600, D_Loss:0.4464484751224518, G_Loss:4.43425989151001

iterator 700, D_Loss:0.4556370675563812, G_Loss:7.920866012573242

iterator 800, D_Loss:0.4104502499103546, G_Loss:5.980283737182617

iterator 900, D_Loss:0.4372805058956146, G_Loss:7.836193084716797

iterator 1000, D_Loss:0.46199867129325867, G_Loss:7.572431564331055

iterator 1100, D_Loss:0.43658581376075745, G_Loss:5.799098968505859

iterator 1200, D_Loss:0.44146493077278137, G_Loss:6.818859100341797

iterator 1300, D_Loss:0.43714532256126404, G_Loss:6.814970016479492

iterator 1400, D_Loss:0.4621303379535675, G_Loss:6.899529933929443

iterator 1500, D_Loss:0.5006077289581299, G_Loss:7.759314060211182

iterator 1600, D_Loss:0.4842737317085266, G_Loss:8.85633659362793

iterator 1700, D_Loss:0.5524799823760986, G_Loss:6.536643028259277

iterator 1800, D_Loss:0.4497221112251282, G_Loss:7.121369361877441

iterator 1900, D_Loss:0.4499168395996094, G_Loss:7.608150005340576

iterator 2000, D_Loss:0.4408966302871704, G_Loss:8.098140716552734

iterator 2100, D_Loss:0.49428603053092957, G_Loss:7.003437042236328

iterator 2200, D_Loss:0.45370620489120483, G_Loss:7.206550598144531

iterator 2300, D_Loss:0.4250277280807495, G_Loss:7.753123760223389

iterator 2400, D_Loss:0.4699322283267975, G_Loss:3.78863525390625

iterator 2500, D_Loss:0.473405659198761, G_Loss:6.8300461769104

iterator 2600, D_Loss:0.4825747609138489, G_Loss:7.194175720214844

iterator 2700, D_Loss:0.4920256733894348, G_Loss:8.22598934173584

iterator 2800, D_Loss:0.44723567366600037, G_Loss:6.889078617095947

iterator 2900, D_Loss:0.43823716044425964, G_Loss:4.505799293518066

iterator 3000, D_Loss:0.44116857647895813, G_Loss:7.378857612609863

iterator 3100, D_Loss:0.4556080400943756, G_Loss:7.3339314460754395

iterator 3200, D_Loss:0.45994552969932556, G_Loss:3.3899121284484863

iterator 3300, D_Loss:0.4509723484516144, G_Loss:7.323312759399414

iterator 3400, D_Loss:0.43422287702560425, G_Loss:3.682642936706543

iterator 3500, D_Loss:0.5417656898498535, G_Loss:2.5438034534454346

iterator 3600, D_Loss:0.44306236505508423, G_Loss:8.143891334533691

iterator 3700, D_Loss:0.4897339940071106, G_Loss:8.473189353942871

iterator 3800, D_Loss:0.45126089453697205, G_Loss:6.614765167236328

iterator 3900, D_Loss:0.43519365787506104, G_Loss:8.477975845336914

iterator 4000, D_Loss:0.5695940852165222, G_Loss:5.7511887550354

iterator 4100, D_Loss:0.4350926876068115, G_Loss:7.572232246398926

iterator 4200, D_Loss:0.491824746131897, G_Loss:8.076332092285156

iterator 4300, D_Loss:0.45895370841026306, G_Loss:7.294254779815674

iterator 4400, D_Loss:0.48179465532302856, G_Loss:6.786176681518555

iterator 4500, D_Loss:0.4575365483760834, G_Loss:4.157011032104492

iterator 4600, D_Loss:0.5039365291595459, G_Loss:6.942587852478027

iterator 4700, D_Loss:0.4423064887523651, G_Loss:4.103713035583496

iterator 4800, D_Loss:0.44239291548728943, G_Loss:8.074854850769043

iterator 4900, D_Loss:0.690907895565033, G_Loss:7.807987689971924

-----------Epoch 5-----------
iterator 0, D_Loss:0.44231098890304565, G_Loss:3.267226457595825

iterator 100, D_Loss:0.43604689836502075, G_Loss:6.903918743133545

iterator 200, D_Loss:0.6675801277160645, G_Loss:6.589345932006836

iterator 300, D_Loss:0.4513290822505951, G_Loss:8.762737274169922

iterator 400, D_Loss:0.5155321359634399, G_Loss:8.785771369934082

iterator 500, D_Loss:0.4599016606807709, G_Loss:7.736457824707031

iterator 600, D_Loss:0.46654224395751953, G_Loss:8.315796852111816

iterator 700, D_Loss:0.4463490843772888, G_Loss:5.69222354888916

iterator 800, D_Loss:0.4298584759235382, G_Loss:7.173806190490723

iterator 900, D_Loss:0.45920515060424805, G_Loss:8.022905349731445

iterator 1000, D_Loss:0.5654416084289551, G_Loss:9.147258758544922

iterator 1100, D_Loss:0.4530467391014099, G_Loss:7.861454010009766

iterator 1200, D_Loss:0.5033362507820129, G_Loss:9.95150089263916

iterator 1300, D_Loss:0.5777157545089722, G_Loss:9.321863174438477

iterator 1400, D_Loss:1.1622755527496338, G_Loss:1.537436604499817

iterator 1500, D_Loss:0.4513225555419922, G_Loss:8.408099174499512

iterator 1600, D_Loss:0.5477675199508667, G_Loss:7.22587776184082

iterator 1700, D_Loss:0.49618253111839294, G_Loss:7.232256889343262

iterator 1800, D_Loss:0.45580482482910156, G_Loss:8.099452018737793

iterator 1900, D_Loss:0.4599917232990265, G_Loss:2.672163963317871

iterator 2000, D_Loss:0.4313127100467682, G_Loss:4.34137487411499

iterator 2100, D_Loss:1.1523357629776, G_Loss:3.9640238285064697

iterator 2200, D_Loss:0.45444005727767944, G_Loss:7.303340911865234

iterator 2300, D_Loss:0.4694020450115204, G_Loss:9.866219520568848

iterator 2400, D_Loss:0.43697836995124817, G_Loss:6.717970848083496

iterator 2500, D_Loss:0.43253666162490845, G_Loss:8.789498329162598

iterator 2600, D_Loss:0.42771822214126587, G_Loss:4.55795955657959

iterator 2700, D_Loss:0.7086079120635986, G_Loss:7.799144744873047

iterator 2800, D_Loss:0.843652606010437, G_Loss:6.6274919509887695

iterator 2900, D_Loss:0.4595894515514374, G_Loss:9.45896053314209

iterator 3000, D_Loss:0.487047404050827, G_Loss:7.42342472076416

iterator 3100, D_Loss:0.4322482943534851, G_Loss:4.412242412567139

iterator 3200, D_Loss:0.5318986177444458, G_Loss:2.807715654373169

iterator 3300, D_Loss:0.6999841928482056, G_Loss:7.641640663146973

iterator 3400, D_Loss:0.4448569118976593, G_Loss:8.163847923278809

iterator 3500, D_Loss:0.44249171018600464, G_Loss:6.675592422485352

iterator 3600, D_Loss:0.4440212547779083, G_Loss:10.378549575805664

iterator 3700, D_Loss:0.4163883626461029, G_Loss:7.270765781402588

iterator 3800, D_Loss:0.4549259543418884, G_Loss:5.568687438964844

iterator 3900, D_Loss:0.8009560704231262, G_Loss:4.41588020324707

iterator 4000, D_Loss:0.4282958209514618, G_Loss:2.6455695629119873

iterator 4100, D_Loss:0.4210151731967926, G_Loss:9.010161399841309

iterator 4200, D_Loss:0.5635197758674622, G_Loss:6.85578727722168

iterator 4300, D_Loss:0.4172394275665283, G_Loss:6.794824600219727

iterator 4400, D_Loss:0.4585740268230438, G_Loss:7.057494163513184

iterator 4500, D_Loss:0.43671736121177673, G_Loss:9.607913970947266

iterator 4600, D_Loss:0.41509559750556946, G_Loss:8.952998161315918

iterator 4700, D_Loss:0.4472479522228241, G_Loss:6.273986339569092

iterator 4800, D_Loss:0.6239938735961914, G_Loss:8.191727638244629

iterator 4900, D_Loss:0.4088781774044037, G_Loss:7.049230098724365

-----------Epoch 6-----------
iterator 0, D_Loss:0.9956120252609253, G_Loss:6.643204212188721

iterator 100, D_Loss:0.5313791036605835, G_Loss:8.099772453308105

iterator 200, D_Loss:0.4499988257884979, G_Loss:5.509225368499756

iterator 300, D_Loss:0.45504051446914673, G_Loss:7.161529541015625

iterator 400, D_Loss:0.4524490237236023, G_Loss:6.464437961578369

iterator 500, D_Loss:0.4510051906108856, G_Loss:9.340851783752441

iterator 600, D_Loss:0.4510103166103363, G_Loss:3.780327796936035

iterator 700, D_Loss:0.41167905926704407, G_Loss:2.57731294631958

iterator 800, D_Loss:0.5034546256065369, G_Loss:8.899362564086914

iterator 900, D_Loss:0.47586140036582947, G_Loss:7.120323181152344

iterator 1000, D_Loss:2.5235438346862793, G_Loss:7.789309978485107

iterator 1100, D_Loss:0.43735724687576294, G_Loss:4.473945140838623

iterator 1200, D_Loss:0.4597873091697693, G_Loss:3.7516438961029053

iterator 1300, D_Loss:0.4390128254890442, G_Loss:3.108792304992676

iterator 1400, D_Loss:0.42327195405960083, G_Loss:3.8051676750183105

iterator 1500, D_Loss:0.4490392804145813, G_Loss:7.3988213539123535

iterator 1600, D_Loss:0.9010234475135803, G_Loss:6.155091762542725

iterator 1700, D_Loss:0.4906146824359894, G_Loss:5.341632843017578

iterator 1800, D_Loss:0.4535449743270874, G_Loss:3.232545852661133

iterator 1900, D_Loss:0.45176205039024353, G_Loss:5.437067985534668

iterator 2000, D_Loss:0.6058350801467896, G_Loss:8.332466125488281

iterator 2100, D_Loss:2.1946864128112793, G_Loss:9.062106132507324

iterator 2200, D_Loss:0.46190232038497925, G_Loss:5.5831379890441895

iterator 2300, D_Loss:0.47301754355430603, G_Loss:3.5299439430236816

iterator 2400, D_Loss:0.4570106863975525, G_Loss:8.194194793701172

iterator 2500, D_Loss:1.0215452909469604, G_Loss:3.696188449859619

iterator 2600, D_Loss:0.41933485865592957, G_Loss:8.956623077392578

iterator 2700, D_Loss:0.5754756927490234, G_Loss:7.031159400939941

iterator 2800, D_Loss:0.4396832585334778, G_Loss:1.2875319719314575

iterator 2900, D_Loss:0.46375295519828796, G_Loss:6.23471736907959

iterator 3000, D_Loss:0.6215035915374756, G_Loss:4.391669273376465

iterator 3100, D_Loss:0.4336302578449249, G_Loss:8.36434555053711

iterator 3200, D_Loss:0.5221655368804932, G_Loss:7.267108917236328

iterator 3300, D_Loss:0.6120179891586304, G_Loss:2.246417760848999

iterator 3400, D_Loss:0.4566969871520996, G_Loss:6.840478420257568

iterator 3500, D_Loss:0.4710075855255127, G_Loss:8.94000244140625

iterator 3600, D_Loss:0.4612411558628082, G_Loss:4.343754768371582

iterator 3700, D_Loss:0.44307413697242737, G_Loss:3.95857572555542

iterator 3800, D_Loss:0.46408265829086304, G_Loss:8.215099334716797

iterator 3900, D_Loss:0.588984489440918, G_Loss:8.560663223266602

iterator 4000, D_Loss:0.4454857409000397, G_Loss:9.853837013244629

iterator 4100, D_Loss:0.4446903169155121, G_Loss:7.122569561004639

iterator 4200, D_Loss:0.4534415006637573, G_Loss:6.434691905975342

iterator 4300, D_Loss:0.4740465581417084, G_Loss:6.205418586730957

iterator 4400, D_Loss:0.41006338596343994, G_Loss:6.757211685180664

iterator 4500, D_Loss:0.442365825176239, G_Loss:7.695006847381592

iterator 4600, D_Loss:0.7897976040840149, G_Loss:7.561648368835449

iterator 4700, D_Loss:0.4715871214866638, G_Loss:8.715245246887207

iterator 4800, D_Loss:0.5044391751289368, G_Loss:5.936831474304199

iterator 4900, D_Loss:0.5868945121765137, G_Loss:9.459357261657715

-----------Epoch 7-----------
iterator 0, D_Loss:0.4264703094959259, G_Loss:8.476447105407715

iterator 100, D_Loss:0.4556277394294739, G_Loss:4.21525764465332

iterator 200, D_Loss:1.4276593923568726, G_Loss:7.786703109741211

iterator 300, D_Loss:0.5322096943855286, G_Loss:8.252443313598633

iterator 400, D_Loss:0.6890593767166138, G_Loss:9.068359375

iterator 500, D_Loss:0.41029152274131775, G_Loss:5.890627384185791

iterator 600, D_Loss:0.45453885197639465, G_Loss:5.200069427490234

iterator 700, D_Loss:0.4252398610115051, G_Loss:6.803151607513428

iterator 800, D_Loss:1.5057226419448853, G_Loss:2.5416407585144043

iterator 900, D_Loss:0.457387238740921, G_Loss:7.665292263031006

iterator 1000, D_Loss:0.46809449791908264, G_Loss:8.395508766174316

iterator 1100, D_Loss:0.5139806866645813, G_Loss:4.415726661682129

iterator 1200, D_Loss:0.4348739981651306, G_Loss:8.906232833862305

iterator 1300, D_Loss:0.7243208289146423, G_Loss:4.5468292236328125

iterator 1400, D_Loss:0.48609375953674316, G_Loss:6.145975589752197

iterator 1500, D_Loss:0.4472183287143707, G_Loss:6.017856597900391

iterator 1600, D_Loss:0.4397006034851074, G_Loss:5.2642316818237305

iterator 1700, D_Loss:0.42925775051116943, G_Loss:6.426513195037842

iterator 1800, D_Loss:0.4462890028953552, G_Loss:7.231828689575195

iterator 1900, D_Loss:0.48757046461105347, G_Loss:7.9944539070129395

iterator 2000, D_Loss:0.4738961458206177, G_Loss:9.13593578338623

iterator 2100, D_Loss:0.44349756836891174, G_Loss:2.7969326972961426

iterator 2200, D_Loss:0.42965447902679443, G_Loss:2.6594648361206055

iterator 2300, D_Loss:0.4353657364845276, G_Loss:8.583518981933594

iterator 2400, D_Loss:0.5135928392410278, G_Loss:5.250604629516602

iterator 2500, D_Loss:0.4934329390525818, G_Loss:5.317035675048828

iterator 2600, D_Loss:0.42749494314193726, G_Loss:6.988948822021484

iterator 2700, D_Loss:0.501645028591156, G_Loss:9.439163208007812

iterator 2800, D_Loss:0.4444248676300049, G_Loss:8.998566627502441

iterator 2900, D_Loss:0.4639897048473358, G_Loss:2.9935741424560547

iterator 3000, D_Loss:0.4669927656650543, G_Loss:5.237828254699707

iterator 3100, D_Loss:0.4541454017162323, G_Loss:3.1199727058410645

iterator 3200, D_Loss:0.47302475571632385, G_Loss:10.285317420959473

iterator 3300, D_Loss:0.44332215189933777, G_Loss:4.154094696044922

iterator 3400, D_Loss:0.4939866065979004, G_Loss:6.014870643615723

iterator 3500, D_Loss:0.45269498229026794, G_Loss:6.615321159362793

iterator 3600, D_Loss:0.4383816719055176, G_Loss:8.492822647094727

iterator 3700, D_Loss:0.6008664965629578, G_Loss:6.359043121337891

iterator 3800, D_Loss:0.5817227363586426, G_Loss:5.643260955810547

iterator 3900, D_Loss:0.44055914878845215, G_Loss:7.445291996002197

iterator 4000, D_Loss:0.4647112190723419, G_Loss:8.090736389160156

iterator 4100, D_Loss:0.4498838484287262, G_Loss:4.445895671844482

iterator 4200, D_Loss:0.44211068749427795, G_Loss:9.574823379516602

iterator 4300, D_Loss:1.1616599559783936, G_Loss:5.252236843109131

iterator 4400, D_Loss:0.4348025321960449, G_Loss:7.535112380981445

iterator 4500, D_Loss:0.512201189994812, G_Loss:9.113361358642578

iterator 4600, D_Loss:0.43706583976745605, G_Loss:5.311372756958008

iterator 4700, D_Loss:0.44620755314826965, G_Loss:2.722932815551758

iterator 4800, D_Loss:0.4664885699748993, G_Loss:3.813229560852051

iterator 4900, D_Loss:0.5856113433837891, G_Loss:6.426126480102539

-----------Epoch 8-----------
iterator 0, D_Loss:0.45588448643684387, G_Loss:4.354433536529541

iterator 100, D_Loss:0.4765789210796356, G_Loss:6.222254276275635

iterator 200, D_Loss:0.5669710636138916, G_Loss:2.24747896194458

iterator 300, D_Loss:0.4340622127056122, G_Loss:7.468791961669922

iterator 400, D_Loss:0.848637044429779, G_Loss:7.889243125915527

iterator 500, D_Loss:0.4697933793067932, G_Loss:8.586048126220703

iterator 600, D_Loss:0.44508758187294006, G_Loss:9.385185241699219

iterator 700, D_Loss:0.41857069730758667, G_Loss:6.835774898529053

iterator 800, D_Loss:0.4381575882434845, G_Loss:9.915215492248535

iterator 900, D_Loss:0.41434401273727417, G_Loss:8.165441513061523

iterator 1000, D_Loss:0.4473098814487457, G_Loss:6.234481334686279

iterator 1100, D_Loss:0.4600560963153839, G_Loss:8.517152786254883

iterator 1200, D_Loss:0.5606920719146729, G_Loss:3.532864570617676

iterator 1300, D_Loss:0.42635485529899597, G_Loss:4.275289058685303

iterator 1400, D_Loss:0.5606963038444519, G_Loss:5.449230194091797

iterator 1500, D_Loss:0.45284736156463623, G_Loss:3.9491593837738037

iterator 1600, D_Loss:0.42875227332115173, G_Loss:5.757741451263428

iterator 1700, D_Loss:0.49189168214797974, G_Loss:5.345771789550781

iterator 1800, D_Loss:0.46024182438850403, G_Loss:8.817100524902344

iterator 1900, D_Loss:0.4465271532535553, G_Loss:2.8897016048431396

iterator 2000, D_Loss:0.7448219060897827, G_Loss:5.155117034912109

iterator 2100, D_Loss:0.5741989016532898, G_Loss:4.87838077545166

iterator 2200, D_Loss:1.1266566514968872, G_Loss:9.20007610321045

iterator 2300, D_Loss:0.4383622109889984, G_Loss:8.131808280944824

iterator 2400, D_Loss:0.43345120549201965, G_Loss:6.395985126495361

iterator 2500, D_Loss:0.47118842601776123, G_Loss:9.161203384399414

iterator 2600, D_Loss:0.4721391797065735, G_Loss:4.076319217681885

iterator 2700, D_Loss:0.4551321864128113, G_Loss:7.138322830200195

iterator 2800, D_Loss:0.40709972381591797, G_Loss:9.59520435333252

iterator 2900, D_Loss:0.4506130516529083, G_Loss:9.74485969543457

iterator 3000, D_Loss:0.4387611746788025, G_Loss:8.711982727050781

iterator 3100, D_Loss:0.43741050362586975, G_Loss:9.232632637023926

iterator 3200, D_Loss:0.4372675120830536, G_Loss:9.82930850982666

iterator 3300, D_Loss:0.5002951622009277, G_Loss:5.453915596008301

iterator 3400, D_Loss:0.44110602140426636, G_Loss:5.233920097351074

iterator 3500, D_Loss:0.4452255070209503, G_Loss:9.591050148010254

iterator 3600, D_Loss:0.4289357662200928, G_Loss:9.135004043579102

iterator 3700, D_Loss:0.4783441126346588, G_Loss:8.798233032226562

iterator 3800, D_Loss:0.45143863558769226, G_Loss:9.508293151855469

iterator 3900, D_Loss:0.7401626110076904, G_Loss:1.9456398487091064

iterator 4000, D_Loss:0.5745714902877808, G_Loss:8.325600624084473

iterator 4100, D_Loss:0.4399706721305847, G_Loss:5.901350021362305

iterator 4200, D_Loss:0.5558027625083923, G_Loss:8.033095359802246

iterator 4300, D_Loss:0.5977376103401184, G_Loss:5.5126543045043945

iterator 4400, D_Loss:0.5286012887954712, G_Loss:6.048786163330078

iterator 4500, D_Loss:0.5076068639755249, G_Loss:7.318976402282715

iterator 4600, D_Loss:0.44084256887435913, G_Loss:8.768657684326172

iterator 4700, D_Loss:0.48655152320861816, G_Loss:4.103141784667969

iterator 4800, D_Loss:0.4851374924182892, G_Loss:4.56109619140625

iterator 4900, D_Loss:0.4549311399459839, G_Loss:9.513519287109375

-----------Epoch 9-----------
iterator 0, D_Loss:0.4626832604408264, G_Loss:3.343380928039551

iterator 100, D_Loss:0.8209336400032043, G_Loss:6.705063819885254

iterator 200, D_Loss:0.42141032218933105, G_Loss:7.533263206481934

iterator 300, D_Loss:0.48788145184516907, G_Loss:7.977715492248535

iterator 400, D_Loss:0.7427256107330322, G_Loss:2.4212839603424072

iterator 500, D_Loss:0.4093264937400818, G_Loss:8.61404037475586

iterator 600, D_Loss:0.5022474527359009, G_Loss:7.19193696975708

iterator 700, D_Loss:0.4346845746040344, G_Loss:4.025145530700684

iterator 800, D_Loss:0.4501340389251709, G_Loss:4.3532514572143555

iterator 900, D_Loss:2.3710522651672363, G_Loss:8.651832580566406

iterator 1000, D_Loss:0.44647476077079773, G_Loss:7.5464301109313965

iterator 1100, D_Loss:0.4856951832771301, G_Loss:7.872265815734863

iterator 1200, D_Loss:0.4742242395877838, G_Loss:6.521550178527832

iterator 1300, D_Loss:0.5550913214683533, G_Loss:2.5386061668395996

iterator 1400, D_Loss:0.4716140925884247, G_Loss:4.333774566650391

iterator 1500, D_Loss:1.379234790802002, G_Loss:7.439298152923584

iterator 1600, D_Loss:0.43785911798477173, G_Loss:6.935075759887695

iterator 1700, D_Loss:0.44595032930374146, G_Loss:3.3541951179504395

iterator 1800, D_Loss:0.6214312314987183, G_Loss:6.774527549743652

iterator 1900, D_Loss:0.45152831077575684, G_Loss:9.698989868164062

iterator 2000, D_Loss:0.4538458585739136, G_Loss:8.754815101623535

iterator 2100, D_Loss:0.5241467356681824, G_Loss:8.251585006713867

iterator 2200, D_Loss:0.47503185272216797, G_Loss:2.590106964111328

iterator 2300, D_Loss:0.4657392203807831, G_Loss:4.395373821258545

iterator 2400, D_Loss:0.5055511593818665, G_Loss:7.192380905151367

iterator 2500, D_Loss:0.4116978943347931, G_Loss:3.1109719276428223

iterator 2600, D_Loss:0.4978324770927429, G_Loss:9.320720672607422

iterator 2700, D_Loss:0.5392017960548401, G_Loss:4.788555145263672

iterator 2800, D_Loss:0.43313732743263245, G_Loss:4.467135429382324

iterator 2900, D_Loss:0.46110308170318604, G_Loss:7.6006011962890625

iterator 3000, D_Loss:0.5863357782363892, G_Loss:7.155305862426758

iterator 3100, D_Loss:0.48268142342567444, G_Loss:7.2262420654296875

iterator 3200, D_Loss:0.539776086807251, G_Loss:5.956346035003662

iterator 3300, D_Loss:0.5803708434104919, G_Loss:5.481383323669434

iterator 3400, D_Loss:0.5099428296089172, G_Loss:9.003150939941406

iterator 3500, D_Loss:0.5357449054718018, G_Loss:9.659957885742188

iterator 3600, D_Loss:0.4415538012981415, G_Loss:4.510317802429199

iterator 3700, D_Loss:0.4924839437007904, G_Loss:8.699601173400879

iterator 3800, D_Loss:0.49558088183403015, G_Loss:8.519872665405273

iterator 3900, D_Loss:0.7365943193435669, G_Loss:10.269613265991211

iterator 4000, D_Loss:0.4391430914402008, G_Loss:10.927153587341309

iterator 4100, D_Loss:0.5538648962974548, G_Loss:5.2798051834106445

iterator 4200, D_Loss:0.4493788778781891, G_Loss:7.656396865844727

iterator 4300, D_Loss:3.703826904296875, G_Loss:8.20985221862793

iterator 4400, D_Loss:0.6056133508682251, G_Loss:5.344554901123047

iterator 4500, D_Loss:0.557327151298523, G_Loss:7.128269195556641

iterator 4600, D_Loss:0.4776041805744171, G_Loss:6.468404293060303

iterator 4700, D_Loss:0.4424355924129486, G_Loss:2.9549360275268555

iterator 4800, D_Loss:0.4542474150657654, G_Loss:2.875892400741577

iterator 4900, D_Loss:0.4197424054145813, G_Loss:7.996331691741943

train row : 30148
sample row: 30148
LGAN_generator(
  (LSTM): LSTMCell(602, 200)
  (gmfc00): Linear(in_features=200, out_features=1, bias=True)
  (gmfc01): Linear(in_features=200, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=200, bias=True)
  (gmfe00): Linear(in_features=200, out_features=200, bias=True)
  (gmfe01): Linear(in_features=200, out_features=200, bias=True)
  (fc10): Linear(in_features=200, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=200, bias=True)
  (fe1): Linear(in_features=200, out_features=200, bias=True)
  (gmfc20): Linear(in_features=200, out_features=1, bias=True)
  (gmfc21): Linear(in_features=200, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=200, bias=True)
  (gmfe20): Linear(in_features=200, out_features=200, bias=True)
  (gmfe21): Linear(in_features=200, out_features=200, bias=True)
  (fc30): Linear(in_features=200, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=200, bias=True)
  (fe3): Linear(in_features=200, out_features=200, bias=True)
  (gmfc40): Linear(in_features=200, out_features=1, bias=True)
  (gmfc41): Linear(in_features=200, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=200, bias=True)
  (gmfe40): Linear(in_features=200, out_features=200, bias=True)
  (gmfe41): Linear(in_features=200, out_features=200, bias=True)
  (fc50): Linear(in_features=200, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=200, bias=True)
  (fe5): Linear(in_features=200, out_features=200, bias=True)
  (fc60): Linear(in_features=200, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=200, bias=True)
  (fe6): Linear(in_features=200, out_features=200, bias=True)
  (fc70): Linear(in_features=200, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=200, bias=True)
  (fe7): Linear(in_features=200, out_features=200, bias=True)
  (fc80): Linear(in_features=200, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=200, bias=True)
  (fe8): Linear(in_features=200, out_features=200, bias=True)
  (fc90): Linear(in_features=200, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=200, bias=True)
  (fe9): Linear(in_features=200, out_features=200, bias=True)
  (gmfc100): Linear(in_features=200, out_features=1, bias=True)
  (gmfc101): Linear(in_features=200, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=200, bias=True)
  (gmfe100): Linear(in_features=200, out_features=200, bias=True)
  (gmfe101): Linear(in_features=200, out_features=200, bias=True)
  (gmfc110): Linear(in_features=200, out_features=1, bias=True)
  (gmfc111): Linear(in_features=200, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=200, bias=True)
  (gmfe110): Linear(in_features=200, out_features=200, bias=True)
  (gmfe111): Linear(in_features=200, out_features=200, bias=True)
  (gmfc120): Linear(in_features=200, out_features=1, bias=True)
  (gmfc121): Linear(in_features=200, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=200, bias=True)
  (gmfe120): Linear(in_features=200, out_features=200, bias=True)
  (gmfe121): Linear(in_features=200, out_features=200, bias=True)
  (fc130): Linear(in_features=200, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=200, bias=True)
  (fe13): Linear(in_features=200, out_features=200, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=200, bias=True)
  (inputbn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (bn0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=200, out_features=200, bias=True)
  (bn1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=200, out_features=200, bias=True)
  (bn2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=200, out_features=1, bias=True)
)
-----------Epoch 0-----------
iterator 100, D_Loss:1.4076108932495117, G_Loss:1.4091508388519287

iterator 200, D_Loss:1.3507986068725586, G_Loss:1.7538478374481201

iterator 300, D_Loss:1.389392375946045, G_Loss:1.6839772462844849

iterator 400, D_Loss:1.391484022140503, G_Loss:1.224316120147705

iterator 500, D_Loss:1.3533117771148682, G_Loss:1.3485865592956543

iterator 600, D_Loss:1.291599154472351, G_Loss:1.5357486009597778

iterator 700, D_Loss:1.2912503480911255, G_Loss:1.363075613975525

iterator 800, D_Loss:1.1776632070541382, G_Loss:1.4752473831176758

iterator 900, D_Loss:1.1265473365783691, G_Loss:2.1880710124969482

iterator 1000, D_Loss:0.960490345954895, G_Loss:2.077592372894287

iterator 1100, D_Loss:0.876570463180542, G_Loss:1.6961102485656738

iterator 1200, D_Loss:0.7568536996841431, G_Loss:2.624951124191284

iterator 1300, D_Loss:0.776879608631134, G_Loss:2.964811325073242

iterator 1400, D_Loss:0.6316132545471191, G_Loss:3.0159144401550293

iterator 1500, D_Loss:0.6065219640731812, G_Loss:3.4832262992858887

iterator 1600, D_Loss:1.5842366218566895, G_Loss:1.9180066585540771

iterator 1700, D_Loss:1.15753173828125, G_Loss:1.6447046995162964

iterator 1800, D_Loss:0.8546011447906494, G_Loss:3.1409401893615723

iterator 1900, D_Loss:0.9897506237030029, G_Loss:2.388439655303955

iterator 2000, D_Loss:0.7788597345352173, G_Loss:2.4858875274658203

iterator 2100, D_Loss:0.6853373050689697, G_Loss:2.7956857681274414

iterator 2200, D_Loss:1.046972393989563, G_Loss:2.208489418029785

iterator 2300, D_Loss:0.9114471673965454, G_Loss:3.3992936611175537

iterator 2400, D_Loss:0.9177308082580566, G_Loss:2.158257484436035

iterator 2500, D_Loss:0.9217029809951782, G_Loss:2.313202381134033

iterator 2600, D_Loss:0.972723126411438, G_Loss:2.815054178237915

iterator 2700, D_Loss:0.9905533790588379, G_Loss:2.805640697479248

iterator 2800, D_Loss:0.9554128646850586, G_Loss:3.040003776550293

iterator 2900, D_Loss:1.1903380155563354, G_Loss:2.001418113708496

iterator 3000, D_Loss:0.8564156293869019, G_Loss:3.069812297821045

iterator 3100, D_Loss:0.9917765855789185, G_Loss:3.8826675415039062

iterator 3200, D_Loss:0.8872628211975098, G_Loss:3.449441909790039

iterator 3300, D_Loss:0.6956807374954224, G_Loss:3.2535462379455566

iterator 3400, D_Loss:1.0923571586608887, G_Loss:3.2649083137512207

iterator 3500, D_Loss:0.9730180501937866, G_Loss:2.4509830474853516

iterator 3600, D_Loss:0.6662852764129639, G_Loss:2.9995555877685547

iterator 3700, D_Loss:0.5953144431114197, G_Loss:2.3872013092041016

iterator 3800, D_Loss:0.7981414794921875, G_Loss:2.963249683380127

iterator 3900, D_Loss:0.7018685936927795, G_Loss:2.056234121322632

iterator 4000, D_Loss:0.9155257940292358, G_Loss:3.224639415740967

iterator 4100, D_Loss:0.7781726121902466, G_Loss:3.2888855934143066

iterator 4200, D_Loss:0.7595986127853394, G_Loss:3.598362922668457

iterator 4300, D_Loss:0.6010320782661438, G_Loss:3.8513545989990234

iterator 4400, D_Loss:0.7021229863166809, G_Loss:3.776423692703247

iterator 4500, D_Loss:0.5533902645111084, G_Loss:4.096828460693359

iterator 4600, D_Loss:0.6131033897399902, G_Loss:4.701224327087402

iterator 4700, D_Loss:0.6145151257514954, G_Loss:3.9816577434539795

iterator 4800, D_Loss:0.5881425738334656, G_Loss:3.5873501300811768

iterator 4900, D_Loss:0.5301794409751892, G_Loss:3.889866590499878

iterator 5000, D_Loss:0.8062868714332581, G_Loss:2.8556079864501953

-----------Epoch 1-----------
iterator 100, D_Loss:0.6840956211090088, G_Loss:2.6461071968078613

iterator 200, D_Loss:0.5195900797843933, G_Loss:4.000957489013672

iterator 300, D_Loss:0.4688934087753296, G_Loss:6.077071189880371

iterator 400, D_Loss:0.9661610126495361, G_Loss:3.2282185554504395

iterator 500, D_Loss:0.7547276020050049, G_Loss:3.762962818145752

iterator 600, D_Loss:0.607424795627594, G_Loss:3.479670524597168

iterator 700, D_Loss:0.8739449977874756, G_Loss:3.773594379425049

iterator 800, D_Loss:0.5043825507164001, G_Loss:4.476877689361572

iterator 900, D_Loss:0.7623144388198853, G_Loss:3.9405314922332764

iterator 1000, D_Loss:0.7200074195861816, G_Loss:4.440485000610352

iterator 1100, D_Loss:0.4729180634021759, G_Loss:4.894796371459961

iterator 1200, D_Loss:0.5181102156639099, G_Loss:6.414402961730957

iterator 1300, D_Loss:0.4502786099910736, G_Loss:4.746994972229004

iterator 1400, D_Loss:0.5575665235519409, G_Loss:6.079642295837402

iterator 1500, D_Loss:0.5256907343864441, G_Loss:4.752446174621582

iterator 1600, D_Loss:0.5157052278518677, G_Loss:5.124386787414551

iterator 1700, D_Loss:0.5207244157791138, G_Loss:3.54107403755188

iterator 1800, D_Loss:0.5300597548484802, G_Loss:4.1950764656066895

iterator 1900, D_Loss:0.6468554735183716, G_Loss:4.015876293182373

iterator 2000, D_Loss:0.4320618212223053, G_Loss:6.316560745239258

iterator 2100, D_Loss:0.563097357749939, G_Loss:5.76012659072876

iterator 2200, D_Loss:0.45514976978302, G_Loss:4.271988868713379

iterator 2300, D_Loss:0.5334415435791016, G_Loss:4.493801116943359

iterator 2400, D_Loss:0.545172393321991, G_Loss:5.142822265625

iterator 2500, D_Loss:0.5164655447006226, G_Loss:3.5316383838653564

iterator 2600, D_Loss:0.4928523600101471, G_Loss:4.598446846008301

iterator 2700, D_Loss:0.5977074503898621, G_Loss:6.737598419189453

iterator 2800, D_Loss:0.4878564774990082, G_Loss:3.711285352706909

iterator 2900, D_Loss:0.46540334820747375, G_Loss:5.293089866638184

iterator 3000, D_Loss:0.5509552359580994, G_Loss:6.086325168609619

iterator 3100, D_Loss:0.4634835124015808, G_Loss:5.966919422149658

iterator 3200, D_Loss:0.6008385419845581, G_Loss:6.9962921142578125

iterator 3300, D_Loss:0.4858166575431824, G_Loss:5.098756313323975

iterator 3400, D_Loss:0.5017785429954529, G_Loss:5.990060806274414

iterator 3500, D_Loss:0.5192345976829529, G_Loss:7.679142951965332

iterator 3600, D_Loss:0.5885518789291382, G_Loss:5.6173810958862305

iterator 3700, D_Loss:0.6763657331466675, G_Loss:5.078180313110352

iterator 3800, D_Loss:0.6377604603767395, G_Loss:3.4650721549987793

iterator 3900, D_Loss:0.4736025631427765, G_Loss:8.083304405212402

iterator 4000, D_Loss:0.5518094301223755, G_Loss:3.82547664642334

iterator 4100, D_Loss:0.5262390971183777, G_Loss:5.796092510223389

iterator 4200, D_Loss:0.49059179425239563, G_Loss:5.3559980392456055

iterator 4300, D_Loss:0.6311387419700623, G_Loss:4.924839019775391

iterator 4400, D_Loss:0.48876452445983887, G_Loss:7.304292678833008

iterator 4500, D_Loss:0.6717581748962402, G_Loss:6.68121337890625

iterator 4600, D_Loss:0.44777029752731323, G_Loss:6.5449113845825195

iterator 4700, D_Loss:0.5357567667961121, G_Loss:7.1575164794921875

iterator 4800, D_Loss:0.6551276445388794, G_Loss:5.829875946044922

iterator 4900, D_Loss:0.5275219082832336, G_Loss:5.498251914978027

iterator 5000, D_Loss:0.8315354585647583, G_Loss:8.038515090942383

-----------Epoch 2-----------
iterator 100, D_Loss:0.7907801866531372, G_Loss:3.9013943672180176

iterator 200, D_Loss:0.5108387470245361, G_Loss:6.261674880981445

iterator 300, D_Loss:0.49011334776878357, G_Loss:4.800846576690674

iterator 400, D_Loss:0.44809961318969727, G_Loss:6.973967552185059

iterator 500, D_Loss:0.6344488263130188, G_Loss:6.148988723754883

iterator 600, D_Loss:0.47448065876960754, G_Loss:6.552739143371582

iterator 700, D_Loss:0.5309967994689941, G_Loss:2.854703426361084

iterator 800, D_Loss:0.4698430597782135, G_Loss:5.527421951293945

iterator 900, D_Loss:1.608445644378662, G_Loss:4.233086109161377

iterator 1000, D_Loss:0.4574037790298462, G_Loss:4.986008644104004

iterator 1100, D_Loss:0.5911495685577393, G_Loss:5.098593711853027

iterator 1200, D_Loss:0.4982963800430298, G_Loss:2.539801836013794

iterator 1300, D_Loss:0.4651314318180084, G_Loss:7.60202169418335

iterator 1400, D_Loss:0.4679107964038849, G_Loss:5.233084678649902

iterator 1500, D_Loss:0.43683916330337524, G_Loss:6.1511125564575195

iterator 1600, D_Loss:0.6714872121810913, G_Loss:4.910276412963867

iterator 1700, D_Loss:0.698664128780365, G_Loss:6.151467800140381

iterator 1800, D_Loss:0.5368517637252808, G_Loss:4.951301097869873

iterator 1900, D_Loss:0.47965091466903687, G_Loss:6.139949798583984

iterator 2000, D_Loss:0.6794412732124329, G_Loss:8.359859466552734

iterator 2100, D_Loss:0.4846307337284088, G_Loss:6.680057525634766

iterator 2200, D_Loss:0.546500563621521, G_Loss:5.354630947113037

iterator 2300, D_Loss:0.44550490379333496, G_Loss:6.54001522064209

iterator 2400, D_Loss:0.5447421073913574, G_Loss:7.968676567077637

iterator 2500, D_Loss:0.43476009368896484, G_Loss:4.677534103393555

iterator 2600, D_Loss:0.5346837639808655, G_Loss:8.422358512878418

iterator 2700, D_Loss:0.47266289591789246, G_Loss:5.604342460632324

iterator 2800, D_Loss:0.551703929901123, G_Loss:7.493547439575195

iterator 2900, D_Loss:0.5202820897102356, G_Loss:7.491804599761963

iterator 3000, D_Loss:0.4771004617214203, G_Loss:6.14659309387207

iterator 3100, D_Loss:0.5263409614562988, G_Loss:4.31951904296875

iterator 3200, D_Loss:0.5375245213508606, G_Loss:4.633453369140625

iterator 3300, D_Loss:0.5889164805412292, G_Loss:5.066442489624023

iterator 3400, D_Loss:0.6735649704933167, G_Loss:4.130980491638184

iterator 3500, D_Loss:0.4926920235157013, G_Loss:7.5971360206604

iterator 3600, D_Loss:0.49720630049705505, G_Loss:3.2301430702209473

iterator 3700, D_Loss:0.42869964241981506, G_Loss:6.798369407653809

iterator 3800, D_Loss:0.8661125898361206, G_Loss:3.6032841205596924

iterator 3900, D_Loss:0.6690846681594849, G_Loss:5.23137092590332

iterator 4000, D_Loss:0.4589666724205017, G_Loss:5.920515537261963

iterator 4100, D_Loss:0.49298518896102905, G_Loss:8.365814208984375

iterator 4200, D_Loss:0.5319721102714539, G_Loss:7.897330284118652

iterator 4300, D_Loss:0.4963049292564392, G_Loss:4.221123218536377

iterator 4400, D_Loss:0.4625947177410126, G_Loss:6.962166786193848

iterator 4500, D_Loss:0.46792349219322205, G_Loss:3.7391419410705566

iterator 4600, D_Loss:0.5010190010070801, G_Loss:7.400062561035156

iterator 4700, D_Loss:0.4829801023006439, G_Loss:6.235496520996094

iterator 4800, D_Loss:1.7233288288116455, G_Loss:7.7039899826049805

iterator 4900, D_Loss:0.45375195145606995, G_Loss:5.305055618286133

iterator 5000, D_Loss:0.6193274259567261, G_Loss:5.730066299438477

-----------Epoch 3-----------
iterator 100, D_Loss:0.5397384166717529, G_Loss:5.058897018432617

iterator 200, D_Loss:0.8172259330749512, G_Loss:6.514614105224609

iterator 300, D_Loss:0.5038489103317261, G_Loss:4.926152229309082

iterator 400, D_Loss:0.5321317315101624, G_Loss:3.895092487335205

iterator 500, D_Loss:0.44869762659072876, G_Loss:4.734312057495117

iterator 600, D_Loss:0.5797299742698669, G_Loss:5.834596157073975

iterator 700, D_Loss:0.47633999586105347, G_Loss:4.456335067749023

iterator 800, D_Loss:0.4988524317741394, G_Loss:8.259324073791504

iterator 900, D_Loss:0.5016708970069885, G_Loss:6.743105888366699

iterator 1000, D_Loss:0.5393981337547302, G_Loss:6.591107368469238

iterator 1100, D_Loss:0.4957103729248047, G_Loss:6.053472995758057

iterator 1200, D_Loss:0.46537861227989197, G_Loss:5.63075065612793

iterator 1300, D_Loss:0.7713112235069275, G_Loss:4.792543888092041

iterator 1400, D_Loss:0.43851542472839355, G_Loss:4.3678083419799805

iterator 1500, D_Loss:0.49869638681411743, G_Loss:6.005361557006836

iterator 1600, D_Loss:0.6632903814315796, G_Loss:7.306252956390381

iterator 1700, D_Loss:0.7635517120361328, G_Loss:6.7480058670043945

iterator 1800, D_Loss:0.5154390335083008, G_Loss:7.591888427734375

iterator 1900, D_Loss:0.6078083515167236, G_Loss:6.986962795257568

iterator 2000, D_Loss:0.46214035153388977, G_Loss:8.472796440124512

iterator 2100, D_Loss:0.9559969902038574, G_Loss:5.888431072235107

iterator 2200, D_Loss:0.46919724345207214, G_Loss:7.981484413146973

iterator 2300, D_Loss:0.44411537051200867, G_Loss:6.937783241271973

iterator 2400, D_Loss:0.47646084427833557, G_Loss:6.624706268310547

iterator 2500, D_Loss:0.5125666260719299, G_Loss:3.1672258377075195

iterator 2600, D_Loss:0.6041662096977234, G_Loss:7.335801124572754

iterator 2700, D_Loss:0.5214532613754272, G_Loss:8.592143058776855

iterator 2800, D_Loss:0.4954027235507965, G_Loss:6.519453048706055

iterator 2900, D_Loss:0.4572852551937103, G_Loss:6.969333648681641

iterator 3000, D_Loss:0.4148557782173157, G_Loss:8.311297416687012

iterator 3100, D_Loss:0.5041536688804626, G_Loss:4.911716938018799

iterator 3200, D_Loss:0.4956761598587036, G_Loss:5.348743438720703

iterator 3300, D_Loss:0.4373043179512024, G_Loss:7.788387298583984

iterator 3400, D_Loss:0.4445207715034485, G_Loss:4.0615363121032715

iterator 3500, D_Loss:0.475227952003479, G_Loss:7.967386245727539

iterator 3600, D_Loss:0.5228994488716125, G_Loss:8.41305923461914

iterator 3700, D_Loss:0.5283232927322388, G_Loss:8.725569725036621

iterator 3800, D_Loss:0.6626519560813904, G_Loss:6.7101640701293945

iterator 3900, D_Loss:0.4853230118751526, G_Loss:9.753243446350098

iterator 4000, D_Loss:0.6382403373718262, G_Loss:6.009772777557373

iterator 4100, D_Loss:0.534673810005188, G_Loss:10.777410507202148

iterator 4200, D_Loss:0.45151975750923157, G_Loss:9.658864974975586

iterator 4300, D_Loss:0.4630027711391449, G_Loss:7.148567199707031

iterator 4400, D_Loss:0.4360724687576294, G_Loss:8.386968612670898

iterator 4500, D_Loss:0.415939599275589, G_Loss:7.757286071777344

iterator 4600, D_Loss:0.4827825427055359, G_Loss:5.056239128112793

iterator 4700, D_Loss:0.447696328163147, G_Loss:6.383790969848633

iterator 4800, D_Loss:0.677028477191925, G_Loss:9.940042495727539

iterator 4900, D_Loss:0.4282057285308838, G_Loss:7.455841064453125

iterator 5000, D_Loss:1.0883269309997559, G_Loss:7.733813285827637

-----------Epoch 4-----------
iterator 100, D_Loss:0.4883047342300415, G_Loss:4.7358598709106445

iterator 200, D_Loss:0.628966212272644, G_Loss:12.226792335510254

iterator 300, D_Loss:0.4975724220275879, G_Loss:8.39293098449707

iterator 400, D_Loss:0.450412780046463, G_Loss:4.85288667678833

iterator 500, D_Loss:0.9396374225616455, G_Loss:4.838939666748047

iterator 600, D_Loss:0.4535490572452545, G_Loss:11.253914833068848

iterator 700, D_Loss:0.7227821946144104, G_Loss:3.0272443294525146

iterator 800, D_Loss:0.529338002204895, G_Loss:4.41031551361084

iterator 900, D_Loss:0.4645656645298004, G_Loss:4.568028450012207

iterator 1000, D_Loss:0.4762980341911316, G_Loss:7.240623474121094

iterator 1100, D_Loss:0.5387046337127686, G_Loss:5.672882080078125

iterator 1200, D_Loss:0.747550368309021, G_Loss:8.87060832977295

iterator 1300, D_Loss:0.48007264733314514, G_Loss:7.712008953094482

iterator 1400, D_Loss:0.49296754598617554, G_Loss:7.332496166229248

iterator 1500, D_Loss:0.45550084114074707, G_Loss:7.181648254394531

iterator 1600, D_Loss:0.6411944627761841, G_Loss:4.849078178405762

iterator 1700, D_Loss:0.5791330933570862, G_Loss:6.842041492462158

iterator 1800, D_Loss:0.43339642882347107, G_Loss:6.510133743286133

iterator 1900, D_Loss:0.4633651375770569, G_Loss:7.203407287597656

iterator 2000, D_Loss:0.545234203338623, G_Loss:5.503815650939941

iterator 2100, D_Loss:0.5879940986633301, G_Loss:7.619382858276367

iterator 2200, D_Loss:0.5043952465057373, G_Loss:8.648242950439453

iterator 2300, D_Loss:0.46717286109924316, G_Loss:8.418529510498047

iterator 2400, D_Loss:0.45521458983421326, G_Loss:8.876051902770996

iterator 2500, D_Loss:0.38407257199287415, G_Loss:7.086976051330566

iterator 2600, D_Loss:0.4801236689090729, G_Loss:8.342955589294434

iterator 2700, D_Loss:0.5266513824462891, G_Loss:8.9781494140625

iterator 2800, D_Loss:0.41460883617401123, G_Loss:7.745416641235352

iterator 2900, D_Loss:0.4074687361717224, G_Loss:9.47578239440918

iterator 3000, D_Loss:0.593940258026123, G_Loss:10.194694519042969

iterator 3100, D_Loss:0.451086163520813, G_Loss:6.7334442138671875

iterator 3200, D_Loss:0.4544902443885803, G_Loss:8.692033767700195

iterator 3300, D_Loss:0.5002042055130005, G_Loss:8.370176315307617

iterator 3400, D_Loss:0.5109785199165344, G_Loss:7.250613689422607

iterator 3500, D_Loss:0.4623699188232422, G_Loss:8.060320854187012

iterator 3600, D_Loss:0.4899815022945404, G_Loss:11.413830757141113

iterator 3700, D_Loss:0.45056530833244324, G_Loss:9.25117301940918

iterator 3800, D_Loss:0.5304123163223267, G_Loss:10.081396102905273

iterator 3900, D_Loss:0.5007987022399902, G_Loss:6.601377487182617

iterator 4000, D_Loss:0.4707365036010742, G_Loss:7.378414154052734

iterator 4100, D_Loss:0.5331687927246094, G_Loss:4.163980960845947

iterator 4200, D_Loss:0.47099363803863525, G_Loss:7.293813228607178

iterator 4300, D_Loss:0.49447041749954224, G_Loss:6.958100318908691

iterator 4400, D_Loss:0.7237011194229126, G_Loss:8.147281646728516

iterator 4500, D_Loss:0.940762996673584, G_Loss:2.583731174468994

iterator 4600, D_Loss:0.512471616268158, G_Loss:11.526366233825684

iterator 4700, D_Loss:0.4557530879974365, G_Loss:9.33312702178955

iterator 4800, D_Loss:0.47128522396087646, G_Loss:8.784757614135742

iterator 4900, D_Loss:0.4585113227367401, G_Loss:5.964000701904297

iterator 5000, D_Loss:0.563677191734314, G_Loss:9.223093032836914

-----------Epoch 5-----------
iterator 100, D_Loss:0.6545382142066956, G_Loss:5.72943639755249

iterator 200, D_Loss:0.7780857086181641, G_Loss:7.6601409912109375

iterator 300, D_Loss:1.9529266357421875, G_Loss:7.357569217681885

iterator 400, D_Loss:0.5164046883583069, G_Loss:8.027658462524414

iterator 500, D_Loss:0.4860512614250183, G_Loss:5.267759323120117

iterator 600, D_Loss:0.43281280994415283, G_Loss:8.423001289367676

iterator 700, D_Loss:0.49679335951805115, G_Loss:7.65300178527832

iterator 800, D_Loss:0.46549099683761597, G_Loss:7.026423454284668

iterator 900, D_Loss:0.8084708452224731, G_Loss:4.501079559326172

iterator 1000, D_Loss:0.5104385018348694, G_Loss:8.225872039794922

iterator 1100, D_Loss:0.4551069736480713, G_Loss:9.883203506469727

iterator 1200, D_Loss:0.5038637518882751, G_Loss:9.865497589111328

iterator 1300, D_Loss:0.581518292427063, G_Loss:8.797603607177734

iterator 1400, D_Loss:0.723917543888092, G_Loss:3.6810128688812256

iterator 1500, D_Loss:0.45278164744377136, G_Loss:4.59814453125

iterator 1600, D_Loss:0.6151496171951294, G_Loss:3.107863426208496

iterator 1700, D_Loss:0.5843017101287842, G_Loss:3.53888201713562

iterator 1800, D_Loss:0.4719095826148987, G_Loss:3.4019031524658203

iterator 1900, D_Loss:0.4559767246246338, G_Loss:4.897099494934082

iterator 2000, D_Loss:0.4679521322250366, G_Loss:3.91493558883667

iterator 2100, D_Loss:0.4578412175178528, G_Loss:6.369983673095703

iterator 2200, D_Loss:0.8574981689453125, G_Loss:8.999468803405762

iterator 2300, D_Loss:0.46171945333480835, G_Loss:9.446380615234375

iterator 2400, D_Loss:0.4705643653869629, G_Loss:9.303831100463867

iterator 2500, D_Loss:0.512022852897644, G_Loss:2.794806957244873

iterator 2600, D_Loss:0.4485546350479126, G_Loss:4.990055084228516

iterator 2700, D_Loss:0.4426470994949341, G_Loss:10.014711380004883

iterator 2800, D_Loss:0.5092585682868958, G_Loss:8.012337684631348

iterator 2900, D_Loss:0.4078773260116577, G_Loss:3.32962703704834

iterator 3000, D_Loss:0.48308616876602173, G_Loss:9.252171516418457

iterator 3100, D_Loss:0.4757956564426422, G_Loss:10.180233001708984

iterator 3200, D_Loss:0.5057096481323242, G_Loss:11.180892944335938

iterator 3300, D_Loss:0.4574391841888428, G_Loss:11.276402473449707

iterator 3400, D_Loss:1.1702550649642944, G_Loss:12.072626113891602

iterator 3500, D_Loss:0.4392514228820801, G_Loss:11.234109878540039

iterator 3600, D_Loss:0.4165562689304352, G_Loss:5.192647933959961

iterator 3700, D_Loss:0.4786491394042969, G_Loss:7.399425029754639

iterator 3800, D_Loss:0.4930818974971771, G_Loss:14.04248332977295

iterator 3900, D_Loss:0.4533925950527191, G_Loss:8.299897193908691

iterator 4000, D_Loss:0.4761165976524353, G_Loss:9.043431282043457

iterator 4100, D_Loss:0.9223409295082092, G_Loss:9.016447067260742

iterator 4200, D_Loss:0.818851113319397, G_Loss:7.058403968811035

iterator 4300, D_Loss:0.4615546464920044, G_Loss:7.842747688293457

iterator 4400, D_Loss:0.5743041038513184, G_Loss:7.362253665924072

iterator 4500, D_Loss:0.7736772298812866, G_Loss:5.453880310058594

iterator 4600, D_Loss:0.4115254282951355, G_Loss:7.163279056549072

iterator 4700, D_Loss:0.39427927136421204, G_Loss:8.076177597045898

iterator 4800, D_Loss:1.1986877918243408, G_Loss:9.93533992767334

iterator 4900, D_Loss:0.501355767250061, G_Loss:6.682659149169922

iterator 5000, D_Loss:0.5486600995063782, G_Loss:8.634384155273438

-----------Epoch 6-----------
iterator 100, D_Loss:0.4631097614765167, G_Loss:4.322375774383545

iterator 200, D_Loss:0.51183021068573, G_Loss:9.045717239379883

iterator 300, D_Loss:0.46400630474090576, G_Loss:10.355517387390137

iterator 400, D_Loss:0.429964154958725, G_Loss:3.968623638153076

iterator 500, D_Loss:0.6364561319351196, G_Loss:4.889097213745117

iterator 600, D_Loss:0.4579501450061798, G_Loss:7.222408294677734

iterator 700, D_Loss:0.43600496649742126, G_Loss:8.173151016235352

iterator 800, D_Loss:0.5051493644714355, G_Loss:12.839166641235352

iterator 900, D_Loss:0.6975346207618713, G_Loss:8.40678596496582

iterator 1000, D_Loss:1.470343828201294, G_Loss:7.126069068908691

iterator 1100, D_Loss:0.5553790330886841, G_Loss:7.404469966888428

iterator 1200, D_Loss:0.5003908276557922, G_Loss:7.282161235809326

iterator 1300, D_Loss:0.4948289096355438, G_Loss:8.299383163452148

iterator 1400, D_Loss:0.45843446254730225, G_Loss:6.3008222579956055

iterator 1500, D_Loss:0.4692949056625366, G_Loss:7.330913543701172

iterator 1600, D_Loss:0.5132896304130554, G_Loss:4.698501110076904

iterator 1700, D_Loss:0.685917317867279, G_Loss:5.369427680969238

iterator 1800, D_Loss:0.9936915636062622, G_Loss:6.962177276611328

iterator 1900, D_Loss:0.45095953345298767, G_Loss:8.205327987670898

iterator 2000, D_Loss:0.5303751230239868, G_Loss:6.477715492248535

iterator 2100, D_Loss:0.5282564759254456, G_Loss:6.957500457763672

iterator 2200, D_Loss:1.5927088260650635, G_Loss:9.433998107910156

iterator 2300, D_Loss:0.5361893177032471, G_Loss:10.549238204956055

iterator 2400, D_Loss:0.4635913074016571, G_Loss:7.338379859924316

iterator 2500, D_Loss:0.4603959918022156, G_Loss:7.905824661254883

iterator 2600, D_Loss:0.5709882974624634, G_Loss:10.079859733581543

iterator 2700, D_Loss:0.48387232422828674, G_Loss:8.427461624145508

iterator 2800, D_Loss:0.4494795501232147, G_Loss:8.488462448120117

iterator 2900, D_Loss:0.5986644625663757, G_Loss:5.746554374694824

iterator 3000, D_Loss:0.4145943820476532, G_Loss:5.458341598510742

iterator 3100, D_Loss:0.5022355914115906, G_Loss:6.975302219390869

iterator 3200, D_Loss:0.6189325451850891, G_Loss:7.925276279449463

iterator 3300, D_Loss:0.4892598092556, G_Loss:8.039560317993164

iterator 3400, D_Loss:0.624345064163208, G_Loss:9.18532943725586

iterator 3500, D_Loss:0.49158114194869995, G_Loss:5.584233283996582

iterator 3600, D_Loss:0.44374987483024597, G_Loss:11.063397407531738

iterator 3700, D_Loss:0.5429755449295044, G_Loss:8.126066207885742

iterator 3800, D_Loss:0.5470924377441406, G_Loss:9.888849258422852

iterator 3900, D_Loss:0.44745370745658875, G_Loss:2.8944716453552246

iterator 4000, D_Loss:0.5893400311470032, G_Loss:4.5323896408081055

iterator 4100, D_Loss:0.4638436436653137, G_Loss:9.070514678955078

iterator 4200, D_Loss:0.444010466337204, G_Loss:11.037691116333008

iterator 4300, D_Loss:0.6117826700210571, G_Loss:7.6892242431640625

iterator 4400, D_Loss:0.4697667062282562, G_Loss:7.584555625915527

iterator 4500, D_Loss:0.4394521713256836, G_Loss:10.820350646972656

iterator 4600, D_Loss:0.42663800716400146, G_Loss:12.30802059173584

iterator 4700, D_Loss:0.43750640749931335, G_Loss:11.961843490600586

iterator 4800, D_Loss:0.5106438994407654, G_Loss:8.610179901123047

iterator 4900, D_Loss:0.44191861152648926, G_Loss:9.217944145202637

iterator 5000, D_Loss:0.4573836326599121, G_Loss:7.296699047088623

-----------Epoch 7-----------
iterator 100, D_Loss:0.501399040222168, G_Loss:8.631786346435547

iterator 200, D_Loss:0.46630993485450745, G_Loss:6.167311668395996

iterator 300, D_Loss:0.4784429371356964, G_Loss:11.231010437011719

iterator 400, D_Loss:0.44179439544677734, G_Loss:9.984304428100586

iterator 500, D_Loss:0.4732553958892822, G_Loss:7.936269283294678

iterator 600, D_Loss:0.43059393763542175, G_Loss:9.79372501373291

iterator 700, D_Loss:0.43064820766448975, G_Loss:7.608150482177734

iterator 800, D_Loss:0.555091381072998, G_Loss:4.551311016082764

iterator 900, D_Loss:1.4356341361999512, G_Loss:9.38814640045166

iterator 1000, D_Loss:0.5336794853210449, G_Loss:6.38499641418457

iterator 1100, D_Loss:0.49825870990753174, G_Loss:7.318603992462158

iterator 1200, D_Loss:0.444693386554718, G_Loss:10.453676223754883

iterator 1300, D_Loss:0.422423392534256, G_Loss:9.270439147949219

iterator 1400, D_Loss:0.442994087934494, G_Loss:9.8829345703125

iterator 1500, D_Loss:0.43854451179504395, G_Loss:7.136868953704834

iterator 1600, D_Loss:0.7897936701774597, G_Loss:2.5902299880981445

iterator 1700, D_Loss:0.5419448018074036, G_Loss:3.6702380180358887

iterator 1800, D_Loss:0.4057295620441437, G_Loss:5.184055328369141

iterator 1900, D_Loss:0.48034778237342834, G_Loss:7.252845764160156

iterator 2000, D_Loss:0.47472986578941345, G_Loss:9.675985336303711

iterator 2100, D_Loss:0.5025215148925781, G_Loss:7.051609516143799

iterator 2200, D_Loss:0.4281746447086334, G_Loss:5.388403415679932

iterator 2300, D_Loss:0.7217155694961548, G_Loss:6.279831886291504

iterator 2400, D_Loss:0.5337084531784058, G_Loss:7.910571575164795

iterator 2500, D_Loss:0.5052772760391235, G_Loss:8.18878173828125

iterator 2600, D_Loss:0.4495488703250885, G_Loss:7.0938720703125

iterator 2700, D_Loss:0.52299565076828, G_Loss:10.073291778564453

iterator 2800, D_Loss:0.4658312201499939, G_Loss:4.935428619384766

iterator 2900, D_Loss:0.6925825476646423, G_Loss:5.064197063446045

iterator 3000, D_Loss:0.44530344009399414, G_Loss:2.3998868465423584

iterator 3100, D_Loss:0.5855433940887451, G_Loss:6.307834625244141

iterator 3200, D_Loss:0.4967759847640991, G_Loss:6.406763076782227

iterator 3300, D_Loss:0.649121105670929, G_Loss:6.575619220733643

iterator 3400, D_Loss:0.46043241024017334, G_Loss:8.292619705200195

iterator 3500, D_Loss:0.6500649452209473, G_Loss:9.451481819152832

iterator 3600, D_Loss:0.456108033657074, G_Loss:9.102185249328613

iterator 3700, D_Loss:0.4932660460472107, G_Loss:8.541707992553711

iterator 3800, D_Loss:0.4645604193210602, G_Loss:8.935550689697266

iterator 3900, D_Loss:1.7246568202972412, G_Loss:4.190160751342773

iterator 4000, D_Loss:0.4366980493068695, G_Loss:9.714599609375

iterator 4100, D_Loss:0.5230229496955872, G_Loss:10.678860664367676

iterator 4200, D_Loss:0.4352131187915802, G_Loss:9.123052597045898

iterator 4300, D_Loss:0.4969160258769989, G_Loss:7.554449558258057

iterator 4400, D_Loss:0.47029605507850647, G_Loss:10.409984588623047

iterator 4500, D_Loss:0.49506092071533203, G_Loss:8.90064525604248

iterator 4600, D_Loss:0.4673997163772583, G_Loss:12.983521461486816

iterator 4700, D_Loss:0.4984099268913269, G_Loss:7.603795051574707

iterator 4800, D_Loss:0.42973464727401733, G_Loss:9.317577362060547

iterator 4900, D_Loss:0.5724320411682129, G_Loss:7.005463600158691

iterator 5000, D_Loss:0.43483126163482666, G_Loss:5.958017349243164

-----------Epoch 8-----------
iterator 100, D_Loss:0.539503276348114, G_Loss:6.207282066345215

iterator 200, D_Loss:0.644575834274292, G_Loss:10.446033477783203

iterator 300, D_Loss:0.41777053475379944, G_Loss:10.848553657531738

iterator 400, D_Loss:0.4640478789806366, G_Loss:9.958663940429688

iterator 500, D_Loss:0.451747864484787, G_Loss:12.064406394958496

iterator 600, D_Loss:0.4553382992744446, G_Loss:8.999509811401367

iterator 700, D_Loss:0.5105994939804077, G_Loss:9.02424144744873

iterator 800, D_Loss:0.9681761264801025, G_Loss:8.67284870147705

iterator 900, D_Loss:0.6394389271736145, G_Loss:8.064403533935547

iterator 1000, D_Loss:0.4795788526535034, G_Loss:8.416555404663086

iterator 1100, D_Loss:0.44354039430618286, G_Loss:8.187127113342285

iterator 1200, D_Loss:1.6157652139663696, G_Loss:5.110445499420166

iterator 1300, D_Loss:0.49709397554397583, G_Loss:7.806344032287598

iterator 1400, D_Loss:0.47300952672958374, G_Loss:9.39901065826416

iterator 1500, D_Loss:0.4527928829193115, G_Loss:10.557753562927246

iterator 1600, D_Loss:0.46730154752731323, G_Loss:6.06527853012085

iterator 1700, D_Loss:0.5847026705741882, G_Loss:9.092315673828125

iterator 1800, D_Loss:0.4250378906726837, G_Loss:12.083108901977539

iterator 1900, D_Loss:0.42968621850013733, G_Loss:8.952495574951172

iterator 2000, D_Loss:0.46605226397514343, G_Loss:12.952459335327148

iterator 2100, D_Loss:0.582788348197937, G_Loss:7.851728439331055

iterator 2200, D_Loss:0.42911583185195923, G_Loss:13.288557052612305

iterator 2300, D_Loss:0.43640217185020447, G_Loss:11.870386123657227

iterator 2400, D_Loss:0.43463677167892456, G_Loss:10.80990219116211

iterator 2500, D_Loss:0.9686160683631897, G_Loss:3.890961170196533

iterator 2600, D_Loss:0.4869106411933899, G_Loss:6.580456733703613

iterator 2700, D_Loss:0.48010119795799255, G_Loss:13.43989372253418

iterator 2800, D_Loss:0.4678038954734802, G_Loss:10.194135665893555

iterator 2900, D_Loss:0.4216712713241577, G_Loss:6.8766326904296875

iterator 3000, D_Loss:0.48297759890556335, G_Loss:10.46534252166748

iterator 3100, D_Loss:0.49061599373817444, G_Loss:10.5781831741333

iterator 3200, D_Loss:0.4153851270675659, G_Loss:15.264334678649902

iterator 3300, D_Loss:0.4895473122596741, G_Loss:11.502262115478516

iterator 3400, D_Loss:0.45964232087135315, G_Loss:10.302469253540039

iterator 3500, D_Loss:0.4297868311405182, G_Loss:7.6869916915893555

iterator 3600, D_Loss:0.40244224667549133, G_Loss:9.411215782165527

iterator 3700, D_Loss:0.44221627712249756, G_Loss:11.841214179992676

iterator 3800, D_Loss:0.4023876190185547, G_Loss:10.458537101745605

iterator 3900, D_Loss:0.5593056678771973, G_Loss:8.482182502746582

iterator 4000, D_Loss:0.5478971600532532, G_Loss:10.375825881958008

iterator 4100, D_Loss:0.4564138948917389, G_Loss:6.561066627502441

iterator 4200, D_Loss:0.5085257887840271, G_Loss:7.690852642059326

iterator 4300, D_Loss:0.4713548719882965, G_Loss:11.346957206726074

iterator 4400, D_Loss:0.4314187467098236, G_Loss:10.896255493164062

iterator 4500, D_Loss:0.4056388735771179, G_Loss:14.104077339172363

iterator 4600, D_Loss:0.43566253781318665, G_Loss:8.169514656066895

iterator 4700, D_Loss:0.430508553981781, G_Loss:10.708735466003418

iterator 4800, D_Loss:0.46585869789123535, G_Loss:9.370621681213379

iterator 4900, D_Loss:0.459462434053421, G_Loss:11.208751678466797

iterator 5000, D_Loss:0.4307132959365845, G_Loss:10.44410514831543

-----------Epoch 9-----------
iterator 100, D_Loss:0.5504363775253296, G_Loss:9.108919143676758

iterator 200, D_Loss:0.3921447694301605, G_Loss:10.032663345336914

iterator 300, D_Loss:0.43669140338897705, G_Loss:9.172652244567871

iterator 400, D_Loss:0.5508494973182678, G_Loss:10.18737506866455

iterator 500, D_Loss:0.4872541129589081, G_Loss:6.735549449920654

iterator 600, D_Loss:0.4403645992279053, G_Loss:11.528170585632324

iterator 700, D_Loss:0.5698731541633606, G_Loss:9.472795486450195

iterator 800, D_Loss:0.4925127625465393, G_Loss:7.9501872062683105

iterator 900, D_Loss:0.8676583766937256, G_Loss:7.03591775894165

iterator 1000, D_Loss:0.487745463848114, G_Loss:9.993398666381836

iterator 1100, D_Loss:0.42356204986572266, G_Loss:8.538113594055176

iterator 1200, D_Loss:0.5510196089744568, G_Loss:4.440720558166504

iterator 1300, D_Loss:0.4549241364002228, G_Loss:9.137085914611816

iterator 1400, D_Loss:0.48276060819625854, G_Loss:6.2100749015808105

iterator 1500, D_Loss:0.7484164834022522, G_Loss:7.138496398925781

iterator 1600, D_Loss:0.5525678396224976, G_Loss:7.2592973709106445

iterator 1700, D_Loss:0.6182732582092285, G_Loss:4.9789719581604

iterator 1800, D_Loss:0.5315119624137878, G_Loss:5.568934917449951

iterator 1900, D_Loss:0.4995836913585663, G_Loss:4.688586235046387

iterator 2000, D_Loss:0.5008493065834045, G_Loss:10.18552017211914

iterator 2100, D_Loss:0.47024717926979065, G_Loss:10.394128799438477

iterator 2200, D_Loss:0.5151199698448181, G_Loss:11.54185676574707

iterator 2300, D_Loss:0.43411320447921753, G_Loss:12.260002136230469

iterator 2400, D_Loss:0.45731231570243835, G_Loss:11.49533462524414

iterator 2500, D_Loss:0.46314555406570435, G_Loss:9.995500564575195

iterator 2600, D_Loss:0.4606323838233948, G_Loss:12.63528060913086

iterator 2700, D_Loss:0.4657030403614044, G_Loss:6.164281845092773

iterator 2800, D_Loss:0.4380660653114319, G_Loss:7.208279609680176

iterator 2900, D_Loss:0.45276057720184326, G_Loss:10.86586856842041

iterator 3000, D_Loss:0.43808555603027344, G_Loss:6.028031826019287

iterator 3100, D_Loss:0.8331326842308044, G_Loss:7.512152671813965

iterator 3200, D_Loss:0.47223547101020813, G_Loss:9.133682250976562

iterator 3300, D_Loss:0.4486362338066101, G_Loss:10.155839920043945

iterator 3400, D_Loss:0.4384647607803345, G_Loss:7.69904088973999

iterator 3500, D_Loss:0.47824448347091675, G_Loss:9.733976364135742

iterator 3600, D_Loss:0.6130690574645996, G_Loss:6.923366546630859

iterator 3700, D_Loss:0.4493671655654907, G_Loss:7.892916202545166

iterator 3800, D_Loss:0.48080700635910034, G_Loss:8.52614974975586

iterator 3900, D_Loss:0.4417162239551544, G_Loss:4.528594017028809

iterator 4000, D_Loss:0.4333825409412384, G_Loss:7.449837684631348

iterator 4100, D_Loss:0.49103477597236633, G_Loss:10.822840690612793

iterator 4200, D_Loss:0.5499194860458374, G_Loss:10.51479721069336

iterator 4300, D_Loss:0.7390807867050171, G_Loss:9.174257278442383

iterator 4400, D_Loss:0.4775726795196533, G_Loss:3.52618408203125

iterator 4500, D_Loss:0.5626643300056458, G_Loss:10.636514663696289

iterator 4600, D_Loss:0.4493342936038971, G_Loss:6.067545413970947

iterator 4700, D_Loss:0.4892668128013611, G_Loss:9.610254287719727

iterator 4800, D_Loss:0.47156578302383423, G_Loss:6.315702438354492

iterator 4900, D_Loss:0.496111661195755, G_Loss:12.77462387084961

iterator 5000, D_Loss:0.49679431319236755, G_Loss:8.736035346984863

LGAN_generator(
  (LSTM): LSTMCell(702, 100)
  (gmfc00): Linear(in_features=500, out_features=1, bias=True)
  (gmfc01): Linear(in_features=500, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=500, bias=True)
  (gmfe00): Linear(in_features=100, out_features=500, bias=True)
  (gmfe01): Linear(in_features=100, out_features=500, bias=True)
  (fc10): Linear(in_features=500, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=500, bias=True)
  (fe1): Linear(in_features=100, out_features=500, bias=True)
  (gmfc20): Linear(in_features=500, out_features=1, bias=True)
  (gmfc21): Linear(in_features=500, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=500, bias=True)
  (gmfe20): Linear(in_features=100, out_features=500, bias=True)
  (gmfe21): Linear(in_features=100, out_features=500, bias=True)
  (fc30): Linear(in_features=500, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=500, bias=True)
  (fe3): Linear(in_features=100, out_features=500, bias=True)
  (gmfc40): Linear(in_features=500, out_features=1, bias=True)
  (gmfc41): Linear(in_features=500, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=500, bias=True)
  (gmfe40): Linear(in_features=100, out_features=500, bias=True)
  (gmfe41): Linear(in_features=100, out_features=500, bias=True)
  (fc50): Linear(in_features=500, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=500, bias=True)
  (fe5): Linear(in_features=100, out_features=500, bias=True)
  (fc60): Linear(in_features=500, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=500, bias=True)
  (fe6): Linear(in_features=100, out_features=500, bias=True)
  (fc70): Linear(in_features=500, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=500, bias=True)
  (fe7): Linear(in_features=100, out_features=500, bias=True)
  (fc80): Linear(in_features=500, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=500, bias=True)
  (fe8): Linear(in_features=100, out_features=500, bias=True)
  (fc90): Linear(in_features=500, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=500, bias=True)
  (fe9): Linear(in_features=100, out_features=500, bias=True)
  (gmfc100): Linear(in_features=500, out_features=1, bias=True)
  (gmfc101): Linear(in_features=500, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=500, bias=True)
  (gmfe100): Linear(in_features=100, out_features=500, bias=True)
  (gmfe101): Linear(in_features=100, out_features=500, bias=True)
  (gmfc110): Linear(in_features=500, out_features=1, bias=True)
  (gmfc111): Linear(in_features=500, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=500, bias=True)
  (gmfe110): Linear(in_features=100, out_features=500, bias=True)
  (gmfe111): Linear(in_features=100, out_features=500, bias=True)
  (gmfc120): Linear(in_features=500, out_features=1, bias=True)
  (gmfc121): Linear(in_features=500, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=500, bias=True)
  (gmfe120): Linear(in_features=100, out_features=500, bias=True)
  (gmfe121): Linear(in_features=100, out_features=500, bias=True)
  (fc130): Linear(in_features=500, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=500, bias=True)
  (fe13): Linear(in_features=100, out_features=500, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=400, bias=True)
  (inputbn): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=400, out_features=400, bias=True)
  (bn0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=400, bias=True)
  (bn1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=400, out_features=400, bias=True)
  (bn2): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=400, out_features=1, bias=True)
)
-----------Epoch 0-----------
iterator 100, D_Loss:1.4043948650360107, G_Loss:1.0658493041992188

iterator 200, D_Loss:1.4015939235687256, G_Loss:0.9765491485595703

iterator 300, D_Loss:1.3720123767852783, G_Loss:1.0064177513122559

iterator 400, D_Loss:1.3855233192443848, G_Loss:0.9876258373260498

iterator 500, D_Loss:1.3858014345169067, G_Loss:1.0418524742126465

iterator 600, D_Loss:1.3424588441848755, G_Loss:1.0049200057983398

iterator 700, D_Loss:1.3298146724700928, G_Loss:0.963643491268158

iterator 800, D_Loss:1.32221257686615, G_Loss:1.030503511428833

iterator 900, D_Loss:1.333756685256958, G_Loss:0.973052442073822

iterator 1000, D_Loss:1.2915942668914795, G_Loss:1.061737060546875

iterator 1100, D_Loss:1.2894983291625977, G_Loss:1.0960265398025513

iterator 1200, D_Loss:1.2099758386611938, G_Loss:1.1652753353118896

iterator 1300, D_Loss:1.1258403062820435, G_Loss:1.2365418672561646

iterator 1400, D_Loss:1.0308990478515625, G_Loss:1.4498779773712158

iterator 1500, D_Loss:0.9692342281341553, G_Loss:1.4835643768310547

iterator 1600, D_Loss:0.8027339577674866, G_Loss:1.9151638746261597

iterator 1700, D_Loss:0.7507556676864624, G_Loss:2.1219518184661865

iterator 1800, D_Loss:0.6802440285682678, G_Loss:2.3922204971313477

iterator 1900, D_Loss:0.6540027260780334, G_Loss:2.7137014865875244

iterator 2000, D_Loss:0.7017884254455566, G_Loss:2.8225104808807373

iterator 2100, D_Loss:0.6574262976646423, G_Loss:3.0401995182037354

iterator 2200, D_Loss:0.8460517525672913, G_Loss:2.389406204223633

iterator 2300, D_Loss:0.7862603664398193, G_Loss:1.8155955076217651

iterator 2400, D_Loss:0.9168089628219604, G_Loss:2.502732276916504

iterator 2500, D_Loss:0.850656270980835, G_Loss:3.040003538131714

iterator 2600, D_Loss:0.7944053411483765, G_Loss:2.132272243499756

iterator 2700, D_Loss:0.7863808274269104, G_Loss:2.7796120643615723

iterator 2800, D_Loss:0.890709638595581, G_Loss:2.547785997390747

iterator 2900, D_Loss:0.8335000872612, G_Loss:2.3932530879974365

iterator 3000, D_Loss:0.7067314386367798, G_Loss:2.641164779663086

iterator 3100, D_Loss:0.7716824412345886, G_Loss:1.8459432125091553

iterator 3200, D_Loss:0.795038640499115, G_Loss:2.943568229675293

iterator 3300, D_Loss:0.716322660446167, G_Loss:2.2455999851226807

iterator 3400, D_Loss:0.7218018770217896, G_Loss:2.6576879024505615

iterator 3500, D_Loss:0.671879768371582, G_Loss:2.944646120071411

iterator 3600, D_Loss:0.7721800804138184, G_Loss:2.831099033355713

iterator 3700, D_Loss:0.738518238067627, G_Loss:2.490666627883911

iterator 3800, D_Loss:0.6733049750328064, G_Loss:2.5594427585601807

iterator 3900, D_Loss:0.6167926788330078, G_Loss:3.028289794921875

iterator 4000, D_Loss:0.7679435014724731, G_Loss:1.9621102809906006

iterator 4100, D_Loss:0.8718393445014954, G_Loss:2.0123977661132812

iterator 4200, D_Loss:0.910269558429718, G_Loss:2.188375473022461

iterator 4300, D_Loss:0.6826251149177551, G_Loss:2.6067841053009033

iterator 4400, D_Loss:0.7712814211845398, G_Loss:2.307373285293579

iterator 4500, D_Loss:0.8458025455474854, G_Loss:2.2645111083984375

iterator 4600, D_Loss:0.7161372900009155, G_Loss:3.1993584632873535

iterator 4700, D_Loss:0.6093607544898987, G_Loss:2.7820024490356445

iterator 4800, D_Loss:0.6814329624176025, G_Loss:2.5385234355926514

iterator 4900, D_Loss:0.6034069657325745, G_Loss:3.084190845489502

iterator 5000, D_Loss:0.5612050294876099, G_Loss:3.175400972366333

-----------Epoch 1-----------
iterator 100, D_Loss:0.7687890529632568, G_Loss:2.566457748413086

iterator 200, D_Loss:1.3343605995178223, G_Loss:2.240609645843506

iterator 300, D_Loss:0.5760852098464966, G_Loss:4.510555267333984

iterator 400, D_Loss:0.6271247863769531, G_Loss:2.3247218132019043

iterator 500, D_Loss:0.7305421829223633, G_Loss:4.104365348815918

iterator 600, D_Loss:0.7539809942245483, G_Loss:3.985107183456421

iterator 700, D_Loss:0.6977943181991577, G_Loss:4.38641357421875

iterator 800, D_Loss:0.5064554214477539, G_Loss:3.8606529235839844

iterator 900, D_Loss:0.5735915303230286, G_Loss:3.5483288764953613

iterator 1000, D_Loss:0.5084821581840515, G_Loss:3.7830748558044434

iterator 1100, D_Loss:0.538995623588562, G_Loss:4.8573784828186035

iterator 1200, D_Loss:0.6171471476554871, G_Loss:3.250230312347412

iterator 1300, D_Loss:0.5419486165046692, G_Loss:4.53101110458374

iterator 1400, D_Loss:0.5316125154495239, G_Loss:3.2362022399902344

iterator 1500, D_Loss:0.5093483924865723, G_Loss:3.9149630069732666

iterator 1600, D_Loss:0.5030442476272583, G_Loss:4.923482894897461

iterator 1700, D_Loss:0.5597400069236755, G_Loss:4.979816913604736

iterator 1800, D_Loss:0.5403090119361877, G_Loss:4.344416618347168

iterator 1900, D_Loss:0.6131145358085632, G_Loss:3.8622350692749023

iterator 2000, D_Loss:0.5187596678733826, G_Loss:4.394477367401123

iterator 2100, D_Loss:0.48385483026504517, G_Loss:4.412252426147461

iterator 2200, D_Loss:0.6784906983375549, G_Loss:5.336712837219238

iterator 2300, D_Loss:0.49257025122642517, G_Loss:4.5012922286987305

iterator 2400, D_Loss:0.4655698537826538, G_Loss:4.334080696105957

iterator 2500, D_Loss:0.4892469644546509, G_Loss:5.514174461364746

iterator 2600, D_Loss:0.5164743661880493, G_Loss:5.26527214050293

iterator 2700, D_Loss:0.46319252252578735, G_Loss:4.333945274353027

iterator 2800, D_Loss:0.4746325612068176, G_Loss:6.3268303871154785

iterator 2900, D_Loss:0.4646833539009094, G_Loss:4.2640228271484375

iterator 3000, D_Loss:0.48383113741874695, G_Loss:5.891526222229004

iterator 3100, D_Loss:0.48352086544036865, G_Loss:4.029170036315918

iterator 3200, D_Loss:0.5364139080047607, G_Loss:5.32695198059082

iterator 3300, D_Loss:0.4706636369228363, G_Loss:5.820675849914551

iterator 3400, D_Loss:0.5000101327896118, G_Loss:3.1355228424072266

iterator 3500, D_Loss:0.4536600112915039, G_Loss:5.576943397521973

iterator 3600, D_Loss:0.4723554253578186, G_Loss:5.629397869110107

iterator 3700, D_Loss:0.5228368639945984, G_Loss:4.5286455154418945

iterator 3800, D_Loss:0.520371675491333, G_Loss:5.110281944274902

iterator 3900, D_Loss:0.6162599921226501, G_Loss:4.200214385986328

iterator 4000, D_Loss:0.49519509077072144, G_Loss:4.520162582397461

iterator 4100, D_Loss:0.457732230424881, G_Loss:4.55368709564209

iterator 4200, D_Loss:0.4693008363246918, G_Loss:5.750060558319092

iterator 4300, D_Loss:0.4959888160228729, G_Loss:6.195168972015381

iterator 4400, D_Loss:0.4525045156478882, G_Loss:5.399781227111816

iterator 4500, D_Loss:0.45816048979759216, G_Loss:6.664113521575928

iterator 4600, D_Loss:0.5367053747177124, G_Loss:6.761595726013184

iterator 4700, D_Loss:0.45571815967559814, G_Loss:5.547336101531982

iterator 4800, D_Loss:0.4543139636516571, G_Loss:5.9481096267700195

iterator 4900, D_Loss:0.4567882716655731, G_Loss:6.169707298278809

iterator 5000, D_Loss:0.4503689408302307, G_Loss:6.036096572875977

-----------Epoch 2-----------
iterator 100, D_Loss:0.46064484119415283, G_Loss:6.714335918426514

iterator 200, D_Loss:0.4479811489582062, G_Loss:5.0943803787231445

iterator 300, D_Loss:0.42505893111228943, G_Loss:7.508067607879639

iterator 400, D_Loss:0.47033873200416565, G_Loss:7.128125190734863

iterator 500, D_Loss:0.42905622720718384, G_Loss:7.436800479888916

iterator 600, D_Loss:0.4458666741847992, G_Loss:6.452254772186279

iterator 700, D_Loss:0.43529850244522095, G_Loss:7.066554069519043

iterator 800, D_Loss:0.4513336420059204, G_Loss:6.907411098480225

iterator 900, D_Loss:0.4619279205799103, G_Loss:7.551212310791016

iterator 1000, D_Loss:0.4153226613998413, G_Loss:7.402504920959473

iterator 1100, D_Loss:0.4596109390258789, G_Loss:7.5109052658081055

iterator 1200, D_Loss:0.43590083718299866, G_Loss:7.491244316101074

iterator 1300, D_Loss:0.4496993124485016, G_Loss:6.589805603027344

iterator 1400, D_Loss:0.4837055504322052, G_Loss:5.773128032684326

iterator 1500, D_Loss:0.6088002324104309, G_Loss:3.58864164352417

iterator 1600, D_Loss:0.5124145150184631, G_Loss:5.538461208343506

iterator 1700, D_Loss:0.4840051531791687, G_Loss:4.50622034072876

iterator 1800, D_Loss:0.42876961827278137, G_Loss:4.951103210449219

iterator 1900, D_Loss:0.5229026079177856, G_Loss:4.562743663787842

iterator 2000, D_Loss:0.5304968953132629, G_Loss:7.571966648101807

iterator 2100, D_Loss:0.47094470262527466, G_Loss:6.843364715576172

iterator 2200, D_Loss:0.486796110868454, G_Loss:7.349867820739746

iterator 2300, D_Loss:0.4573774039745331, G_Loss:3.464371681213379

iterator 2400, D_Loss:0.5185136198997498, G_Loss:4.938844203948975

iterator 2500, D_Loss:0.5752068161964417, G_Loss:5.7816290855407715

iterator 2600, D_Loss:0.46762651205062866, G_Loss:5.400906562805176

iterator 2700, D_Loss:0.45291897654533386, G_Loss:5.2058210372924805

iterator 2800, D_Loss:0.6869487762451172, G_Loss:5.852563858032227

iterator 2900, D_Loss:0.4900777339935303, G_Loss:5.966700553894043

iterator 3000, D_Loss:0.6415354609489441, G_Loss:5.10498046875

iterator 3100, D_Loss:0.4713124632835388, G_Loss:6.604358673095703

iterator 3200, D_Loss:0.5862991809844971, G_Loss:6.681119441986084

iterator 3300, D_Loss:0.48382362723350525, G_Loss:8.111900329589844

iterator 3400, D_Loss:0.4695865213871002, G_Loss:4.664044380187988

iterator 3500, D_Loss:0.4568118453025818, G_Loss:4.578173637390137

iterator 3600, D_Loss:0.518466055393219, G_Loss:6.244675636291504

iterator 3700, D_Loss:0.4636411964893341, G_Loss:4.988035202026367

iterator 3800, D_Loss:0.5095067620277405, G_Loss:6.2862629890441895

iterator 3900, D_Loss:0.5415769219398499, G_Loss:6.749795913696289

iterator 4000, D_Loss:0.4881078600883484, G_Loss:5.563887596130371

iterator 4100, D_Loss:0.4666731059551239, G_Loss:5.823716640472412

iterator 4200, D_Loss:0.5302373766899109, G_Loss:6.7829155921936035

iterator 4300, D_Loss:0.4256085455417633, G_Loss:6.950699329376221

iterator 4400, D_Loss:0.5200798511505127, G_Loss:3.906388759613037

iterator 4500, D_Loss:0.45331770181655884, G_Loss:5.580848217010498

iterator 4600, D_Loss:0.45981577038764954, G_Loss:6.649251461029053

iterator 4700, D_Loss:0.4535999894142151, G_Loss:7.084926128387451

iterator 4800, D_Loss:0.4561232924461365, G_Loss:7.093070983886719

iterator 4900, D_Loss:0.6921994686126709, G_Loss:4.277187347412109

iterator 5000, D_Loss:0.5046390891075134, G_Loss:3.4114418029785156

-----------Epoch 3-----------
iterator 100, D_Loss:0.522502601146698, G_Loss:4.920210838317871

iterator 200, D_Loss:0.6521492004394531, G_Loss:4.9915080070495605

iterator 300, D_Loss:0.49610385298728943, G_Loss:6.97296667098999

iterator 400, D_Loss:0.4762558043003082, G_Loss:7.87331485748291

iterator 500, D_Loss:0.45765194296836853, G_Loss:5.645738124847412

iterator 600, D_Loss:0.4462983310222626, G_Loss:5.947368621826172

iterator 700, D_Loss:0.46118035912513733, G_Loss:7.461830139160156

iterator 800, D_Loss:0.4615168571472168, G_Loss:7.072507858276367

iterator 900, D_Loss:0.4977605938911438, G_Loss:5.970346927642822

iterator 1000, D_Loss:0.734428882598877, G_Loss:4.801446437835693

iterator 1100, D_Loss:0.45085522532463074, G_Loss:8.209086418151855

iterator 1200, D_Loss:0.43715623021125793, G_Loss:7.740543842315674

iterator 1300, D_Loss:0.5625582337379456, G_Loss:4.679661750793457

iterator 1400, D_Loss:0.46102532744407654, G_Loss:6.364877223968506

iterator 1500, D_Loss:0.47691458463668823, G_Loss:6.831844329833984

iterator 1600, D_Loss:0.44348812103271484, G_Loss:8.621625900268555

iterator 1700, D_Loss:0.4700440764427185, G_Loss:6.37325382232666

iterator 1800, D_Loss:0.4412953555583954, G_Loss:8.67110538482666

iterator 1900, D_Loss:0.45085322856903076, G_Loss:7.114290714263916

iterator 2000, D_Loss:0.4637417197227478, G_Loss:7.37703275680542

iterator 2100, D_Loss:0.439556747674942, G_Loss:8.901949882507324

iterator 2200, D_Loss:0.4625413715839386, G_Loss:7.496445655822754

iterator 2300, D_Loss:0.43209972977638245, G_Loss:8.142942428588867

iterator 2400, D_Loss:0.454901784658432, G_Loss:6.920770168304443

iterator 2500, D_Loss:0.4499707520008087, G_Loss:8.06330394744873

iterator 2600, D_Loss:0.7137491703033447, G_Loss:3.7446746826171875

iterator 2700, D_Loss:0.4803982079029083, G_Loss:7.395712375640869

iterator 2800, D_Loss:0.45244520902633667, G_Loss:8.383360862731934

iterator 2900, D_Loss:0.7799454927444458, G_Loss:4.391397953033447

iterator 3000, D_Loss:0.4272759258747101, G_Loss:3.3258721828460693

iterator 3100, D_Loss:0.45706748962402344, G_Loss:7.823390960693359

iterator 3200, D_Loss:0.5262575745582581, G_Loss:4.2739577293396

iterator 3300, D_Loss:0.48104894161224365, G_Loss:7.603242874145508

iterator 3400, D_Loss:0.4349825084209442, G_Loss:7.630414009094238

iterator 3500, D_Loss:0.5493202209472656, G_Loss:9.054301261901855

iterator 3600, D_Loss:0.4827880859375, G_Loss:5.0256428718566895

iterator 3700, D_Loss:0.5398189425468445, G_Loss:6.551540374755859

iterator 3800, D_Loss:0.49963289499282837, G_Loss:5.733992576599121

iterator 3900, D_Loss:0.44767695665359497, G_Loss:6.287747383117676

iterator 4000, D_Loss:0.4556308686733246, G_Loss:7.898029327392578

iterator 4100, D_Loss:0.4220578968524933, G_Loss:6.0750956535339355

iterator 4200, D_Loss:0.45250099897384644, G_Loss:5.0311737060546875

iterator 4300, D_Loss:0.4841887652873993, G_Loss:5.7025251388549805

iterator 4400, D_Loss:0.4985191226005554, G_Loss:5.730238437652588

iterator 4500, D_Loss:0.4421957731246948, G_Loss:6.948419570922852

iterator 4600, D_Loss:0.4502159357070923, G_Loss:8.719541549682617

iterator 4700, D_Loss:0.448161244392395, G_Loss:6.847362041473389

iterator 4800, D_Loss:0.4654976427555084, G_Loss:8.183246612548828

iterator 4900, D_Loss:0.507008969783783, G_Loss:9.695367813110352

iterator 5000, D_Loss:0.46772387623786926, G_Loss:6.47578239440918

-----------Epoch 4-----------
iterator 100, D_Loss:0.5712031722068787, G_Loss:7.538359642028809

iterator 200, D_Loss:0.49844688177108765, G_Loss:8.679180145263672

iterator 300, D_Loss:0.43333956599235535, G_Loss:6.449051380157471

iterator 400, D_Loss:0.45597824454307556, G_Loss:7.399133205413818

iterator 500, D_Loss:0.4509170651435852, G_Loss:6.022109031677246

iterator 600, D_Loss:0.5303935408592224, G_Loss:9.011648178100586

iterator 700, D_Loss:0.4288381338119507, G_Loss:7.5094709396362305

iterator 800, D_Loss:0.4542602300643921, G_Loss:4.107203960418701

iterator 900, D_Loss:0.43067532777786255, G_Loss:10.02238655090332

iterator 1000, D_Loss:0.45242512226104736, G_Loss:7.940280914306641

iterator 1100, D_Loss:0.48940423130989075, G_Loss:5.519484519958496

iterator 1200, D_Loss:0.4520619809627533, G_Loss:7.367606163024902

iterator 1300, D_Loss:0.46830469369888306, G_Loss:6.984972953796387

iterator 1400, D_Loss:0.4327845871448517, G_Loss:6.893372535705566

iterator 1500, D_Loss:0.43787330389022827, G_Loss:7.542431354522705

iterator 1600, D_Loss:0.4328351616859436, G_Loss:7.743463516235352

iterator 1700, D_Loss:0.4621799886226654, G_Loss:8.988428115844727

iterator 1800, D_Loss:0.43829861283302307, G_Loss:6.885258197784424

iterator 1900, D_Loss:0.5319624543190002, G_Loss:5.654921054840088

iterator 2000, D_Loss:0.4362887740135193, G_Loss:7.15477180480957

iterator 2100, D_Loss:0.4535169303417206, G_Loss:6.665047645568848

iterator 2200, D_Loss:0.4445154070854187, G_Loss:10.895967483520508

iterator 2300, D_Loss:0.6846092343330383, G_Loss:4.838198661804199

iterator 2400, D_Loss:0.4373565912246704, G_Loss:9.143836975097656

iterator 2500, D_Loss:0.4619276523590088, G_Loss:8.104634284973145

iterator 2600, D_Loss:0.431796133518219, G_Loss:8.935600280761719

iterator 2700, D_Loss:0.5704668760299683, G_Loss:4.742209434509277

iterator 2800, D_Loss:0.4752209782600403, G_Loss:5.80539608001709

iterator 2900, D_Loss:0.43236565589904785, G_Loss:5.904991626739502

iterator 3000, D_Loss:0.5420944094657898, G_Loss:8.882150650024414

iterator 3100, D_Loss:0.43851926922798157, G_Loss:7.5474724769592285

iterator 3200, D_Loss:0.4336489140987396, G_Loss:7.528336524963379

iterator 3300, D_Loss:0.49092814326286316, G_Loss:5.630978107452393

iterator 3400, D_Loss:0.43441879749298096, G_Loss:5.676725387573242

iterator 3500, D_Loss:0.4814840257167816, G_Loss:4.670941352844238

iterator 3600, D_Loss:0.4269483983516693, G_Loss:8.572781562805176

iterator 3700, D_Loss:0.449191689491272, G_Loss:5.636194229125977

iterator 3800, D_Loss:0.46183761954307556, G_Loss:5.100896835327148

iterator 3900, D_Loss:0.4317011535167694, G_Loss:3.82863712310791

iterator 4000, D_Loss:0.43953394889831543, G_Loss:9.005378723144531

iterator 4100, D_Loss:0.4659895896911621, G_Loss:6.796952724456787

iterator 4200, D_Loss:0.44098320603370667, G_Loss:9.265318870544434

iterator 4300, D_Loss:0.426888108253479, G_Loss:9.91916561126709

iterator 4400, D_Loss:0.4401167333126068, G_Loss:3.9345946311950684

iterator 4500, D_Loss:0.44842177629470825, G_Loss:7.028294086456299

iterator 4600, D_Loss:0.44759657979011536, G_Loss:8.327775955200195

iterator 4700, D_Loss:0.4932170808315277, G_Loss:7.969496726989746

iterator 4800, D_Loss:0.42351067066192627, G_Loss:10.972660064697266

iterator 4900, D_Loss:0.4534646272659302, G_Loss:8.427799224853516

iterator 5000, D_Loss:0.5009830594062805, G_Loss:9.061384201049805

-----------Epoch 5-----------
iterator 100, D_Loss:0.43331006169319153, G_Loss:8.302520751953125

iterator 200, D_Loss:0.445217102766037, G_Loss:10.140666007995605

iterator 300, D_Loss:0.4588662385940552, G_Loss:8.211776733398438

iterator 400, D_Loss:0.43209120631217957, G_Loss:8.015593528747559

iterator 500, D_Loss:0.5158042311668396, G_Loss:10.787481307983398

iterator 600, D_Loss:0.4609507620334625, G_Loss:5.301760673522949

iterator 700, D_Loss:0.4634871780872345, G_Loss:6.857635498046875

iterator 800, D_Loss:0.47438740730285645, G_Loss:7.760926723480225

iterator 900, D_Loss:0.47125566005706787, G_Loss:6.443426132202148

iterator 1000, D_Loss:0.46158838272094727, G_Loss:7.705920219421387

iterator 1100, D_Loss:0.4404416084289551, G_Loss:8.722149848937988

iterator 1200, D_Loss:0.43189093470573425, G_Loss:9.221891403198242

iterator 1300, D_Loss:0.4504322111606598, G_Loss:8.706854820251465

iterator 1400, D_Loss:0.42349866032600403, G_Loss:8.971426010131836

iterator 1500, D_Loss:0.4575071632862091, G_Loss:5.874649524688721

iterator 1600, D_Loss:0.43791434168815613, G_Loss:9.600896835327148

iterator 1700, D_Loss:0.44915568828582764, G_Loss:7.380621910095215

iterator 1800, D_Loss:0.44585850834846497, G_Loss:7.187320709228516

iterator 1900, D_Loss:0.45259344577789307, G_Loss:5.352586269378662

iterator 2000, D_Loss:0.435417503118515, G_Loss:10.915566444396973

iterator 2100, D_Loss:0.6645688414573669, G_Loss:10.882854461669922

iterator 2200, D_Loss:0.46011361479759216, G_Loss:8.762982368469238

iterator 2300, D_Loss:0.6266847252845764, G_Loss:9.50604248046875

iterator 2400, D_Loss:0.48088693618774414, G_Loss:6.025032043457031

iterator 2500, D_Loss:0.44360440969467163, G_Loss:10.263764381408691

iterator 2600, D_Loss:0.44958287477493286, G_Loss:5.233943939208984

iterator 2700, D_Loss:0.4791140556335449, G_Loss:10.259040832519531

iterator 2800, D_Loss:0.4785776138305664, G_Loss:7.246492862701416

iterator 2900, D_Loss:0.4409327208995819, G_Loss:9.346631050109863

iterator 3000, D_Loss:0.46027547121047974, G_Loss:7.8427653312683105

iterator 3100, D_Loss:0.4254581928253174, G_Loss:8.413952827453613

iterator 3200, D_Loss:0.45546677708625793, G_Loss:10.956660270690918

iterator 3300, D_Loss:0.4942016005516052, G_Loss:5.985391139984131

iterator 3400, D_Loss:0.45308786630630493, G_Loss:5.302545070648193

iterator 3500, D_Loss:0.4380185306072235, G_Loss:7.050685882568359

iterator 3600, D_Loss:0.4471619725227356, G_Loss:10.449649810791016

iterator 3700, D_Loss:0.5290253162384033, G_Loss:3.144200325012207

iterator 3800, D_Loss:0.4483013153076172, G_Loss:7.25696325302124

iterator 3900, D_Loss:0.4609721601009369, G_Loss:6.020837306976318

iterator 4000, D_Loss:0.43603378534317017, G_Loss:10.006196022033691

iterator 4100, D_Loss:0.5311388373374939, G_Loss:7.9473557472229

iterator 4200, D_Loss:0.45639002323150635, G_Loss:5.9480366706848145

iterator 4300, D_Loss:0.5400069952011108, G_Loss:6.997565269470215

iterator 4400, D_Loss:0.48393458127975464, G_Loss:3.3496575355529785

iterator 4500, D_Loss:0.4198775887489319, G_Loss:5.934816837310791

iterator 4600, D_Loss:0.428554892539978, G_Loss:8.43526554107666

iterator 4700, D_Loss:0.4541665315628052, G_Loss:5.491872787475586

iterator 4800, D_Loss:0.4468420147895813, G_Loss:7.919351577758789

iterator 4900, D_Loss:0.4484395980834961, G_Loss:9.318196296691895

iterator 5000, D_Loss:0.43655911087989807, G_Loss:9.373040199279785

-----------Epoch 6-----------
iterator 100, D_Loss:0.48668378591537476, G_Loss:8.566017150878906

iterator 200, D_Loss:0.46604764461517334, G_Loss:2.8532466888427734

iterator 300, D_Loss:0.45180177688598633, G_Loss:11.950274467468262

iterator 400, D_Loss:0.4481097161769867, G_Loss:7.187523365020752

iterator 500, D_Loss:0.43659111857414246, G_Loss:7.41564416885376

iterator 600, D_Loss:0.43468961119651794, G_Loss:5.493395805358887

iterator 700, D_Loss:0.4517768323421478, G_Loss:5.5196146965026855

iterator 800, D_Loss:0.4616965055465698, G_Loss:8.093812942504883

iterator 900, D_Loss:0.44252288341522217, G_Loss:12.334625244140625

iterator 1000, D_Loss:0.4470278024673462, G_Loss:9.198087692260742

iterator 1100, D_Loss:0.45172104239463806, G_Loss:7.254508018493652

iterator 1200, D_Loss:0.4783986508846283, G_Loss:5.702082633972168

iterator 1300, D_Loss:0.7310119867324829, G_Loss:4.835114002227783

iterator 1400, D_Loss:0.43537744879722595, G_Loss:10.160298347473145

iterator 1500, D_Loss:0.4371413290500641, G_Loss:6.501943588256836

iterator 1600, D_Loss:0.4462922215461731, G_Loss:5.097702503204346

iterator 1700, D_Loss:0.41792604327201843, G_Loss:9.798049926757812

iterator 1800, D_Loss:0.44279149174690247, G_Loss:10.304998397827148

iterator 1900, D_Loss:0.5360629558563232, G_Loss:7.9670186042785645

iterator 2000, D_Loss:0.4347505271434784, G_Loss:7.466451644897461

iterator 2100, D_Loss:0.46165573596954346, G_Loss:7.5483784675598145

iterator 2200, D_Loss:0.4655753970146179, G_Loss:6.222670555114746

iterator 2300, D_Loss:0.4471372663974762, G_Loss:9.434849739074707

iterator 2400, D_Loss:0.5200966000556946, G_Loss:6.678348541259766

iterator 2500, D_Loss:0.4435393214225769, G_Loss:9.592796325683594

iterator 2600, D_Loss:0.42179015278816223, G_Loss:6.972724914550781

iterator 2700, D_Loss:0.5353960394859314, G_Loss:10.845938682556152

iterator 2800, D_Loss:0.4342876672744751, G_Loss:9.09191608428955

iterator 2900, D_Loss:0.4419727921485901, G_Loss:8.900479316711426

iterator 3000, D_Loss:0.6536805629730225, G_Loss:11.380158424377441

iterator 3100, D_Loss:0.4227059483528137, G_Loss:6.160672664642334

iterator 3200, D_Loss:0.4405207335948944, G_Loss:8.361430168151855

iterator 3300, D_Loss:0.43489283323287964, G_Loss:6.6571526527404785

iterator 3400, D_Loss:0.4233400821685791, G_Loss:8.033817291259766

iterator 3500, D_Loss:0.4388652741909027, G_Loss:7.984540939331055

iterator 3600, D_Loss:0.46554887294769287, G_Loss:7.99074125289917

iterator 3700, D_Loss:0.4445919096469879, G_Loss:6.8943986892700195

iterator 3800, D_Loss:0.4398749768733978, G_Loss:7.775879859924316

iterator 3900, D_Loss:0.43387165665626526, G_Loss:7.009749889373779

iterator 4000, D_Loss:0.4143877327442169, G_Loss:12.120492935180664

iterator 4100, D_Loss:0.4228658378124237, G_Loss:8.332082748413086

iterator 4200, D_Loss:0.4329060912132263, G_Loss:8.793526649475098

iterator 4300, D_Loss:0.6464704275131226, G_Loss:7.4551472663879395

iterator 4400, D_Loss:0.4441118538379669, G_Loss:6.697872638702393

iterator 4500, D_Loss:0.44193485379219055, G_Loss:9.494524002075195

iterator 4600, D_Loss:0.44071292877197266, G_Loss:10.452920913696289

iterator 4700, D_Loss:0.44179049134254456, G_Loss:7.884797096252441

iterator 4800, D_Loss:0.44410476088523865, G_Loss:10.398036003112793

iterator 4900, D_Loss:0.461421936750412, G_Loss:9.355246543884277

iterator 5000, D_Loss:0.43812164664268494, G_Loss:6.055224418640137

-----------Epoch 7-----------
iterator 100, D_Loss:0.45011264085769653, G_Loss:9.546127319335938

iterator 200, D_Loss:0.4425612688064575, G_Loss:11.571329116821289

iterator 300, D_Loss:0.43370094895362854, G_Loss:9.062352180480957

iterator 400, D_Loss:0.43283703923225403, G_Loss:10.879375457763672

iterator 500, D_Loss:0.4298210144042969, G_Loss:8.289969444274902

iterator 600, D_Loss:0.4356076717376709, G_Loss:9.767436981201172

iterator 700, D_Loss:0.441984623670578, G_Loss:4.2764177322387695

iterator 800, D_Loss:0.5118882060050964, G_Loss:2.9306230545043945

iterator 900, D_Loss:0.44733113050460815, G_Loss:9.483827590942383

iterator 1000, D_Loss:0.41925710439682007, G_Loss:7.792741298675537

iterator 1100, D_Loss:0.4391827881336212, G_Loss:6.143572807312012

iterator 1200, D_Loss:0.4204102158546448, G_Loss:9.942342758178711

iterator 1300, D_Loss:0.45643502473831177, G_Loss:6.387707233428955

iterator 1400, D_Loss:0.4316022992134094, G_Loss:9.79488468170166

iterator 1500, D_Loss:0.4399413466453552, G_Loss:6.4980926513671875

iterator 1600, D_Loss:0.4319347143173218, G_Loss:9.515022277832031

iterator 1700, D_Loss:0.4481699764728546, G_Loss:10.497297286987305

iterator 1800, D_Loss:0.43913426995277405, G_Loss:10.633695602416992

iterator 1900, D_Loss:0.4237838685512543, G_Loss:9.758306503295898

iterator 2000, D_Loss:0.4469548463821411, G_Loss:11.533888816833496

iterator 2100, D_Loss:0.454413503408432, G_Loss:8.910985946655273

iterator 2200, D_Loss:0.45865702629089355, G_Loss:10.673856735229492

iterator 2300, D_Loss:0.43144112825393677, G_Loss:12.80724811553955

iterator 2400, D_Loss:0.41942209005355835, G_Loss:8.790250778198242

iterator 2500, D_Loss:0.4623550772666931, G_Loss:13.063530921936035

iterator 2600, D_Loss:0.43157413601875305, G_Loss:6.312355041503906

iterator 2700, D_Loss:0.4510246813297272, G_Loss:11.744841575622559

iterator 2800, D_Loss:0.4496901333332062, G_Loss:5.770438194274902

iterator 2900, D_Loss:0.43475106358528137, G_Loss:13.047630310058594

iterator 3000, D_Loss:0.5238287448883057, G_Loss:3.6650638580322266

iterator 3100, D_Loss:0.4510754346847534, G_Loss:11.293926239013672

iterator 3200, D_Loss:0.49905386567115784, G_Loss:5.82031774520874

iterator 3300, D_Loss:0.43663832545280457, G_Loss:6.965054512023926

iterator 3400, D_Loss:0.4389088749885559, G_Loss:9.327835083007812

iterator 3500, D_Loss:0.4444074332714081, G_Loss:8.98814868927002

iterator 3600, D_Loss:0.4444096088409424, G_Loss:10.190628051757812

iterator 3700, D_Loss:0.47082629799842834, G_Loss:11.496262550354004

iterator 3800, D_Loss:0.42809751629829407, G_Loss:8.831863403320312

iterator 3900, D_Loss:0.44077423214912415, G_Loss:7.0017876625061035

iterator 4000, D_Loss:0.4207104444503784, G_Loss:9.982856750488281

iterator 4100, D_Loss:0.4421474039554596, G_Loss:7.646365642547607

iterator 4200, D_Loss:0.8092021942138672, G_Loss:5.700272083282471

iterator 4300, D_Loss:0.4385433793067932, G_Loss:11.21962833404541

iterator 4400, D_Loss:0.4622547924518585, G_Loss:5.900869369506836

iterator 4500, D_Loss:0.44623881578445435, G_Loss:5.442594528198242

iterator 4600, D_Loss:0.4300908148288727, G_Loss:11.9993314743042

iterator 4700, D_Loss:0.4650743305683136, G_Loss:8.119598388671875

iterator 4800, D_Loss:0.4383108615875244, G_Loss:9.444816589355469

iterator 4900, D_Loss:0.4451126158237457, G_Loss:13.643794059753418

iterator 5000, D_Loss:0.43611404299736023, G_Loss:9.372759819030762

-----------Epoch 8-----------
iterator 100, D_Loss:0.4105652868747711, G_Loss:11.203291893005371

iterator 200, D_Loss:0.4202415347099304, G_Loss:7.560382843017578

iterator 300, D_Loss:1.6112663745880127, G_Loss:2.375066041946411

iterator 400, D_Loss:0.5106539130210876, G_Loss:9.15756893157959

iterator 500, D_Loss:0.44786709547042847, G_Loss:2.5553646087646484

iterator 600, D_Loss:0.4452926218509674, G_Loss:8.292682647705078

iterator 700, D_Loss:0.4715183973312378, G_Loss:8.604561805725098

iterator 800, D_Loss:0.49830883741378784, G_Loss:11.247594833374023

iterator 900, D_Loss:0.4518539309501648, G_Loss:6.115119457244873

iterator 1000, D_Loss:0.4143271744251251, G_Loss:9.032169342041016

iterator 1100, D_Loss:0.4515417516231537, G_Loss:10.432873725891113

iterator 1200, D_Loss:0.460762083530426, G_Loss:8.0172758102417

iterator 1300, D_Loss:0.423437237739563, G_Loss:9.45620346069336

iterator 1400, D_Loss:0.4804973304271698, G_Loss:5.897000312805176

iterator 1500, D_Loss:0.42920204997062683, G_Loss:10.15876293182373

iterator 1600, D_Loss:0.4369468688964844, G_Loss:8.293780326843262

iterator 1700, D_Loss:0.43335437774658203, G_Loss:10.488418579101562

iterator 1800, D_Loss:0.4457440972328186, G_Loss:11.216459274291992

iterator 1900, D_Loss:0.4466191232204437, G_Loss:7.201331615447998

iterator 2000, D_Loss:0.548615038394928, G_Loss:10.297542572021484

iterator 2100, D_Loss:0.4796473979949951, G_Loss:7.533862113952637

iterator 2200, D_Loss:0.4860278069972992, G_Loss:4.950516223907471

iterator 2300, D_Loss:0.523706316947937, G_Loss:5.649360656738281

iterator 2400, D_Loss:0.44606736302375793, G_Loss:7.245996952056885

iterator 2500, D_Loss:0.4497261643409729, G_Loss:10.413185119628906

iterator 2600, D_Loss:0.44124317169189453, G_Loss:6.417230606079102

iterator 2700, D_Loss:0.4629744589328766, G_Loss:6.727550983428955

iterator 2800, D_Loss:0.4687337577342987, G_Loss:6.219937324523926

iterator 2900, D_Loss:0.44005125761032104, G_Loss:7.653578758239746

iterator 3000, D_Loss:0.43773147463798523, G_Loss:10.431527137756348

iterator 3100, D_Loss:0.5907716751098633, G_Loss:7.482576847076416

iterator 3200, D_Loss:0.5021534562110901, G_Loss:6.272457122802734

iterator 3300, D_Loss:0.5112980604171753, G_Loss:8.731996536254883

iterator 3400, D_Loss:0.4657329022884369, G_Loss:5.5528669357299805

iterator 3500, D_Loss:0.4183385670185089, G_Loss:8.723526000976562

iterator 3600, D_Loss:0.48700955510139465, G_Loss:11.302971839904785

iterator 3700, D_Loss:0.46630409359931946, G_Loss:7.867250919342041

iterator 3800, D_Loss:0.5168694853782654, G_Loss:5.608006954193115

iterator 3900, D_Loss:0.4559621214866638, G_Loss:6.814328193664551

iterator 4000, D_Loss:0.519313633441925, G_Loss:7.429163932800293

iterator 4100, D_Loss:0.47084829211235046, G_Loss:6.456071853637695

iterator 4200, D_Loss:0.4726884067058563, G_Loss:6.7023491859436035

iterator 4300, D_Loss:0.4199120104312897, G_Loss:9.670083045959473

iterator 4400, D_Loss:0.4764242172241211, G_Loss:5.576292991638184

iterator 4500, D_Loss:0.4721122086048126, G_Loss:11.636938095092773

iterator 4600, D_Loss:0.44402438402175903, G_Loss:9.059348106384277

iterator 4700, D_Loss:0.42426440119743347, G_Loss:12.999251365661621

iterator 4800, D_Loss:0.4491574168205261, G_Loss:11.752555847167969

iterator 4900, D_Loss:0.4655567407608032, G_Loss:14.314629554748535

iterator 5000, D_Loss:0.42177915573120117, G_Loss:13.85151195526123

-----------Epoch 9-----------
iterator 100, D_Loss:0.4240723252296448, G_Loss:8.10995101928711

iterator 200, D_Loss:0.4476570785045624, G_Loss:13.875722885131836

iterator 300, D_Loss:0.44346392154693604, G_Loss:8.838438034057617

iterator 400, D_Loss:0.43256300687789917, G_Loss:11.999963760375977

iterator 500, D_Loss:0.4295915365219116, G_Loss:11.793073654174805

iterator 600, D_Loss:0.46371403336524963, G_Loss:9.691429138183594

iterator 700, D_Loss:0.44601672887802124, G_Loss:8.90038776397705

iterator 800, D_Loss:0.4552023112773895, G_Loss:6.380825042724609

iterator 900, D_Loss:0.43655985593795776, G_Loss:8.037529945373535

iterator 1000, D_Loss:0.4181731939315796, G_Loss:10.993563652038574

iterator 1100, D_Loss:0.4372745156288147, G_Loss:3.3698558807373047

iterator 1200, D_Loss:0.4336044192314148, G_Loss:6.852373123168945

iterator 1300, D_Loss:0.433479368686676, G_Loss:8.968345642089844

iterator 1400, D_Loss:0.43918150663375854, G_Loss:7.450530529022217

iterator 1500, D_Loss:0.4431193768978119, G_Loss:11.237166404724121

iterator 1600, D_Loss:0.4570513665676117, G_Loss:10.02762222290039

iterator 1700, D_Loss:0.4393744468688965, G_Loss:9.261306762695312

iterator 1800, D_Loss:0.42283201217651367, G_Loss:8.360978126525879

iterator 1900, D_Loss:0.4532759189605713, G_Loss:8.959619522094727

iterator 2000, D_Loss:0.44664981961250305, G_Loss:7.74439001083374

iterator 2100, D_Loss:0.4447048604488373, G_Loss:11.743480682373047

iterator 2200, D_Loss:0.44770288467407227, G_Loss:7.128772735595703

iterator 2300, D_Loss:0.434177964925766, G_Loss:9.043701171875

iterator 2400, D_Loss:0.41857194900512695, G_Loss:11.545103073120117

iterator 2500, D_Loss:0.4364302158355713, G_Loss:13.050296783447266

iterator 2600, D_Loss:0.42857348918914795, G_Loss:11.940345764160156

iterator 2700, D_Loss:0.42631569504737854, G_Loss:9.964658737182617

iterator 2800, D_Loss:0.43956950306892395, G_Loss:9.425248146057129

iterator 2900, D_Loss:0.4282046854496002, G_Loss:12.219735145568848

iterator 3000, D_Loss:0.4296065866947174, G_Loss:10.93659782409668

iterator 3100, D_Loss:0.47144508361816406, G_Loss:9.519136428833008

iterator 3200, D_Loss:0.5426536202430725, G_Loss:8.853656768798828

iterator 3300, D_Loss:0.46610885858535767, G_Loss:9.757948875427246

iterator 3400, D_Loss:0.5407931804656982, G_Loss:5.740245342254639

iterator 3500, D_Loss:0.4332053065299988, G_Loss:10.672967910766602

iterator 3600, D_Loss:0.4636066257953644, G_Loss:10.90296745300293

iterator 3700, D_Loss:0.42917782068252563, G_Loss:5.405392169952393

iterator 3800, D_Loss:0.45400121808052063, G_Loss:6.623597145080566

iterator 3900, D_Loss:0.5440484881401062, G_Loss:12.005706787109375

iterator 4000, D_Loss:0.4410082697868347, G_Loss:9.017024040222168

iterator 4100, D_Loss:0.45191481709480286, G_Loss:6.666701316833496

iterator 4200, D_Loss:0.4524952173233032, G_Loss:6.918402671813965

iterator 4300, D_Loss:0.46279120445251465, G_Loss:9.318105697631836

iterator 4400, D_Loss:0.4475168287754059, G_Loss:7.6929731369018555

iterator 4500, D_Loss:0.43017956614494324, G_Loss:9.981250762939453

iterator 4600, D_Loss:0.44722750782966614, G_Loss:10.362948417663574

iterator 4700, D_Loss:0.454667329788208, G_Loss:8.859586715698242

iterator 4800, D_Loss:0.435840368270874, G_Loss:9.088492393493652

iterator 4900, D_Loss:0.4363309442996979, G_Loss:9.49393081665039

iterator 5000, D_Loss:0.5339701771736145, G_Loss:9.065963745117188

train row : 30148
sample row: 30148
Process Process-72:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 69, in thread_run
    train_method = config["train_method"]
KeyError: 'train_method'
Process Process-71:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 69, in thread_run
    train_method = config["train_method"]
KeyError: 'train_method'
Process Process-73:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 69, in thread_run
    train_method = config["train_method"]
KeyError: 'train_method'
Process Process-76:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 69, in thread_run
    train_method = config["train_method"]
KeyError: 'train_method'
Process Process-75:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 69, in thread_run
    train_method = config["train_method"]
KeyError: 'train_method'
Process Process-74:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 69, in thread_run
    train_method = config["train_method"]
KeyError: 'train_method'
Process Process-77:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 69, in thread_run
    train_method = config["train_method"]
KeyError: 'train_method'
train row : 30148
sample row: 30148
LGAN_generator(
  (LSTM): LSTMCell(600, 300)
  (gmfc00): Linear(in_features=200, out_features=1, bias=True)
  (gmfc01): Linear(in_features=200, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=200, bias=True)
  (gmfe00): Linear(in_features=300, out_features=200, bias=True)
  (gmfe01): Linear(in_features=300, out_features=200, bias=True)
  (fc10): Linear(in_features=200, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=200, bias=True)
  (fe1): Linear(in_features=300, out_features=200, bias=True)
  (gmfc20): Linear(in_features=200, out_features=1, bias=True)
  (gmfc21): Linear(in_features=200, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=200, bias=True)
  (gmfe20): Linear(in_features=300, out_features=200, bias=True)
  (gmfe21): Linear(in_features=300, out_features=200, bias=True)
  (fc30): Linear(in_features=200, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=200, bias=True)
  (fe3): Linear(in_features=300, out_features=200, bias=True)
  (gmfc40): Linear(in_features=200, out_features=1, bias=True)
  (gmfc41): Linear(in_features=200, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=200, bias=True)
  (gmfe40): Linear(in_features=300, out_features=200, bias=True)
  (gmfe41): Linear(in_features=300, out_features=200, bias=True)
  (fc50): Linear(in_features=200, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=200, bias=True)
  (fe5): Linear(in_features=300, out_features=200, bias=True)
  (fc60): Linear(in_features=200, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=200, bias=True)
  (fe6): Linear(in_features=300, out_features=200, bias=True)
  (fc70): Linear(in_features=200, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=200, bias=True)
  (fe7): Linear(in_features=300, out_features=200, bias=True)
  (fc80): Linear(in_features=200, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=200, bias=True)
  (fe8): Linear(in_features=300, out_features=200, bias=True)
  (fc90): Linear(in_features=200, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=200, bias=True)
  (fe9): Linear(in_features=300, out_features=200, bias=True)
  (gmfc100): Linear(in_features=200, out_features=1, bias=True)
  (gmfc101): Linear(in_features=200, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=200, bias=True)
  (gmfe100): Linear(in_features=300, out_features=200, bias=True)
  (gmfe101): Linear(in_features=300, out_features=200, bias=True)
  (gmfc110): Linear(in_features=200, out_features=1, bias=True)
  (gmfc111): Linear(in_features=200, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=200, bias=True)
  (gmfe110): Linear(in_features=300, out_features=200, bias=True)
  (gmfe111): Linear(in_features=300, out_features=200, bias=True)
  (gmfc120): Linear(in_features=200, out_features=1, bias=True)
  (gmfc121): Linear(in_features=200, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=200, bias=True)
  (gmfe120): Linear(in_features=300, out_features=200, bias=True)
  (gmfe121): Linear(in_features=300, out_features=200, bias=True)
  (fc130): Linear(in_features=200, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=200, bias=True)
  (fe13): Linear(in_features=300, out_features=200, bias=True)
  (fc140): Linear(in_features=200, out_features=2, bias=True)
  (fc141): Linear(in_features=2, out_features=200, bias=True)
  (fe14): Linear(in_features=300, out_features=200, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=200, bias=True)
  (inputbn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (bn0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=200, out_features=200, bias=True)
  (bn1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=200, out_features=200, bias=True)
  (bn2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=200, out_features=1, bias=True)
)
------ng : 0-------
generator loss: 0.002270350931212306
discriminator loss: -1.6307691112160683e-05
------ng : 100-------
generator loss: -0.0012600678019225597
discriminator loss: -0.002132675377652049
------ng : 200-------
generator loss: -0.0013511135475710034
discriminator loss: -0.0037358328700065613
------ng : 300-------
generator loss: -0.002847072435542941
discriminator loss: -0.0037103553768247366
------ng : 400-------
generator loss: -0.0010679865954443812
discriminator loss: -0.003037638496607542
------ng : 500-------
generator loss: -0.0016071475110948086
discriminator loss: -0.0033949294593185186
------ng : 600-------
generator loss: -0.0014971564523875713
discriminator loss: -0.003465138841420412
------ng : 700-------
generator loss: -0.00089233712060377
discriminator loss: -0.002337845042347908
------ng : 800-------
generator loss: -0.0010245833545923233
discriminator loss: -0.0030930673237890005
------ng : 900-------
generator loss: -0.0007991351885721087
discriminator loss: -0.0024656644091010094
------ng : 1000-------
generator loss: -0.0014065742725506425
discriminator loss: -0.003086910815909505
------ng : 1100-------
generator loss: -0.0008592532249167562
discriminator loss: -0.0015058149583637714
------ng : 1200-------
generator loss: -0.0008093322394415736
discriminator loss: -0.002171371830627322
------ng : 1300-------
generator loss: -0.00045898862299509346
discriminator loss: -0.0020799560006707907
------ng : 1400-------
generator loss: -0.0027250838465988636
discriminator loss: -0.003423152258619666
------ng : 1500-------
generator loss: -0.0011350825661793351
discriminator loss: -0.0020605260506272316
------ng : 1600-------
generator loss: -0.002108880551531911
discriminator loss: -0.0025287806056439877
------ng : 1700-------
generator loss: -0.0016154965851455927
discriminator loss: -0.002701654564589262
------ng : 1800-------
generator loss: -0.002183547243475914
discriminator loss: -0.002777216723188758
------ng : 1900-------
generator loss: -0.002379416720941663
discriminator loss: -0.0023101307451725006
------ng : 2000-------
generator loss: -0.0011743878712877631
discriminator loss: -0.0024145019706338644
------ng : 2100-------
generator loss: -0.0013841757318004966
discriminator loss: -0.0017802410293370485
------ng : 2200-------
generator loss: -0.0018724050605669618
discriminator loss: -0.002024996094405651
------ng : 2300-------
generator loss: -0.002620856510475278
discriminator loss: -0.0021638236939907074
------ng : 2400-------
generator loss: -0.0012878206325694919
discriminator loss: -0.0013595541240647435
------ng : 2500-------
generator loss: -0.001884833094663918
discriminator loss: -0.0017708612140268087
------ng : 2600-------
generator loss: -0.0013158965157344937
discriminator loss: -0.002483523450791836
------ng : 2700-------
generator loss: -0.0011439721565693617
discriminator loss: -0.0017637473065406084
------ng : 2800-------
generator loss: -0.0015888485359027982
discriminator loss: -0.002233455888926983
------ng : 2900-------
generator loss: -0.0009098530281335115
discriminator loss: -0.001200854079797864
------ng : 3000-------
generator loss: -0.0018127941293641925
discriminator loss: -0.0026859622448682785
------ng : 3100-------
generator loss: -0.0011869157897308469
discriminator loss: -0.0013981708325445652
------ng : 3200-------
generator loss: -0.0016495623858645558
discriminator loss: -0.002339698141440749
------ng : 3300-------
generator loss: -0.0013107872800901532
discriminator loss: -0.0019061085768043995
------ng : 3400-------
generator loss: -0.002385789528489113
discriminator loss: -0.0017049477901309729
------ng : 3500-------
generator loss: -0.0038531129248440266
discriminator loss: -0.0024013996589928865
------ng : 3600-------
generator loss: -0.000818606757093221
discriminator loss: -0.0018820969853550196
------ng : 3700-------
generator loss: -0.001360486727207899
discriminator loss: -0.0033107332419604063
------ng : 3800-------
generator loss: -0.0018530444940552115
discriminator loss: -0.002349534071981907
------ng : 3900-------
generator loss: -0.0008153024245984852
discriminator loss: -0.0014509684406220913
------ng : 4000-------
generator loss: -0.0008120394195429981
discriminator loss: -0.0015652908477932215
------ng : 4100-------
generator loss: -0.002205821219831705
discriminator loss: -0.0027019456028938293
------ng : 4200-------
generator loss: -0.0021729106083512306
discriminator loss: -0.0023414669558405876
------ng : 4300-------
generator loss: -0.001838138559833169
discriminator loss: -0.0014920829562470317
------ng : 4400-------
generator loss: -0.001384154544211924
discriminator loss: -0.002218766137957573
------ng : 4500-------
generator loss: -0.002319661434739828
discriminator loss: -0.002128642052412033
------ng : 4600-------
generator loss: -0.002113253576681018
discriminator loss: -0.0011678454466164112
------ng : 4700-------
generator loss: -0.002057616598904133
discriminator loss: -0.002306518144905567
------ng : 4800-------
generator loss: -0.001452449127100408
discriminator loss: -0.0021687985863536596
------ng : 4900-------
generator loss: -0.0011279289610683918
discriminator loss: -0.0017465578857809305
LGAN_generator(
  (LSTM): LSTMCell(450, 400)
  (gmfc00): Linear(in_features=400, out_features=1, bias=True)
  (gmfc01): Linear(in_features=400, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=400, bias=True)
  (gmfe00): Linear(in_features=400, out_features=400, bias=True)
  (gmfe01): Linear(in_features=400, out_features=400, bias=True)
  (fc10): Linear(in_features=400, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=400, bias=True)
  (fe1): Linear(in_features=400, out_features=400, bias=True)
  (gmfc20): Linear(in_features=400, out_features=1, bias=True)
  (gmfc21): Linear(in_features=400, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=400, bias=True)
  (gmfe20): Linear(in_features=400, out_features=400, bias=True)
  (gmfe21): Linear(in_features=400, out_features=400, bias=True)
  (fc30): Linear(in_features=400, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=400, bias=True)
  (fe3): Linear(in_features=400, out_features=400, bias=True)
  (gmfc40): Linear(in_features=400, out_features=1, bias=True)
  (gmfc41): Linear(in_features=400, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=400, bias=True)
  (gmfe40): Linear(in_features=400, out_features=400, bias=True)
  (gmfe41): Linear(in_features=400, out_features=400, bias=True)
  (fc50): Linear(in_features=400, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=400, bias=True)
  (fe5): Linear(in_features=400, out_features=400, bias=True)
  (fc60): Linear(in_features=400, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=400, bias=True)
  (fe6): Linear(in_features=400, out_features=400, bias=True)
  (fc70): Linear(in_features=400, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=400, bias=True)
  (fe7): Linear(in_features=400, out_features=400, bias=True)
  (fc80): Linear(in_features=400, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=400, bias=True)
  (fe8): Linear(in_features=400, out_features=400, bias=True)
  (fc90): Linear(in_features=400, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=400, bias=True)
  (fe9): Linear(in_features=400, out_features=400, bias=True)
  (gmfc100): Linear(in_features=400, out_features=1, bias=True)
  (gmfc101): Linear(in_features=400, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=400, bias=True)
  (gmfe100): Linear(in_features=400, out_features=400, bias=True)
  (gmfe101): Linear(in_features=400, out_features=400, bias=True)
  (gmfc110): Linear(in_features=400, out_features=1, bias=True)
  (gmfc111): Linear(in_features=400, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=400, bias=True)
  (gmfe110): Linear(in_features=400, out_features=400, bias=True)
  (gmfe111): Linear(in_features=400, out_features=400, bias=True)
  (gmfc120): Linear(in_features=400, out_features=1, bias=True)
  (gmfc121): Linear(in_features=400, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=400, bias=True)
  (gmfe120): Linear(in_features=400, out_features=400, bias=True)
  (gmfe121): Linear(in_features=400, out_features=400, bias=True)
  (fc130): Linear(in_features=400, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=400, bias=True)
  (fe13): Linear(in_features=400, out_features=400, bias=True)
  (fc140): Linear(in_features=400, out_features=2, bias=True)
  (fc141): Linear(in_features=2, out_features=400, bias=True)
  (fe14): Linear(in_features=400, out_features=400, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=400, bias=True)
  (inputbn): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=400, out_features=400, bias=True)
  (bn0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=400, bias=True)
  (bn1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=400, out_features=400, bias=True)
  (bn2): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=400, out_features=400, bias=True)
  (bn3): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=400, out_features=1, bias=True)
)
------ng : 0-------
generator loss: -0.003641969757154584
discriminator loss: 0.0001240381971001625
------ng : 100-------
generator loss: -0.0002874906058423221
discriminator loss: 3.2588111935183406e-05
------ng : 200-------
generator loss: 0.00012027307093376294
discriminator loss: -4.296496626920998e-06
------ng : 300-------
generator loss: -0.00024942829622887075
discriminator loss: -7.781287422403693e-06
------ng : 400-------
generator loss: 0.00024316567578352988
discriminator loss: -2.614891855046153e-06
------ng : 500-------
generator loss: -9.100350143853575e-05
discriminator loss: 6.906968337716535e-06
------ng : 600-------
generator loss: -0.00024872776702977717
discriminator loss: 1.115014310926199e-05
------ng : 700-------
generator loss: -0.0001096112173399888
discriminator loss: 4.0361661376664415e-05
------ng : 800-------
generator loss: 8.277777669718489e-05
discriminator loss: 1.1610492947511375e-05
------ng : 900-------
generator loss: -0.0002570331562310457
discriminator loss: 6.390619091689587e-07
------ng : 1000-------
generator loss: 0.00022680593247059733
discriminator loss: 6.7649089032784104e-06
------ng : 1100-------
generator loss: 0.0002407257561571896
discriminator loss: -5.5019918363541365e-06
------ng : 1200-------
generator loss: -3.587672472349368e-05
discriminator loss: -3.560935510904528e-05
------ng : 1300-------
generator loss: 0.00013088856940157712
discriminator loss: -6.027854396961629e-06
------ng : 1400-------
generator loss: 1.573132976773195e-05
discriminator loss: -9.642892109695822e-06
------ng : 1500-------
generator loss: -0.00027174080605618656
discriminator loss: -2.2901062038727105e-05
------ng : 1600-------
generator loss: -0.00025398776051588356
discriminator loss: 2.3464221158064902e-05
------ng : 1700-------
generator loss: -0.00010439535253681242
discriminator loss: -3.356752131367102e-05
------ng : 1800-------
generator loss: -0.00017946294974535704
discriminator loss: -9.721159585751593e-06
------ng : 1900-------
generator loss: -9.692234743852168e-05
discriminator loss: -1.3023382052779198e-05
------ng : 2000-------
generator loss: 0.0002713723515626043
discriminator loss: 9.05620981939137e-06
------ng : 2100-------
generator loss: -3.5346787626622245e-05
discriminator loss: 2.6795150915859267e-05
------ng : 2200-------
generator loss: 0.00016993678582366556
discriminator loss: 2.5336194084957242e-05
------ng : 2300-------
generator loss: 0.00019137377967126667
discriminator loss: 1.94311433006078e-05
------ng : 2400-------
generator loss: -6.619353371206671e-05
discriminator loss: -3.2627853215672076e-05
------ng : 2500-------
generator loss: -5.970868005533703e-05
discriminator loss: -1.98722627828829e-05
------ng : 2600-------
generator loss: -0.00015690144209656864
discriminator loss: 4.334462573751807e-06
------ng : 2700-------
generator loss: -8.665645873406902e-05
discriminator loss: 3.052184547414072e-05
------ng : 2800-------
generator loss: 0.00012923363829031587
discriminator loss: 1.4013740837981459e-05
------ng : 2900-------
generator loss: 0.00025441605248488486
discriminator loss: -3.488964284770191e-05
------ng : 3000-------
generator loss: 8.114899537758902e-05
discriminator loss: 3.300721800769679e-05
------ng : 3100-------
generator loss: -7.279258716152981e-05
discriminator loss: -2.4592038244009018e-05
------ng : 3200-------
generator loss: 0.00011759697372326627
discriminator loss: -4.5920227421447635e-05
------ng : 3300-------
generator loss: 6.049417152098613e-06
discriminator loss: -2.7882764698006213e-05
------ng : 3400-------
generator loss: -0.0003041406744159758
discriminator loss: -1.8136313883587718e-05
------ng : 3500-------
generator loss: -4.7852117859292775e-05
discriminator loss: -1.4931503756088205e-05
------ng : 3600-------
generator loss: 0.0003712608595378697
discriminator loss: 7.4540439527481794e-06
------ng : 3700-------
generator loss: -0.0003393590450286865
discriminator loss: 1.655978849157691e-05
------ng : 3800-------
generator loss: -0.00032568900496698916
discriminator loss: -4.598288796842098e-06
------ng : 3900-------
generator loss: -4.8232930566882715e-05
discriminator loss: 9.824958397075534e-06
------ng : 4000-------
generator loss: -7.91291386121884e-05
discriminator loss: 7.896116585470736e-06
------ng : 4100-------
generator loss: -2.780812337732641e-06
discriminator loss: -8.318689651787281e-06
------ng : 4200-------
generator loss: 0.0004395820142235607
discriminator loss: 5.292950663715601e-05
------ng : 4300-------
generator loss: 0.0001466372632421553
discriminator loss: 2.0805979147553444e-05
------ng : 4400-------
generator loss: -0.00022517639445140958
discriminator loss: 4.476532922126353e-06
------ng : 4500-------
generator loss: -0.0003293140616733581
discriminator loss: 1.1892203474417329e-05
------ng : 4600-------
generator loss: 0.00011234705743845552
discriminator loss: -1.940984839166049e-05
------ng : 4700-------
generator loss: 0.00015922790043987334
discriminator loss: 2.7224450604990125e-05
------ng : 4800-------
generator loss: -0.00022874740534462035
discriminator loss: -5.006921128369868e-06
------ng : 4900-------
generator loss: -7.746562914690003e-05
discriminator loss: 7.512194315495435e-06
slurmstepd: error: Detected 58898 oom-kill event(s) in StepId=29527231.batch cgroup. Some of your processes may have been killed by the cgroup out-of-memory handler.
Sep 27 19:23:06 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 19:23:06 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:71680KB rss:4024320KB rss_huge:813056KB mapped_file:71680KB swap:0KB inactive_anon:683592KB active_anon:3412400KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 27 19:23:09 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 19:23:09 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:63716KB rss:4032284KB rss_huge:731136KB mapped_file:62032KB swap:0KB inactive_anon:689080KB active_anon:3404644KB inactive_file:1108KB active_file:1040KB unevictable:0KB
Sep 27 19:23:13 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 19:23:13 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:53080KB rss:4042920KB rss_huge:704512KB mapped_file:52112KB swap:0KB inactive_anon:682404KB active_anon:3411716KB inactive_file:968KB active_file:912KB unevictable:0KB
Sep 27 19:23:16 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 19:23:16 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:40960KB rss:4055040KB rss_huge:702464KB mapped_file:40960KB swap:0KB inactive_anon:682704KB active_anon:3413256KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 27 19:23:18 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 19:23:18 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:30720KB rss:4065280KB rss_huge:849920KB mapped_file:30720KB swap:0KB inactive_anon:684700KB active_anon:3411300KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 27 19:55:25 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 19:55:25 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:72320KB rss:4023680KB rss_huge:788480KB mapped_file:72320KB swap:0KB inactive_anon:682680KB active_anon:3412640KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 27 19:55:28 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 19:55:28 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:63360KB rss:4032640KB rss_huge:692224KB mapped_file:61852KB swap:0KB inactive_anon:682352KB active_anon:3411728KB inactive_file:960KB active_file:960KB unevictable:0KB
Sep 27 19:55:30 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 19:55:30 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:52672KB rss:4043328KB rss_huge:675840KB mapped_file:51212KB swap:0KB inactive_anon:682484KB active_anon:3412044KB inactive_file:744KB active_file:728KB unevictable:0KB
Sep 27 19:55:32 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 19:55:32 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:41216KB rss:4054784KB rss_huge:561152KB mapped_file:41216KB swap:0KB inactive_anon:682748KB active_anon:3412992KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 27 19:55:34 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 19:55:34 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:30720KB rss:4065280KB rss_huge:747520KB mapped_file:30720KB swap:0KB inactive_anon:709104KB active_anon:3386896KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 27 20:23:22 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 20:23:22 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:71876KB rss:4024124KB rss_huge:1060864KB mapped_file:71744KB swap:0KB inactive_anon:689680KB active_anon:3406124KB inactive_file:132KB active_file:64KB unevictable:0KB
Sep 27 20:23:25 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 20:23:25 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:62700KB rss:4033300KB rss_huge:983040KB mapped_file:61444KB swap:0KB inactive_anon:688396KB active_anon:3406344KB inactive_file:692KB active_file:568KB unevictable:0KB
Sep 27 20:23:29 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 20:23:29 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:53348KB rss:4042652KB rss_huge:919552KB mapped_file:51908KB swap:0KB inactive_anon:687936KB active_anon:3405916KB inactive_file:1092KB active_file:1056KB unevictable:0KB
Sep 27 20:23:33 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 20:23:33 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:40960KB rss:4055040KB rss_huge:866304KB mapped_file:40960KB swap:0KB inactive_anon:684740KB active_anon:3411252KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 27 20:23:35 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 20:23:35 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:30720KB rss:4065280KB rss_huge:1011712KB mapped_file:30720KB swap:0KB inactive_anon:684456KB active_anon:3411544KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 27 20:55:38 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 20:55:38 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:71876KB rss:4024124KB rss_huge:1101824KB mapped_file:71684KB swap:0KB inactive_anon:684380KB active_anon:3411424KB inactive_file:120KB active_file:76KB unevictable:0KB
Sep 27 20:55:40 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 20:55:40 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:61444KB rss:4034556KB rss_huge:1001472KB mapped_file:61440KB swap:0KB inactive_anon:685092KB active_anon:3410904KB inactive_file:4KB active_file:0KB unevictable:0KB
Sep 27 20:55:43 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 20:55:43 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:52012KB rss:4043988KB rss_huge:921600KB mapped_file:51300KB swap:0KB inactive_anon:682576KB active_anon:3412612KB inactive_file:448KB active_file:364KB unevictable:0KB
Sep 27 20:55:45 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 20:55:45 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:40960KB rss:4055040KB rss_huge:880640KB mapped_file:40960KB swap:0KB inactive_anon:682720KB active_anon:3413244KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 27 20:55:47 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 20:55:47 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:30720KB rss:4065280KB rss_huge:1021952KB mapped_file:30720KB swap:0KB inactive_anon:684428KB active_anon:3411572KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 27 21:27:22 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 21:27:22 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:72344KB rss:4023656KB rss_huge:1398784KB mapped_file:71936KB swap:0KB inactive_anon:682568KB active_anon:3412768KB inactive_file:272KB active_file:136KB unevictable:0KB
Sep 27 21:27:26 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 21:27:26 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:61788KB rss:4034212KB rss_huge:1216512KB mapped_file:61444KB swap:0KB inactive_anon:688064KB active_anon:3407588KB inactive_file:260KB active_file:88KB unevictable:0KB
Sep 27 21:27:30 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 21:27:30 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:51208KB rss:4044792KB rss_huge:1032192KB mapped_file:51204KB swap:0KB inactive_anon:686924KB active_anon:3409068KB inactive_file:4KB active_file:4KB unevictable:0KB
Sep 27 21:27:33 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 21:27:33 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:49200KB rss:4046720KB rss_huge:956416KB mapped_file:49200KB swap:0KB inactive_anon:686812KB active_anon:3409052KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 27 21:27:35 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 21:27:35 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:36864KB rss:4059136KB rss_huge:1026048KB mapped_file:36864KB swap:0KB inactive_anon:685904KB active_anon:3410096KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 27 22:59:57 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 22:59:57 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:72840KB rss:4023160KB rss_huge:970752KB mapped_file:71968KB swap:0KB inactive_anon:685836KB active_anon:3409004KB inactive_file:588KB active_file:572KB unevictable:0KB
Sep 27 23:00:00 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 23:00:00 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:61460KB rss:4034540KB rss_huge:876544KB mapped_file:61440KB swap:0KB inactive_anon:684432KB active_anon:3411548KB inactive_file:20KB active_file:0KB unevictable:0KB
Sep 27 23:00:04 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 23:00:04 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:51812KB rss:4044188KB rss_huge:845824KB mapped_file:51216KB swap:0KB inactive_anon:682568KB active_anon:3412820KB inactive_file:324KB active_file:288KB unevictable:0KB
Sep 27 23:00:08 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 23:00:08 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:49152KB rss:4046848KB rss_huge:831488KB mapped_file:49152KB swap:0KB inactive_anon:684592KB active_anon:3411396KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 27 23:00:09 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 27 23:00:09 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:36864KB rss:4059136KB rss_huge:923648KB mapped_file:36864KB swap:0KB inactive_anon:684928KB active_anon:3411072KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 00:24:33 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 00:24:33 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:72828KB rss:4023172KB rss_huge:657408KB mapped_file:71712KB swap:0KB inactive_anon:686792KB active_anon:3408060KB inactive_file:580KB active_file:568KB unevictable:0KB
Sep 28 00:24:36 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 00:24:36 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:61444KB rss:4034556KB rss_huge:632832KB mapped_file:61440KB swap:0KB inactive_anon:682680KB active_anon:3413316KB inactive_file:4KB active_file:0KB unevictable:0KB
Sep 28 00:24:40 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 00:24:40 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:52992KB rss:4043008KB rss_huge:567296KB mapped_file:51304KB swap:0KB inactive_anon:683992KB active_anon:3410216KB inactive_file:924KB active_file:868KB unevictable:0KB
Sep 28 00:24:44 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 00:24:44 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:49232KB rss:4046720KB rss_huge:587776KB mapped_file:49232KB swap:0KB inactive_anon:683668KB active_anon:3412164KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 00:24:45 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 00:24:45 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:36864KB rss:4059136KB rss_huge:745472KB mapped_file:36864KB swap:0KB inactive_anon:684836KB active_anon:3411164KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 01:30:43 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 01:30:43 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:71680KB rss:4024320KB rss_huge:161792KB mapped_file:71680KB swap:0KB inactive_anon:682688KB active_anon:3413284KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 01:30:46 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 01:30:46 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:61440KB rss:4034560KB rss_huge:178176KB mapped_file:61440KB swap:0KB inactive_anon:682776KB active_anon:3413220KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 01:30:50 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 01:30:50 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:51584KB rss:4044416KB rss_huge:231424KB mapped_file:51432KB swap:0KB inactive_anon:682636KB active_anon:3412960KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 01:30:52 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 01:30:52 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:49152KB rss:4046848KB rss_huge:303104KB mapped_file:49152KB swap:0KB inactive_anon:682752KB active_anon:3413224KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 01:30:55 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 01:30:55 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:36864KB rss:4059136KB rss_huge:303104KB mapped_file:36864KB swap:0KB inactive_anon:684904KB active_anon:3411096KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 02:17:06 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 02:17:06 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:72576KB rss:4023368KB rss_huge:126976KB mapped_file:71684KB swap:0KB inactive_anon:825180KB active_anon:3269868KB inactive_file:508KB active_file:316KB unevictable:0KB
Sep 28 02:17:09 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 02:17:09 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:61448KB rss:4034552KB rss_huge:126976KB mapped_file:61444KB swap:0KB inactive_anon:806428KB active_anon:3289564KB inactive_file:4KB active_file:4KB unevictable:0KB
Sep 28 02:17:14 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 02:17:14 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:54116KB rss:4041884KB rss_huge:126976KB mapped_file:51812KB swap:0KB inactive_anon:783376KB active_anon:3309708KB inactive_file:1496KB active_file:1420KB unevictable:0KB
Sep 28 02:17:18 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 02:17:18 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:49408KB rss:4046592KB rss_huge:126976KB mapped_file:49408KB swap:0KB inactive_anon:766916KB active_anon:3328812KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 02:17:20 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 02:17:20 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:36864KB rss:4059136KB rss_huge:126976KB mapped_file:36864KB swap:0KB inactive_anon:753344KB active_anon:3342656KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 03:54:25 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 03:54:25 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:71808KB rss:4024192KB rss_huge:32768KB mapped_file:71808KB swap:0KB inactive_anon:1023524KB active_anon:3072332KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 03:54:30 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 03:54:30 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:62444KB rss:4033556KB rss_huge:32768KB mapped_file:61444KB swap:0KB inactive_anon:1035668KB active_anon:3059328KB inactive_file:524KB active_file:480KB unevictable:0KB
Sep 28 03:54:34 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 03:54:34 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:51200KB rss:4044800KB rss_huge:32768KB mapped_file:51200KB swap:0KB inactive_anon:1113232KB active_anon:2982740KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 03:54:38 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 03:54:38 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:49152KB rss:4046848KB rss_huge:32768KB mapped_file:49152KB swap:0KB inactive_anon:1029100KB active_anon:3066896KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 03:54:40 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 03:54:40 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:36864KB rss:4059136KB rss_huge:32768KB mapped_file:36864KB swap:0KB inactive_anon:874192KB active_anon:3221808KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 05:26:13 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 05:26:13 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:72064KB rss:4023936KB rss_huge:24576KB mapped_file:72064KB swap:0KB inactive_anon:682636KB active_anon:3412940KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 05:26:17 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 05:26:17 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:61820KB rss:4034172KB rss_huge:24576KB mapped_file:61820KB swap:0KB inactive_anon:682664KB active_anon:3412908KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 05:26:21 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 05:26:21 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:51712KB rss:4044288KB rss_huge:24576KB mapped_file:51712KB swap:0KB inactive_anon:682612KB active_anon:3412868KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 05:26:27 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 05:26:27 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:49152KB rss:4046848KB rss_huge:24576KB mapped_file:49152KB swap:0KB inactive_anon:682768KB active_anon:3413196KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 05:26:28 spartan-gpgpu080 kernel: Task in /slurm/uid_13885/job_29527231/step_batch killed as a result of limit of /slurm/uid_13885/job_29527231/step_batch
Sep 28 05:26:28 spartan-gpgpu080 kernel: Memory cgroup stats for /slurm/uid_13885/job_29527231/step_batch: cache:36864KB rss:4059136KB rss_huge:24576KB mapped_file:36864KB swap:0KB inactive_anon:601028KB active_anon:3494972KB inactive_file:0KB active_file:0KB unevictable:0KB
