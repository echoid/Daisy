train row : 30148
sample row: 30148
VGAN_generator(
  (input): Linear(in_features=128, out_features=300, bias=True)
  (inputbn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=300, out_features=300, bias=True)
  (bn0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=300, out_features=300, bias=True)
  (bn1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=300, out_features=300, bias=True)
  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=300, out_features=105, bias=True)
  (outputbn): BatchNorm1d(105, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=105, out_features=100, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (output): Linear(in_features=100, out_features=1, bias=True)
)
(0, False, 105)
-----------Epoch 0-----------
iterator 100, D_Loss:0.6406540274620056, G_Loss:5.9167280197143555

iterator 200, D_Loss:0.5922768115997314, G_Loss:7.161771774291992

iterator 300, D_Loss:0.6035172343254089, G_Loss:6.829960823059082

iterator 400, D_Loss:0.6195234060287476, G_Loss:6.038949966430664

iterator 500, D_Loss:0.6193972826004028, G_Loss:5.484425067901611

iterator 600, D_Loss:0.6636060476303101, G_Loss:4.919785499572754

iterator 700, D_Loss:0.6094446182250977, G_Loss:4.605921268463135

iterator 800, D_Loss:0.6316395401954651, G_Loss:3.6463873386383057

iterator 900, D_Loss:0.7215018272399902, G_Loss:3.2673778533935547

iterator 1000, D_Loss:0.7979639768600464, G_Loss:2.752225875854492

iterator 1100, D_Loss:0.83188396692276, G_Loss:2.8356547355651855

iterator 1200, D_Loss:0.9092245101928711, G_Loss:2.540790557861328

iterator 1300, D_Loss:0.8379886150360107, G_Loss:2.7023236751556396

iterator 1400, D_Loss:0.8588014245033264, G_Loss:2.469228506088257

iterator 1500, D_Loss:0.9199727177619934, G_Loss:2.2576544284820557

iterator 1600, D_Loss:0.8267700672149658, G_Loss:2.280895471572876

iterator 1700, D_Loss:0.8826398849487305, G_Loss:2.335381031036377

iterator 1800, D_Loss:0.8631014823913574, G_Loss:2.478208541870117

iterator 1900, D_Loss:0.9087284803390503, G_Loss:2.3642215728759766

iterator 2000, D_Loss:0.9550803899765015, G_Loss:2.235799789428711

iterator 2100, D_Loss:0.8419647216796875, G_Loss:1.9588240385055542

iterator 2200, D_Loss:0.9749332070350647, G_Loss:1.967388391494751

iterator 2300, D_Loss:1.004615068435669, G_Loss:2.1616835594177246

iterator 2400, D_Loss:0.9818530678749084, G_Loss:1.9236444234848022

iterator 2500, D_Loss:1.0365986824035645, G_Loss:1.9078909158706665

iterator 2600, D_Loss:1.0496166944503784, G_Loss:1.7537916898727417

iterator 2700, D_Loss:0.9775094985961914, G_Loss:2.0172858238220215

iterator 2800, D_Loss:1.167980670928955, G_Loss:1.5599958896636963

iterator 2900, D_Loss:1.1486600637435913, G_Loss:1.4730479717254639

iterator 3000, D_Loss:1.1935911178588867, G_Loss:1.434418797492981

iterator 3100, D_Loss:1.0993099212646484, G_Loss:1.5249699354171753

iterator 3200, D_Loss:1.1133997440338135, G_Loss:1.5087645053863525

iterator 3300, D_Loss:1.1299257278442383, G_Loss:1.6153665781021118

iterator 3400, D_Loss:1.1704926490783691, G_Loss:1.653342604637146

iterator 3500, D_Loss:1.133495807647705, G_Loss:1.4657617807388306

iterator 3600, D_Loss:1.095503568649292, G_Loss:1.42308509349823

iterator 3700, D_Loss:1.15675950050354, G_Loss:1.3480992317199707

iterator 3800, D_Loss:1.1584348678588867, G_Loss:1.3901523351669312

iterator 3900, D_Loss:1.1044648885726929, G_Loss:1.4782097339630127

iterator 4000, D_Loss:1.1642084121704102, G_Loss:1.3613049983978271

iterator 4100, D_Loss:1.2234106063842773, G_Loss:1.385396122932434

iterator 4200, D_Loss:1.2053377628326416, G_Loss:1.336754560470581

iterator 4300, D_Loss:1.2399110794067383, G_Loss:1.3471006155014038

iterator 4400, D_Loss:1.3085483312606812, G_Loss:1.2667930126190186

iterator 4500, D_Loss:1.2244815826416016, G_Loss:1.3617331981658936

iterator 4600, D_Loss:1.1932121515274048, G_Loss:1.3087115287780762

iterator 4700, D_Loss:1.259472370147705, G_Loss:1.2373682260513306

iterator 4800, D_Loss:1.2026962041854858, G_Loss:1.230679988861084

iterator 4900, D_Loss:1.1730912923812866, G_Loss:1.3092432022094727

iterator 5000, D_Loss:1.2857087850570679, G_Loss:1.2537667751312256

-----------Epoch 1-----------
iterator 100, D_Loss:1.2334363460540771, G_Loss:1.2079869508743286

iterator 200, D_Loss:1.2334473133087158, G_Loss:1.1216137409210205

iterator 300, D_Loss:1.2178928852081299, G_Loss:1.319419503211975

iterator 400, D_Loss:1.2412223815917969, G_Loss:1.3013919591903687

iterator 500, D_Loss:1.2722387313842773, G_Loss:1.1571526527404785

iterator 600, D_Loss:1.2229037284851074, G_Loss:1.2265853881835938

iterator 700, D_Loss:1.2484452724456787, G_Loss:1.0607553720474243

iterator 800, D_Loss:1.3001853227615356, G_Loss:1.1628307104110718

iterator 900, D_Loss:1.2885267734527588, G_Loss:1.203518033027649

iterator 1000, D_Loss:1.2273380756378174, G_Loss:1.1325129270553589

iterator 1100, D_Loss:1.2317308187484741, G_Loss:1.1138536930084229

iterator 1200, D_Loss:1.275909185409546, G_Loss:1.1131216287612915

iterator 1300, D_Loss:1.2760438919067383, G_Loss:1.202490210533142

iterator 1400, D_Loss:1.2891993522644043, G_Loss:1.0912333726882935

iterator 1500, D_Loss:1.249157428741455, G_Loss:1.1397439241409302

iterator 1600, D_Loss:1.3040424585342407, G_Loss:1.0502525568008423

iterator 1700, D_Loss:1.262193202972412, G_Loss:1.0289485454559326

iterator 1800, D_Loss:1.3014981746673584, G_Loss:1.1173051595687866

iterator 1900, D_Loss:1.3060731887817383, G_Loss:1.053187370300293

iterator 2000, D_Loss:1.3023334741592407, G_Loss:1.07225501537323

iterator 2100, D_Loss:1.3150776624679565, G_Loss:1.0323892831802368

iterator 2200, D_Loss:1.2789523601531982, G_Loss:1.0470041036605835

iterator 2300, D_Loss:1.3058114051818848, G_Loss:1.0112998485565186

iterator 2400, D_Loss:1.29236900806427, G_Loss:1.042140245437622

iterator 2500, D_Loss:1.3074902296066284, G_Loss:1.0136460065841675

iterator 2600, D_Loss:1.285224437713623, G_Loss:1.0365574359893799

iterator 2700, D_Loss:1.318509578704834, G_Loss:0.9998438954353333

iterator 2800, D_Loss:1.3016188144683838, G_Loss:1.0265158414840698

iterator 2900, D_Loss:1.3127102851867676, G_Loss:1.042556881904602

iterator 3000, D_Loss:1.270089864730835, G_Loss:1.0714836120605469

iterator 3100, D_Loss:1.3002302646636963, G_Loss:1.0599747896194458

iterator 3200, D_Loss:1.288041591644287, G_Loss:1.108343243598938

iterator 3300, D_Loss:1.2839579582214355, G_Loss:1.1085017919540405

iterator 3400, D_Loss:1.2791669368743896, G_Loss:1.086343765258789

iterator 3500, D_Loss:1.2784669399261475, G_Loss:1.115325689315796

iterator 3600, D_Loss:1.2779936790466309, G_Loss:1.039015769958496

iterator 3700, D_Loss:1.3085198402404785, G_Loss:0.9321507215499878

iterator 3800, D_Loss:1.2872424125671387, G_Loss:1.0412063598632812

iterator 3900, D_Loss:1.296005129814148, G_Loss:0.997475266456604

iterator 4000, D_Loss:1.2745468616485596, G_Loss:1.0134955644607544

iterator 4100, D_Loss:1.2952792644500732, G_Loss:1.0117298364639282

iterator 4200, D_Loss:1.3161860704421997, G_Loss:1.0584136247634888

iterator 4300, D_Loss:1.3110105991363525, G_Loss:1.0558502674102783

iterator 4400, D_Loss:1.3298108577728271, G_Loss:1.0359724760055542

iterator 4500, D_Loss:1.3019278049468994, G_Loss:0.9751906394958496

iterator 4600, D_Loss:1.3067643642425537, G_Loss:1.0379139184951782

iterator 4700, D_Loss:1.3091521263122559, G_Loss:1.0002825260162354

iterator 4800, D_Loss:1.3569185733795166, G_Loss:1.0044586658477783

iterator 4900, D_Loss:1.3569893836975098, G_Loss:1.0167385339736938

iterator 5000, D_Loss:1.315500020980835, G_Loss:0.9485476016998291

-----------Epoch 2-----------
iterator 100, D_Loss:1.3165279626846313, G_Loss:1.024308204650879

iterator 200, D_Loss:1.359022617340088, G_Loss:0.9573079943656921

iterator 300, D_Loss:1.33725905418396, G_Loss:0.9575703740119934

iterator 400, D_Loss:1.3494000434875488, G_Loss:0.9427071213722229

iterator 500, D_Loss:1.315946340560913, G_Loss:0.9217715859413147

iterator 600, D_Loss:1.3453717231750488, G_Loss:0.9384483695030212

iterator 700, D_Loss:1.3165582418441772, G_Loss:0.9657316207885742

iterator 800, D_Loss:1.3609399795532227, G_Loss:0.9640126824378967

iterator 900, D_Loss:1.3272485733032227, G_Loss:0.9499168395996094

iterator 1000, D_Loss:1.3328089714050293, G_Loss:0.9616935849189758

iterator 1100, D_Loss:1.338255524635315, G_Loss:0.9723849892616272

iterator 1200, D_Loss:1.361050009727478, G_Loss:0.9491701722145081

iterator 1300, D_Loss:1.326243281364441, G_Loss:0.9733684062957764

iterator 1400, D_Loss:1.3034992218017578, G_Loss:0.9314648509025574

iterator 1500, D_Loss:1.3139302730560303, G_Loss:0.9673937559127808

iterator 1600, D_Loss:1.326157808303833, G_Loss:0.9551203846931458

iterator 1700, D_Loss:1.3477206230163574, G_Loss:0.9924399256706238

iterator 1800, D_Loss:1.3351774215698242, G_Loss:0.9964431524276733

iterator 1900, D_Loss:1.341863989830017, G_Loss:0.9386526346206665

iterator 2000, D_Loss:1.3365501165390015, G_Loss:0.9894071817398071

iterator 2100, D_Loss:1.3324652910232544, G_Loss:0.9676846861839294

iterator 2200, D_Loss:1.308535099029541, G_Loss:1.037201166152954

iterator 2300, D_Loss:1.324216365814209, G_Loss:0.974711537361145

iterator 2400, D_Loss:1.3240485191345215, G_Loss:0.9579063653945923

iterator 2500, D_Loss:1.3392170667648315, G_Loss:0.9521132111549377

iterator 2600, D_Loss:1.3256105184555054, G_Loss:0.9841210246086121

iterator 2700, D_Loss:1.3629872798919678, G_Loss:0.9665907621383667

iterator 2800, D_Loss:1.3151582479476929, G_Loss:0.9683309197425842

iterator 2900, D_Loss:1.3346149921417236, G_Loss:0.9944026470184326

iterator 3000, D_Loss:1.3328399658203125, G_Loss:0.9754220843315125

iterator 3100, D_Loss:1.3357722759246826, G_Loss:0.9988940954208374

iterator 3200, D_Loss:1.3360373973846436, G_Loss:0.931226372718811

iterator 3300, D_Loss:1.3375654220581055, G_Loss:0.9882288575172424

iterator 3400, D_Loss:1.3254408836364746, G_Loss:0.9663304090499878

iterator 3500, D_Loss:1.3295639753341675, G_Loss:0.9777498245239258

iterator 3600, D_Loss:1.338005542755127, G_Loss:0.9676972031593323

iterator 3700, D_Loss:1.3126251697540283, G_Loss:0.9561550617218018

iterator 3800, D_Loss:1.3127132654190063, G_Loss:1.000962495803833

iterator 3900, D_Loss:1.366304874420166, G_Loss:0.9610744118690491

iterator 4000, D_Loss:1.3348808288574219, G_Loss:0.929179847240448

iterator 4100, D_Loss:1.3066229820251465, G_Loss:1.026236653327942

iterator 4200, D_Loss:1.3066976070404053, G_Loss:0.9783431887626648

iterator 4300, D_Loss:1.3620268106460571, G_Loss:0.9472603797912598

iterator 4400, D_Loss:1.3238284587860107, G_Loss:0.9751943349838257

iterator 4500, D_Loss:1.316626787185669, G_Loss:0.9492970108985901

iterator 4600, D_Loss:1.3413796424865723, G_Loss:0.9554216265678406

iterator 4700, D_Loss:1.3124475479125977, G_Loss:0.9709383249282837

iterator 4800, D_Loss:1.3363374471664429, G_Loss:0.9504421949386597

iterator 4900, D_Loss:1.352013349533081, G_Loss:0.9466403126716614

iterator 5000, D_Loss:1.3558545112609863, G_Loss:0.9308632612228394

-----------Epoch 3-----------
iterator 100, D_Loss:1.3146791458129883, G_Loss:0.9667208790779114

iterator 200, D_Loss:1.333106517791748, G_Loss:0.9434229731559753

iterator 300, D_Loss:1.3606607913970947, G_Loss:0.981982946395874

iterator 400, D_Loss:1.3179895877838135, G_Loss:0.9426619410514832

iterator 500, D_Loss:1.2941900491714478, G_Loss:0.9305614829063416

iterator 600, D_Loss:1.337968349456787, G_Loss:0.9633529186248779

iterator 700, D_Loss:1.3352601528167725, G_Loss:0.9594522714614868

iterator 800, D_Loss:1.3552716970443726, G_Loss:0.9552379846572876

iterator 900, D_Loss:1.324613332748413, G_Loss:0.9452319145202637

iterator 1000, D_Loss:1.3492021560668945, G_Loss:0.9640873074531555

iterator 1100, D_Loss:1.2718027830123901, G_Loss:1.0281200408935547

iterator 1200, D_Loss:1.3293685913085938, G_Loss:0.9147550463676453

iterator 1300, D_Loss:1.3387880325317383, G_Loss:0.9430021643638611

iterator 1400, D_Loss:1.2984716892242432, G_Loss:0.9303159713745117

iterator 1500, D_Loss:1.3425954580307007, G_Loss:0.95921790599823

iterator 1600, D_Loss:1.3347127437591553, G_Loss:0.9357599020004272

iterator 1700, D_Loss:1.3213483095169067, G_Loss:1.0305403470993042

iterator 1800, D_Loss:1.328944206237793, G_Loss:0.9886901378631592

iterator 1900, D_Loss:1.3101301193237305, G_Loss:0.9737673401832581

iterator 2000, D_Loss:1.3579041957855225, G_Loss:0.983538031578064

iterator 2100, D_Loss:1.342958927154541, G_Loss:0.9815757274627686

iterator 2200, D_Loss:1.3523759841918945, G_Loss:0.9695372581481934

iterator 2300, D_Loss:1.349884033203125, G_Loss:0.9931235909461975

iterator 2400, D_Loss:1.344895601272583, G_Loss:0.9583230018615723

iterator 2500, D_Loss:1.3118336200714111, G_Loss:1.0147675275802612

iterator 2600, D_Loss:1.3239635229110718, G_Loss:1.0001888275146484

iterator 2700, D_Loss:1.3418858051300049, G_Loss:1.0054413080215454

iterator 2800, D_Loss:1.339398741722107, G_Loss:1.0051485300064087

iterator 2900, D_Loss:1.355329990386963, G_Loss:0.955807626247406

iterator 3000, D_Loss:1.3250364065170288, G_Loss:0.9573187828063965

iterator 3100, D_Loss:1.316138505935669, G_Loss:0.9626281261444092

iterator 3200, D_Loss:1.316488265991211, G_Loss:0.9235756397247314

iterator 3300, D_Loss:1.3477756977081299, G_Loss:0.9546825289726257

iterator 3400, D_Loss:1.354371190071106, G_Loss:0.942671000957489

iterator 3500, D_Loss:1.3260691165924072, G_Loss:1.0095494985580444

iterator 3600, D_Loss:1.3159254789352417, G_Loss:0.9659082889556885

iterator 3700, D_Loss:1.337056040763855, G_Loss:0.9708372950553894

iterator 3800, D_Loss:1.325862169265747, G_Loss:0.9969651699066162

iterator 3900, D_Loss:1.3236796855926514, G_Loss:1.0072234869003296

iterator 4000, D_Loss:1.3495022058486938, G_Loss:0.9648824334144592

iterator 4100, D_Loss:1.3321542739868164, G_Loss:0.9757230281829834

iterator 4200, D_Loss:1.3262147903442383, G_Loss:0.9378795027732849

iterator 4300, D_Loss:1.3349566459655762, G_Loss:0.9722498059272766

iterator 4400, D_Loss:1.3308748006820679, G_Loss:1.00275456905365

iterator 4500, D_Loss:1.319612979888916, G_Loss:0.9963337779045105

iterator 4600, D_Loss:1.3549509048461914, G_Loss:0.9671012163162231

iterator 4700, D_Loss:1.3395156860351562, G_Loss:0.956170380115509

iterator 4800, D_Loss:1.3107874393463135, G_Loss:0.9753364324569702

iterator 4900, D_Loss:1.338970422744751, G_Loss:0.9427337646484375

iterator 5000, D_Loss:1.3282495737075806, G_Loss:0.9741764068603516

-----------Epoch 4-----------
iterator 100, D_Loss:1.3213472366333008, G_Loss:0.9539611339569092

iterator 200, D_Loss:1.3224904537200928, G_Loss:0.9895469546318054

iterator 300, D_Loss:1.3175809383392334, G_Loss:0.9982658624649048

iterator 400, D_Loss:1.3216757774353027, G_Loss:0.9633793830871582

iterator 500, D_Loss:1.2928932905197144, G_Loss:0.9897696375846863

iterator 600, D_Loss:1.333747148513794, G_Loss:0.9788636565208435

iterator 700, D_Loss:1.343019962310791, G_Loss:0.9557514190673828

iterator 800, D_Loss:1.3372796773910522, G_Loss:0.9688281416893005

iterator 900, D_Loss:1.3305611610412598, G_Loss:0.9283686280250549

iterator 1000, D_Loss:1.331400752067566, G_Loss:0.9486038684844971

iterator 1100, D_Loss:1.3438630104064941, G_Loss:0.9708983898162842

iterator 1200, D_Loss:1.3577626943588257, G_Loss:0.9103332757949829

iterator 1300, D_Loss:1.3398516178131104, G_Loss:0.9269292950630188

iterator 1400, D_Loss:1.3286470174789429, G_Loss:0.9087575674057007

iterator 1500, D_Loss:1.3437632322311401, G_Loss:0.9446099996566772

iterator 1600, D_Loss:1.335051417350769, G_Loss:0.9944657683372498

iterator 1700, D_Loss:1.3392868041992188, G_Loss:0.9537773132324219

iterator 1800, D_Loss:1.334367275238037, G_Loss:0.9919236302375793

iterator 1900, D_Loss:1.3129749298095703, G_Loss:0.9481199979782104

iterator 2000, D_Loss:1.3170676231384277, G_Loss:0.9752730131149292

iterator 2100, D_Loss:1.3241939544677734, G_Loss:0.940268337726593

iterator 2200, D_Loss:1.3176867961883545, G_Loss:0.9815911054611206

iterator 2300, D_Loss:1.3329195976257324, G_Loss:0.9985450506210327

iterator 2400, D_Loss:1.3408972024917603, G_Loss:0.9598322510719299

iterator 2500, D_Loss:1.3534334897994995, G_Loss:0.947685956954956

iterator 2600, D_Loss:1.3405886888504028, G_Loss:0.947364091873169

iterator 2700, D_Loss:1.3438236713409424, G_Loss:1.0125540494918823

iterator 2800, D_Loss:1.2931733131408691, G_Loss:0.9611735343933105

iterator 2900, D_Loss:1.322542667388916, G_Loss:0.9613528251647949

iterator 3000, D_Loss:1.3347382545471191, G_Loss:0.9441252946853638

iterator 3100, D_Loss:1.3269975185394287, G_Loss:0.9776791930198669

iterator 3200, D_Loss:1.3353780508041382, G_Loss:0.9425244927406311

iterator 3300, D_Loss:1.3483988046646118, G_Loss:0.9820215702056885

iterator 3400, D_Loss:1.3261232376098633, G_Loss:0.9533926844596863

iterator 3500, D_Loss:1.326960563659668, G_Loss:0.9817129969596863

iterator 3600, D_Loss:1.3556642532348633, G_Loss:0.943983256816864

iterator 3700, D_Loss:1.3406953811645508, G_Loss:0.9102194309234619

iterator 3800, D_Loss:1.3268468379974365, G_Loss:0.9223102927207947

iterator 3900, D_Loss:1.3444652557373047, G_Loss:0.935620903968811

iterator 4000, D_Loss:1.320924997329712, G_Loss:0.9589216709136963

iterator 4100, D_Loss:1.3526136875152588, G_Loss:0.9684261083602905

iterator 4200, D_Loss:1.3426605463027954, G_Loss:0.9652135372161865

iterator 4300, D_Loss:1.3349511623382568, G_Loss:0.9543383717536926

iterator 4400, D_Loss:1.3252981901168823, G_Loss:1.0205223560333252

iterator 4500, D_Loss:1.331289291381836, G_Loss:0.9437719583511353

iterator 4600, D_Loss:1.3452017307281494, G_Loss:0.9963153600692749

iterator 4700, D_Loss:1.3384110927581787, G_Loss:0.9684392809867859

iterator 4800, D_Loss:1.3488848209381104, G_Loss:0.930260956287384

iterator 4900, D_Loss:1.3230440616607666, G_Loss:0.921599268913269

iterator 5000, D_Loss:1.342636227607727, G_Loss:0.9233338236808777

-----------Epoch 5-----------
iterator 100, D_Loss:1.3564598560333252, G_Loss:0.9261220097541809

iterator 200, D_Loss:1.325155258178711, G_Loss:0.9440842270851135

iterator 300, D_Loss:1.332409143447876, G_Loss:0.9617311954498291

iterator 400, D_Loss:1.3592946529388428, G_Loss:0.9643399715423584

iterator 500, D_Loss:1.3353996276855469, G_Loss:0.9472925662994385

iterator 600, D_Loss:1.344276785850525, G_Loss:0.9558389186859131

iterator 700, D_Loss:1.3430817127227783, G_Loss:0.988012433052063

iterator 800, D_Loss:1.3518173694610596, G_Loss:0.9339774250984192

iterator 900, D_Loss:1.3227782249450684, G_Loss:0.937105119228363

iterator 1000, D_Loss:1.319939136505127, G_Loss:1.0033373832702637

iterator 1100, D_Loss:1.3108214139938354, G_Loss:0.9514453411102295

iterator 1200, D_Loss:1.3327736854553223, G_Loss:0.9476636648178101

iterator 1300, D_Loss:1.32676100730896, G_Loss:0.9677258729934692

iterator 1400, D_Loss:1.2971577644348145, G_Loss:0.97733473777771

iterator 1500, D_Loss:1.3146076202392578, G_Loss:1.0007654428482056

iterator 1600, D_Loss:1.3121083974838257, G_Loss:0.9747128486633301

iterator 1700, D_Loss:1.3628209829330444, G_Loss:0.9901500940322876

iterator 1800, D_Loss:1.3282296657562256, G_Loss:0.9413278698921204

iterator 1900, D_Loss:1.3250465393066406, G_Loss:0.9770996570587158

iterator 2000, D_Loss:1.3013155460357666, G_Loss:0.9343402981758118

iterator 2100, D_Loss:1.333857536315918, G_Loss:0.941279411315918

iterator 2200, D_Loss:1.3296568393707275, G_Loss:1.0219889879226685

iterator 2300, D_Loss:1.3411369323730469, G_Loss:0.9483300447463989

iterator 2400, D_Loss:1.315846562385559, G_Loss:0.9478070139884949

iterator 2500, D_Loss:1.319589376449585, G_Loss:1.0006484985351562

iterator 2600, D_Loss:1.3311591148376465, G_Loss:0.9750845432281494

iterator 2700, D_Loss:1.3194204568862915, G_Loss:0.9751096367835999

iterator 2800, D_Loss:1.3487800359725952, G_Loss:0.9919110536575317

iterator 2900, D_Loss:1.3622156381607056, G_Loss:0.978704035282135

iterator 3000, D_Loss:1.3289892673492432, G_Loss:0.9701458215713501

iterator 3100, D_Loss:1.3521921634674072, G_Loss:0.9578945636749268

iterator 3200, D_Loss:1.3230369091033936, G_Loss:0.9526791572570801

iterator 3300, D_Loss:1.3468475341796875, G_Loss:0.9944260716438293

iterator 3400, D_Loss:1.3557438850402832, G_Loss:0.9591002464294434

iterator 3500, D_Loss:1.316264271736145, G_Loss:0.9938037395477295

iterator 3600, D_Loss:1.313082218170166, G_Loss:0.9821904897689819

iterator 3700, D_Loss:1.3243181705474854, G_Loss:0.9997669458389282

iterator 3800, D_Loss:1.3309046030044556, G_Loss:0.9345846176147461

iterator 3900, D_Loss:1.3212472200393677, G_Loss:0.940382182598114

iterator 4000, D_Loss:1.3208824396133423, G_Loss:0.9964120984077454

iterator 4100, D_Loss:1.3295198678970337, G_Loss:0.9267678260803223

iterator 4200, D_Loss:1.341808557510376, G_Loss:0.9275195002555847

iterator 4300, D_Loss:1.3202321529388428, G_Loss:0.9384207725524902

iterator 4400, D_Loss:1.3391879796981812, G_Loss:0.9932493567466736

iterator 4500, D_Loss:1.3142741918563843, G_Loss:0.976395308971405

iterator 4600, D_Loss:1.325844645500183, G_Loss:1.0308955907821655

iterator 4700, D_Loss:1.3148863315582275, G_Loss:0.9562738537788391

iterator 4800, D_Loss:1.300788164138794, G_Loss:0.9780825972557068

iterator 4900, D_Loss:1.3294401168823242, G_Loss:0.9895415306091309

iterator 5000, D_Loss:1.338186264038086, G_Loss:0.9581905603408813

-----------Epoch 6-----------
iterator 100, D_Loss:1.3527343273162842, G_Loss:0.9501969814300537

iterator 200, D_Loss:1.3001391887664795, G_Loss:0.9596880674362183

iterator 300, D_Loss:1.3352363109588623, G_Loss:1.0024335384368896

iterator 400, D_Loss:1.3348979949951172, G_Loss:0.9794455766677856

iterator 500, D_Loss:1.317897081375122, G_Loss:0.9558404088020325

iterator 600, D_Loss:1.3138396739959717, G_Loss:0.9343128204345703

iterator 700, D_Loss:1.3504881858825684, G_Loss:0.9581632018089294

iterator 800, D_Loss:1.3336000442504883, G_Loss:0.9631670117378235

iterator 900, D_Loss:1.3060818910598755, G_Loss:0.9642476439476013

iterator 1000, D_Loss:1.3216943740844727, G_Loss:1.0379858016967773

iterator 1100, D_Loss:1.3250198364257812, G_Loss:0.9606267809867859

iterator 1200, D_Loss:1.321760654449463, G_Loss:0.9306182861328125

iterator 1300, D_Loss:1.3416668176651, G_Loss:0.9593576788902283

iterator 1400, D_Loss:1.3206167221069336, G_Loss:0.9424310326576233

iterator 1500, D_Loss:1.3357486724853516, G_Loss:1.0550222396850586

iterator 1600, D_Loss:1.3436393737792969, G_Loss:1.0016714334487915

iterator 1700, D_Loss:1.3121428489685059, G_Loss:0.9836254715919495

iterator 1800, D_Loss:1.3225857019424438, G_Loss:1.0135672092437744

iterator 1900, D_Loss:1.3169233798980713, G_Loss:0.9786986112594604

iterator 2000, D_Loss:1.3256256580352783, G_Loss:1.0009657144546509

iterator 2100, D_Loss:1.3554372787475586, G_Loss:0.9213607311248779

iterator 2200, D_Loss:1.31620192527771, G_Loss:0.9759773015975952

iterator 2300, D_Loss:1.3209600448608398, G_Loss:0.9922950267791748

iterator 2400, D_Loss:1.3175528049468994, G_Loss:0.9564820528030396

iterator 2500, D_Loss:1.3169689178466797, G_Loss:0.9485155344009399

iterator 2600, D_Loss:1.3201751708984375, G_Loss:0.9487707614898682

iterator 2700, D_Loss:1.3577916622161865, G_Loss:0.9510824084281921

iterator 2800, D_Loss:1.3413231372833252, G_Loss:0.9608532190322876

iterator 2900, D_Loss:1.3360912799835205, G_Loss:0.9520150423049927

iterator 3000, D_Loss:1.3208013772964478, G_Loss:0.9795786738395691

iterator 3100, D_Loss:1.3237311840057373, G_Loss:0.9506843686103821

iterator 3200, D_Loss:1.3424007892608643, G_Loss:1.0001240968704224

iterator 3300, D_Loss:1.3431899547576904, G_Loss:0.9568846225738525

iterator 3400, D_Loss:1.35574209690094, G_Loss:0.9139681458473206

iterator 3500, D_Loss:1.3262059688568115, G_Loss:0.9718738198280334

iterator 3600, D_Loss:1.3159239292144775, G_Loss:0.9362556338310242

iterator 3700, D_Loss:1.3268709182739258, G_Loss:0.9703578948974609

iterator 3800, D_Loss:1.3254460096359253, G_Loss:0.9731920957565308

iterator 3900, D_Loss:1.347579002380371, G_Loss:0.9785810112953186

iterator 4000, D_Loss:1.3053374290466309, G_Loss:1.022512435913086

iterator 4100, D_Loss:1.3074871301651, G_Loss:1.0478250980377197

iterator 4200, D_Loss:1.3516298532485962, G_Loss:0.9715986251831055

iterator 4300, D_Loss:1.3207789659500122, G_Loss:1.010696291923523

iterator 4400, D_Loss:1.304335355758667, G_Loss:1.0401030778884888

iterator 4500, D_Loss:1.28440523147583, G_Loss:1.0085868835449219

iterator 4600, D_Loss:1.286743402481079, G_Loss:1.0576541423797607

iterator 4700, D_Loss:1.2913010120391846, G_Loss:1.0164668560028076

iterator 4800, D_Loss:1.295630931854248, G_Loss:1.000789999961853

iterator 4900, D_Loss:1.314103364944458, G_Loss:1.0191898345947266

iterator 5000, D_Loss:1.3403172492980957, G_Loss:0.9922595024108887

-----------Epoch 7-----------
iterator 100, D_Loss:1.2999074459075928, G_Loss:0.9956613183021545

iterator 200, D_Loss:1.3332630395889282, G_Loss:1.008198618888855

iterator 300, D_Loss:1.310100793838501, G_Loss:1.000900387763977

iterator 400, D_Loss:1.308577537536621, G_Loss:1.0184208154678345

iterator 500, D_Loss:1.3104205131530762, G_Loss:0.977868378162384

iterator 600, D_Loss:1.3298757076263428, G_Loss:0.982832670211792

iterator 700, D_Loss:1.30659818649292, G_Loss:0.9788904190063477

iterator 800, D_Loss:1.3467803001403809, G_Loss:0.9557669758796692

iterator 900, D_Loss:1.3400933742523193, G_Loss:0.9812209606170654

iterator 1000, D_Loss:1.30064857006073, G_Loss:1.0356700420379639

iterator 1100, D_Loss:1.3106167316436768, G_Loss:1.0076818466186523

iterator 1200, D_Loss:1.3114819526672363, G_Loss:0.9926445484161377

iterator 1300, D_Loss:1.3062434196472168, G_Loss:1.0200008153915405

iterator 1400, D_Loss:1.2910335063934326, G_Loss:1.0131402015686035

iterator 1500, D_Loss:1.3155584335327148, G_Loss:1.0248217582702637

iterator 1600, D_Loss:1.3051656484603882, G_Loss:0.9917352199554443

iterator 1700, D_Loss:1.2909809350967407, G_Loss:1.0193761587142944

iterator 1800, D_Loss:1.3350492715835571, G_Loss:1.0779966115951538

iterator 1900, D_Loss:1.295440912246704, G_Loss:0.9775093197822571

iterator 2000, D_Loss:1.3407193422317505, G_Loss:1.002720594406128

iterator 2100, D_Loss:1.3121821880340576, G_Loss:0.980191707611084

iterator 2200, D_Loss:1.288815975189209, G_Loss:1.005821943283081

iterator 2300, D_Loss:1.3222472667694092, G_Loss:0.9686245918273926

iterator 2400, D_Loss:1.329604983329773, G_Loss:0.9996294379234314

iterator 2500, D_Loss:1.3068435192108154, G_Loss:1.0381062030792236

iterator 2600, D_Loss:1.3410999774932861, G_Loss:0.9865433573722839

iterator 2700, D_Loss:1.361619234085083, G_Loss:1.018155813217163

iterator 2800, D_Loss:1.3049283027648926, G_Loss:0.9844276905059814

iterator 2900, D_Loss:1.328270673751831, G_Loss:1.0281511545181274

iterator 3000, D_Loss:1.3285189867019653, G_Loss:0.9912633299827576

iterator 3100, D_Loss:1.317399501800537, G_Loss:0.9845417141914368

iterator 3200, D_Loss:1.277564287185669, G_Loss:0.9765133857727051

iterator 3300, D_Loss:1.3012070655822754, G_Loss:0.9845671057701111

iterator 3400, D_Loss:1.3227427005767822, G_Loss:0.9778954982757568

iterator 3500, D_Loss:1.3119046688079834, G_Loss:1.007409930229187

iterator 3600, D_Loss:1.2837332487106323, G_Loss:1.047818660736084

iterator 3700, D_Loss:1.3105638027191162, G_Loss:0.9860714077949524

iterator 3800, D_Loss:1.2950488328933716, G_Loss:1.0328925848007202

iterator 3900, D_Loss:1.3160045146942139, G_Loss:1.0030841827392578

iterator 4000, D_Loss:1.2791850566864014, G_Loss:1.0505754947662354

iterator 4100, D_Loss:1.2760120630264282, G_Loss:1.0531593561172485

iterator 4200, D_Loss:1.3095731735229492, G_Loss:0.9898749589920044

iterator 4300, D_Loss:1.3179181814193726, G_Loss:1.0081490278244019

iterator 4400, D_Loss:1.3132503032684326, G_Loss:1.1313992738723755

iterator 4500, D_Loss:1.2313847541809082, G_Loss:1.042846918106079

iterator 4600, D_Loss:1.2746905088424683, G_Loss:1.037957787513733

iterator 4700, D_Loss:1.285059928894043, G_Loss:1.056229829788208

iterator 4800, D_Loss:1.279734492301941, G_Loss:1.015613317489624

iterator 4900, D_Loss:1.3039565086364746, G_Loss:1.0807305574417114

iterator 5000, D_Loss:1.2849204540252686, G_Loss:1.062116026878357

-----------Epoch 8-----------
iterator 100, D_Loss:1.2782518863677979, G_Loss:1.074942708015442

iterator 200, D_Loss:1.2342568635940552, G_Loss:1.1416696310043335

iterator 300, D_Loss:1.2620654106140137, G_Loss:1.0500407218933105

iterator 400, D_Loss:1.3285751342773438, G_Loss:1.0409408807754517

iterator 500, D_Loss:1.272247076034546, G_Loss:1.024763822555542

iterator 600, D_Loss:1.261704921722412, G_Loss:1.061585545539856

iterator 700, D_Loss:1.2713209390640259, G_Loss:1.0236766338348389

iterator 800, D_Loss:1.276772379875183, G_Loss:1.1095584630966187

iterator 900, D_Loss:1.236509084701538, G_Loss:1.0843836069107056

iterator 1000, D_Loss:1.244349718093872, G_Loss:1.1160937547683716

iterator 1100, D_Loss:1.3027764558792114, G_Loss:1.0469470024108887

iterator 1200, D_Loss:1.2516980171203613, G_Loss:1.104453206062317

iterator 1300, D_Loss:1.3266407251358032, G_Loss:1.045833945274353

iterator 1400, D_Loss:1.3113977909088135, G_Loss:1.0135854482650757

iterator 1500, D_Loss:1.2933576107025146, G_Loss:1.0201555490493774

iterator 1600, D_Loss:1.3343966007232666, G_Loss:0.985061526298523

iterator 1700, D_Loss:1.2676665782928467, G_Loss:1.0202325582504272

iterator 1800, D_Loss:1.2720764875411987, G_Loss:1.0772231817245483

iterator 1900, D_Loss:1.2947330474853516, G_Loss:1.1433253288269043

iterator 2000, D_Loss:1.3037320375442505, G_Loss:1.01803457736969

iterator 2100, D_Loss:1.2858726978302002, G_Loss:1.0002814531326294

iterator 2200, D_Loss:1.2943626642227173, G_Loss:1.0012335777282715

iterator 2300, D_Loss:1.2732582092285156, G_Loss:1.048209309577942

iterator 2400, D_Loss:1.3173422813415527, G_Loss:1.003514289855957

iterator 2500, D_Loss:1.2867755889892578, G_Loss:0.9993288516998291

iterator 2600, D_Loss:1.275854229927063, G_Loss:1.0546404123306274

iterator 2700, D_Loss:1.3072152137756348, G_Loss:1.052297830581665

iterator 2800, D_Loss:1.2852210998535156, G_Loss:1.0299922227859497

iterator 2900, D_Loss:1.3269264698028564, G_Loss:1.0906848907470703

iterator 3000, D_Loss:1.3012341260910034, G_Loss:1.0088562965393066

iterator 3100, D_Loss:1.2850570678710938, G_Loss:1.054003119468689

iterator 3200, D_Loss:1.2842681407928467, G_Loss:1.0008659362792969

iterator 3300, D_Loss:1.310854196548462, G_Loss:1.0975255966186523

iterator 3400, D_Loss:1.2823506593704224, G_Loss:1.062612771987915

iterator 3500, D_Loss:1.2834392786026, G_Loss:1.041326880455017

iterator 3600, D_Loss:1.375255823135376, G_Loss:1.0201075077056885

iterator 3700, D_Loss:1.288874864578247, G_Loss:1.0401581525802612

iterator 3800, D_Loss:1.2853529453277588, G_Loss:1.0434163808822632

iterator 3900, D_Loss:1.317415714263916, G_Loss:1.059127926826477

iterator 4000, D_Loss:1.2993147373199463, G_Loss:1.0151780843734741

iterator 4100, D_Loss:1.2696020603179932, G_Loss:1.0905096530914307

iterator 4200, D_Loss:1.3210458755493164, G_Loss:1.0438393354415894

iterator 4300, D_Loss:1.3168513774871826, G_Loss:1.0659435987472534

iterator 4400, D_Loss:1.2792855501174927, G_Loss:1.0982987880706787

iterator 4500, D_Loss:1.2646321058273315, G_Loss:1.0706439018249512

iterator 4600, D_Loss:1.316301941871643, G_Loss:1.038823127746582

iterator 4700, D_Loss:1.3371798992156982, G_Loss:1.1171079874038696

iterator 4800, D_Loss:1.2733709812164307, G_Loss:1.0545501708984375

iterator 4900, D_Loss:1.2765979766845703, G_Loss:1.049423336982727

iterator 5000, D_Loss:1.2974913120269775, G_Loss:1.0195738077163696

-----------Epoch 9-----------
iterator 100, D_Loss:1.32206130027771, G_Loss:0.9936594367027283

iterator 200, D_Loss:1.259955644607544, G_Loss:1.072900652885437

iterator 300, D_Loss:1.275254487991333, G_Loss:1.0678991079330444

iterator 400, D_Loss:1.2893732786178589, G_Loss:1.0749197006225586

iterator 500, D_Loss:1.274428129196167, G_Loss:1.0210613012313843

iterator 600, D_Loss:1.3367056846618652, G_Loss:0.9984982013702393

iterator 700, D_Loss:1.2886912822723389, G_Loss:0.9938589930534363

iterator 800, D_Loss:1.2708728313446045, G_Loss:1.0298584699630737

iterator 900, D_Loss:1.2935709953308105, G_Loss:1.0426360368728638

iterator 1000, D_Loss:1.2810509204864502, G_Loss:1.1173908710479736

iterator 1100, D_Loss:1.2350733280181885, G_Loss:1.09407639503479

iterator 1200, D_Loss:1.2732877731323242, G_Loss:1.0389267206192017

iterator 1300, D_Loss:1.319850206375122, G_Loss:1.0175782442092896

iterator 1400, D_Loss:1.2879371643066406, G_Loss:1.0562959909439087

iterator 1500, D_Loss:1.3346912860870361, G_Loss:1.018181324005127

iterator 1600, D_Loss:1.329824686050415, G_Loss:1.0216946601867676

iterator 1700, D_Loss:1.3083523511886597, G_Loss:0.9795254468917847

iterator 1800, D_Loss:1.3083903789520264, G_Loss:1.0246883630752563

iterator 1900, D_Loss:1.3012453317642212, G_Loss:1.000314712524414

iterator 2000, D_Loss:1.323195457458496, G_Loss:1.0078632831573486

iterator 2100, D_Loss:1.2883940935134888, G_Loss:1.049335241317749

iterator 2200, D_Loss:1.3058212995529175, G_Loss:1.0390783548355103

iterator 2300, D_Loss:1.3001883029937744, G_Loss:1.066781759262085

iterator 2400, D_Loss:1.2973079681396484, G_Loss:1.0081418752670288

iterator 2500, D_Loss:1.2825865745544434, G_Loss:1.0113835334777832

iterator 2600, D_Loss:1.2826558351516724, G_Loss:1.0431373119354248

iterator 2700, D_Loss:1.2801239490509033, G_Loss:1.0841633081436157

iterator 2800, D_Loss:1.279768466949463, G_Loss:1.0666754245758057

iterator 2900, D_Loss:1.2678449153900146, G_Loss:1.0862385034561157

iterator 3000, D_Loss:1.282200574874878, G_Loss:1.0661096572875977

iterator 3100, D_Loss:1.3341861963272095, G_Loss:0.9902878403663635

iterator 3200, D_Loss:1.2923805713653564, G_Loss:1.0034222602844238

iterator 3300, D_Loss:1.2836997509002686, G_Loss:1.0622729063034058

iterator 3400, D_Loss:1.2881641387939453, G_Loss:0.95741206407547

iterator 3500, D_Loss:1.2871707677841187, G_Loss:1.0333523750305176

iterator 3600, D_Loss:1.2749156951904297, G_Loss:0.9946954250335693

iterator 3700, D_Loss:1.3256069421768188, G_Loss:1.021267056465149

iterator 3800, D_Loss:1.2910609245300293, G_Loss:1.0609196424484253

iterator 3900, D_Loss:1.306429147720337, G_Loss:1.0502501726150513

iterator 4000, D_Loss:1.3142106533050537, G_Loss:1.016086220741272

iterator 4100, D_Loss:1.272709608078003, G_Loss:1.031274437904358

iterator 4200, D_Loss:1.3073909282684326, G_Loss:0.9955596923828125

iterator 4300, D_Loss:1.3272981643676758, G_Loss:1.0257654190063477

iterator 4400, D_Loss:1.2794634103775024, G_Loss:1.034480333328247

iterator 4500, D_Loss:1.300304889678955, G_Loss:1.0080592632293701

iterator 4600, D_Loss:1.2845008373260498, G_Loss:1.0472134351730347

iterator 4700, D_Loss:1.302969217300415, G_Loss:1.01054048538208

iterator 4800, D_Loss:1.304842233657837, G_Loss:1.035070776939392

iterator 4900, D_Loss:1.2728807926177979, G_Loss:1.028939127922058

iterator 5000, D_Loss:1.3136063814163208, G_Loss:1.1236389875411987

VGAN_generator(
  (input): Linear(in_features=128, out_features=200, bias=True)
  (inputbn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (bn0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=200, out_features=200, bias=True)
  (bn1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=200, out_features=200, bias=True)
  (bn2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=200, out_features=105, bias=True)
  (outputbn): BatchNorm1d(105, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=105, out_features=400, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=400, out_features=400, bias=True)
  (fc1): Linear(in_features=400, out_features=400, bias=True)
  (fc2): Linear(in_features=400, out_features=400, bias=True)
  (output): Linear(in_features=400, out_features=1, bias=True)
)
(0, False, 105)
-----------Epoch 0-----------
iterator 100, D_Loss:0.557563841342926, G_Loss:8.980863571166992

iterator 200, D_Loss:0.5023829340934753, G_Loss:12.590222358703613

iterator 300, D_Loss:0.45524951815605164, G_Loss:10.706720352172852

iterator 400, D_Loss:0.45808860659599304, G_Loss:9.769940376281738

iterator 500, D_Loss:0.4698917865753174, G_Loss:8.320889472961426

iterator 600, D_Loss:0.49677756428718567, G_Loss:8.511963844299316

iterator 700, D_Loss:0.45528703927993774, G_Loss:7.287055015563965

iterator 800, D_Loss:0.48667898774147034, G_Loss:6.794228553771973

iterator 900, D_Loss:0.5078241229057312, G_Loss:6.521941184997559

iterator 1000, D_Loss:0.47395989298820496, G_Loss:5.817078590393066

iterator 1100, D_Loss:0.4841774106025696, G_Loss:5.812408447265625

iterator 1200, D_Loss:0.5721123218536377, G_Loss:5.329615116119385

iterator 1300, D_Loss:0.5499570369720459, G_Loss:5.516152381896973

iterator 1400, D_Loss:0.5623553991317749, G_Loss:5.5870361328125

iterator 1500, D_Loss:0.5519828200340271, G_Loss:4.800710201263428

iterator 1600, D_Loss:0.6744772791862488, G_Loss:4.469832897186279

iterator 1700, D_Loss:0.5989140272140503, G_Loss:4.6392717361450195

iterator 1800, D_Loss:0.6516171097755432, G_Loss:5.164373874664307

iterator 1900, D_Loss:0.6794419288635254, G_Loss:4.230160236358643

iterator 2000, D_Loss:0.6794536709785461, G_Loss:4.069119930267334

iterator 2100, D_Loss:0.6678574085235596, G_Loss:3.6710739135742188

iterator 2200, D_Loss:0.6393070220947266, G_Loss:4.482954025268555

iterator 2300, D_Loss:0.6390900611877441, G_Loss:4.164985179901123

iterator 2400, D_Loss:0.6535726189613342, G_Loss:4.532203674316406

iterator 2500, D_Loss:0.627255916595459, G_Loss:3.993408679962158

iterator 2600, D_Loss:0.705348789691925, G_Loss:3.7156260013580322

iterator 2700, D_Loss:0.5923787355422974, G_Loss:4.053462982177734

iterator 2800, D_Loss:0.7206817865371704, G_Loss:3.5193965435028076

iterator 2900, D_Loss:0.6924794912338257, G_Loss:4.215728282928467

iterator 3000, D_Loss:0.7289491295814514, G_Loss:3.9335014820098877

iterator 3100, D_Loss:0.7394345998764038, G_Loss:3.6735856533050537

iterator 3200, D_Loss:0.7338986396789551, G_Loss:3.747096061706543

iterator 3300, D_Loss:0.6635442972183228, G_Loss:3.5071516036987305

iterator 3400, D_Loss:0.801267147064209, G_Loss:3.309091091156006

iterator 3500, D_Loss:0.7848646640777588, G_Loss:3.2454373836517334

iterator 3600, D_Loss:0.7894773483276367, G_Loss:3.0840747356414795

iterator 3700, D_Loss:0.7779583930969238, G_Loss:3.366870880126953

iterator 3800, D_Loss:0.7939218878746033, G_Loss:3.634235143661499

iterator 3900, D_Loss:0.8174395561218262, G_Loss:3.076587200164795

iterator 4000, D_Loss:0.7664875388145447, G_Loss:3.54516339302063

iterator 4100, D_Loss:0.7457027435302734, G_Loss:3.3350439071655273

iterator 4200, D_Loss:0.7441836595535278, G_Loss:2.981145143508911

iterator 4300, D_Loss:0.7669299840927124, G_Loss:2.7385900020599365

iterator 4400, D_Loss:0.7592767477035522, G_Loss:2.6888480186462402

iterator 4500, D_Loss:0.7791623473167419, G_Loss:3.066774845123291

iterator 4600, D_Loss:0.810315728187561, G_Loss:2.988297462463379

iterator 4700, D_Loss:0.8253053426742554, G_Loss:2.73667311668396

iterator 4800, D_Loss:0.8439289927482605, G_Loss:3.156785249710083

iterator 4900, D_Loss:0.8239079713821411, G_Loss:2.7676358222961426

iterator 5000, D_Loss:0.8457673192024231, G_Loss:2.8997480869293213

-----------Epoch 1-----------
iterator 100, D_Loss:0.806644082069397, G_Loss:2.7001852989196777

iterator 200, D_Loss:0.8217757940292358, G_Loss:3.1277966499328613

iterator 300, D_Loss:0.8611730337142944, G_Loss:2.923530101776123

iterator 400, D_Loss:0.7821270823478699, G_Loss:3.057121753692627

iterator 500, D_Loss:0.7808707356452942, G_Loss:2.7541487216949463

iterator 600, D_Loss:0.7844700217247009, G_Loss:2.6610748767852783

iterator 700, D_Loss:0.9059484004974365, G_Loss:2.3468403816223145

iterator 800, D_Loss:0.8475337028503418, G_Loss:2.684715986251831

iterator 900, D_Loss:0.7762129902839661, G_Loss:2.7340612411499023

iterator 1000, D_Loss:0.8329098224639893, G_Loss:2.6395816802978516

iterator 1100, D_Loss:0.7838166356086731, G_Loss:2.7288599014282227

iterator 1200, D_Loss:0.8531222343444824, G_Loss:2.503363847732544

iterator 1300, D_Loss:0.8797018527984619, G_Loss:2.357036828994751

iterator 1400, D_Loss:0.8717695474624634, G_Loss:2.655998945236206

iterator 1500, D_Loss:0.8599347472190857, G_Loss:2.4686319828033447

iterator 1600, D_Loss:0.8360812067985535, G_Loss:2.24814772605896

iterator 1700, D_Loss:0.8755708336830139, G_Loss:2.6479992866516113

iterator 1800, D_Loss:0.9404376745223999, G_Loss:2.3221893310546875

iterator 1900, D_Loss:0.9161791801452637, G_Loss:2.6989519596099854

iterator 2000, D_Loss:0.9305558204650879, G_Loss:2.3316149711608887

iterator 2100, D_Loss:0.9096425771713257, G_Loss:2.0774495601654053

iterator 2200, D_Loss:0.949999988079071, G_Loss:2.2209084033966064

iterator 2300, D_Loss:0.8626002073287964, G_Loss:2.2592530250549316

iterator 2400, D_Loss:0.8843960165977478, G_Loss:2.2055423259735107

iterator 2500, D_Loss:0.8965798616409302, G_Loss:2.176502227783203

iterator 2600, D_Loss:0.9106252789497375, G_Loss:2.3850386142730713

iterator 2700, D_Loss:0.923051655292511, G_Loss:2.408264398574829

iterator 2800, D_Loss:0.8998403549194336, G_Loss:2.1975553035736084

iterator 2900, D_Loss:0.9151511788368225, G_Loss:2.5748612880706787

iterator 3000, D_Loss:0.9584656953811646, G_Loss:2.2887206077575684

iterator 3100, D_Loss:0.9155359268188477, G_Loss:2.306478500366211

iterator 3200, D_Loss:0.9104361534118652, G_Loss:2.531649351119995

iterator 3300, D_Loss:0.9214900135993958, G_Loss:2.3388898372650146

iterator 3400, D_Loss:0.907122015953064, G_Loss:2.270699977874756

iterator 3500, D_Loss:0.9541574716567993, G_Loss:2.311734676361084

iterator 3600, D_Loss:0.9354649186134338, G_Loss:2.1452667713165283

iterator 3700, D_Loss:0.9331771731376648, G_Loss:2.0985324382781982

iterator 3800, D_Loss:0.9452860355377197, G_Loss:2.000437021255493

iterator 3900, D_Loss:1.0091643333435059, G_Loss:2.166980028152466

iterator 4000, D_Loss:0.8901952505111694, G_Loss:2.245579719543457

iterator 4100, D_Loss:0.9278132319450378, G_Loss:2.336451292037964

iterator 4200, D_Loss:0.9616403579711914, G_Loss:2.170339584350586

iterator 4300, D_Loss:0.9244644641876221, G_Loss:2.2129321098327637

iterator 4400, D_Loss:0.963272750377655, G_Loss:2.2173104286193848

iterator 4500, D_Loss:0.896314799785614, G_Loss:2.087496519088745

iterator 4600, D_Loss:0.8918803930282593, G_Loss:2.485407829284668

iterator 4700, D_Loss:0.929570198059082, G_Loss:2.3981857299804688

iterator 4800, D_Loss:0.9498693943023682, G_Loss:2.388420820236206

iterator 4900, D_Loss:0.937063455581665, G_Loss:2.1653008460998535

iterator 5000, D_Loss:1.0407110452651978, G_Loss:2.4865150451660156

-----------Epoch 2-----------
iterator 100, D_Loss:0.9014793634414673, G_Loss:2.0957765579223633

iterator 200, D_Loss:0.9318077564239502, G_Loss:1.996248722076416

iterator 300, D_Loss:0.9127720594406128, G_Loss:2.2536776065826416

iterator 400, D_Loss:0.9711271524429321, G_Loss:2.390364170074463

iterator 500, D_Loss:0.9436353445053101, G_Loss:2.4593286514282227

iterator 600, D_Loss:0.9210014343261719, G_Loss:2.317023515701294

iterator 700, D_Loss:0.8689283728599548, G_Loss:2.64428448677063

iterator 800, D_Loss:0.9454730749130249, G_Loss:2.7074637413024902

iterator 900, D_Loss:0.9115562438964844, G_Loss:2.3864755630493164

iterator 1000, D_Loss:0.8904532790184021, G_Loss:2.3093483448028564

iterator 1100, D_Loss:0.917681097984314, G_Loss:2.5747532844543457

iterator 1200, D_Loss:0.8325070738792419, G_Loss:2.378225326538086

iterator 1300, D_Loss:0.9018819332122803, G_Loss:2.424342632293701

iterator 1400, D_Loss:0.9356496334075928, G_Loss:2.302262306213379

iterator 1500, D_Loss:0.8360247611999512, G_Loss:2.5035035610198975

iterator 1600, D_Loss:0.9109369516372681, G_Loss:2.1445658206939697

iterator 1700, D_Loss:0.8269730806350708, G_Loss:2.5247528553009033

iterator 1800, D_Loss:0.9167838096618652, G_Loss:2.3266940116882324

iterator 1900, D_Loss:0.9334096908569336, G_Loss:2.385435104370117

iterator 2000, D_Loss:0.8416965007781982, G_Loss:2.2170467376708984

iterator 2100, D_Loss:0.8927257657051086, G_Loss:2.3238914012908936

iterator 2200, D_Loss:0.9287313222885132, G_Loss:2.3319311141967773

iterator 2300, D_Loss:0.9214783906936646, G_Loss:2.2177937030792236

iterator 2400, D_Loss:0.8227882385253906, G_Loss:2.4134671688079834

iterator 2500, D_Loss:0.9417223930358887, G_Loss:2.5277490615844727

iterator 2600, D_Loss:0.8956623077392578, G_Loss:2.515085458755493

iterator 2700, D_Loss:0.8598599433898926, G_Loss:2.5005011558532715

iterator 2800, D_Loss:0.8933531641960144, G_Loss:2.3698995113372803

iterator 2900, D_Loss:0.9219444990158081, G_Loss:2.374879837036133

iterator 3000, D_Loss:0.9151300191879272, G_Loss:2.2246627807617188

iterator 3100, D_Loss:0.9478622674942017, G_Loss:2.4908900260925293

iterator 3200, D_Loss:0.876152753829956, G_Loss:2.6074678897857666

iterator 3300, D_Loss:0.9731165170669556, G_Loss:2.6537628173828125

iterator 3400, D_Loss:0.9380700588226318, G_Loss:2.591057062149048

iterator 3500, D_Loss:0.8912363052368164, G_Loss:2.612417697906494

iterator 3600, D_Loss:0.8880456686019897, G_Loss:1.9751567840576172

iterator 3700, D_Loss:0.9674944281578064, G_Loss:2.2289021015167236

iterator 3800, D_Loss:0.8763064742088318, G_Loss:2.1075658798217773

iterator 3900, D_Loss:0.9495378732681274, G_Loss:2.111422538757324

iterator 4000, D_Loss:0.9025919437408447, G_Loss:2.392164468765259

iterator 4100, D_Loss:0.902716875076294, G_Loss:2.167912483215332

iterator 4200, D_Loss:0.8845281600952148, G_Loss:2.2269346714019775

iterator 4300, D_Loss:0.9310844540596008, G_Loss:2.221226930618286

iterator 4400, D_Loss:0.9243457317352295, G_Loss:2.3135645389556885

iterator 4500, D_Loss:0.904895007610321, G_Loss:2.4112699031829834

iterator 4600, D_Loss:0.9266248941421509, G_Loss:2.3104875087738037

iterator 4700, D_Loss:0.9634528160095215, G_Loss:2.0892317295074463

iterator 4800, D_Loss:0.917938232421875, G_Loss:2.340196371078491

iterator 4900, D_Loss:0.880983293056488, G_Loss:2.4020261764526367

iterator 5000, D_Loss:0.8906722068786621, G_Loss:2.511401653289795

-----------Epoch 3-----------
iterator 100, D_Loss:0.9163691401481628, G_Loss:2.333130359649658

iterator 200, D_Loss:0.9927638173103333, G_Loss:2.397066831588745

iterator 300, D_Loss:0.8802999258041382, G_Loss:2.5681912899017334

iterator 400, D_Loss:0.8842982053756714, G_Loss:2.2054598331451416

iterator 500, D_Loss:0.9335657358169556, G_Loss:2.6423628330230713

iterator 600, D_Loss:0.9030405282974243, G_Loss:2.5764687061309814

iterator 700, D_Loss:0.9500534534454346, G_Loss:2.1838700771331787

iterator 800, D_Loss:0.8932778239250183, G_Loss:2.760324239730835

iterator 900, D_Loss:0.9642906188964844, G_Loss:2.2897019386291504

iterator 1000, D_Loss:0.9310470819473267, G_Loss:2.4706597328186035

iterator 1100, D_Loss:0.8957396149635315, G_Loss:2.252110719680786

iterator 1200, D_Loss:0.9025644659996033, G_Loss:2.424137830734253

iterator 1300, D_Loss:0.8871780633926392, G_Loss:2.4650580883026123

iterator 1400, D_Loss:0.9033421277999878, G_Loss:2.0139307975769043

iterator 1500, D_Loss:0.9105823040008545, G_Loss:2.287289619445801

iterator 1600, D_Loss:0.9444308280944824, G_Loss:2.2870121002197266

iterator 1700, D_Loss:0.8977512121200562, G_Loss:2.2303895950317383

iterator 1800, D_Loss:0.912996232509613, G_Loss:2.3002991676330566

iterator 1900, D_Loss:0.8998285531997681, G_Loss:2.1936752796173096

iterator 2000, D_Loss:0.9156642556190491, G_Loss:2.2922298908233643

iterator 2100, D_Loss:0.8762838840484619, G_Loss:2.3884270191192627

iterator 2200, D_Loss:0.8899800181388855, G_Loss:2.3132240772247314

iterator 2300, D_Loss:0.9616135358810425, G_Loss:2.2684648036956787

iterator 2400, D_Loss:0.9243398904800415, G_Loss:2.173123359680176

iterator 2500, D_Loss:0.9248780012130737, G_Loss:2.275214672088623

iterator 2600, D_Loss:0.9477035999298096, G_Loss:2.1560616493225098

iterator 2700, D_Loss:0.9327493906021118, G_Loss:2.3534340858459473

iterator 2800, D_Loss:0.9169755578041077, G_Loss:2.325212001800537

iterator 2900, D_Loss:0.9532466530799866, G_Loss:2.2263827323913574

iterator 3000, D_Loss:0.9390171766281128, G_Loss:2.282578468322754

iterator 3100, D_Loss:0.9242010116577148, G_Loss:2.28670334815979

iterator 3200, D_Loss:0.8995622992515564, G_Loss:2.34350848197937

iterator 3300, D_Loss:0.9356143474578857, G_Loss:2.1437039375305176

iterator 3400, D_Loss:0.9446728825569153, G_Loss:2.206040143966675

iterator 3500, D_Loss:0.9603234529495239, G_Loss:2.326045513153076

iterator 3600, D_Loss:0.9575866460800171, G_Loss:2.2115206718444824

iterator 3700, D_Loss:0.8913525342941284, G_Loss:2.2567811012268066

iterator 3800, D_Loss:0.8769509792327881, G_Loss:2.151963949203491

iterator 3900, D_Loss:0.9649732112884521, G_Loss:2.1639320850372314

iterator 4000, D_Loss:0.9239246249198914, G_Loss:2.1666336059570312

iterator 4100, D_Loss:0.8473964929580688, G_Loss:2.3905320167541504

iterator 4200, D_Loss:0.9156934022903442, G_Loss:2.4910218715667725

iterator 4300, D_Loss:0.9099266529083252, G_Loss:2.055985450744629

iterator 4400, D_Loss:0.9706851840019226, G_Loss:2.3323962688446045

iterator 4500, D_Loss:0.8835266828536987, G_Loss:2.261375904083252

iterator 4600, D_Loss:0.8808546662330627, G_Loss:2.1329267024993896

iterator 4700, D_Loss:0.9491703510284424, G_Loss:2.092719793319702

iterator 4800, D_Loss:0.9928881525993347, G_Loss:2.1197609901428223

iterator 4900, D_Loss:0.942473292350769, G_Loss:2.1385340690612793

iterator 5000, D_Loss:0.9610744118690491, G_Loss:2.138185501098633

-----------Epoch 4-----------
iterator 100, D_Loss:0.9515430927276611, G_Loss:2.1302289962768555

iterator 200, D_Loss:0.9691528677940369, G_Loss:2.2998340129852295

iterator 300, D_Loss:0.8958340883255005, G_Loss:2.2400431632995605

iterator 400, D_Loss:0.8667877316474915, G_Loss:2.0856852531433105

iterator 500, D_Loss:0.9392775297164917, G_Loss:2.3248207569122314

iterator 600, D_Loss:0.9759666919708252, G_Loss:2.2209866046905518

iterator 700, D_Loss:0.9270902872085571, G_Loss:2.1788384914398193

iterator 800, D_Loss:0.9616761803627014, G_Loss:2.4379303455352783

iterator 900, D_Loss:0.947772204875946, G_Loss:2.1101789474487305

iterator 1000, D_Loss:0.9174776077270508, G_Loss:2.237325429916382

iterator 1100, D_Loss:0.9209898710250854, G_Loss:2.0402510166168213

iterator 1200, D_Loss:0.9041174054145813, G_Loss:2.218733072280884

iterator 1300, D_Loss:0.8582134246826172, G_Loss:2.5099434852600098

iterator 1400, D_Loss:0.9081956148147583, G_Loss:2.203324556350708

iterator 1500, D_Loss:0.9360415935516357, G_Loss:2.2310049533843994

iterator 1600, D_Loss:0.9776291847229004, G_Loss:1.9695167541503906

iterator 1700, D_Loss:0.9234631061553955, G_Loss:2.114752769470215

iterator 1800, D_Loss:0.9365319609642029, G_Loss:1.9988590478897095

iterator 1900, D_Loss:0.8910744786262512, G_Loss:2.038526773452759

iterator 2000, D_Loss:0.9438502788543701, G_Loss:2.2033607959747314

iterator 2100, D_Loss:0.9967970252037048, G_Loss:2.0303072929382324

iterator 2200, D_Loss:0.986961841583252, G_Loss:1.882491111755371

iterator 2300, D_Loss:0.959942102432251, G_Loss:1.964318871498108

iterator 2400, D_Loss:0.9822588562965393, G_Loss:2.0894675254821777

iterator 2500, D_Loss:0.9110058546066284, G_Loss:1.983332872390747

iterator 2600, D_Loss:0.9371365904808044, G_Loss:2.361983060836792

iterator 2700, D_Loss:0.9600023031234741, G_Loss:2.019458532333374

iterator 2800, D_Loss:0.9055503606796265, G_Loss:2.251805305480957

iterator 2900, D_Loss:0.995317816734314, G_Loss:2.2109293937683105

iterator 3000, D_Loss:0.9243345856666565, G_Loss:2.2168922424316406

iterator 3100, D_Loss:0.9403671026229858, G_Loss:2.1415328979492188

iterator 3200, D_Loss:0.959662914276123, G_Loss:2.0233893394470215

iterator 3300, D_Loss:0.9468141794204712, G_Loss:1.9920170307159424

iterator 3400, D_Loss:0.9592077136039734, G_Loss:2.0961105823516846

iterator 3500, D_Loss:0.9677495956420898, G_Loss:2.0345406532287598

iterator 3600, D_Loss:0.9576530456542969, G_Loss:2.1524927616119385

iterator 3700, D_Loss:0.9640556573867798, G_Loss:2.0849192142486572

iterator 3800, D_Loss:0.9832342863082886, G_Loss:2.0932555198669434

iterator 3900, D_Loss:0.9607646465301514, G_Loss:2.0902271270751953

iterator 4000, D_Loss:0.9964317679405212, G_Loss:1.9342654943466187

iterator 4100, D_Loss:0.9619975090026855, G_Loss:1.9634289741516113

iterator 4200, D_Loss:0.9461625814437866, G_Loss:2.0983519554138184

iterator 4300, D_Loss:0.9573612213134766, G_Loss:2.1027557849884033

iterator 4400, D_Loss:0.9322100877761841, G_Loss:2.118744373321533

iterator 4500, D_Loss:0.9167490005493164, G_Loss:2.2253098487854004

iterator 4600, D_Loss:0.9319443702697754, G_Loss:2.2024543285369873

iterator 4700, D_Loss:0.9395734667778015, G_Loss:1.948240041732788

iterator 4800, D_Loss:0.9383764266967773, G_Loss:2.0900814533233643

iterator 4900, D_Loss:0.9349538087844849, G_Loss:2.04933500289917

iterator 5000, D_Loss:0.9526082277297974, G_Loss:2.2102487087249756

-----------Epoch 5-----------
iterator 100, D_Loss:0.9907994270324707, G_Loss:2.1042299270629883

iterator 200, D_Loss:1.0016613006591797, G_Loss:2.0090203285217285

iterator 300, D_Loss:0.974348783493042, G_Loss:2.0526485443115234

iterator 400, D_Loss:0.9224305152893066, G_Loss:2.1402745246887207

iterator 500, D_Loss:0.9677429795265198, G_Loss:2.098601818084717

iterator 600, D_Loss:0.974166750907898, G_Loss:2.0446906089782715

iterator 700, D_Loss:0.9511798620223999, G_Loss:1.9584038257598877

iterator 800, D_Loss:1.017362117767334, G_Loss:2.0257210731506348

iterator 900, D_Loss:1.0032825469970703, G_Loss:1.8396461009979248

iterator 1000, D_Loss:0.9705803394317627, G_Loss:2.031325340270996

iterator 1100, D_Loss:0.9741039276123047, G_Loss:1.930787205696106

iterator 1200, D_Loss:0.9641329050064087, G_Loss:2.0784456729888916

iterator 1300, D_Loss:0.9455734491348267, G_Loss:2.033639430999756

iterator 1400, D_Loss:0.9505329132080078, G_Loss:2.156619071960449

iterator 1500, D_Loss:0.900370717048645, G_Loss:2.075232744216919

iterator 1600, D_Loss:0.9350577592849731, G_Loss:1.921453595161438

iterator 1700, D_Loss:0.9354004263877869, G_Loss:2.0495693683624268

iterator 1800, D_Loss:1.0120887756347656, G_Loss:2.0371479988098145

iterator 1900, D_Loss:1.0229425430297852, G_Loss:2.1163370609283447

iterator 2000, D_Loss:0.9747863411903381, G_Loss:1.9775785207748413

iterator 2100, D_Loss:0.9307494759559631, G_Loss:1.9469279050827026

iterator 2200, D_Loss:1.0039927959442139, G_Loss:1.9977527856826782

iterator 2300, D_Loss:0.954492449760437, G_Loss:2.225539207458496

iterator 2400, D_Loss:1.0071825981140137, G_Loss:2.062061309814453

iterator 2500, D_Loss:0.9484602212905884, G_Loss:2.0353944301605225

iterator 2600, D_Loss:0.9565130472183228, G_Loss:2.1967616081237793

iterator 2700, D_Loss:0.9471166133880615, G_Loss:2.141728401184082

iterator 2800, D_Loss:0.9515026807785034, G_Loss:2.3087353706359863

iterator 2900, D_Loss:0.9908051490783691, G_Loss:2.018538475036621

iterator 3000, D_Loss:0.9699903726577759, G_Loss:2.271397829055786

iterator 3100, D_Loss:0.9561352729797363, G_Loss:1.8679139614105225

iterator 3200, D_Loss:0.899772047996521, G_Loss:2.112560749053955

iterator 3300, D_Loss:0.9574391841888428, G_Loss:1.8509248495101929

iterator 3400, D_Loss:0.9457336664199829, G_Loss:2.11892032623291

iterator 3500, D_Loss:0.9135862588882446, G_Loss:1.8375027179718018

iterator 3600, D_Loss:0.956494927406311, G_Loss:1.9974640607833862

iterator 3700, D_Loss:0.959586501121521, G_Loss:1.9945430755615234

iterator 3800, D_Loss:0.9686400890350342, G_Loss:2.0819454193115234

iterator 3900, D_Loss:0.9366338849067688, G_Loss:2.0067946910858154

iterator 4000, D_Loss:0.9754190444946289, G_Loss:1.902471899986267

iterator 4100, D_Loss:0.9630786180496216, G_Loss:2.3470540046691895

iterator 4200, D_Loss:0.9630653858184814, G_Loss:2.0247161388397217

iterator 4300, D_Loss:1.0022538900375366, G_Loss:2.0189826488494873

iterator 4400, D_Loss:0.9282917976379395, G_Loss:2.249100685119629

iterator 4500, D_Loss:0.9052936434745789, G_Loss:2.2040669918060303

iterator 4600, D_Loss:0.9461503028869629, G_Loss:2.05792236328125

iterator 4700, D_Loss:0.9717792272567749, G_Loss:2.120577812194824

iterator 4800, D_Loss:1.0000152587890625, G_Loss:1.9880025386810303

iterator 4900, D_Loss:0.9440927505493164, G_Loss:1.9970288276672363

iterator 5000, D_Loss:0.9344473481178284, G_Loss:2.023399591445923

-----------Epoch 6-----------
iterator 100, D_Loss:0.9954602718353271, G_Loss:1.949599027633667

iterator 200, D_Loss:0.9443964958190918, G_Loss:1.9526846408843994

iterator 300, D_Loss:0.8954064846038818, G_Loss:2.0050647258758545

iterator 400, D_Loss:0.9448293447494507, G_Loss:2.1436691284179688

iterator 500, D_Loss:0.9647072553634644, G_Loss:1.9871751070022583

iterator 600, D_Loss:0.9486755132675171, G_Loss:2.045027732849121

iterator 700, D_Loss:0.9457395076751709, G_Loss:1.9427393674850464

iterator 800, D_Loss:0.9859264492988586, G_Loss:2.0809519290924072

iterator 900, D_Loss:0.9854299426078796, G_Loss:2.064457893371582

iterator 1000, D_Loss:0.9216787219047546, G_Loss:2.14906907081604

iterator 1100, D_Loss:0.9361233115196228, G_Loss:2.2030105590820312

iterator 1200, D_Loss:0.9145123958587646, G_Loss:2.052696704864502

iterator 1300, D_Loss:0.918066143989563, G_Loss:2.038964033126831

iterator 1400, D_Loss:0.9278128147125244, G_Loss:2.058779239654541

iterator 1500, D_Loss:0.9530519247055054, G_Loss:2.1188442707061768

iterator 1600, D_Loss:0.9331005811691284, G_Loss:2.1249337196350098

iterator 1700, D_Loss:0.9648990631103516, G_Loss:2.1214663982391357

iterator 1800, D_Loss:0.9037250876426697, G_Loss:1.9557125568389893

iterator 1900, D_Loss:0.9992334842681885, G_Loss:2.0558688640594482

iterator 2000, D_Loss:0.9526479840278625, G_Loss:2.0506861209869385

iterator 2100, D_Loss:0.9511540532112122, G_Loss:1.98678719997406

iterator 2200, D_Loss:1.0280866622924805, G_Loss:1.90249764919281

iterator 2300, D_Loss:0.9245965480804443, G_Loss:2.2300143241882324

iterator 2400, D_Loss:1.0047038793563843, G_Loss:1.8480846881866455

iterator 2500, D_Loss:0.9300410747528076, G_Loss:2.0378024578094482

iterator 2600, D_Loss:0.9999140501022339, G_Loss:2.1565349102020264

iterator 2700, D_Loss:0.991222620010376, G_Loss:1.8795223236083984

iterator 2800, D_Loss:0.9960073232650757, G_Loss:1.9395880699157715

iterator 2900, D_Loss:1.0157893896102905, G_Loss:1.9642844200134277

iterator 3000, D_Loss:0.9020603895187378, G_Loss:2.096392869949341

iterator 3100, D_Loss:0.9867467880249023, G_Loss:1.8461220264434814

iterator 3200, D_Loss:0.9124035239219666, G_Loss:2.0852065086364746

iterator 3300, D_Loss:0.9760256409645081, G_Loss:2.070197343826294

iterator 3400, D_Loss:1.0051853656768799, G_Loss:1.9299885034561157

iterator 3500, D_Loss:0.9498667120933533, G_Loss:2.0850484371185303

iterator 3600, D_Loss:0.9748919010162354, G_Loss:2.0360188484191895

iterator 3700, D_Loss:0.96735680103302, G_Loss:1.9795235395431519

iterator 3800, D_Loss:0.9342918395996094, G_Loss:1.9903303384780884

iterator 3900, D_Loss:0.9549621939659119, G_Loss:2.131206512451172

iterator 4000, D_Loss:0.9684224128723145, G_Loss:2.036916732788086

iterator 4100, D_Loss:0.9205306768417358, G_Loss:2.13838791847229

iterator 4200, D_Loss:0.9364699721336365, G_Loss:1.9887844324111938

iterator 4300, D_Loss:0.9127457141876221, G_Loss:2.1043508052825928

iterator 4400, D_Loss:1.0297061204910278, G_Loss:2.083017349243164

iterator 4500, D_Loss:0.9305857419967651, G_Loss:2.0301923751831055

iterator 4600, D_Loss:0.9398994445800781, G_Loss:2.180908679962158

iterator 4700, D_Loss:0.9231902360916138, G_Loss:2.0959787368774414

iterator 4800, D_Loss:0.9614450931549072, G_Loss:1.9615721702575684

iterator 4900, D_Loss:0.9908134937286377, G_Loss:2.267430305480957

iterator 5000, D_Loss:0.9653781056404114, G_Loss:2.17161226272583

-----------Epoch 7-----------
iterator 100, D_Loss:0.9804770946502686, G_Loss:2.1526432037353516

iterator 200, D_Loss:0.985339343547821, G_Loss:2.0249459743499756

iterator 300, D_Loss:0.9325500726699829, G_Loss:2.041912317276001

iterator 400, D_Loss:0.9787991046905518, G_Loss:2.086784601211548

iterator 500, D_Loss:1.0141849517822266, G_Loss:2.1540164947509766

iterator 600, D_Loss:0.9630697965621948, G_Loss:2.0078108310699463

iterator 700, D_Loss:1.0128612518310547, G_Loss:2.0016374588012695

iterator 800, D_Loss:1.0357941389083862, G_Loss:2.084552764892578

iterator 900, D_Loss:1.0266306400299072, G_Loss:1.9592220783233643

iterator 1000, D_Loss:0.9639530777931213, G_Loss:2.1019937992095947

iterator 1100, D_Loss:0.949974775314331, G_Loss:1.9408206939697266

iterator 1200, D_Loss:0.9500418901443481, G_Loss:2.0983424186706543

iterator 1300, D_Loss:0.9472352266311646, G_Loss:2.1796047687530518

iterator 1400, D_Loss:0.9408318996429443, G_Loss:1.9822471141815186

iterator 1500, D_Loss:0.9162901639938354, G_Loss:1.9468789100646973

iterator 1600, D_Loss:1.0055769681930542, G_Loss:2.0765299797058105

iterator 1700, D_Loss:0.9290140271186829, G_Loss:2.076864719390869

iterator 1800, D_Loss:0.9183919429779053, G_Loss:1.8402684926986694

iterator 1900, D_Loss:0.9518414735794067, G_Loss:2.185547113418579

iterator 2000, D_Loss:0.9622607231140137, G_Loss:1.9710172414779663

iterator 2100, D_Loss:0.9966387152671814, G_Loss:2.2689342498779297

iterator 2200, D_Loss:1.0466867685317993, G_Loss:1.9266051054000854

iterator 2300, D_Loss:0.9367792010307312, G_Loss:1.9631985425949097

iterator 2400, D_Loss:0.9722912311553955, G_Loss:2.1283655166625977

iterator 2500, D_Loss:0.9404873847961426, G_Loss:2.056206226348877

iterator 2600, D_Loss:0.9313011169433594, G_Loss:2.0395474433898926

iterator 2700, D_Loss:1.0374189615249634, G_Loss:1.9723994731903076

iterator 2800, D_Loss:0.9255825281143188, G_Loss:2.0351996421813965

iterator 2900, D_Loss:1.0291922092437744, G_Loss:2.0142688751220703

iterator 3000, D_Loss:0.9204587936401367, G_Loss:2.2329797744750977

iterator 3100, D_Loss:1.0104807615280151, G_Loss:2.0764033794403076

iterator 3200, D_Loss:0.9331063628196716, G_Loss:1.9132801294326782

iterator 3300, D_Loss:0.9330101013183594, G_Loss:2.2405214309692383

iterator 3400, D_Loss:0.9744666814804077, G_Loss:1.9481277465820312

iterator 3500, D_Loss:0.965794026851654, G_Loss:1.9984498023986816

iterator 3600, D_Loss:0.9686079025268555, G_Loss:2.184246301651001

iterator 3700, D_Loss:0.950061023235321, G_Loss:1.990336537361145

iterator 3800, D_Loss:0.9407774806022644, G_Loss:2.1150670051574707

iterator 3900, D_Loss:0.9699941873550415, G_Loss:2.185875654220581

iterator 4000, D_Loss:0.9638335704803467, G_Loss:1.9896328449249268

iterator 4100, D_Loss:0.9119933843612671, G_Loss:2.209839105606079

iterator 4200, D_Loss:0.9698444604873657, G_Loss:1.9332773685455322

iterator 4300, D_Loss:1.0197169780731201, G_Loss:2.0456576347351074

iterator 4400, D_Loss:1.003764033317566, G_Loss:2.2082552909851074

iterator 4500, D_Loss:0.9139087200164795, G_Loss:2.027278423309326

iterator 4600, D_Loss:0.9117716550827026, G_Loss:2.1544885635375977

iterator 4700, D_Loss:0.9794764518737793, G_Loss:1.9149243831634521

iterator 4800, D_Loss:0.9772874116897583, G_Loss:1.949480414390564

iterator 4900, D_Loss:0.9108819961547852, G_Loss:2.1157267093658447

iterator 5000, D_Loss:0.9961183071136475, G_Loss:1.9942600727081299

-----------Epoch 8-----------
iterator 100, D_Loss:0.9605291485786438, G_Loss:1.801976203918457

iterator 200, D_Loss:1.002909779548645, G_Loss:1.9372916221618652

iterator 300, D_Loss:0.9395836591720581, G_Loss:2.1082005500793457

iterator 400, D_Loss:0.9204965829849243, G_Loss:1.8715386390686035

iterator 500, D_Loss:1.0097014904022217, G_Loss:1.9853514432907104

iterator 600, D_Loss:1.0042598247528076, G_Loss:1.9948979616165161

iterator 700, D_Loss:0.9748522639274597, G_Loss:1.9175007343292236

iterator 800, D_Loss:0.9990841150283813, G_Loss:2.02687668800354

iterator 900, D_Loss:0.9826101064682007, G_Loss:1.952629804611206

iterator 1000, D_Loss:0.9351822137832642, G_Loss:2.1046695709228516

iterator 1100, D_Loss:0.9490352272987366, G_Loss:1.9767564535140991

iterator 1200, D_Loss:0.9939727783203125, G_Loss:2.1535584926605225

iterator 1300, D_Loss:0.9362961053848267, G_Loss:2.030710220336914

iterator 1400, D_Loss:0.9038963317871094, G_Loss:2.0490832328796387

iterator 1500, D_Loss:0.916555643081665, G_Loss:2.0556797981262207

iterator 1600, D_Loss:0.9924582242965698, G_Loss:2.235538959503174

iterator 1700, D_Loss:0.9567996859550476, G_Loss:2.1837525367736816

iterator 1800, D_Loss:0.9876670241355896, G_Loss:1.9155017137527466

iterator 1900, D_Loss:0.943672776222229, G_Loss:2.1377434730529785

iterator 2000, D_Loss:0.9837892055511475, G_Loss:1.9483174085617065

iterator 2100, D_Loss:1.0483874082565308, G_Loss:2.1471939086914062

iterator 2200, D_Loss:0.9862916469573975, G_Loss:1.780107855796814

iterator 2300, D_Loss:0.9647018909454346, G_Loss:1.990935206413269

iterator 2400, D_Loss:0.9572229385375977, G_Loss:2.1298043727874756

iterator 2500, D_Loss:1.0415042638778687, G_Loss:1.9427484273910522

iterator 2600, D_Loss:0.9630918502807617, G_Loss:2.1298866271972656

iterator 2700, D_Loss:0.9439764022827148, G_Loss:2.0897140502929688

iterator 2800, D_Loss:0.980806827545166, G_Loss:1.8488956689834595

iterator 2900, D_Loss:1.019554853439331, G_Loss:2.014451503753662

iterator 3000, D_Loss:0.9415772557258606, G_Loss:2.141615629196167

iterator 3100, D_Loss:0.9369926452636719, G_Loss:1.9869999885559082

iterator 3200, D_Loss:0.957221269607544, G_Loss:1.9726258516311646

iterator 3300, D_Loss:0.9699454307556152, G_Loss:1.9913541078567505

iterator 3400, D_Loss:0.9508336782455444, G_Loss:1.945330262184143

iterator 3500, D_Loss:0.9684548377990723, G_Loss:1.8866454362869263

iterator 3600, D_Loss:1.0142966508865356, G_Loss:1.9673140048980713

iterator 3700, D_Loss:0.8763434290885925, G_Loss:2.0003275871276855

iterator 3800, D_Loss:0.9132493138313293, G_Loss:1.961264967918396

iterator 3900, D_Loss:0.9278392195701599, G_Loss:2.0964016914367676

iterator 4000, D_Loss:0.9538271427154541, G_Loss:1.9208580255508423

iterator 4100, D_Loss:0.9621305465698242, G_Loss:2.066089630126953

iterator 4200, D_Loss:1.0390973091125488, G_Loss:2.0141491889953613

iterator 4300, D_Loss:0.924968421459198, G_Loss:2.1138150691986084

iterator 4400, D_Loss:0.9939143657684326, G_Loss:2.1229302883148193

iterator 4500, D_Loss:0.9150580167770386, G_Loss:2.2312638759613037

iterator 4600, D_Loss:0.904496967792511, G_Loss:2.183755874633789

iterator 4700, D_Loss:0.9471527338027954, G_Loss:2.0045254230499268

iterator 4800, D_Loss:0.9318952560424805, G_Loss:1.7888622283935547

iterator 4900, D_Loss:1.0068788528442383, G_Loss:2.0473134517669678

iterator 5000, D_Loss:0.933746874332428, G_Loss:1.8672778606414795

-----------Epoch 9-----------
iterator 100, D_Loss:0.9851500988006592, G_Loss:1.988242506980896

iterator 200, D_Loss:1.012507438659668, G_Loss:1.8597685098648071

iterator 300, D_Loss:0.9782856106758118, G_Loss:2.016145944595337

iterator 400, D_Loss:0.9701390862464905, G_Loss:1.92901611328125

iterator 500, D_Loss:1.0044105052947998, G_Loss:2.029370069503784

iterator 600, D_Loss:0.9382028579711914, G_Loss:1.9239397048950195

iterator 700, D_Loss:1.0383353233337402, G_Loss:1.877147912979126

iterator 800, D_Loss:1.024672031402588, G_Loss:2.041421413421631

iterator 900, D_Loss:1.0126394033432007, G_Loss:1.8047165870666504

iterator 1000, D_Loss:0.9152684211730957, G_Loss:2.0889031887054443

iterator 1100, D_Loss:0.9697647094726562, G_Loss:2.0295603275299072

iterator 1200, D_Loss:1.0068118572235107, G_Loss:2.048833131790161

iterator 1300, D_Loss:0.949517548084259, G_Loss:1.988017201423645

iterator 1400, D_Loss:1.048290729522705, G_Loss:1.9144392013549805

iterator 1500, D_Loss:0.9464206099510193, G_Loss:1.9351886510849

iterator 1600, D_Loss:1.0120735168457031, G_Loss:2.0653252601623535

iterator 1700, D_Loss:0.9593269228935242, G_Loss:2.083251953125

iterator 1800, D_Loss:0.9807711839675903, G_Loss:1.8966058492660522

iterator 1900, D_Loss:0.9942023754119873, G_Loss:1.9170184135437012

iterator 2000, D_Loss:0.9780091643333435, G_Loss:2.0676586627960205

iterator 2100, D_Loss:1.0312848091125488, G_Loss:2.0121524333953857

iterator 2200, D_Loss:1.01390540599823, G_Loss:1.8823621273040771

iterator 2300, D_Loss:1.0027482509613037, G_Loss:2.0346484184265137

iterator 2400, D_Loss:1.024376630783081, G_Loss:1.9663068056106567

iterator 2500, D_Loss:0.9975212812423706, G_Loss:2.0582985877990723

iterator 2600, D_Loss:0.9719241261482239, G_Loss:2.176126718521118

iterator 2700, D_Loss:1.0314931869506836, G_Loss:1.9701933860778809

iterator 2800, D_Loss:0.9448456168174744, G_Loss:1.9557353258132935

iterator 2900, D_Loss:1.0472251176834106, G_Loss:1.9830964803695679

iterator 3000, D_Loss:0.9345712065696716, G_Loss:2.1390721797943115

iterator 3100, D_Loss:0.9938918352127075, G_Loss:1.9544622898101807

iterator 3200, D_Loss:0.9302464723587036, G_Loss:1.9695932865142822

iterator 3300, D_Loss:0.9689339995384216, G_Loss:1.9150058031082153

iterator 3400, D_Loss:0.960312008857727, G_Loss:1.9921114444732666

iterator 3500, D_Loss:0.9211604595184326, G_Loss:1.9697123765945435

iterator 3600, D_Loss:0.9510370492935181, G_Loss:1.920974850654602

iterator 3700, D_Loss:0.9598469734191895, G_Loss:2.04007625579834

iterator 3800, D_Loss:0.921971321105957, G_Loss:2.0493979454040527

iterator 3900, D_Loss:0.9703022241592407, G_Loss:2.006977081298828

iterator 4000, D_Loss:0.9757882356643677, G_Loss:1.9155892133712769

iterator 4100, D_Loss:0.8296580910682678, G_Loss:1.9512543678283691

iterator 4200, D_Loss:0.9574581980705261, G_Loss:1.8587743043899536

iterator 4300, D_Loss:0.9488488435745239, G_Loss:2.1204216480255127

iterator 4400, D_Loss:0.9834948182106018, G_Loss:2.0473432540893555

iterator 4500, D_Loss:0.9030272960662842, G_Loss:1.9169349670410156

iterator 4600, D_Loss:1.011007308959961, G_Loss:1.9966661930084229

iterator 4700, D_Loss:0.962326169013977, G_Loss:1.9175851345062256

iterator 4800, D_Loss:0.9751704931259155, G_Loss:1.8426097631454468

iterator 4900, D_Loss:0.9696725606918335, G_Loss:1.9955395460128784

iterator 5000, D_Loss:1.0109553337097168, G_Loss:1.955735445022583

train row : 30148
sample row: 30148
VGAN_generator(
  (input): Linear(in_features=256, out_features=400, bias=True)
  (inputbn): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=400, out_features=400, bias=True)
  (bn0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=400, out_features=15, bias=True)
  (outputbn): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=15, out_features=300, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=300, out_features=300, bias=True)
  (fc1): Linear(in_features=300, out_features=300, bias=True)
  (output): Linear(in_features=300, out_features=1, bias=True)
)
(0, False, 15)
-----------Epoch 0-----------
iterator 100, D_Loss:0.6983317136764526, G_Loss:2.9576992988586426

iterator 200, D_Loss:0.719694197177887, G_Loss:4.1873087882995605

iterator 300, D_Loss:0.6252126097679138, G_Loss:5.135061264038086

iterator 400, D_Loss:0.606343686580658, G_Loss:6.022994518280029

iterator 500, D_Loss:0.5266717076301575, G_Loss:6.710752010345459

iterator 600, D_Loss:0.5248110890388489, G_Loss:6.794607162475586

iterator 700, D_Loss:0.508633553981781, G_Loss:7.356047630310059

iterator 800, D_Loss:0.5275394320487976, G_Loss:7.834832191467285

iterator 900, D_Loss:0.4917636215686798, G_Loss:8.141607284545898

iterator 1000, D_Loss:0.48807182908058167, G_Loss:8.49937629699707

iterator 1100, D_Loss:0.4703446328639984, G_Loss:8.424899101257324

iterator 1200, D_Loss:0.4720756709575653, G_Loss:8.402786254882812

iterator 1300, D_Loss:0.4877435266971588, G_Loss:9.242179870605469

iterator 1400, D_Loss:0.47027644515037537, G_Loss:8.98524284362793

iterator 1500, D_Loss:0.45914560556411743, G_Loss:8.750442504882812

iterator 1600, D_Loss:0.4797888696193695, G_Loss:8.827836036682129

iterator 1700, D_Loss:0.4647809565067291, G_Loss:9.256465911865234

iterator 1800, D_Loss:0.46611058712005615, G_Loss:9.02286434173584

iterator 1900, D_Loss:0.46897652745246887, G_Loss:8.561455726623535

iterator 2000, D_Loss:0.4873628616333008, G_Loss:9.473371505737305

iterator 2100, D_Loss:0.45703962445259094, G_Loss:8.807913780212402

iterator 2200, D_Loss:0.49613848328590393, G_Loss:8.48900032043457

iterator 2300, D_Loss:0.4559149742126465, G_Loss:8.427166938781738

iterator 2400, D_Loss:0.4464740753173828, G_Loss:8.616109848022461

iterator 2500, D_Loss:0.4499167501926422, G_Loss:8.592409133911133

iterator 2600, D_Loss:0.4778708517551422, G_Loss:8.357728958129883

iterator 2700, D_Loss:0.4616994261741638, G_Loss:8.848076820373535

iterator 2800, D_Loss:0.4862379729747772, G_Loss:8.360280990600586

iterator 2900, D_Loss:0.45859214663505554, G_Loss:8.199061393737793

iterator 3000, D_Loss:0.4851763844490051, G_Loss:7.98911714553833

iterator 3100, D_Loss:0.5206148028373718, G_Loss:7.896166801452637

iterator 3200, D_Loss:0.4873247444629669, G_Loss:8.201611518859863

iterator 3300, D_Loss:0.4474469721317291, G_Loss:7.7194366455078125

iterator 3400, D_Loss:0.47979456186294556, G_Loss:7.980042457580566

iterator 3500, D_Loss:0.4770979881286621, G_Loss:7.734073638916016

iterator 3600, D_Loss:0.488339900970459, G_Loss:7.817789554595947

iterator 3700, D_Loss:0.46953555941581726, G_Loss:7.974115371704102

iterator 3800, D_Loss:0.4879779815673828, G_Loss:7.708646297454834

iterator 3900, D_Loss:0.4463619291782379, G_Loss:8.131199836730957

iterator 4000, D_Loss:0.46586552262306213, G_Loss:7.734113693237305

iterator 4100, D_Loss:0.5279925465583801, G_Loss:7.192721366882324

iterator 4200, D_Loss:0.5035569071769714, G_Loss:7.69285774230957

iterator 4300, D_Loss:0.4860524535179138, G_Loss:7.762549877166748

iterator 4400, D_Loss:0.4683316648006439, G_Loss:7.527349948883057

iterator 4500, D_Loss:0.44930562376976013, G_Loss:7.480483055114746

iterator 4600, D_Loss:0.5033483505249023, G_Loss:7.535945415496826

iterator 4700, D_Loss:0.4964628219604492, G_Loss:6.980145454406738

iterator 4800, D_Loss:0.44280049204826355, G_Loss:7.462601661682129

iterator 4900, D_Loss:0.47676944732666016, G_Loss:7.123336315155029

iterator 5000, D_Loss:0.46837881207466125, G_Loss:7.299018859863281

-----------Epoch 1-----------
iterator 100, D_Loss:0.5068902969360352, G_Loss:6.973852634429932

iterator 200, D_Loss:0.43987029790878296, G_Loss:6.969973564147949

iterator 300, D_Loss:0.5496785044670105, G_Loss:6.568319797515869

iterator 400, D_Loss:0.4993213415145874, G_Loss:7.056928634643555

iterator 500, D_Loss:0.4996563196182251, G_Loss:6.804377555847168

iterator 600, D_Loss:0.4957787096500397, G_Loss:7.350253105163574

iterator 700, D_Loss:0.48335081338882446, G_Loss:6.91243839263916

iterator 800, D_Loss:0.4810599684715271, G_Loss:6.619190216064453

iterator 900, D_Loss:0.5164881944656372, G_Loss:6.906136512756348

iterator 1000, D_Loss:0.4891490638256073, G_Loss:6.612120151519775

iterator 1100, D_Loss:0.512092113494873, G_Loss:7.0068254470825195

iterator 1200, D_Loss:0.5153722763061523, G_Loss:6.467461585998535

iterator 1300, D_Loss:0.5184859037399292, G_Loss:6.493391036987305

iterator 1400, D_Loss:0.4992418587207794, G_Loss:6.292174816131592

iterator 1500, D_Loss:0.5002836585044861, G_Loss:6.400069713592529

iterator 1600, D_Loss:0.5262985229492188, G_Loss:6.276271820068359

iterator 1700, D_Loss:0.4892767071723938, G_Loss:6.653902053833008

iterator 1800, D_Loss:0.5053324103355408, G_Loss:6.4912190437316895

iterator 1900, D_Loss:0.5483099818229675, G_Loss:6.513169288635254

iterator 2000, D_Loss:0.537026584148407, G_Loss:5.946436882019043

iterator 2100, D_Loss:0.5217610597610474, G_Loss:6.1879353523254395

iterator 2200, D_Loss:0.5572421550750732, G_Loss:6.447037220001221

iterator 2300, D_Loss:0.512566328048706, G_Loss:6.150352954864502

iterator 2400, D_Loss:0.5014910697937012, G_Loss:6.401010513305664

iterator 2500, D_Loss:0.48756325244903564, G_Loss:6.29505729675293

iterator 2600, D_Loss:0.5615196228027344, G_Loss:6.192939758300781

iterator 2700, D_Loss:0.5194670557975769, G_Loss:6.199922561645508

iterator 2800, D_Loss:0.5223764181137085, G_Loss:6.178679466247559

iterator 2900, D_Loss:0.5402450561523438, G_Loss:6.290635585784912

iterator 3000, D_Loss:0.5584999918937683, G_Loss:5.778681755065918

iterator 3100, D_Loss:0.5202326774597168, G_Loss:6.218222141265869

iterator 3200, D_Loss:0.5191951394081116, G_Loss:5.911928653717041

iterator 3300, D_Loss:0.49705013632774353, G_Loss:6.101307392120361

iterator 3400, D_Loss:0.5303627252578735, G_Loss:5.8956756591796875

iterator 3500, D_Loss:0.5406470894813538, G_Loss:5.994606018066406

iterator 3600, D_Loss:0.5418379306793213, G_Loss:6.153764247894287

iterator 3700, D_Loss:0.5583626627922058, G_Loss:6.1808695793151855

iterator 3800, D_Loss:0.5367759466171265, G_Loss:6.00161075592041

iterator 3900, D_Loss:0.5442959070205688, G_Loss:6.274670600891113

iterator 4000, D_Loss:0.5043566226959229, G_Loss:6.251613616943359

iterator 4100, D_Loss:0.534235417842865, G_Loss:6.650119304656982

iterator 4200, D_Loss:0.5201674103736877, G_Loss:5.980948448181152

iterator 4300, D_Loss:0.5194844007492065, G_Loss:6.188787937164307

iterator 4400, D_Loss:0.4652571678161621, G_Loss:5.978282451629639

iterator 4500, D_Loss:0.5215747952461243, G_Loss:6.135103702545166

iterator 4600, D_Loss:0.5244385600090027, G_Loss:6.095392227172852

iterator 4700, D_Loss:0.5531435012817383, G_Loss:5.862918376922607

iterator 4800, D_Loss:0.5304531455039978, G_Loss:6.105863571166992

iterator 4900, D_Loss:0.532986044883728, G_Loss:6.207437515258789

iterator 5000, D_Loss:0.4963918626308441, G_Loss:5.976378917694092

-----------Epoch 2-----------
iterator 100, D_Loss:0.5454148054122925, G_Loss:5.723316669464111

iterator 200, D_Loss:0.5315846800804138, G_Loss:6.132474899291992

iterator 300, D_Loss:0.5121325850486755, G_Loss:6.267634868621826

iterator 400, D_Loss:0.5314964056015015, G_Loss:6.337966442108154

iterator 500, D_Loss:0.4688328206539154, G_Loss:6.325129508972168

iterator 600, D_Loss:0.5316242575645447, G_Loss:6.147733688354492

iterator 700, D_Loss:0.5233690142631531, G_Loss:5.854928970336914

iterator 800, D_Loss:0.551521897315979, G_Loss:6.0408616065979

iterator 900, D_Loss:0.5343075394630432, G_Loss:5.744694232940674

iterator 1000, D_Loss:0.5100119113922119, G_Loss:5.829051971435547

iterator 1100, D_Loss:0.5333817005157471, G_Loss:5.939990997314453

iterator 1200, D_Loss:0.5247904658317566, G_Loss:5.9484453201293945

iterator 1300, D_Loss:0.5148923397064209, G_Loss:5.855194568634033

iterator 1400, D_Loss:0.4872238337993622, G_Loss:6.014126300811768

iterator 1500, D_Loss:0.49024534225463867, G_Loss:6.198619842529297

iterator 1600, D_Loss:0.5522069334983826, G_Loss:6.218636512756348

iterator 1700, D_Loss:0.5830253958702087, G_Loss:5.826746463775635

iterator 1800, D_Loss:0.5779393911361694, G_Loss:5.947565078735352

iterator 1900, D_Loss:0.5265114903450012, G_Loss:6.051690101623535

iterator 2000, D_Loss:0.5603470206260681, G_Loss:5.802127361297607

iterator 2100, D_Loss:0.523450493812561, G_Loss:5.79404354095459

iterator 2200, D_Loss:0.5005122423171997, G_Loss:5.783111095428467

iterator 2300, D_Loss:0.5165205597877502, G_Loss:5.804227352142334

iterator 2400, D_Loss:0.5170155763626099, G_Loss:5.776396751403809

iterator 2500, D_Loss:0.5444687604904175, G_Loss:5.663049221038818

iterator 2600, D_Loss:0.5035858154296875, G_Loss:6.034451007843018

iterator 2700, D_Loss:0.5292974710464478, G_Loss:6.128627777099609

iterator 2800, D_Loss:0.5254994630813599, G_Loss:5.706962585449219

iterator 2900, D_Loss:0.5270020365715027, G_Loss:6.047710418701172

iterator 3000, D_Loss:0.5217714309692383, G_Loss:6.019420623779297

iterator 3100, D_Loss:0.5150237679481506, G_Loss:6.206186771392822

iterator 3200, D_Loss:0.5220004320144653, G_Loss:5.968389987945557

iterator 3300, D_Loss:0.5041245222091675, G_Loss:5.827760219573975

iterator 3400, D_Loss:0.6069601774215698, G_Loss:5.7413811683654785

iterator 3500, D_Loss:0.510841965675354, G_Loss:6.048657417297363

iterator 3600, D_Loss:0.5038955211639404, G_Loss:5.6469221115112305

iterator 3700, D_Loss:0.5982292890548706, G_Loss:5.92042350769043

iterator 3800, D_Loss:0.5172924995422363, G_Loss:6.015253067016602

iterator 3900, D_Loss:0.501660943031311, G_Loss:5.748000621795654

iterator 4000, D_Loss:0.4903602600097656, G_Loss:5.783660888671875

iterator 4100, D_Loss:0.5377154350280762, G_Loss:5.811666488647461

iterator 4200, D_Loss:0.4886135160923004, G_Loss:5.925843715667725

iterator 4300, D_Loss:0.530301034450531, G_Loss:5.824651718139648

iterator 4400, D_Loss:0.48490750789642334, G_Loss:6.085134029388428

iterator 4500, D_Loss:0.5809212327003479, G_Loss:5.6131463050842285

iterator 4600, D_Loss:0.483932763338089, G_Loss:5.995702743530273

iterator 4700, D_Loss:0.5410409569740295, G_Loss:5.558874130249023

iterator 4800, D_Loss:0.5333602428436279, G_Loss:5.732675552368164

iterator 4900, D_Loss:0.490753710269928, G_Loss:5.702051162719727

iterator 5000, D_Loss:0.5275267362594604, G_Loss:5.924757957458496

-----------Epoch 3-----------
iterator 100, D_Loss:0.503345787525177, G_Loss:5.56675910949707

iterator 200, D_Loss:0.6028316020965576, G_Loss:6.253097057342529

iterator 300, D_Loss:0.5313693881034851, G_Loss:5.5805277824401855

iterator 400, D_Loss:0.4943893551826477, G_Loss:5.522356033325195

iterator 500, D_Loss:0.4912998378276825, G_Loss:5.553808212280273

iterator 600, D_Loss:0.5164999961853027, G_Loss:5.775420665740967

iterator 700, D_Loss:0.5228803753852844, G_Loss:5.907802581787109

iterator 800, D_Loss:0.49871695041656494, G_Loss:5.769344329833984

iterator 900, D_Loss:0.515574038028717, G_Loss:5.684165954589844

iterator 1000, D_Loss:0.5466594696044922, G_Loss:5.637434959411621

iterator 1100, D_Loss:0.47365134954452515, G_Loss:5.916956901550293

iterator 1200, D_Loss:0.515566349029541, G_Loss:5.923605442047119

iterator 1300, D_Loss:0.5313694477081299, G_Loss:5.551362037658691

iterator 1400, D_Loss:0.5389738082885742, G_Loss:5.659221649169922

iterator 1500, D_Loss:0.5091022849082947, G_Loss:5.519300937652588

iterator 1600, D_Loss:0.5112667083740234, G_Loss:5.32172155380249

iterator 1700, D_Loss:0.5122691988945007, G_Loss:6.048041343688965

iterator 1800, D_Loss:0.5567035675048828, G_Loss:5.995416641235352

iterator 1900, D_Loss:0.5104865431785583, G_Loss:5.271712303161621

iterator 2000, D_Loss:0.528138279914856, G_Loss:5.534709930419922

iterator 2100, D_Loss:0.5061414837837219, G_Loss:5.352190017700195

iterator 2200, D_Loss:0.5548045039176941, G_Loss:5.644587516784668

iterator 2300, D_Loss:0.5370360612869263, G_Loss:5.52398157119751

iterator 2400, D_Loss:0.4920642077922821, G_Loss:5.822899341583252

iterator 2500, D_Loss:0.507843017578125, G_Loss:6.1724066734313965

iterator 2600, D_Loss:0.5080519914627075, G_Loss:5.473356246948242

iterator 2700, D_Loss:0.5604704022407532, G_Loss:5.38021183013916

iterator 2800, D_Loss:0.5356152057647705, G_Loss:5.544152736663818

iterator 2900, D_Loss:0.4989631474018097, G_Loss:5.564299583435059

iterator 3000, D_Loss:0.5337469577789307, G_Loss:5.204971790313721

iterator 3100, D_Loss:0.5590941905975342, G_Loss:5.62294864654541

iterator 3200, D_Loss:0.5098257660865784, G_Loss:5.574870586395264

iterator 3300, D_Loss:0.5432496070861816, G_Loss:5.662026882171631

iterator 3400, D_Loss:0.5171366333961487, G_Loss:5.408417701721191

iterator 3500, D_Loss:0.5422195792198181, G_Loss:5.32533597946167

iterator 3600, D_Loss:0.5137067437171936, G_Loss:5.458475589752197

iterator 3700, D_Loss:0.5503239631652832, G_Loss:5.508513927459717

iterator 3800, D_Loss:0.5258679986000061, G_Loss:5.465564727783203

iterator 3900, D_Loss:0.5394279360771179, G_Loss:5.311723232269287

iterator 4000, D_Loss:0.5166439414024353, G_Loss:5.374891757965088

iterator 4100, D_Loss:0.5302324295043945, G_Loss:5.153006076812744

iterator 4200, D_Loss:0.5243258476257324, G_Loss:5.182924270629883

iterator 4300, D_Loss:0.5119901299476624, G_Loss:5.222577095031738

iterator 4400, D_Loss:0.5354499816894531, G_Loss:5.294127941131592

iterator 4500, D_Loss:0.5438827872276306, G_Loss:5.700961112976074

iterator 4600, D_Loss:0.5252978801727295, G_Loss:5.086771488189697

iterator 4700, D_Loss:0.5334669351577759, G_Loss:5.1237592697143555

iterator 4800, D_Loss:0.5401880145072937, G_Loss:5.224581718444824

iterator 4900, D_Loss:0.517451286315918, G_Loss:5.532376766204834

iterator 5000, D_Loss:0.5095127820968628, G_Loss:5.355792045593262

-----------Epoch 4-----------
iterator 100, D_Loss:0.5202630758285522, G_Loss:5.7598371505737305

iterator 200, D_Loss:0.5074593424797058, G_Loss:5.423644065856934

iterator 300, D_Loss:0.534892201423645, G_Loss:5.317701816558838

iterator 400, D_Loss:0.6007224917411804, G_Loss:5.491954803466797

iterator 500, D_Loss:0.5199740529060364, G_Loss:5.409506320953369

iterator 600, D_Loss:0.5580964684486389, G_Loss:5.313820838928223

iterator 700, D_Loss:0.49722158908843994, G_Loss:5.073178291320801

iterator 800, D_Loss:0.548816442489624, G_Loss:5.105621337890625

iterator 900, D_Loss:0.5160293579101562, G_Loss:5.242005348205566

iterator 1000, D_Loss:0.5197810530662537, G_Loss:5.12192440032959

iterator 1100, D_Loss:0.5587695837020874, G_Loss:5.211233139038086

iterator 1200, D_Loss:0.4999528229236603, G_Loss:5.681727886199951

iterator 1300, D_Loss:0.5647375583648682, G_Loss:5.200710773468018

iterator 1400, D_Loss:0.538489818572998, G_Loss:5.39733362197876

iterator 1500, D_Loss:0.5538472533226013, G_Loss:5.3083672523498535

iterator 1600, D_Loss:0.549282968044281, G_Loss:5.193521976470947

iterator 1700, D_Loss:0.5447044372558594, G_Loss:5.080684661865234

iterator 1800, D_Loss:0.5568476915359497, G_Loss:5.340681076049805

iterator 1900, D_Loss:0.5337299108505249, G_Loss:5.182919502258301

iterator 2000, D_Loss:0.5559091567993164, G_Loss:5.151318073272705

iterator 2100, D_Loss:0.5002837181091309, G_Loss:5.315573692321777

iterator 2200, D_Loss:0.5280793905258179, G_Loss:5.085485935211182

iterator 2300, D_Loss:0.5424981713294983, G_Loss:5.041844367980957

iterator 2400, D_Loss:0.4756920039653778, G_Loss:5.298216819763184

iterator 2500, D_Loss:0.533380389213562, G_Loss:5.2210164070129395

iterator 2600, D_Loss:0.5952540636062622, G_Loss:5.059759140014648

iterator 2700, D_Loss:0.5286898016929626, G_Loss:5.228954792022705

iterator 2800, D_Loss:0.5221168994903564, G_Loss:4.734455585479736

iterator 2900, D_Loss:0.5273728966712952, G_Loss:4.930243968963623

iterator 3000, D_Loss:0.5903445482254028, G_Loss:4.96358585357666

iterator 3100, D_Loss:0.5563336610794067, G_Loss:4.866250514984131

iterator 3200, D_Loss:0.5428988933563232, G_Loss:4.850947380065918

iterator 3300, D_Loss:0.5575752258300781, G_Loss:5.1760687828063965

iterator 3400, D_Loss:0.5898250341415405, G_Loss:4.895549297332764

iterator 3500, D_Loss:0.5440900325775146, G_Loss:5.011536598205566

iterator 3600, D_Loss:0.5529979467391968, G_Loss:4.669244766235352

iterator 3700, D_Loss:0.5264414548873901, G_Loss:5.163035869598389

iterator 3800, D_Loss:0.5377293229103088, G_Loss:5.026695251464844

iterator 3900, D_Loss:0.5301711559295654, G_Loss:5.070845603942871

iterator 4000, D_Loss:0.5100753307342529, G_Loss:4.828521728515625

iterator 4100, D_Loss:0.6131581664085388, G_Loss:4.791995048522949

iterator 4200, D_Loss:0.5883211493492126, G_Loss:4.801427364349365

iterator 4300, D_Loss:0.5379474759101868, G_Loss:4.777923583984375

iterator 4400, D_Loss:0.5205935835838318, G_Loss:4.978817462921143

iterator 4500, D_Loss:0.5602670907974243, G_Loss:4.705644607543945

iterator 4600, D_Loss:0.5268970727920532, G_Loss:4.879655361175537

iterator 4700, D_Loss:0.5257756114006042, G_Loss:4.886470794677734

iterator 4800, D_Loss:0.5644308924674988, G_Loss:4.765774726867676

iterator 4900, D_Loss:0.6179407238960266, G_Loss:4.691046714782715

iterator 5000, D_Loss:0.5707956552505493, G_Loss:4.939736843109131

-----------Epoch 5-----------
iterator 100, D_Loss:0.5791423320770264, G_Loss:4.305893898010254

iterator 200, D_Loss:0.570354163646698, G_Loss:4.599327564239502

iterator 300, D_Loss:0.5633295178413391, G_Loss:4.697463512420654

iterator 400, D_Loss:0.559013843536377, G_Loss:4.8164963722229

iterator 500, D_Loss:0.5638501048088074, G_Loss:4.825688362121582

iterator 600, D_Loss:0.6009952425956726, G_Loss:5.135599136352539

iterator 700, D_Loss:0.5242680907249451, G_Loss:4.755502700805664

iterator 800, D_Loss:0.557496190071106, G_Loss:5.011455059051514

iterator 900, D_Loss:0.5777410864830017, G_Loss:4.802933216094971

iterator 1000, D_Loss:0.5809061527252197, G_Loss:4.950021743774414

iterator 1100, D_Loss:0.5817989706993103, G_Loss:4.947057723999023

iterator 1200, D_Loss:0.5793597102165222, G_Loss:4.763613224029541

iterator 1300, D_Loss:0.5928398966789246, G_Loss:4.717350006103516

iterator 1400, D_Loss:0.5645604133605957, G_Loss:4.757233142852783

iterator 1500, D_Loss:0.5744495987892151, G_Loss:4.715933799743652

iterator 1600, D_Loss:0.6292417049407959, G_Loss:5.136497497558594

iterator 1700, D_Loss:0.5568758249282837, G_Loss:4.671701431274414

iterator 1800, D_Loss:0.6542523503303528, G_Loss:4.708649635314941

iterator 1900, D_Loss:0.6382600665092468, G_Loss:4.69338321685791

iterator 2000, D_Loss:0.5622374415397644, G_Loss:4.594780445098877

iterator 2100, D_Loss:0.6056815385818481, G_Loss:5.073129653930664

iterator 2200, D_Loss:0.5433292388916016, G_Loss:4.74616813659668

iterator 2300, D_Loss:0.5829887390136719, G_Loss:4.881239414215088

iterator 2400, D_Loss:0.5310381650924683, G_Loss:4.735325813293457

iterator 2500, D_Loss:0.5993171334266663, G_Loss:4.739657878875732

iterator 2600, D_Loss:0.6563457250595093, G_Loss:4.342179775238037

iterator 2700, D_Loss:0.5556339025497437, G_Loss:4.568521499633789

iterator 2800, D_Loss:0.6029294729232788, G_Loss:4.365608215332031

iterator 2900, D_Loss:0.572517991065979, G_Loss:4.298046588897705

iterator 3000, D_Loss:0.6325408220291138, G_Loss:4.366026401519775

iterator 3100, D_Loss:0.556691586971283, G_Loss:4.504697799682617

iterator 3200, D_Loss:0.6298236846923828, G_Loss:4.55559778213501

iterator 3300, D_Loss:0.6384203433990479, G_Loss:4.529289722442627

iterator 3400, D_Loss:0.5734796524047852, G_Loss:4.414582252502441

iterator 3500, D_Loss:0.6178107857704163, G_Loss:4.60200834274292

iterator 3600, D_Loss:0.6128246784210205, G_Loss:4.419109344482422

iterator 3700, D_Loss:0.5937687158584595, G_Loss:4.233802318572998

iterator 3800, D_Loss:0.5213016271591187, G_Loss:4.7010626792907715

iterator 3900, D_Loss:0.5809272527694702, G_Loss:4.496481418609619

iterator 4000, D_Loss:0.601073682308197, G_Loss:4.531757831573486

iterator 4100, D_Loss:0.6213438510894775, G_Loss:4.051681995391846

iterator 4200, D_Loss:0.6440461874008179, G_Loss:4.363260269165039

iterator 4300, D_Loss:0.59402996301651, G_Loss:3.9368655681610107

iterator 4400, D_Loss:0.5913497805595398, G_Loss:3.9333386421203613

iterator 4500, D_Loss:0.6470288038253784, G_Loss:4.306075096130371

iterator 4600, D_Loss:0.6513010859489441, G_Loss:4.451716423034668

iterator 4700, D_Loss:0.5638635754585266, G_Loss:4.180023193359375

iterator 4800, D_Loss:0.6053522825241089, G_Loss:4.485413551330566

iterator 4900, D_Loss:0.6084980368614197, G_Loss:4.170664310455322

iterator 5000, D_Loss:0.6201254725456238, G_Loss:4.402320861816406

-----------Epoch 6-----------
iterator 100, D_Loss:0.5882124900817871, G_Loss:4.38738489151001

iterator 200, D_Loss:0.5688475370407104, G_Loss:4.2627458572387695

iterator 300, D_Loss:0.5816316604614258, G_Loss:4.087047576904297

iterator 400, D_Loss:0.6077700853347778, G_Loss:4.006123065948486

iterator 500, D_Loss:0.6386051774024963, G_Loss:4.033128261566162

iterator 600, D_Loss:0.6075369119644165, G_Loss:4.311412811279297

iterator 700, D_Loss:0.6070123314857483, G_Loss:3.8378045558929443

iterator 800, D_Loss:0.6457722783088684, G_Loss:4.24174165725708

iterator 900, D_Loss:0.5499994158744812, G_Loss:4.127577781677246

iterator 1000, D_Loss:0.6656651496887207, G_Loss:3.891878366470337

iterator 1100, D_Loss:0.6375479698181152, G_Loss:3.63067364692688

iterator 1200, D_Loss:0.6816245317459106, G_Loss:4.030823707580566

iterator 1300, D_Loss:0.6534132361412048, G_Loss:3.7076401710510254

iterator 1400, D_Loss:0.6360684037208557, G_Loss:3.817774534225464

iterator 1500, D_Loss:0.6454626321792603, G_Loss:3.761232614517212

iterator 1600, D_Loss:0.633230447769165, G_Loss:3.6152353286743164

iterator 1700, D_Loss:0.6334359645843506, G_Loss:3.6608753204345703

iterator 1800, D_Loss:0.622889518737793, G_Loss:3.9147119522094727

iterator 1900, D_Loss:0.6850850582122803, G_Loss:3.786052703857422

iterator 2000, D_Loss:0.6548218727111816, G_Loss:3.7277398109436035

iterator 2100, D_Loss:0.6000499725341797, G_Loss:4.036711692810059

iterator 2200, D_Loss:0.629331111907959, G_Loss:3.8892736434936523

iterator 2300, D_Loss:0.6047849059104919, G_Loss:3.5631227493286133

iterator 2400, D_Loss:0.6513324975967407, G_Loss:3.7674100399017334

iterator 2500, D_Loss:0.6121053099632263, G_Loss:3.7953922748565674

iterator 2600, D_Loss:0.666924238204956, G_Loss:3.859574556350708

iterator 2700, D_Loss:0.6132539510726929, G_Loss:3.8634467124938965

iterator 2800, D_Loss:0.6622947454452515, G_Loss:3.5437188148498535

iterator 2900, D_Loss:0.648833692073822, G_Loss:3.5607681274414062

iterator 3000, D_Loss:0.6369819641113281, G_Loss:3.409970760345459

iterator 3100, D_Loss:0.6483392119407654, G_Loss:3.483895778656006

iterator 3200, D_Loss:0.6139971017837524, G_Loss:3.940147638320923

iterator 3300, D_Loss:0.6525290012359619, G_Loss:3.741772174835205

iterator 3400, D_Loss:0.686316728591919, G_Loss:3.718339204788208

iterator 3500, D_Loss:0.6445842385292053, G_Loss:3.418304204940796

iterator 3600, D_Loss:0.6410455703735352, G_Loss:3.7081689834594727

iterator 3700, D_Loss:0.6119462251663208, G_Loss:3.852626085281372

iterator 3800, D_Loss:0.613280177116394, G_Loss:3.810255527496338

iterator 3900, D_Loss:0.607886552810669, G_Loss:3.8535661697387695

iterator 4000, D_Loss:0.6504713296890259, G_Loss:3.694105625152588

iterator 4100, D_Loss:0.7320995330810547, G_Loss:3.720998764038086

iterator 4200, D_Loss:0.6742396950721741, G_Loss:3.7792129516601562

iterator 4300, D_Loss:0.6517271399497986, G_Loss:3.643893241882324

iterator 4400, D_Loss:0.6486390829086304, G_Loss:3.665104866027832

iterator 4500, D_Loss:0.6948152184486389, G_Loss:3.446937322616577

iterator 4600, D_Loss:0.6614317893981934, G_Loss:3.4735944271087646

iterator 4700, D_Loss:0.6814330816268921, G_Loss:3.3390958309173584

iterator 4800, D_Loss:0.6779835820198059, G_Loss:3.6114768981933594

iterator 4900, D_Loss:0.7075214982032776, G_Loss:3.17690372467041

iterator 5000, D_Loss:0.7037053108215332, G_Loss:3.4716546535491943

-----------Epoch 7-----------
iterator 100, D_Loss:0.6964784860610962, G_Loss:3.5915188789367676

iterator 200, D_Loss:0.6643673181533813, G_Loss:3.287754774093628

iterator 300, D_Loss:0.7063824534416199, G_Loss:3.2834603786468506

iterator 400, D_Loss:0.7326790690422058, G_Loss:3.062346935272217

iterator 500, D_Loss:0.6771471500396729, G_Loss:3.1166510581970215

iterator 600, D_Loss:0.7177685499191284, G_Loss:3.379318952560425

iterator 700, D_Loss:0.7012642025947571, G_Loss:3.2721779346466064

iterator 800, D_Loss:0.7003614902496338, G_Loss:3.258112668991089

iterator 900, D_Loss:0.6553547382354736, G_Loss:3.430271863937378

iterator 1000, D_Loss:0.7539129257202148, G_Loss:3.0938994884490967

iterator 1100, D_Loss:0.7111489772796631, G_Loss:3.2771666049957275

iterator 1200, D_Loss:0.6745375394821167, G_Loss:3.4819674491882324

iterator 1300, D_Loss:0.7406149506568909, G_Loss:3.483280897140503

iterator 1400, D_Loss:0.6743947267532349, G_Loss:3.313136100769043

iterator 1500, D_Loss:0.7499822974205017, G_Loss:3.221151828765869

iterator 1600, D_Loss:0.6874529123306274, G_Loss:3.4128575325012207

iterator 1700, D_Loss:0.7055513262748718, G_Loss:3.2059669494628906

iterator 1800, D_Loss:0.8083566427230835, G_Loss:3.398576259613037

iterator 1900, D_Loss:0.6794478297233582, G_Loss:3.3203072547912598

iterator 2000, D_Loss:0.6814455986022949, G_Loss:3.443251609802246

iterator 2100, D_Loss:0.6756071448326111, G_Loss:3.516761302947998

iterator 2200, D_Loss:0.7132060527801514, G_Loss:2.949831485748291

iterator 2300, D_Loss:0.6886980533599854, G_Loss:3.2497644424438477

iterator 2400, D_Loss:0.6599385738372803, G_Loss:3.4233765602111816

iterator 2500, D_Loss:0.643569827079773, G_Loss:3.264592170715332

iterator 2600, D_Loss:0.713454008102417, G_Loss:3.351189136505127

iterator 2700, D_Loss:0.6348835825920105, G_Loss:3.229855537414551

iterator 2800, D_Loss:0.6814938187599182, G_Loss:3.3590121269226074

iterator 2900, D_Loss:0.6598100066184998, G_Loss:3.277242660522461

iterator 3000, D_Loss:0.7136405110359192, G_Loss:2.737328052520752

iterator 3100, D_Loss:0.6582212448120117, G_Loss:3.332120418548584

iterator 3200, D_Loss:0.6821647882461548, G_Loss:3.197199821472168

iterator 3300, D_Loss:0.7430503368377686, G_Loss:2.9585514068603516

iterator 3400, D_Loss:0.7556124329566956, G_Loss:3.1092803478240967

iterator 3500, D_Loss:0.7470845580101013, G_Loss:3.0132040977478027

iterator 3600, D_Loss:0.7244202494621277, G_Loss:2.920466661453247

iterator 3700, D_Loss:0.7201429605484009, G_Loss:3.3790507316589355

iterator 3800, D_Loss:0.6896566152572632, G_Loss:3.1505212783813477

iterator 3900, D_Loss:0.7167521119117737, G_Loss:3.176354169845581

iterator 4000, D_Loss:0.674253523349762, G_Loss:2.9981706142425537

iterator 4100, D_Loss:0.7578163146972656, G_Loss:3.31286358833313

iterator 4200, D_Loss:0.7000524997711182, G_Loss:3.2808420658111572

iterator 4300, D_Loss:0.7360507845878601, G_Loss:2.7849583625793457

iterator 4400, D_Loss:0.7148330807685852, G_Loss:3.6019515991210938

iterator 4500, D_Loss:0.725491464138031, G_Loss:3.2218093872070312

iterator 4600, D_Loss:0.7195866703987122, G_Loss:3.320530414581299

iterator 4700, D_Loss:0.6769042015075684, G_Loss:3.1345314979553223

iterator 4800, D_Loss:0.6930713653564453, G_Loss:3.3593649864196777

iterator 4900, D_Loss:0.7299559116363525, G_Loss:2.9600563049316406

iterator 5000, D_Loss:0.710350751876831, G_Loss:3.0695903301239014

-----------Epoch 8-----------
iterator 100, D_Loss:0.711411714553833, G_Loss:3.2436940670013428

iterator 200, D_Loss:0.6998151540756226, G_Loss:3.195060968399048

iterator 300, D_Loss:0.746789813041687, G_Loss:3.318239688873291

iterator 400, D_Loss:0.6905423402786255, G_Loss:3.131282329559326

iterator 500, D_Loss:0.6778687834739685, G_Loss:2.9337050914764404

iterator 600, D_Loss:0.703889012336731, G_Loss:3.0220608711242676

iterator 700, D_Loss:0.7760686874389648, G_Loss:2.873652935028076

iterator 800, D_Loss:0.7576104998588562, G_Loss:2.872267723083496

iterator 900, D_Loss:0.7626312971115112, G_Loss:2.811328172683716

iterator 1000, D_Loss:0.7871629595756531, G_Loss:2.6648614406585693

iterator 1100, D_Loss:0.7668987512588501, G_Loss:2.8715341091156006

iterator 1200, D_Loss:0.7723243236541748, G_Loss:2.664921522140503

iterator 1300, D_Loss:0.8001682758331299, G_Loss:2.7393572330474854

iterator 1400, D_Loss:0.7779991626739502, G_Loss:2.4382026195526123

iterator 1500, D_Loss:0.7850774526596069, G_Loss:2.6574106216430664

iterator 1600, D_Loss:0.7669349908828735, G_Loss:2.8390181064605713

iterator 1700, D_Loss:0.8088705539703369, G_Loss:2.6814310550689697

iterator 1800, D_Loss:0.7729917168617249, G_Loss:2.5850305557250977

iterator 1900, D_Loss:0.7653326988220215, G_Loss:2.7099595069885254

iterator 2000, D_Loss:0.8136225938796997, G_Loss:2.6654491424560547

iterator 2100, D_Loss:0.7750591039657593, G_Loss:2.7285804748535156

iterator 2200, D_Loss:0.7476301789283752, G_Loss:2.740327835083008

iterator 2300, D_Loss:0.7984039783477783, G_Loss:2.477228879928589

iterator 2400, D_Loss:0.7464288473129272, G_Loss:2.481977939605713

iterator 2500, D_Loss:0.751836895942688, G_Loss:2.949300527572632

iterator 2600, D_Loss:0.797035813331604, G_Loss:2.9779443740844727

iterator 2700, D_Loss:0.7610301375389099, G_Loss:2.819934606552124

iterator 2800, D_Loss:0.8390123844146729, G_Loss:2.512136220932007

iterator 2900, D_Loss:0.7104682326316833, G_Loss:3.0492351055145264

iterator 3000, D_Loss:0.7939407229423523, G_Loss:2.413370132446289

iterator 3100, D_Loss:0.8028191924095154, G_Loss:2.9001591205596924

iterator 3200, D_Loss:0.7716187238693237, G_Loss:2.601221799850464

iterator 3300, D_Loss:0.873180627822876, G_Loss:2.6684632301330566

iterator 3400, D_Loss:0.783391535282135, G_Loss:2.619507312774658

iterator 3500, D_Loss:0.8590343594551086, G_Loss:2.7970898151397705

iterator 3600, D_Loss:0.7777429819107056, G_Loss:2.7233431339263916

iterator 3700, D_Loss:0.7898721694946289, G_Loss:2.886796236038208

iterator 3800, D_Loss:0.7911621332168579, G_Loss:2.579418182373047

iterator 3900, D_Loss:0.7462052702903748, G_Loss:2.8156332969665527

iterator 4000, D_Loss:0.7480639815330505, G_Loss:2.5734028816223145

iterator 4100, D_Loss:0.7931681871414185, G_Loss:2.5284788608551025

iterator 4200, D_Loss:0.7710016965866089, G_Loss:2.68100643157959

iterator 4300, D_Loss:0.7981157898902893, G_Loss:2.6926674842834473

iterator 4400, D_Loss:0.7429569959640503, G_Loss:2.799912214279175

iterator 4500, D_Loss:0.78498375415802, G_Loss:2.759945869445801

iterator 4600, D_Loss:0.7636927366256714, G_Loss:2.619993209838867

iterator 4700, D_Loss:0.6757988929748535, G_Loss:3.058912754058838

iterator 4800, D_Loss:0.7441360354423523, G_Loss:2.883521795272827

iterator 4900, D_Loss:0.7888092994689941, G_Loss:2.944953203201294

iterator 5000, D_Loss:0.7963532209396362, G_Loss:2.5384609699249268

-----------Epoch 9-----------
iterator 100, D_Loss:0.7701165676116943, G_Loss:2.8517565727233887

iterator 200, D_Loss:0.80887770652771, G_Loss:2.638606309890747

iterator 300, D_Loss:0.8174480199813843, G_Loss:2.901700496673584

iterator 400, D_Loss:0.7827587723731995, G_Loss:2.345694065093994

iterator 500, D_Loss:0.760611891746521, G_Loss:2.602046489715576

iterator 600, D_Loss:0.7716801762580872, G_Loss:2.796398639678955

iterator 700, D_Loss:0.7163100838661194, G_Loss:2.5835556983947754

iterator 800, D_Loss:0.7983956336975098, G_Loss:2.76123046875

iterator 900, D_Loss:0.7859510183334351, G_Loss:2.904045820236206

iterator 1000, D_Loss:0.7753700017929077, G_Loss:2.5811779499053955

iterator 1100, D_Loss:0.8274121284484863, G_Loss:2.6808764934539795

iterator 1200, D_Loss:0.8543615341186523, G_Loss:2.7300994396209717

iterator 1300, D_Loss:0.815536618232727, G_Loss:2.581324577331543

iterator 1400, D_Loss:0.8207200765609741, G_Loss:2.7095508575439453

iterator 1500, D_Loss:0.808576762676239, G_Loss:2.6324546337127686

iterator 1600, D_Loss:0.7944185137748718, G_Loss:2.510115146636963

iterator 1700, D_Loss:0.7902400493621826, G_Loss:2.585387945175171

iterator 1800, D_Loss:0.7901688814163208, G_Loss:3.090099811553955

iterator 1900, D_Loss:0.7553536891937256, G_Loss:2.6112799644470215

iterator 2000, D_Loss:0.7894769906997681, G_Loss:2.4425086975097656

iterator 2100, D_Loss:0.7742880582809448, G_Loss:2.744734764099121

iterator 2200, D_Loss:0.7309340834617615, G_Loss:2.60646653175354

iterator 2300, D_Loss:0.7998743653297424, G_Loss:2.5527901649475098

iterator 2400, D_Loss:0.7694749236106873, G_Loss:2.6921613216400146

iterator 2500, D_Loss:0.7551678419113159, G_Loss:2.783963203430176

iterator 2600, D_Loss:0.8088825941085815, G_Loss:2.9478158950805664

iterator 2700, D_Loss:0.7146083116531372, G_Loss:2.9950509071350098

iterator 2800, D_Loss:0.8252818584442139, G_Loss:2.779108762741089

iterator 2900, D_Loss:0.7778629064559937, G_Loss:2.6091597080230713

iterator 3000, D_Loss:0.8769036531448364, G_Loss:2.1630055904388428

iterator 3100, D_Loss:0.7869253158569336, G_Loss:2.673976421356201

iterator 3200, D_Loss:0.7967751622200012, G_Loss:2.563570976257324

iterator 3300, D_Loss:0.8562676310539246, G_Loss:2.7431092262268066

iterator 3400, D_Loss:0.7990763187408447, G_Loss:2.687527894973755

iterator 3500, D_Loss:0.8509321212768555, G_Loss:2.738656759262085

iterator 3600, D_Loss:0.7893640398979187, G_Loss:2.7780580520629883

iterator 3700, D_Loss:0.7836261987686157, G_Loss:2.438854455947876

iterator 3800, D_Loss:0.7360152006149292, G_Loss:2.8982622623443604

iterator 3900, D_Loss:0.7480303645133972, G_Loss:2.8179681301116943

iterator 4000, D_Loss:0.7555496692657471, G_Loss:2.8094682693481445

iterator 4100, D_Loss:0.86714106798172, G_Loss:2.6467483043670654

iterator 4200, D_Loss:0.8213902711868286, G_Loss:2.700810432434082

iterator 4300, D_Loss:0.8514356017112732, G_Loss:2.3814730644226074

iterator 4400, D_Loss:0.8566592931747437, G_Loss:2.795419931411743

iterator 4500, D_Loss:0.777415931224823, G_Loss:2.69136118888855

iterator 4600, D_Loss:0.7416231036186218, G_Loss:2.6143887042999268

iterator 4700, D_Loss:0.7959105372428894, G_Loss:2.518712282180786

iterator 4800, D_Loss:0.755231499671936, G_Loss:2.59203839302063

iterator 4900, D_Loss:0.7956477403640747, G_Loss:2.508831024169922

iterator 5000, D_Loss:0.790800929069519, G_Loss:2.7619025707244873

VGAN_generator(
  (input): Linear(in_features=128, out_features=200, bias=True)
  (inputbn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (bn0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=200, out_features=200, bias=True)
  (bn1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=200, out_features=200, bias=True)
  (bn2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=200, out_features=15, bias=True)
  (outputbn): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=15, out_features=200, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (fc1): Linear(in_features=200, out_features=200, bias=True)
  (output): Linear(in_features=200, out_features=1, bias=True)
)
(0, False, 15)
-----------Epoch 0-----------
iterator 100, D_Loss:0.7900684475898743, G_Loss:3.414590835571289

iterator 200, D_Loss:0.6221651434898376, G_Loss:4.809288024902344

iterator 300, D_Loss:0.5642696022987366, G_Loss:5.811757564544678

iterator 400, D_Loss:0.552788496017456, G_Loss:6.384786605834961

iterator 500, D_Loss:0.5165613293647766, G_Loss:6.593930244445801

iterator 600, D_Loss:0.4770773649215698, G_Loss:6.7569684982299805

iterator 700, D_Loss:0.4600861966609955, G_Loss:7.292452812194824

iterator 800, D_Loss:0.485187828540802, G_Loss:7.451786994934082

iterator 900, D_Loss:0.4852146804332733, G_Loss:7.2817583084106445

iterator 1000, D_Loss:0.4934070110321045, G_Loss:7.438131332397461

iterator 1100, D_Loss:0.521225094795227, G_Loss:6.848855972290039

iterator 1200, D_Loss:0.4797372817993164, G_Loss:7.463071823120117

iterator 1300, D_Loss:0.48506009578704834, G_Loss:6.942748546600342

iterator 1400, D_Loss:0.46205276250839233, G_Loss:6.8595147132873535

iterator 1500, D_Loss:0.49725770950317383, G_Loss:6.961675643920898

iterator 1600, D_Loss:0.49210402369499207, G_Loss:7.025505065917969

iterator 1700, D_Loss:0.4846169948577881, G_Loss:6.964969635009766

iterator 1800, D_Loss:0.4965790808200836, G_Loss:6.52915096282959

iterator 1900, D_Loss:0.5137512683868408, G_Loss:7.063060760498047

iterator 2000, D_Loss:0.4914802014827728, G_Loss:6.693000316619873

iterator 2100, D_Loss:0.4849279522895813, G_Loss:6.515719413757324

iterator 2200, D_Loss:0.4808714985847473, G_Loss:6.812742233276367

iterator 2300, D_Loss:0.5066375136375427, G_Loss:6.709316253662109

iterator 2400, D_Loss:0.4695965349674225, G_Loss:6.394933223724365

iterator 2500, D_Loss:0.5220782160758972, G_Loss:6.531795501708984

iterator 2600, D_Loss:0.5008980631828308, G_Loss:6.249919414520264

iterator 2700, D_Loss:0.49798744916915894, G_Loss:5.936862945556641

iterator 2800, D_Loss:0.5138251781463623, G_Loss:5.938727378845215

iterator 2900, D_Loss:0.49926239252090454, G_Loss:6.173818588256836

iterator 3000, D_Loss:0.4984360933303833, G_Loss:6.344370365142822

iterator 3100, D_Loss:0.5225083827972412, G_Loss:5.832637310028076

iterator 3200, D_Loss:0.511347770690918, G_Loss:6.156570911407471

iterator 3300, D_Loss:0.5002502799034119, G_Loss:5.951545238494873

iterator 3400, D_Loss:0.4876720607280731, G_Loss:5.575348854064941

iterator 3500, D_Loss:0.5222883820533752, G_Loss:5.722322463989258

iterator 3600, D_Loss:0.5708348751068115, G_Loss:5.634490966796875

iterator 3700, D_Loss:0.5040926337242126, G_Loss:5.782718658447266

iterator 3800, D_Loss:0.5324366688728333, G_Loss:5.68355131149292

iterator 3900, D_Loss:0.497659832239151, G_Loss:5.549320697784424

iterator 4000, D_Loss:0.5287870168685913, G_Loss:5.636256217956543

iterator 4100, D_Loss:0.5113922357559204, G_Loss:5.486847400665283

iterator 4200, D_Loss:0.5086846947669983, G_Loss:5.717059135437012

iterator 4300, D_Loss:0.547062337398529, G_Loss:5.616476058959961

iterator 4400, D_Loss:0.5339298844337463, G_Loss:5.010745048522949

iterator 4500, D_Loss:0.5303341150283813, G_Loss:5.713998317718506

iterator 4600, D_Loss:0.5192082524299622, G_Loss:5.512846946716309

iterator 4700, D_Loss:0.5069514513015747, G_Loss:5.2769904136657715

iterator 4800, D_Loss:0.5688750743865967, G_Loss:5.289524555206299

iterator 4900, D_Loss:0.5100679993629456, G_Loss:5.367659568786621

iterator 5000, D_Loss:0.5291330218315125, G_Loss:5.514238357543945

-----------Epoch 1-----------
iterator 100, D_Loss:0.5317822694778442, G_Loss:5.742681503295898

iterator 200, D_Loss:0.5167205333709717, G_Loss:5.557116508483887

iterator 300, D_Loss:0.49129390716552734, G_Loss:5.608302116394043

iterator 400, D_Loss:0.5267584919929504, G_Loss:4.992913722991943

iterator 500, D_Loss:0.556118905544281, G_Loss:5.505128860473633

iterator 600, D_Loss:0.4698311686515808, G_Loss:5.391131401062012

iterator 700, D_Loss:0.5023733377456665, G_Loss:5.2582221031188965

iterator 800, D_Loss:0.5317060351371765, G_Loss:5.587735176086426

iterator 900, D_Loss:0.5119723081588745, G_Loss:5.656391620635986

iterator 1000, D_Loss:0.4835290014743805, G_Loss:5.865398406982422

iterator 1100, D_Loss:0.5539237260818481, G_Loss:5.467283725738525

iterator 1200, D_Loss:0.5060029029846191, G_Loss:5.646515846252441

iterator 1300, D_Loss:0.5100660920143127, G_Loss:5.425144195556641

iterator 1400, D_Loss:0.550754725933075, G_Loss:5.08254861831665

iterator 1500, D_Loss:0.4899696707725525, G_Loss:5.476062774658203

iterator 1600, D_Loss:0.5355936288833618, G_Loss:5.740775108337402

iterator 1700, D_Loss:0.5420344471931458, G_Loss:5.224580764770508

iterator 1800, D_Loss:0.5102825164794922, G_Loss:5.69980525970459

iterator 1900, D_Loss:0.5465264320373535, G_Loss:5.788477897644043

iterator 2000, D_Loss:0.5238405466079712, G_Loss:5.5038299560546875

iterator 2100, D_Loss:0.5310951471328735, G_Loss:5.2036638259887695

iterator 2200, D_Loss:0.4842105507850647, G_Loss:5.91383171081543

iterator 2300, D_Loss:0.4942942261695862, G_Loss:6.134400844573975

iterator 2400, D_Loss:0.5114127993583679, G_Loss:5.692120552062988

iterator 2500, D_Loss:0.5305272340774536, G_Loss:5.759567737579346

iterator 2600, D_Loss:0.5091357827186584, G_Loss:5.155364036560059

iterator 2700, D_Loss:0.4975009560585022, G_Loss:5.136921405792236

iterator 2800, D_Loss:0.504098653793335, G_Loss:5.425300121307373

iterator 2900, D_Loss:0.5324957370758057, G_Loss:5.762378692626953

iterator 3000, D_Loss:0.5096850991249084, G_Loss:5.7939958572387695

iterator 3100, D_Loss:0.4990231394767761, G_Loss:5.943575859069824

iterator 3200, D_Loss:0.5155546069145203, G_Loss:5.607221603393555

iterator 3300, D_Loss:0.46855372190475464, G_Loss:6.001018047332764

iterator 3400, D_Loss:0.5329222083091736, G_Loss:4.604827880859375

iterator 3500, D_Loss:0.5332207679748535, G_Loss:4.757915019989014

iterator 3600, D_Loss:0.5358531475067139, G_Loss:5.431481838226318

iterator 3700, D_Loss:0.49478381872177124, G_Loss:5.258869171142578

iterator 3800, D_Loss:0.5303925275802612, G_Loss:5.418572425842285

iterator 3900, D_Loss:0.5429750680923462, G_Loss:5.4857635498046875

iterator 4000, D_Loss:0.545458197593689, G_Loss:4.980859756469727

iterator 4100, D_Loss:0.566641092300415, G_Loss:4.77774715423584

iterator 4200, D_Loss:0.5311545729637146, G_Loss:5.0466437339782715

iterator 4300, D_Loss:0.5201531052589417, G_Loss:4.934094429016113

iterator 4400, D_Loss:0.5752648115158081, G_Loss:4.5032877922058105

iterator 4500, D_Loss:0.5735054612159729, G_Loss:4.54096794128418

iterator 4600, D_Loss:0.5574793815612793, G_Loss:5.35158634185791

iterator 4700, D_Loss:0.57073974609375, G_Loss:4.597715377807617

iterator 4800, D_Loss:0.5512411594390869, G_Loss:4.787922382354736

iterator 4900, D_Loss:0.5464726686477661, G_Loss:4.718862056732178

iterator 5000, D_Loss:0.5515117645263672, G_Loss:4.757758140563965

-----------Epoch 2-----------
iterator 100, D_Loss:0.5827600359916687, G_Loss:4.70448112487793

iterator 200, D_Loss:0.57628333568573, G_Loss:4.644096374511719

iterator 300, D_Loss:0.5513583421707153, G_Loss:4.695268154144287

iterator 400, D_Loss:0.5620048642158508, G_Loss:4.591670036315918

iterator 500, D_Loss:0.5639538764953613, G_Loss:4.533167839050293

iterator 600, D_Loss:0.5533143281936646, G_Loss:4.488531112670898

iterator 700, D_Loss:0.6063204407691956, G_Loss:4.283827304840088

iterator 800, D_Loss:0.6124725341796875, G_Loss:4.215246200561523

iterator 900, D_Loss:0.6123498678207397, G_Loss:4.539991855621338

iterator 1000, D_Loss:0.5890872478485107, G_Loss:4.506486415863037

iterator 1100, D_Loss:0.5812064409255981, G_Loss:4.404259204864502

iterator 1200, D_Loss:0.5437996983528137, G_Loss:4.51800537109375

iterator 1300, D_Loss:0.6407637596130371, G_Loss:4.618784427642822

iterator 1400, D_Loss:0.6718719005584717, G_Loss:3.850006341934204

iterator 1500, D_Loss:0.5721975564956665, G_Loss:4.303528785705566

iterator 1600, D_Loss:0.5933828353881836, G_Loss:4.05373477935791

iterator 1700, D_Loss:0.6469048261642456, G_Loss:3.6597437858581543

iterator 1800, D_Loss:0.6069000363349915, G_Loss:4.019642353057861

iterator 1900, D_Loss:0.642976701259613, G_Loss:3.6877403259277344

iterator 2000, D_Loss:0.5730035305023193, G_Loss:3.863314390182495

iterator 2100, D_Loss:0.6172375679016113, G_Loss:3.939166784286499

iterator 2200, D_Loss:0.6160241961479187, G_Loss:3.658548355102539

iterator 2300, D_Loss:0.5967444181442261, G_Loss:3.569118022918701

iterator 2400, D_Loss:0.6659187078475952, G_Loss:3.413071632385254

iterator 2500, D_Loss:0.6530325412750244, G_Loss:3.8171823024749756

iterator 2600, D_Loss:0.589175820350647, G_Loss:4.198291778564453

iterator 2700, D_Loss:0.6285337805747986, G_Loss:3.9950265884399414

iterator 2800, D_Loss:0.5827425718307495, G_Loss:3.9672369956970215

iterator 2900, D_Loss:0.5955680012702942, G_Loss:3.99867582321167

iterator 3000, D_Loss:0.5803055763244629, G_Loss:4.217723369598389

iterator 3100, D_Loss:0.5759234428405762, G_Loss:3.8194730281829834

iterator 3200, D_Loss:0.6115884780883789, G_Loss:3.4225029945373535

iterator 3300, D_Loss:0.5729348063468933, G_Loss:3.726205587387085

iterator 3400, D_Loss:0.6606398820877075, G_Loss:3.4990785121917725

iterator 3500, D_Loss:0.6360714435577393, G_Loss:3.6801528930664062

iterator 3600, D_Loss:0.6693341135978699, G_Loss:4.023093223571777

iterator 3700, D_Loss:0.6100289821624756, G_Loss:3.458730936050415

iterator 3800, D_Loss:0.6558531522750854, G_Loss:3.5112340450286865

iterator 3900, D_Loss:0.6508806943893433, G_Loss:3.436997413635254

iterator 4000, D_Loss:0.6732062101364136, G_Loss:3.288496255874634

iterator 4100, D_Loss:0.6486223936080933, G_Loss:3.503636360168457

iterator 4200, D_Loss:0.6203261613845825, G_Loss:4.062326431274414

iterator 4300, D_Loss:0.7068415880203247, G_Loss:3.5493643283843994

iterator 4400, D_Loss:0.6411962509155273, G_Loss:3.692894697189331

iterator 4500, D_Loss:0.6839237213134766, G_Loss:3.5766091346740723

iterator 4600, D_Loss:0.6561382412910461, G_Loss:3.379516124725342

iterator 4700, D_Loss:0.6752280592918396, G_Loss:3.5916497707366943

iterator 4800, D_Loss:0.6945395469665527, G_Loss:3.472459554672241

iterator 4900, D_Loss:0.6220137476921082, G_Loss:3.534778356552124

iterator 5000, D_Loss:0.6948648691177368, G_Loss:3.7935590744018555

-----------Epoch 3-----------
iterator 100, D_Loss:0.6587156057357788, G_Loss:3.604287624359131

iterator 200, D_Loss:0.6795915365219116, G_Loss:3.4083638191223145

iterator 300, D_Loss:0.695096492767334, G_Loss:3.5276594161987305

iterator 400, D_Loss:0.6344020962715149, G_Loss:3.36183762550354

iterator 500, D_Loss:0.6952676773071289, G_Loss:3.324411630630493

iterator 600, D_Loss:0.6867753863334656, G_Loss:3.3572280406951904

iterator 700, D_Loss:0.7530485391616821, G_Loss:3.581325054168701

iterator 800, D_Loss:0.6609392166137695, G_Loss:3.414060592651367

iterator 900, D_Loss:0.6941357851028442, G_Loss:3.494065523147583

iterator 1000, D_Loss:0.6549355983734131, G_Loss:3.310727596282959

iterator 1100, D_Loss:0.7115886807441711, G_Loss:3.2456021308898926

iterator 1200, D_Loss:0.7200137376785278, G_Loss:3.350924491882324

iterator 1300, D_Loss:0.6830896139144897, G_Loss:3.446988105773926

iterator 1400, D_Loss:0.7078052759170532, G_Loss:3.321194887161255

iterator 1500, D_Loss:0.6607340574264526, G_Loss:3.4494540691375732

iterator 1600, D_Loss:0.6603949666023254, G_Loss:3.53045392036438

iterator 1700, D_Loss:0.7205836772918701, G_Loss:3.2744140625

iterator 1800, D_Loss:0.7299317121505737, G_Loss:3.0044727325439453

iterator 1900, D_Loss:0.7094101309776306, G_Loss:3.270808458328247

iterator 2000, D_Loss:0.6994119882583618, G_Loss:2.8920998573303223

iterator 2100, D_Loss:0.7288287878036499, G_Loss:3.00791072845459

iterator 2200, D_Loss:0.7167973518371582, G_Loss:2.9536333084106445

iterator 2300, D_Loss:0.7818412184715271, G_Loss:2.747498035430908

iterator 2400, D_Loss:0.7311262488365173, G_Loss:2.907172441482544

iterator 2500, D_Loss:0.7501487731933594, G_Loss:3.0543413162231445

iterator 2600, D_Loss:0.6964917778968811, G_Loss:3.1160504817962646

iterator 2700, D_Loss:0.695661187171936, G_Loss:3.2754082679748535

iterator 2800, D_Loss:0.7320350408554077, G_Loss:3.0212574005126953

iterator 2900, D_Loss:0.7741284370422363, G_Loss:2.9635426998138428

iterator 3000, D_Loss:0.7592562437057495, G_Loss:2.8262779712677

iterator 3100, D_Loss:0.7695479393005371, G_Loss:2.9446487426757812

iterator 3200, D_Loss:0.7385895848274231, G_Loss:2.8343915939331055

iterator 3300, D_Loss:0.7737882137298584, G_Loss:2.7576303482055664

iterator 3400, D_Loss:0.7639644145965576, G_Loss:2.6244447231292725

iterator 3500, D_Loss:0.7638260126113892, G_Loss:2.513080596923828

iterator 3600, D_Loss:0.7856682538986206, G_Loss:2.8850820064544678

iterator 3700, D_Loss:0.774334192276001, G_Loss:2.5355474948883057

iterator 3800, D_Loss:0.79616779088974, G_Loss:2.5561482906341553

iterator 3900, D_Loss:0.8377441763877869, G_Loss:2.5538623332977295

iterator 4000, D_Loss:0.7898914813995361, G_Loss:2.53238582611084

iterator 4100, D_Loss:0.771991491317749, G_Loss:2.393246650695801

iterator 4200, D_Loss:0.7642572522163391, G_Loss:2.7595720291137695

iterator 4300, D_Loss:0.8149596452713013, G_Loss:2.655109167098999

iterator 4400, D_Loss:0.8682791590690613, G_Loss:2.7366530895233154

iterator 4500, D_Loss:0.761603832244873, G_Loss:2.7847678661346436

iterator 4600, D_Loss:0.7682636380195618, G_Loss:2.467085361480713

iterator 4700, D_Loss:0.8310167789459229, G_Loss:2.4006807804107666

iterator 4800, D_Loss:0.7596001625061035, G_Loss:2.540303945541382

iterator 4900, D_Loss:0.7634821534156799, G_Loss:2.606458902359009

iterator 5000, D_Loss:0.8215152025222778, G_Loss:2.724632740020752

-----------Epoch 4-----------
iterator 100, D_Loss:0.7941362857818604, G_Loss:2.6004557609558105

iterator 200, D_Loss:0.8264551162719727, G_Loss:2.575531482696533

iterator 300, D_Loss:0.8124374151229858, G_Loss:2.548264980316162

iterator 400, D_Loss:0.800856351852417, G_Loss:2.443007469177246

iterator 500, D_Loss:0.7641557455062866, G_Loss:2.614229679107666

iterator 600, D_Loss:0.848961591720581, G_Loss:2.7188897132873535

iterator 700, D_Loss:0.7594117522239685, G_Loss:2.818513870239258

iterator 800, D_Loss:0.7709437012672424, G_Loss:2.293105363845825

iterator 900, D_Loss:0.7883236408233643, G_Loss:2.5411763191223145

iterator 1000, D_Loss:0.8413532972335815, G_Loss:2.714075803756714

iterator 1100, D_Loss:0.8480257391929626, G_Loss:2.4557571411132812

iterator 1200, D_Loss:0.7834413051605225, G_Loss:2.5449881553649902

iterator 1300, D_Loss:0.8362430930137634, G_Loss:2.351412296295166

iterator 1400, D_Loss:0.8032420873641968, G_Loss:2.2728447914123535

iterator 1500, D_Loss:0.8518272042274475, G_Loss:2.4209554195404053

iterator 1600, D_Loss:0.8443436622619629, G_Loss:2.305478811264038

iterator 1700, D_Loss:0.7974545955657959, G_Loss:2.421471357345581

iterator 1800, D_Loss:0.8620212078094482, G_Loss:2.226926565170288

iterator 1900, D_Loss:0.8543856739997864, G_Loss:2.191570997238159

iterator 2000, D_Loss:0.8273624181747437, G_Loss:2.262991189956665

iterator 2100, D_Loss:0.8447408676147461, G_Loss:2.2711122035980225

iterator 2200, D_Loss:0.883611798286438, G_Loss:2.380925178527832

iterator 2300, D_Loss:0.8590459823608398, G_Loss:2.320512294769287

iterator 2400, D_Loss:0.8526465892791748, G_Loss:2.079801559448242

iterator 2500, D_Loss:0.8737814426422119, G_Loss:2.20487642288208

iterator 2600, D_Loss:0.8237180709838867, G_Loss:2.279829502105713

iterator 2700, D_Loss:0.8910176157951355, G_Loss:2.1121740341186523

iterator 2800, D_Loss:0.8573989868164062, G_Loss:2.2589797973632812

iterator 2900, D_Loss:0.8649671077728271, G_Loss:2.035163402557373

iterator 3000, D_Loss:0.8982356190681458, G_Loss:2.1329522132873535

iterator 3100, D_Loss:0.8406190276145935, G_Loss:2.2945871353149414

iterator 3200, D_Loss:0.8604093790054321, G_Loss:2.3790688514709473

iterator 3300, D_Loss:0.8371903300285339, G_Loss:2.396754264831543

iterator 3400, D_Loss:0.8336487412452698, G_Loss:2.390918493270874

iterator 3500, D_Loss:0.818895161151886, G_Loss:2.369065761566162

iterator 3600, D_Loss:0.8537787795066833, G_Loss:2.2200210094451904

iterator 3700, D_Loss:0.884321391582489, G_Loss:2.374959707260132

iterator 3800, D_Loss:0.8622123003005981, G_Loss:2.123569965362549

iterator 3900, D_Loss:0.8918701410293579, G_Loss:2.3114466667175293

iterator 4000, D_Loss:0.8901224136352539, G_Loss:1.9969536066055298

iterator 4100, D_Loss:0.901166558265686, G_Loss:1.9633145332336426

iterator 4200, D_Loss:0.8572473526000977, G_Loss:2.3431458473205566

iterator 4300, D_Loss:0.8745193481445312, G_Loss:2.108581304550171

iterator 4400, D_Loss:0.9071046710014343, G_Loss:1.9426320791244507

iterator 4500, D_Loss:0.9053491353988647, G_Loss:2.0244688987731934

iterator 4600, D_Loss:0.9149878025054932, G_Loss:2.0674805641174316

iterator 4700, D_Loss:0.9132408499717712, G_Loss:2.159102439880371

iterator 4800, D_Loss:0.9152527451515198, G_Loss:2.0844714641571045

iterator 4900, D_Loss:0.8809043765068054, G_Loss:1.8894133567810059

iterator 5000, D_Loss:0.8927793502807617, G_Loss:1.8963507413864136

-----------Epoch 5-----------
iterator 100, D_Loss:0.8532065749168396, G_Loss:2.1212830543518066

iterator 200, D_Loss:0.8968157768249512, G_Loss:2.1816437244415283

iterator 300, D_Loss:0.9101916551589966, G_Loss:1.927715539932251

iterator 400, D_Loss:0.95184326171875, G_Loss:2.1175079345703125

iterator 500, D_Loss:0.9308218359947205, G_Loss:2.1436619758605957

iterator 600, D_Loss:0.8607560992240906, G_Loss:2.155618906021118

iterator 700, D_Loss:0.9125328660011292, G_Loss:2.1840827465057373

iterator 800, D_Loss:0.8581298589706421, G_Loss:2.187234878540039

iterator 900, D_Loss:0.9129320979118347, G_Loss:2.1535589694976807

iterator 1000, D_Loss:0.9105042219161987, G_Loss:1.919219970703125

iterator 1100, D_Loss:0.9641009569168091, G_Loss:1.9976041316986084

iterator 1200, D_Loss:0.8961853981018066, G_Loss:2.0771288871765137

iterator 1300, D_Loss:0.8833103179931641, G_Loss:1.9934172630310059

iterator 1400, D_Loss:0.9146079421043396, G_Loss:2.0402047634124756

iterator 1500, D_Loss:0.9066154956817627, G_Loss:1.973632574081421

iterator 1600, D_Loss:0.9226508736610413, G_Loss:1.9288028478622437

iterator 1700, D_Loss:0.9475758075714111, G_Loss:2.0285303592681885

iterator 1800, D_Loss:0.8707109689712524, G_Loss:2.2717878818511963

iterator 1900, D_Loss:0.9130595922470093, G_Loss:1.9939419031143188

iterator 2000, D_Loss:0.9132187366485596, G_Loss:2.117413282394409

iterator 2100, D_Loss:0.8589460253715515, G_Loss:2.0734198093414307

iterator 2200, D_Loss:0.9177427291870117, G_Loss:1.9992222785949707

iterator 2300, D_Loss:0.9312654137611389, G_Loss:1.957406997680664

iterator 2400, D_Loss:0.9318000078201294, G_Loss:1.8862067461013794

iterator 2500, D_Loss:0.9120157361030579, G_Loss:2.1626899242401123

iterator 2600, D_Loss:0.8530088067054749, G_Loss:2.064858913421631

iterator 2700, D_Loss:0.9471285343170166, G_Loss:2.052727222442627

iterator 2800, D_Loss:0.9504349231719971, G_Loss:1.8787493705749512

iterator 2900, D_Loss:0.9529858827590942, G_Loss:1.863950252532959

iterator 3000, D_Loss:0.8925616145133972, G_Loss:2.0074400901794434

iterator 3100, D_Loss:0.9483030438423157, G_Loss:1.8019497394561768

iterator 3200, D_Loss:0.9468788504600525, G_Loss:1.8799461126327515

iterator 3300, D_Loss:0.9686431884765625, G_Loss:1.8937709331512451

iterator 3400, D_Loss:0.9401305913925171, G_Loss:2.177816867828369

iterator 3500, D_Loss:0.9212162494659424, G_Loss:2.025952100753784

iterator 3600, D_Loss:0.928007185459137, G_Loss:2.078010082244873

iterator 3700, D_Loss:1.0167334079742432, G_Loss:1.7923599481582642

iterator 3800, D_Loss:0.9703110456466675, G_Loss:1.800766944885254

iterator 3900, D_Loss:0.9908459186553955, G_Loss:1.8017710447311401

iterator 4000, D_Loss:0.9009484648704529, G_Loss:2.097355365753174

iterator 4100, D_Loss:0.9465759992599487, G_Loss:1.729086995124817

iterator 4200, D_Loss:0.9121682047843933, G_Loss:1.908766746520996

iterator 4300, D_Loss:0.9215489625930786, G_Loss:1.8581846952438354

iterator 4400, D_Loss:0.9633384943008423, G_Loss:1.9074821472167969

iterator 4500, D_Loss:0.9365588426589966, G_Loss:1.8807460069656372

iterator 4600, D_Loss:0.9690769910812378, G_Loss:1.642366647720337

iterator 4700, D_Loss:0.9778215289115906, G_Loss:1.9481682777404785

iterator 4800, D_Loss:0.9832660555839539, G_Loss:2.049393653869629

iterator 4900, D_Loss:0.9355450868606567, G_Loss:1.799152135848999

iterator 5000, D_Loss:0.9434024691581726, G_Loss:1.974158525466919

-----------Epoch 6-----------
iterator 100, D_Loss:0.9005872011184692, G_Loss:1.9412897825241089

iterator 200, D_Loss:0.9971882104873657, G_Loss:2.072087049484253

iterator 300, D_Loss:0.9695433378219604, G_Loss:1.8385382890701294

iterator 400, D_Loss:0.9142757654190063, G_Loss:2.088880777359009

iterator 500, D_Loss:0.9785765409469604, G_Loss:1.8731062412261963

iterator 600, D_Loss:0.9630377292633057, G_Loss:1.8312557935714722

iterator 700, D_Loss:0.948646068572998, G_Loss:1.6654446125030518

iterator 800, D_Loss:0.9670639038085938, G_Loss:1.968466877937317

iterator 900, D_Loss:0.9709757566452026, G_Loss:1.8750793933868408

iterator 1000, D_Loss:1.0005300045013428, G_Loss:1.8301405906677246

iterator 1100, D_Loss:0.9550244212150574, G_Loss:1.8564014434814453

iterator 1200, D_Loss:0.9899853467941284, G_Loss:1.8154807090759277

iterator 1300, D_Loss:0.9362872242927551, G_Loss:1.831158995628357

iterator 1400, D_Loss:0.9210827350616455, G_Loss:1.839917778968811

iterator 1500, D_Loss:1.0172736644744873, G_Loss:1.8264269828796387

iterator 1600, D_Loss:1.0108118057250977, G_Loss:1.8523125648498535

iterator 1700, D_Loss:0.9414287805557251, G_Loss:1.670586347579956

iterator 1800, D_Loss:0.9962419271469116, G_Loss:1.7300176620483398

iterator 1900, D_Loss:0.9847222566604614, G_Loss:1.7120938301086426

iterator 2000, D_Loss:0.9622297883033752, G_Loss:1.695067286491394

iterator 2100, D_Loss:0.979451060295105, G_Loss:1.6396712064743042

iterator 2200, D_Loss:0.9470828771591187, G_Loss:1.9319168329238892

iterator 2300, D_Loss:0.9833881258964539, G_Loss:1.861507534980774

iterator 2400, D_Loss:0.9344109296798706, G_Loss:2.006845235824585

iterator 2500, D_Loss:0.9885362386703491, G_Loss:1.7425767183303833

iterator 2600, D_Loss:0.9320875406265259, G_Loss:1.9093551635742188

iterator 2700, D_Loss:0.943444013595581, G_Loss:1.6678361892700195

iterator 2800, D_Loss:0.9450799226760864, G_Loss:1.910395622253418

iterator 2900, D_Loss:1.0491864681243896, G_Loss:1.7662642002105713

iterator 3000, D_Loss:1.0132538080215454, G_Loss:1.9794018268585205

iterator 3100, D_Loss:1.0482834577560425, G_Loss:2.0258195400238037

iterator 3200, D_Loss:0.9730517864227295, G_Loss:1.7983851432800293

iterator 3300, D_Loss:0.9103356599807739, G_Loss:2.018447160720825

iterator 3400, D_Loss:0.9727525115013123, G_Loss:1.8738185167312622

iterator 3500, D_Loss:0.963586151599884, G_Loss:1.7462412118911743

iterator 3600, D_Loss:0.9891176223754883, G_Loss:1.7022526264190674

iterator 3700, D_Loss:1.011003851890564, G_Loss:1.6801725625991821

iterator 3800, D_Loss:1.0208930969238281, G_Loss:1.7833484411239624

iterator 3900, D_Loss:0.9946292638778687, G_Loss:1.8178585767745972

iterator 4000, D_Loss:0.9867606163024902, G_Loss:1.7994697093963623

iterator 4100, D_Loss:1.0075291395187378, G_Loss:1.7479140758514404

iterator 4200, D_Loss:1.0457026958465576, G_Loss:1.6421886682510376

iterator 4300, D_Loss:1.0128676891326904, G_Loss:1.9136773347854614

iterator 4400, D_Loss:1.0103939771652222, G_Loss:1.7862732410430908

iterator 4500, D_Loss:1.013779878616333, G_Loss:1.6967275142669678

iterator 4600, D_Loss:0.9660536646842957, G_Loss:1.6943612098693848

iterator 4700, D_Loss:0.9982150197029114, G_Loss:1.7502824068069458

iterator 4800, D_Loss:0.9888739585876465, G_Loss:1.825944185256958

iterator 4900, D_Loss:0.9722722768783569, G_Loss:1.827048420906067

iterator 5000, D_Loss:1.0047892332077026, G_Loss:1.6697858572006226

-----------Epoch 7-----------
iterator 100, D_Loss:0.9581697583198547, G_Loss:1.8641109466552734

iterator 200, D_Loss:0.995596170425415, G_Loss:1.8440412282943726

iterator 300, D_Loss:0.9758756160736084, G_Loss:1.8333708047866821

iterator 400, D_Loss:0.9972836971282959, G_Loss:1.8052021265029907

iterator 500, D_Loss:0.9974266886711121, G_Loss:1.8678921461105347

iterator 600, D_Loss:0.9597356915473938, G_Loss:2.1751675605773926

iterator 700, D_Loss:0.9314939379692078, G_Loss:1.9407562017440796

iterator 800, D_Loss:0.9488577842712402, G_Loss:1.9428387880325317

iterator 900, D_Loss:0.9885785579681396, G_Loss:1.7895574569702148

iterator 1000, D_Loss:1.0598012208938599, G_Loss:1.7704615592956543

iterator 1100, D_Loss:1.0354079008102417, G_Loss:1.7135124206542969

iterator 1200, D_Loss:1.0012726783752441, G_Loss:1.6769438982009888

iterator 1300, D_Loss:1.0047798156738281, G_Loss:1.8574674129486084

iterator 1400, D_Loss:1.0286091566085815, G_Loss:1.7109055519104004

iterator 1500, D_Loss:1.0433931350708008, G_Loss:1.7413673400878906

iterator 1600, D_Loss:0.978142499923706, G_Loss:1.6419310569763184

iterator 1700, D_Loss:1.00826096534729, G_Loss:1.8211561441421509

iterator 1800, D_Loss:0.9712071418762207, G_Loss:1.7097889184951782

iterator 1900, D_Loss:0.9759877324104309, G_Loss:1.7859009504318237

iterator 2000, D_Loss:0.9574223756790161, G_Loss:1.8440569639205933

iterator 2100, D_Loss:1.0412718057632446, G_Loss:1.5732216835021973

iterator 2200, D_Loss:1.0262871980667114, G_Loss:1.715003490447998

iterator 2300, D_Loss:1.0263606309890747, G_Loss:1.6363089084625244

iterator 2400, D_Loss:0.9379023909568787, G_Loss:1.750199556350708

iterator 2500, D_Loss:1.0273466110229492, G_Loss:1.7083598375320435

iterator 2600, D_Loss:0.9701820015907288, G_Loss:1.681519627571106

iterator 2700, D_Loss:1.0288772583007812, G_Loss:1.8495070934295654

iterator 2800, D_Loss:1.0158343315124512, G_Loss:1.8125158548355103

iterator 2900, D_Loss:0.9615261554718018, G_Loss:1.7764155864715576

iterator 3000, D_Loss:1.0437742471694946, G_Loss:1.6897356510162354

iterator 3100, D_Loss:1.0401184558868408, G_Loss:1.589565396308899

iterator 3200, D_Loss:1.0571519136428833, G_Loss:1.659508228302002

iterator 3300, D_Loss:0.9901889562606812, G_Loss:1.7539198398590088

iterator 3400, D_Loss:1.0037970542907715, G_Loss:1.7371925115585327

iterator 3500, D_Loss:1.0010261535644531, G_Loss:1.8976092338562012

iterator 3600, D_Loss:1.0150595903396606, G_Loss:1.7131246328353882

iterator 3700, D_Loss:1.01385498046875, G_Loss:1.8089219331741333

iterator 3800, D_Loss:0.9743846654891968, G_Loss:1.7772748470306396

iterator 3900, D_Loss:0.9974164962768555, G_Loss:1.8436517715454102

iterator 4000, D_Loss:0.9989462494850159, G_Loss:1.7567765712738037

iterator 4100, D_Loss:1.0277588367462158, G_Loss:1.842698335647583

iterator 4200, D_Loss:1.0364164113998413, G_Loss:1.6631357669830322

iterator 4300, D_Loss:1.0163464546203613, G_Loss:1.8084417581558228

iterator 4400, D_Loss:1.0364232063293457, G_Loss:1.9039394855499268

iterator 4500, D_Loss:0.9653069972991943, G_Loss:1.7462711334228516

iterator 4600, D_Loss:1.0365313291549683, G_Loss:1.807381510734558

iterator 4700, D_Loss:1.0202791690826416, G_Loss:1.6504054069519043

iterator 4800, D_Loss:0.9688794612884521, G_Loss:1.6500873565673828

iterator 4900, D_Loss:1.045569896697998, G_Loss:1.9142630100250244

iterator 5000, D_Loss:1.0106667280197144, G_Loss:1.930428385734558

-----------Epoch 8-----------
iterator 100, D_Loss:1.005760669708252, G_Loss:1.826568365097046

iterator 200, D_Loss:0.9781869649887085, G_Loss:1.7962344884872437

iterator 300, D_Loss:1.0211124420166016, G_Loss:1.786502718925476

iterator 400, D_Loss:0.9730449914932251, G_Loss:1.9055650234222412

iterator 500, D_Loss:0.9925954341888428, G_Loss:1.7703721523284912

iterator 600, D_Loss:0.9664691686630249, G_Loss:1.7734602689743042

iterator 700, D_Loss:0.9618080258369446, G_Loss:1.891967535018921

iterator 800, D_Loss:1.016533613204956, G_Loss:1.920006275177002

iterator 900, D_Loss:1.0241401195526123, G_Loss:1.675531029701233

iterator 1000, D_Loss:1.0520321130752563, G_Loss:1.7950522899627686

iterator 1100, D_Loss:0.9930909872055054, G_Loss:1.6532928943634033

iterator 1200, D_Loss:1.0175591707229614, G_Loss:1.7599971294403076

iterator 1300, D_Loss:0.9868119955062866, G_Loss:1.8992133140563965

iterator 1400, D_Loss:1.0186513662338257, G_Loss:1.8562405109405518

iterator 1500, D_Loss:0.9727751016616821, G_Loss:1.9059875011444092

iterator 1600, D_Loss:1.0186748504638672, G_Loss:1.8825469017028809

iterator 1700, D_Loss:0.9934215545654297, G_Loss:1.719663381576538

iterator 1800, D_Loss:0.9700524806976318, G_Loss:1.7754069566726685

iterator 1900, D_Loss:1.0009994506835938, G_Loss:1.9175702333450317

iterator 2000, D_Loss:0.9373185038566589, G_Loss:1.909462809562683

iterator 2100, D_Loss:0.9999274015426636, G_Loss:1.7791452407836914

iterator 2200, D_Loss:0.956149697303772, G_Loss:1.8909233808517456

iterator 2300, D_Loss:1.0318740606307983, G_Loss:1.8973194360733032

iterator 2400, D_Loss:0.9753895401954651, G_Loss:1.8947224617004395

iterator 2500, D_Loss:0.979462742805481, G_Loss:1.8987222909927368

iterator 2600, D_Loss:0.9840675592422485, G_Loss:1.7207727432250977

iterator 2700, D_Loss:0.9865108728408813, G_Loss:1.988882303237915

iterator 2800, D_Loss:0.9607967138290405, G_Loss:1.9852774143218994

iterator 2900, D_Loss:1.0035743713378906, G_Loss:1.6996917724609375

iterator 3000, D_Loss:0.9619128108024597, G_Loss:1.8888046741485596

iterator 3100, D_Loss:0.9818835258483887, G_Loss:2.030787467956543

iterator 3200, D_Loss:0.9757816791534424, G_Loss:1.8789337873458862

iterator 3300, D_Loss:0.9396806955337524, G_Loss:1.9385589361190796

iterator 3400, D_Loss:1.0171061754226685, G_Loss:2.104146957397461

iterator 3500, D_Loss:0.9449281692504883, G_Loss:2.0357227325439453

iterator 3600, D_Loss:0.9781590700149536, G_Loss:1.809962511062622

iterator 3700, D_Loss:0.9495640993118286, G_Loss:1.9237357378005981

iterator 3800, D_Loss:0.950620174407959, G_Loss:1.9271085262298584

iterator 3900, D_Loss:0.9444472789764404, G_Loss:1.89925217628479

iterator 4000, D_Loss:0.9764032363891602, G_Loss:1.8610069751739502

iterator 4100, D_Loss:0.9557465314865112, G_Loss:1.9828251600265503

iterator 4200, D_Loss:0.978739321231842, G_Loss:1.7495852708816528

iterator 4300, D_Loss:0.934180736541748, G_Loss:1.98589026927948

iterator 4400, D_Loss:0.931847333908081, G_Loss:1.8310651779174805

iterator 4500, D_Loss:1.0013378858566284, G_Loss:1.9361037015914917

iterator 4600, D_Loss:0.9686523079872131, G_Loss:1.8399021625518799

iterator 4700, D_Loss:0.9878475666046143, G_Loss:1.8665450811386108

iterator 4800, D_Loss:1.0049108266830444, G_Loss:1.8672518730163574

iterator 4900, D_Loss:0.9723799228668213, G_Loss:1.9067643880844116

iterator 5000, D_Loss:1.0367039442062378, G_Loss:1.795017957687378

-----------Epoch 9-----------
iterator 100, D_Loss:0.9576274156570435, G_Loss:1.8360438346862793

iterator 200, D_Loss:0.9450584650039673, G_Loss:1.8978971242904663

iterator 300, D_Loss:0.9544389247894287, G_Loss:1.7745027542114258

iterator 400, D_Loss:1.0146024227142334, G_Loss:1.7564001083374023

iterator 500, D_Loss:0.9440029859542847, G_Loss:1.930532693862915

iterator 600, D_Loss:0.9901711940765381, G_Loss:1.93095862865448

iterator 700, D_Loss:0.9428346753120422, G_Loss:1.965696096420288

iterator 800, D_Loss:0.9824856519699097, G_Loss:1.8698753118515015

iterator 900, D_Loss:0.9491115808486938, G_Loss:1.8508164882659912

iterator 1000, D_Loss:1.0163192749023438, G_Loss:1.7714177370071411

iterator 1100, D_Loss:0.9262696504592896, G_Loss:1.7924742698669434

iterator 1200, D_Loss:1.01416015625, G_Loss:1.8617453575134277

iterator 1300, D_Loss:0.9621603488922119, G_Loss:1.8097865581512451

iterator 1400, D_Loss:0.982737123966217, G_Loss:1.9903652667999268

iterator 1500, D_Loss:1.0274500846862793, G_Loss:1.973870038986206

iterator 1600, D_Loss:1.000748872756958, G_Loss:1.7678855657577515

iterator 1700, D_Loss:0.9699751138687134, G_Loss:1.8753247261047363

iterator 1800, D_Loss:0.9786944389343262, G_Loss:2.0546069145202637

iterator 1900, D_Loss:0.9313600063323975, G_Loss:2.0535643100738525

iterator 2000, D_Loss:0.9402402639389038, G_Loss:1.9219789505004883

iterator 2100, D_Loss:0.958980917930603, G_Loss:1.9105302095413208

iterator 2200, D_Loss:0.9386881589889526, G_Loss:1.8036422729492188

iterator 2300, D_Loss:0.9906970262527466, G_Loss:1.8462480306625366

iterator 2400, D_Loss:1.0182616710662842, G_Loss:1.8969558477401733

iterator 2500, D_Loss:0.9669527411460876, G_Loss:1.8776832818984985

iterator 2600, D_Loss:1.0503175258636475, G_Loss:1.916796326637268

iterator 2700, D_Loss:1.0053296089172363, G_Loss:1.8663132190704346

iterator 2800, D_Loss:0.9349161386489868, G_Loss:1.9049513339996338

iterator 2900, D_Loss:0.9309099912643433, G_Loss:2.032599449157715

iterator 3000, D_Loss:0.9137532711029053, G_Loss:2.0895495414733887

iterator 3100, D_Loss:0.9552290439605713, G_Loss:1.9630205631256104

iterator 3200, D_Loss:0.9377878904342651, G_Loss:1.9952902793884277

iterator 3300, D_Loss:0.9250843524932861, G_Loss:1.9499483108520508

iterator 3400, D_Loss:0.8983461856842041, G_Loss:2.171971321105957

iterator 3500, D_Loss:1.0055885314941406, G_Loss:2.0887410640716553

iterator 3600, D_Loss:0.9727139472961426, G_Loss:2.2482521533966064

iterator 3700, D_Loss:0.9242902994155884, G_Loss:2.285473346710205

iterator 3800, D_Loss:0.9417520761489868, G_Loss:2.020890235900879

iterator 3900, D_Loss:0.9280261993408203, G_Loss:2.2019758224487305

iterator 4000, D_Loss:0.9133853912353516, G_Loss:2.105051040649414

iterator 4100, D_Loss:0.9346742033958435, G_Loss:2.1368987560272217

iterator 4200, D_Loss:0.9708370566368103, G_Loss:2.129181385040283

iterator 4300, D_Loss:0.9467472434043884, G_Loss:2.0479438304901123

iterator 4400, D_Loss:0.9467111825942993, G_Loss:2.0155506134033203

iterator 4500, D_Loss:0.9009989500045776, G_Loss:2.000934362411499

iterator 4600, D_Loss:0.9331233501434326, G_Loss:2.1833853721618652

iterator 4700, D_Loss:0.9173399806022644, G_Loss:1.9494705200195312

iterator 4800, D_Loss:0.9270365238189697, G_Loss:2.063748598098755

iterator 4900, D_Loss:0.9466339349746704, G_Loss:2.0817670822143555

iterator 5000, D_Loss:0.9108625650405884, G_Loss:2.189605712890625

train row : 30148
sample row: 30148
VGAN_generator(
  (input): Linear(in_features=128, out_features=100, bias=True)
  (inputbn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=100, out_features=100, bias=True)
  (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=100, out_features=135, bias=True)
  (outputbn): BatchNorm1d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=135, out_features=300, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=300, out_features=300, bias=True)
  (output): Linear(in_features=300, out_features=1, bias=True)
)
(0, False, 135)
-----------Epoch 0-----------
iterator 100, D_Loss:0.5583934783935547, G_Loss:8.962247848510742

iterator 200, D_Loss:0.4740171432495117, G_Loss:8.941946029663086

iterator 300, D_Loss:0.4891031086444855, G_Loss:8.5477294921875

iterator 400, D_Loss:0.43950361013412476, G_Loss:8.234001159667969

iterator 500, D_Loss:0.47992801666259766, G_Loss:8.340229988098145

iterator 600, D_Loss:0.4765283465385437, G_Loss:7.6859283447265625

iterator 700, D_Loss:0.4500844180583954, G_Loss:7.234570503234863

iterator 800, D_Loss:0.48200491070747375, G_Loss:7.28554630279541

iterator 900, D_Loss:0.5027018189430237, G_Loss:6.93577241897583

iterator 1000, D_Loss:0.5420233607292175, G_Loss:7.460083961486816

iterator 1100, D_Loss:0.5537973046302795, G_Loss:5.970888614654541

iterator 1200, D_Loss:0.6220948100090027, G_Loss:6.876288890838623

iterator 1300, D_Loss:0.5470251441001892, G_Loss:6.168185234069824

iterator 1400, D_Loss:0.5363507270812988, G_Loss:6.053603649139404

iterator 1500, D_Loss:0.6748895645141602, G_Loss:5.863443851470947

iterator 1600, D_Loss:0.567816436290741, G_Loss:5.6315388679504395

iterator 1700, D_Loss:0.6445941925048828, G_Loss:5.773187637329102

iterator 1800, D_Loss:0.6904820203781128, G_Loss:4.692760467529297

iterator 1900, D_Loss:0.6568530201911926, G_Loss:5.180299282073975

iterator 2000, D_Loss:0.5903246402740479, G_Loss:4.759851932525635

iterator 2100, D_Loss:0.6143823862075806, G_Loss:5.208025932312012

iterator 2200, D_Loss:0.6209363341331482, G_Loss:4.8823723793029785

iterator 2300, D_Loss:0.6362785696983337, G_Loss:4.968860626220703

iterator 2400, D_Loss:0.7102898359298706, G_Loss:4.880434036254883

iterator 2500, D_Loss:0.7145791053771973, G_Loss:4.656588077545166

iterator 2600, D_Loss:0.6686040163040161, G_Loss:4.351504325866699

iterator 2700, D_Loss:0.770103394985199, G_Loss:3.9735755920410156

iterator 2800, D_Loss:0.6346692442893982, G_Loss:3.8706820011138916

iterator 2900, D_Loss:0.7351293563842773, G_Loss:3.494981050491333

iterator 3000, D_Loss:0.8239312171936035, G_Loss:3.3560800552368164

iterator 3100, D_Loss:0.7066318392753601, G_Loss:3.8584909439086914

iterator 3200, D_Loss:0.6893631219863892, G_Loss:3.819823980331421

iterator 3300, D_Loss:0.7982343435287476, G_Loss:3.3555126190185547

iterator 3400, D_Loss:0.7216613292694092, G_Loss:3.6544113159179688

iterator 3500, D_Loss:0.8494289517402649, G_Loss:3.4657740592956543

iterator 3600, D_Loss:0.7615038156509399, G_Loss:3.2789697647094727

iterator 3700, D_Loss:0.800098180770874, G_Loss:3.238212823867798

iterator 3800, D_Loss:0.796518862247467, G_Loss:3.4717772006988525

iterator 3900, D_Loss:0.8135750889778137, G_Loss:3.047559976577759

iterator 4000, D_Loss:0.8755850791931152, G_Loss:3.095414161682129

iterator 4100, D_Loss:0.8882223963737488, G_Loss:2.99481463432312

iterator 4200, D_Loss:0.8548589944839478, G_Loss:3.049002170562744

iterator 4300, D_Loss:0.7381328344345093, G_Loss:3.0178322792053223

iterator 4400, D_Loss:0.8162099123001099, G_Loss:3.1326117515563965

iterator 4500, D_Loss:0.8160308003425598, G_Loss:3.1269314289093018

iterator 4600, D_Loss:0.8516046404838562, G_Loss:3.265988349914551

iterator 4700, D_Loss:0.8456858396530151, G_Loss:2.8885786533355713

iterator 4800, D_Loss:0.9372953176498413, G_Loss:2.5548081398010254

iterator 4900, D_Loss:0.8663151264190674, G_Loss:3.433962821960449

iterator 5000, D_Loss:0.8837429285049438, G_Loss:2.869499683380127

-----------Epoch 1-----------
iterator 100, D_Loss:0.8721208572387695, G_Loss:2.656393051147461

iterator 200, D_Loss:0.8992531299591064, G_Loss:2.8189594745635986

iterator 300, D_Loss:0.8059604167938232, G_Loss:2.6077911853790283

iterator 400, D_Loss:0.870600700378418, G_Loss:2.802785873413086

iterator 500, D_Loss:0.8697401285171509, G_Loss:2.3421261310577393

iterator 600, D_Loss:0.9232296347618103, G_Loss:2.5712625980377197

iterator 700, D_Loss:0.9224618673324585, G_Loss:2.4840006828308105

iterator 800, D_Loss:0.9881517887115479, G_Loss:2.345444679260254

iterator 900, D_Loss:0.9093694090843201, G_Loss:2.4686927795410156

iterator 1000, D_Loss:0.9111183881759644, G_Loss:2.6733736991882324

iterator 1100, D_Loss:0.9013477563858032, G_Loss:2.4373226165771484

iterator 1200, D_Loss:0.8401594758033752, G_Loss:2.3762552738189697

iterator 1300, D_Loss:0.9404488801956177, G_Loss:2.4411330223083496

iterator 1400, D_Loss:0.9412107467651367, G_Loss:2.314544677734375

iterator 1500, D_Loss:0.9523253440856934, G_Loss:2.6972482204437256

iterator 1600, D_Loss:0.9921995997428894, G_Loss:2.5639638900756836

iterator 1700, D_Loss:0.8985781669616699, G_Loss:2.310591697692871

iterator 1800, D_Loss:0.9472250938415527, G_Loss:2.5926995277404785

iterator 1900, D_Loss:0.9342612028121948, G_Loss:2.462547779083252

iterator 2000, D_Loss:0.910415530204773, G_Loss:2.264096736907959

iterator 2100, D_Loss:0.988131582736969, G_Loss:2.424041748046875

iterator 2200, D_Loss:0.9665639400482178, G_Loss:2.5689101219177246

iterator 2300, D_Loss:0.9013444781303406, G_Loss:2.1843678951263428

iterator 2400, D_Loss:1.0062899589538574, G_Loss:2.3160457611083984

iterator 2500, D_Loss:0.9348193407058716, G_Loss:2.6089906692504883

iterator 2600, D_Loss:0.8756870031356812, G_Loss:2.370590925216675

iterator 2700, D_Loss:0.8599389791488647, G_Loss:2.437734603881836

iterator 2800, D_Loss:1.0140587091445923, G_Loss:2.2817952632904053

iterator 2900, D_Loss:0.9331153035163879, G_Loss:2.1173229217529297

iterator 3000, D_Loss:0.9343265295028687, G_Loss:2.3309326171875

iterator 3100, D_Loss:0.8645286560058594, G_Loss:2.3689515590667725

iterator 3200, D_Loss:1.0115525722503662, G_Loss:2.2676761150360107

iterator 3300, D_Loss:0.9651325941085815, G_Loss:2.177638530731201

iterator 3400, D_Loss:0.7912970781326294, G_Loss:2.5939574241638184

iterator 3500, D_Loss:0.9726322889328003, G_Loss:2.203977584838867

iterator 3600, D_Loss:1.0252737998962402, G_Loss:2.023653745651245

iterator 3700, D_Loss:0.941325306892395, G_Loss:2.063324213027954

iterator 3800, D_Loss:1.0245563983917236, G_Loss:2.5892207622528076

iterator 3900, D_Loss:0.890651524066925, G_Loss:2.491183280944824

iterator 4000, D_Loss:0.8601977825164795, G_Loss:2.2048041820526123

iterator 4100, D_Loss:0.9549703598022461, G_Loss:2.4684691429138184

iterator 4200, D_Loss:0.9704997539520264, G_Loss:2.4426021575927734

iterator 4300, D_Loss:0.9552469849586487, G_Loss:2.0602762699127197

iterator 4400, D_Loss:0.9821234345436096, G_Loss:2.338714361190796

iterator 4500, D_Loss:0.9869752526283264, G_Loss:2.4139561653137207

iterator 4600, D_Loss:0.8674834370613098, G_Loss:2.6271448135375977

iterator 4700, D_Loss:1.0513014793395996, G_Loss:2.0886120796203613

iterator 4800, D_Loss:0.9548475742340088, G_Loss:2.487255811691284

iterator 4900, D_Loss:0.8918975591659546, G_Loss:2.406620979309082

iterator 5000, D_Loss:0.9367822408676147, G_Loss:2.476078987121582

-----------Epoch 2-----------
iterator 100, D_Loss:0.9937095642089844, G_Loss:2.537951707839966

iterator 200, D_Loss:1.0246578454971313, G_Loss:2.5645320415496826

iterator 300, D_Loss:0.9708232879638672, G_Loss:2.357724666595459

iterator 400, D_Loss:0.8910949230194092, G_Loss:2.6807363033294678

iterator 500, D_Loss:1.0213215351104736, G_Loss:2.383568525314331

iterator 600, D_Loss:0.9147998690605164, G_Loss:2.1310839653015137

iterator 700, D_Loss:0.8362361192703247, G_Loss:2.521174192428589

iterator 800, D_Loss:0.8853219151496887, G_Loss:2.4914937019348145

iterator 900, D_Loss:1.0376499891281128, G_Loss:2.2385098934173584

iterator 1000, D_Loss:0.9249469041824341, G_Loss:2.3866984844207764

iterator 1100, D_Loss:0.8487452268600464, G_Loss:2.4935944080352783

iterator 1200, D_Loss:0.8129966855049133, G_Loss:2.670466423034668

iterator 1300, D_Loss:0.9655741453170776, G_Loss:2.57564377784729

iterator 1400, D_Loss:0.8773336410522461, G_Loss:2.3152456283569336

iterator 1500, D_Loss:0.9148690700531006, G_Loss:2.732398748397827

iterator 1600, D_Loss:0.9112600088119507, G_Loss:2.67429518699646

iterator 1700, D_Loss:0.8582803606987, G_Loss:2.156002998352051

iterator 1800, D_Loss:0.910728931427002, G_Loss:2.2473878860473633

iterator 1900, D_Loss:0.8796430826187134, G_Loss:2.426433563232422

iterator 2000, D_Loss:0.9047415256500244, G_Loss:2.909860372543335

iterator 2100, D_Loss:1.0360413789749146, G_Loss:2.4988832473754883

iterator 2200, D_Loss:0.9240879416465759, G_Loss:2.652411699295044

iterator 2300, D_Loss:0.8462119102478027, G_Loss:2.6613035202026367

iterator 2400, D_Loss:0.9631611108779907, G_Loss:2.6370675563812256

iterator 2500, D_Loss:0.9777076840400696, G_Loss:2.4044580459594727

iterator 2600, D_Loss:0.9651405811309814, G_Loss:2.2502951622009277

iterator 2700, D_Loss:0.8999669551849365, G_Loss:2.727847099304199

iterator 2800, D_Loss:0.9044886827468872, G_Loss:2.6041765213012695

iterator 2900, D_Loss:0.9378993511199951, G_Loss:2.0933215618133545

iterator 3000, D_Loss:0.8594937920570374, G_Loss:2.7677385807037354

iterator 3100, D_Loss:0.9502710103988647, G_Loss:2.5801329612731934

iterator 3200, D_Loss:0.8833287954330444, G_Loss:2.5848586559295654

iterator 3300, D_Loss:0.8874588012695312, G_Loss:2.614459991455078

iterator 3400, D_Loss:0.9027208089828491, G_Loss:2.6801300048828125

iterator 3500, D_Loss:0.9359257817268372, G_Loss:2.509645700454712

iterator 3600, D_Loss:0.8158006072044373, G_Loss:2.900512456893921

iterator 3700, D_Loss:0.9023975729942322, G_Loss:2.52978515625

iterator 3800, D_Loss:0.9646554589271545, G_Loss:3.0077965259552

iterator 3900, D_Loss:0.9697351455688477, G_Loss:2.902310848236084

iterator 4000, D_Loss:0.780596137046814, G_Loss:2.7972044944763184

iterator 4100, D_Loss:0.9235773086547852, G_Loss:2.500668525695801

iterator 4200, D_Loss:0.8984909057617188, G_Loss:2.7398765087127686

iterator 4300, D_Loss:0.9574397802352905, G_Loss:2.5937981605529785

iterator 4400, D_Loss:1.022063136100769, G_Loss:2.3423731327056885

iterator 4500, D_Loss:0.9268102645874023, G_Loss:2.566089153289795

iterator 4600, D_Loss:0.8418863415718079, G_Loss:2.6434884071350098

iterator 4700, D_Loss:0.9315382838249207, G_Loss:2.887822389602661

iterator 4800, D_Loss:0.8319198489189148, G_Loss:2.6675469875335693

iterator 4900, D_Loss:0.7901676893234253, G_Loss:3.0668489933013916

iterator 5000, D_Loss:0.9387650489807129, G_Loss:2.5487680435180664

-----------Epoch 3-----------
iterator 100, D_Loss:0.805929958820343, G_Loss:2.6171529293060303

iterator 200, D_Loss:0.8490220308303833, G_Loss:2.8357656002044678

iterator 300, D_Loss:0.9308755993843079, G_Loss:2.6734838485717773

iterator 400, D_Loss:0.9609466195106506, G_Loss:2.4220948219299316

iterator 500, D_Loss:0.8732004165649414, G_Loss:2.874199390411377

iterator 600, D_Loss:0.8963936567306519, G_Loss:2.525322198867798

iterator 700, D_Loss:0.8358834981918335, G_Loss:2.7644357681274414

iterator 800, D_Loss:0.9679352045059204, G_Loss:2.8147010803222656

iterator 900, D_Loss:0.936934232711792, G_Loss:3.0483202934265137

iterator 1000, D_Loss:0.8413996696472168, G_Loss:2.77494215965271

iterator 1100, D_Loss:0.9161018133163452, G_Loss:2.6475489139556885

iterator 1200, D_Loss:0.8274834752082825, G_Loss:3.123250961303711

iterator 1300, D_Loss:0.8502429127693176, G_Loss:2.728350877761841

iterator 1400, D_Loss:0.8882829546928406, G_Loss:2.8864941596984863

iterator 1500, D_Loss:0.9163159728050232, G_Loss:2.721235513687134

iterator 1600, D_Loss:0.8702288866043091, G_Loss:2.71110200881958

iterator 1700, D_Loss:0.9184473752975464, G_Loss:2.714338541030884

iterator 1800, D_Loss:0.8395466208457947, G_Loss:2.713588237762451

iterator 1900, D_Loss:0.8184855580329895, G_Loss:3.191240072250366

iterator 2000, D_Loss:0.8459556102752686, G_Loss:2.859886407852173

iterator 2100, D_Loss:0.8303929567337036, G_Loss:2.8671483993530273

iterator 2200, D_Loss:0.8531776070594788, G_Loss:2.712327718734741

iterator 2300, D_Loss:0.8604645133018494, G_Loss:2.5840249061584473

iterator 2400, D_Loss:0.9318711757659912, G_Loss:3.070483446121216

iterator 2500, D_Loss:0.9709737300872803, G_Loss:2.5546350479125977

iterator 2600, D_Loss:0.8612569570541382, G_Loss:3.3165876865386963

iterator 2700, D_Loss:0.8288092017173767, G_Loss:2.71513032913208

iterator 2800, D_Loss:0.8712841868400574, G_Loss:2.866652250289917

iterator 2900, D_Loss:0.8076164722442627, G_Loss:3.001948833465576

iterator 3000, D_Loss:0.8817349076271057, G_Loss:2.79256010055542

iterator 3100, D_Loss:0.8500674962997437, G_Loss:2.857750177383423

iterator 3200, D_Loss:0.8487130403518677, G_Loss:2.7481765747070312

iterator 3300, D_Loss:0.8084127306938171, G_Loss:3.127894878387451

iterator 3400, D_Loss:0.8857132196426392, G_Loss:3.002941370010376

iterator 3500, D_Loss:0.8872674703598022, G_Loss:2.7102673053741455

iterator 3600, D_Loss:0.8185599446296692, G_Loss:2.927748918533325

iterator 3700, D_Loss:0.9069939851760864, G_Loss:3.078920841217041

iterator 3800, D_Loss:0.7343126535415649, G_Loss:2.863840103149414

iterator 3900, D_Loss:0.8133723735809326, G_Loss:2.9739952087402344

iterator 4000, D_Loss:0.8888959884643555, G_Loss:2.8896872997283936

iterator 4100, D_Loss:0.891438901424408, G_Loss:3.342034101486206

iterator 4200, D_Loss:0.8535685539245605, G_Loss:2.8181357383728027

iterator 4300, D_Loss:0.8705243468284607, G_Loss:3.134584903717041

iterator 4400, D_Loss:0.7533623576164246, G_Loss:3.021977424621582

iterator 4500, D_Loss:0.8444295525550842, G_Loss:3.114553213119507

iterator 4600, D_Loss:0.7502316236495972, G_Loss:3.1532413959503174

iterator 4700, D_Loss:0.8068146109580994, G_Loss:2.793401002883911

iterator 4800, D_Loss:0.8706167936325073, G_Loss:2.957475185394287

iterator 4900, D_Loss:0.8437464237213135, G_Loss:3.3382205963134766

iterator 5000, D_Loss:0.8974887132644653, G_Loss:2.968991756439209

-----------Epoch 4-----------
iterator 100, D_Loss:0.8598098754882812, G_Loss:3.100510597229004

iterator 200, D_Loss:0.8833946585655212, G_Loss:3.0192172527313232

iterator 300, D_Loss:0.7603926658630371, G_Loss:3.0503127574920654

iterator 400, D_Loss:0.8014347553253174, G_Loss:3.2814834117889404

iterator 500, D_Loss:0.8729089498519897, G_Loss:3.0063884258270264

iterator 600, D_Loss:0.9190618395805359, G_Loss:3.226935386657715

iterator 700, D_Loss:0.7551966905593872, G_Loss:3.4675965309143066

iterator 800, D_Loss:0.8554015159606934, G_Loss:3.0562543869018555

iterator 900, D_Loss:0.8043969869613647, G_Loss:3.1546292304992676

iterator 1000, D_Loss:0.8017677068710327, G_Loss:3.029362678527832

iterator 1100, D_Loss:0.8460061550140381, G_Loss:3.047731637954712

iterator 1200, D_Loss:0.7825580835342407, G_Loss:2.7833404541015625

iterator 1300, D_Loss:0.8170613050460815, G_Loss:3.058628559112549

iterator 1400, D_Loss:0.855440616607666, G_Loss:3.30546236038208

iterator 1500, D_Loss:0.8916226029396057, G_Loss:3.1321210861206055

iterator 1600, D_Loss:0.7632931470870972, G_Loss:3.3067474365234375

iterator 1700, D_Loss:0.8788260817527771, G_Loss:3.131277084350586

iterator 1800, D_Loss:0.8301330804824829, G_Loss:2.8712451457977295

iterator 1900, D_Loss:0.8278500437736511, G_Loss:2.997695207595825

iterator 2000, D_Loss:0.7925622463226318, G_Loss:3.1245739459991455

iterator 2100, D_Loss:0.7536073923110962, G_Loss:3.2239561080932617

iterator 2200, D_Loss:0.8062268495559692, G_Loss:3.9470460414886475

iterator 2300, D_Loss:0.7368309497833252, G_Loss:3.147974967956543

iterator 2400, D_Loss:0.8789888620376587, G_Loss:3.797574996948242

iterator 2500, D_Loss:0.8629564046859741, G_Loss:3.059628963470459

iterator 2600, D_Loss:0.825193464756012, G_Loss:3.287614107131958

iterator 2700, D_Loss:0.8120214343070984, G_Loss:3.1947474479675293

iterator 2800, D_Loss:0.7924257516860962, G_Loss:2.9561986923217773

iterator 2900, D_Loss:0.7958170175552368, G_Loss:2.9973130226135254

iterator 3000, D_Loss:0.8019077777862549, G_Loss:3.2377848625183105

iterator 3100, D_Loss:0.7854455709457397, G_Loss:3.6531143188476562

iterator 3200, D_Loss:0.8576204776763916, G_Loss:3.376762628555298

iterator 3300, D_Loss:0.8792457580566406, G_Loss:3.4434521198272705

iterator 3400, D_Loss:0.8353182673454285, G_Loss:2.9173736572265625

iterator 3500, D_Loss:0.863847017288208, G_Loss:2.9498186111450195

iterator 3600, D_Loss:0.7794498205184937, G_Loss:2.9579501152038574

iterator 3700, D_Loss:0.8616831302642822, G_Loss:2.750255584716797

iterator 3800, D_Loss:0.8388345241546631, G_Loss:3.7075352668762207

iterator 3900, D_Loss:0.8185448050498962, G_Loss:3.0865182876586914

iterator 4000, D_Loss:0.8061049580574036, G_Loss:2.8852031230926514

iterator 4100, D_Loss:0.772695779800415, G_Loss:3.259312629699707

iterator 4200, D_Loss:0.8007209300994873, G_Loss:2.932849407196045

iterator 4300, D_Loss:0.7889456748962402, G_Loss:3.181600570678711

iterator 4400, D_Loss:0.8166361451148987, G_Loss:3.1324310302734375

iterator 4500, D_Loss:0.8527771830558777, G_Loss:3.425114393234253

iterator 4600, D_Loss:0.8570330739021301, G_Loss:3.1401078701019287

iterator 4700, D_Loss:0.834577202796936, G_Loss:2.725668430328369

iterator 4800, D_Loss:0.8210446834564209, G_Loss:2.929793357849121

iterator 4900, D_Loss:0.8247438073158264, G_Loss:3.045654773712158

iterator 5000, D_Loss:0.7895087599754333, G_Loss:3.1701529026031494

-----------Epoch 5-----------
iterator 100, D_Loss:0.8410773873329163, G_Loss:2.7762317657470703

iterator 200, D_Loss:0.8583817481994629, G_Loss:3.0354669094085693

iterator 300, D_Loss:0.7887132167816162, G_Loss:3.524742841720581

iterator 400, D_Loss:0.8063154220581055, G_Loss:3.337156295776367

iterator 500, D_Loss:0.8339076638221741, G_Loss:3.235081911087036

iterator 600, D_Loss:0.922653317451477, G_Loss:3.6211228370666504

iterator 700, D_Loss:0.8422502279281616, G_Loss:3.2731664180755615

iterator 800, D_Loss:0.8749668002128601, G_Loss:3.499918222427368

iterator 900, D_Loss:0.8841459155082703, G_Loss:3.306915283203125

iterator 1000, D_Loss:0.8661062717437744, G_Loss:2.9172751903533936

iterator 1100, D_Loss:0.8372114896774292, G_Loss:2.9656014442443848

iterator 1200, D_Loss:0.7567725777626038, G_Loss:3.0383176803588867

iterator 1300, D_Loss:0.8442268371582031, G_Loss:3.465808391571045

iterator 1400, D_Loss:0.7959392666816711, G_Loss:3.176940679550171

iterator 1500, D_Loss:0.7772449851036072, G_Loss:3.273836135864258

iterator 1600, D_Loss:0.8580559492111206, G_Loss:2.8743972778320312

iterator 1700, D_Loss:0.8102831840515137, G_Loss:3.147782802581787

iterator 1800, D_Loss:0.8008475303649902, G_Loss:3.2863407135009766

iterator 1900, D_Loss:0.8544571995735168, G_Loss:3.077596664428711

iterator 2000, D_Loss:0.8537275195121765, G_Loss:3.1143064498901367

iterator 2100, D_Loss:0.7585835456848145, G_Loss:3.457520008087158

iterator 2200, D_Loss:0.8594664335250854, G_Loss:2.9136359691619873

iterator 2300, D_Loss:0.8106712698936462, G_Loss:3.287029266357422

iterator 2400, D_Loss:0.8895156383514404, G_Loss:2.922898769378662

iterator 2500, D_Loss:0.7683057188987732, G_Loss:3.471073627471924

iterator 2600, D_Loss:0.7709880471229553, G_Loss:3.123523473739624

iterator 2700, D_Loss:0.836363673210144, G_Loss:3.5100502967834473

iterator 2800, D_Loss:0.749855101108551, G_Loss:3.3262529373168945

iterator 2900, D_Loss:0.8703385591506958, G_Loss:3.4270541667938232

iterator 3000, D_Loss:0.7503260970115662, G_Loss:3.3062143325805664

iterator 3100, D_Loss:0.8284206390380859, G_Loss:3.41316556930542

iterator 3200, D_Loss:0.7833017706871033, G_Loss:2.8863799571990967

iterator 3300, D_Loss:0.9119806289672852, G_Loss:3.517099380493164

iterator 3400, D_Loss:0.8524507284164429, G_Loss:3.556096076965332

iterator 3500, D_Loss:0.739271342754364, G_Loss:2.8018746376037598

iterator 3600, D_Loss:0.7625023722648621, G_Loss:3.063706874847412

iterator 3700, D_Loss:0.897169291973114, G_Loss:3.1495370864868164

iterator 3800, D_Loss:0.7244510650634766, G_Loss:3.2889251708984375

iterator 3900, D_Loss:0.7453489303588867, G_Loss:3.3206284046173096

iterator 4000, D_Loss:0.8178731799125671, G_Loss:3.35562801361084

iterator 4100, D_Loss:0.8259103298187256, G_Loss:3.072033405303955

iterator 4200, D_Loss:0.8115460276603699, G_Loss:3.4911386966705322

iterator 4300, D_Loss:0.7681168913841248, G_Loss:2.9661734104156494

iterator 4400, D_Loss:0.8702361583709717, G_Loss:3.2516143321990967

iterator 4500, D_Loss:0.8429499268531799, G_Loss:3.5568270683288574

iterator 4600, D_Loss:0.7798194289207458, G_Loss:3.1992881298065186

iterator 4700, D_Loss:0.7820030450820923, G_Loss:3.125282049179077

iterator 4800, D_Loss:0.7968132495880127, G_Loss:3.2540526390075684

iterator 4900, D_Loss:0.8512375354766846, G_Loss:3.260129690170288

iterator 5000, D_Loss:0.8132081031799316, G_Loss:3.2159225940704346

-----------Epoch 6-----------
iterator 100, D_Loss:0.8434189558029175, G_Loss:3.2581725120544434

iterator 200, D_Loss:0.8016703128814697, G_Loss:3.2213399410247803

iterator 300, D_Loss:0.8804308176040649, G_Loss:3.1846110820770264

iterator 400, D_Loss:0.8616157174110413, G_Loss:3.345121145248413

iterator 500, D_Loss:0.8028786182403564, G_Loss:3.3327345848083496

iterator 600, D_Loss:0.8090679049491882, G_Loss:3.10369873046875

iterator 700, D_Loss:0.7833163142204285, G_Loss:3.362499237060547

iterator 800, D_Loss:0.8878616690635681, G_Loss:3.351046085357666

iterator 900, D_Loss:0.7478897571563721, G_Loss:3.0784332752227783

iterator 1000, D_Loss:0.7804754972457886, G_Loss:3.4852399826049805

iterator 1100, D_Loss:0.7510191202163696, G_Loss:2.8347725868225098

iterator 1200, D_Loss:0.8023223280906677, G_Loss:3.8366541862487793

iterator 1300, D_Loss:0.8191406726837158, G_Loss:3.3854684829711914

iterator 1400, D_Loss:0.779701828956604, G_Loss:3.6489503383636475

iterator 1500, D_Loss:0.8602861762046814, G_Loss:3.2374086380004883

iterator 1600, D_Loss:0.7949015498161316, G_Loss:3.7398242950439453

iterator 1700, D_Loss:0.8414846658706665, G_Loss:2.994441270828247

iterator 1800, D_Loss:0.7566590905189514, G_Loss:3.5839462280273438

iterator 1900, D_Loss:0.853581428527832, G_Loss:3.185896873474121

iterator 2000, D_Loss:0.817990779876709, G_Loss:3.700296401977539

iterator 2100, D_Loss:0.8093958497047424, G_Loss:3.039069652557373

iterator 2200, D_Loss:0.7491279244422913, G_Loss:2.9598138332366943

iterator 2300, D_Loss:0.7942426204681396, G_Loss:3.241027593612671

iterator 2400, D_Loss:0.8607388734817505, G_Loss:3.6390891075134277

iterator 2500, D_Loss:0.8281934261322021, G_Loss:3.656749725341797

iterator 2600, D_Loss:0.8231213092803955, G_Loss:3.0178821086883545

iterator 2700, D_Loss:0.7413128614425659, G_Loss:3.035496234893799

iterator 2800, D_Loss:0.744005560874939, G_Loss:3.0643677711486816

iterator 2900, D_Loss:0.805967390537262, G_Loss:3.4022467136383057

iterator 3000, D_Loss:0.7912840843200684, G_Loss:3.368459463119507

iterator 3100, D_Loss:0.8795145750045776, G_Loss:2.9210684299468994

iterator 3200, D_Loss:0.8374927043914795, G_Loss:3.244520664215088

iterator 3300, D_Loss:0.7512403726577759, G_Loss:3.3570568561553955

iterator 3400, D_Loss:0.7319096326828003, G_Loss:3.232832431793213

iterator 3500, D_Loss:0.8157825469970703, G_Loss:3.3810412883758545

iterator 3600, D_Loss:0.7422429919242859, G_Loss:3.863558292388916

iterator 3700, D_Loss:0.8111778497695923, G_Loss:3.297710418701172

iterator 3800, D_Loss:0.7957231402397156, G_Loss:3.5404112339019775

iterator 3900, D_Loss:0.7667291164398193, G_Loss:3.165461301803589

iterator 4000, D_Loss:0.8208545446395874, G_Loss:3.0809853076934814

iterator 4100, D_Loss:0.825236439704895, G_Loss:3.0951249599456787

iterator 4200, D_Loss:0.8345090746879578, G_Loss:3.6794557571411133

iterator 4300, D_Loss:0.7997663021087646, G_Loss:2.917720317840576

iterator 4400, D_Loss:0.7749042510986328, G_Loss:3.242152452468872

iterator 4500, D_Loss:0.8314507007598877, G_Loss:3.389010190963745

iterator 4600, D_Loss:0.7651452422142029, G_Loss:3.391787052154541

iterator 4700, D_Loss:0.9046998023986816, G_Loss:2.7840356826782227

iterator 4800, D_Loss:0.7488775253295898, G_Loss:3.4762959480285645

iterator 4900, D_Loss:0.8268791437149048, G_Loss:3.439662456512451

iterator 5000, D_Loss:0.73209148645401, G_Loss:3.5114903450012207

-----------Epoch 7-----------
iterator 100, D_Loss:0.8525682091712952, G_Loss:3.2290146350860596

iterator 200, D_Loss:0.825629711151123, G_Loss:3.907379627227783

iterator 300, D_Loss:0.8170056343078613, G_Loss:3.2498652935028076

iterator 400, D_Loss:0.8184629082679749, G_Loss:3.3388142585754395

iterator 500, D_Loss:0.8726000785827637, G_Loss:3.5651254653930664

iterator 600, D_Loss:0.7535399198532104, G_Loss:3.290895462036133

iterator 700, D_Loss:0.7582507133483887, G_Loss:3.162482500076294

iterator 800, D_Loss:0.8285722732543945, G_Loss:3.40268874168396

iterator 900, D_Loss:0.7879387140274048, G_Loss:2.780545473098755

iterator 1000, D_Loss:0.822064995765686, G_Loss:3.570347309112549

iterator 1100, D_Loss:0.7642993927001953, G_Loss:2.989447832107544

iterator 1200, D_Loss:0.8221012353897095, G_Loss:3.4164187908172607

iterator 1300, D_Loss:0.8179190158843994, G_Loss:3.1699140071868896

iterator 1400, D_Loss:0.824434757232666, G_Loss:3.5515635013580322

iterator 1500, D_Loss:0.9042879939079285, G_Loss:3.588818073272705

iterator 1600, D_Loss:0.8099439740180969, G_Loss:2.860832452774048

iterator 1700, D_Loss:0.8218176960945129, G_Loss:3.137657403945923

iterator 1800, D_Loss:0.8687634468078613, G_Loss:3.668339252471924

iterator 1900, D_Loss:0.8467944860458374, G_Loss:3.417548656463623

iterator 2000, D_Loss:0.8317933082580566, G_Loss:3.319272518157959

iterator 2100, D_Loss:0.8107534646987915, G_Loss:3.3722894191741943

iterator 2200, D_Loss:0.7222723960876465, G_Loss:2.844454050064087

iterator 2300, D_Loss:0.7558164596557617, G_Loss:3.371149778366089

iterator 2400, D_Loss:0.8762630224227905, G_Loss:3.2439305782318115

iterator 2500, D_Loss:0.7743984460830688, G_Loss:2.9936089515686035

iterator 2600, D_Loss:0.8159534931182861, G_Loss:3.3983514308929443

iterator 2700, D_Loss:0.8089861273765564, G_Loss:3.282766580581665

iterator 2800, D_Loss:0.8742625117301941, G_Loss:3.4279823303222656

iterator 2900, D_Loss:0.8909796476364136, G_Loss:2.9274775981903076

iterator 3000, D_Loss:0.8339368104934692, G_Loss:3.158163070678711

iterator 3100, D_Loss:0.7822536826133728, G_Loss:3.0540544986724854

iterator 3200, D_Loss:0.8535169959068298, G_Loss:3.1392486095428467

iterator 3300, D_Loss:0.7867453098297119, G_Loss:3.1222586631774902

iterator 3400, D_Loss:0.7627519369125366, G_Loss:3.340912342071533

iterator 3500, D_Loss:0.9016966223716736, G_Loss:3.5780673027038574

iterator 3600, D_Loss:0.8073012828826904, G_Loss:3.384228229522705

iterator 3700, D_Loss:0.8290665745735168, G_Loss:3.1911885738372803

iterator 3800, D_Loss:0.8007209897041321, G_Loss:2.9620537757873535

iterator 3900, D_Loss:0.7575922012329102, G_Loss:3.9229865074157715

iterator 4000, D_Loss:0.8169589042663574, G_Loss:3.1633520126342773

iterator 4100, D_Loss:0.8974339365959167, G_Loss:2.9328830242156982

iterator 4200, D_Loss:0.8091713190078735, G_Loss:3.3507823944091797

iterator 4300, D_Loss:0.8070473670959473, G_Loss:3.3206279277801514

iterator 4400, D_Loss:0.7999711036682129, G_Loss:3.3342623710632324

iterator 4500, D_Loss:0.9405806064605713, G_Loss:2.9777133464813232

iterator 4600, D_Loss:0.8758137226104736, G_Loss:3.168433904647827

iterator 4700, D_Loss:0.7794666290283203, G_Loss:2.78144907951355

iterator 4800, D_Loss:0.8166977167129517, G_Loss:3.001875162124634

iterator 4900, D_Loss:0.7978014945983887, G_Loss:3.547560691833496

iterator 5000, D_Loss:0.7894198894500732, G_Loss:3.404383420944214

-----------Epoch 8-----------
iterator 100, D_Loss:0.9067972302436829, G_Loss:3.285287380218506

iterator 200, D_Loss:0.7680317759513855, G_Loss:3.2881572246551514

iterator 300, D_Loss:0.932358980178833, G_Loss:3.226717948913574

iterator 400, D_Loss:0.8021042346954346, G_Loss:3.5050315856933594

iterator 500, D_Loss:0.8757692575454712, G_Loss:3.3469033241271973

iterator 600, D_Loss:0.8737757205963135, G_Loss:3.5984604358673096

iterator 700, D_Loss:0.9076023101806641, G_Loss:3.5877628326416016

iterator 800, D_Loss:0.8157060742378235, G_Loss:3.0441558361053467

iterator 900, D_Loss:0.8490012288093567, G_Loss:3.425600051879883

iterator 1000, D_Loss:0.8561336994171143, G_Loss:3.003614902496338

iterator 1100, D_Loss:0.7349534034729004, G_Loss:3.2528774738311768

iterator 1200, D_Loss:0.8010995984077454, G_Loss:2.9121313095092773

iterator 1300, D_Loss:0.7700973749160767, G_Loss:3.2361583709716797

iterator 1400, D_Loss:0.8310478925704956, G_Loss:3.0763962268829346

iterator 1500, D_Loss:0.8755664229393005, G_Loss:3.3114051818847656

iterator 1600, D_Loss:0.8924908638000488, G_Loss:3.1773905754089355

iterator 1700, D_Loss:0.8908329010009766, G_Loss:3.242286443710327

iterator 1800, D_Loss:0.8212533593177795, G_Loss:3.4949896335601807

iterator 1900, D_Loss:0.8842800259590149, G_Loss:2.854769706726074

iterator 2000, D_Loss:0.9082246422767639, G_Loss:2.944225311279297

iterator 2100, D_Loss:0.8792394399642944, G_Loss:3.0475804805755615

iterator 2200, D_Loss:0.8427048921585083, G_Loss:3.3100924491882324

iterator 2300, D_Loss:0.8513925075531006, G_Loss:3.0029947757720947

iterator 2400, D_Loss:0.8405906558036804, G_Loss:3.6171607971191406

iterator 2500, D_Loss:0.9022536873817444, G_Loss:3.083272695541382

iterator 2600, D_Loss:0.7976698875427246, G_Loss:3.5826876163482666

iterator 2700, D_Loss:0.8668739795684814, G_Loss:2.9159586429595947

iterator 2800, D_Loss:0.8145902156829834, G_Loss:3.0025084018707275

iterator 2900, D_Loss:0.8395709991455078, G_Loss:2.747824192047119

iterator 3000, D_Loss:0.7946413159370422, G_Loss:3.6571011543273926

iterator 3100, D_Loss:0.8048484325408936, G_Loss:3.1267974376678467

iterator 3200, D_Loss:0.9672887325286865, G_Loss:3.2422988414764404

iterator 3300, D_Loss:0.8081798553466797, G_Loss:3.1460537910461426

iterator 3400, D_Loss:0.7996346950531006, G_Loss:3.104642868041992

iterator 3500, D_Loss:0.8423383235931396, G_Loss:3.008784770965576

iterator 3600, D_Loss:0.8144135475158691, G_Loss:3.3184988498687744

iterator 3700, D_Loss:0.9139822125434875, G_Loss:3.0690255165100098

iterator 3800, D_Loss:0.7420380115509033, G_Loss:3.0286858081817627

iterator 3900, D_Loss:0.9213085174560547, G_Loss:3.961276054382324

iterator 4000, D_Loss:0.7782083749771118, G_Loss:3.1686244010925293

iterator 4100, D_Loss:0.9385732412338257, G_Loss:2.982353448867798

iterator 4200, D_Loss:0.7774922847747803, G_Loss:2.8866970539093018

iterator 4300, D_Loss:0.8097734451293945, G_Loss:2.9421300888061523

iterator 4400, D_Loss:0.8828694224357605, G_Loss:2.9996542930603027

iterator 4500, D_Loss:0.8165555000305176, G_Loss:3.126028537750244

iterator 4600, D_Loss:0.8233810663223267, G_Loss:3.454230785369873

iterator 4700, D_Loss:0.8214361667633057, G_Loss:3.530500888824463

iterator 4800, D_Loss:0.845474898815155, G_Loss:2.9618377685546875

iterator 4900, D_Loss:0.8766371011734009, G_Loss:3.227172613143921

iterator 5000, D_Loss:0.7657349109649658, G_Loss:2.7660903930664062

-----------Epoch 9-----------
iterator 100, D_Loss:0.9289017915725708, G_Loss:3.1136302947998047

iterator 200, D_Loss:0.8952785730361938, G_Loss:3.201167345046997

iterator 300, D_Loss:0.8325513005256653, G_Loss:3.088524341583252

iterator 400, D_Loss:0.7904406785964966, G_Loss:3.2133615016937256

iterator 500, D_Loss:0.9769787788391113, G_Loss:3.1257030963897705

iterator 600, D_Loss:0.856225311756134, G_Loss:3.201328754425049

iterator 700, D_Loss:0.8581935167312622, G_Loss:3.0300605297088623

iterator 800, D_Loss:0.7627556920051575, G_Loss:3.0406014919281006

iterator 900, D_Loss:0.8172273635864258, G_Loss:2.6044373512268066

iterator 1000, D_Loss:0.8517141938209534, G_Loss:2.5931897163391113

iterator 1100, D_Loss:0.9080808162689209, G_Loss:3.033334493637085

iterator 1200, D_Loss:0.8412182331085205, G_Loss:2.9345197677612305

iterator 1300, D_Loss:0.8840104937553406, G_Loss:3.244110584259033

iterator 1400, D_Loss:0.8651179075241089, G_Loss:2.966324806213379

iterator 1500, D_Loss:0.8854235410690308, G_Loss:2.9470860958099365

iterator 1600, D_Loss:0.800430417060852, G_Loss:2.5758323669433594

iterator 1700, D_Loss:0.7882529497146606, G_Loss:2.7078540325164795

iterator 1800, D_Loss:0.8227500319480896, G_Loss:3.1000168323516846

iterator 1900, D_Loss:0.793472409248352, G_Loss:3.137155294418335

iterator 2000, D_Loss:0.848145604133606, G_Loss:3.127690315246582

iterator 2100, D_Loss:0.8374975323677063, G_Loss:2.972844362258911

iterator 2200, D_Loss:0.9133403897285461, G_Loss:2.9093024730682373

iterator 2300, D_Loss:0.7664631605148315, G_Loss:3.1253819465637207

iterator 2400, D_Loss:0.9887025356292725, G_Loss:3.0550456047058105

iterator 2500, D_Loss:0.9301742315292358, G_Loss:3.0199334621429443

iterator 2600, D_Loss:0.8009604215621948, G_Loss:3.1087615489959717

iterator 2700, D_Loss:0.8787482380867004, G_Loss:2.7988357543945312

iterator 2800, D_Loss:0.9115335941314697, G_Loss:3.5662872791290283

iterator 2900, D_Loss:0.9162712097167969, G_Loss:2.7747108936309814

iterator 3000, D_Loss:0.8369091749191284, G_Loss:2.9559483528137207

iterator 3100, D_Loss:0.9178972244262695, G_Loss:3.045799970626831

iterator 3200, D_Loss:0.8786226511001587, G_Loss:3.1418042182922363

iterator 3300, D_Loss:0.8499595522880554, G_Loss:2.704484224319458

iterator 3400, D_Loss:0.7837401628494263, G_Loss:3.5675859451293945

iterator 3500, D_Loss:0.9091296792030334, G_Loss:2.899078845977783

iterator 3600, D_Loss:0.8460124135017395, G_Loss:3.239260196685791

iterator 3700, D_Loss:0.8382736444473267, G_Loss:2.9638760089874268

iterator 3800, D_Loss:0.9153624773025513, G_Loss:3.474992275238037

iterator 3900, D_Loss:0.8485499024391174, G_Loss:3.182201623916626

iterator 4000, D_Loss:0.8554853796958923, G_Loss:3.1647119522094727

iterator 4100, D_Loss:0.9447060227394104, G_Loss:2.7155921459198

iterator 4200, D_Loss:0.8065663576126099, G_Loss:3.6589064598083496

iterator 4300, D_Loss:0.8529391288757324, G_Loss:3.1037275791168213

iterator 4400, D_Loss:0.8994745016098022, G_Loss:3.3269033432006836

iterator 4500, D_Loss:0.7427728772163391, G_Loss:3.175976514816284

iterator 4600, D_Loss:0.7699078917503357, G_Loss:3.3151333332061768

iterator 4700, D_Loss:0.951263427734375, G_Loss:3.011925220489502

iterator 4800, D_Loss:0.7489688992500305, G_Loss:2.9957592487335205

iterator 4900, D_Loss:0.7917753458023071, G_Loss:3.043043851852417

iterator 5000, D_Loss:0.8306067585945129, G_Loss:3.370914936065674

VGAN_generator(
  (input): Linear(in_features=128, out_features=200, bias=True)
  (inputbn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (bn0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=200, out_features=135, bias=True)
  (outputbn): BatchNorm1d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=135, out_features=100, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (fc1): Linear(in_features=100, out_features=100, bias=True)
  (fc2): Linear(in_features=100, out_features=100, bias=True)
  (output): Linear(in_features=100, out_features=1, bias=True)
)
(0, False, 135)
-----------Epoch 0-----------
iterator 100, D_Loss:0.6087153553962708, G_Loss:9.299911499023438

iterator 200, D_Loss:0.5108622908592224, G_Loss:9.420340538024902

iterator 300, D_Loss:0.5210214853286743, G_Loss:7.654989242553711

iterator 400, D_Loss:0.5047786235809326, G_Loss:7.363274574279785

iterator 500, D_Loss:0.5522260665893555, G_Loss:8.132048606872559

iterator 600, D_Loss:0.5766538381576538, G_Loss:6.967294216156006

iterator 700, D_Loss:0.5900937914848328, G_Loss:6.896076202392578

iterator 800, D_Loss:0.5560020208358765, G_Loss:5.886293411254883

iterator 900, D_Loss:0.6073671579360962, G_Loss:6.668342113494873

iterator 1000, D_Loss:0.5629435181617737, G_Loss:6.135782241821289

iterator 1100, D_Loss:0.5705161690711975, G_Loss:5.867656230926514

iterator 1200, D_Loss:0.6006611585617065, G_Loss:5.941171169281006

iterator 1300, D_Loss:0.6994196772575378, G_Loss:5.403610706329346

iterator 1400, D_Loss:0.594570517539978, G_Loss:5.713748931884766

iterator 1500, D_Loss:0.7626339793205261, G_Loss:4.918566703796387

iterator 1600, D_Loss:0.6603050231933594, G_Loss:5.254114627838135

iterator 1700, D_Loss:0.6875258088111877, G_Loss:5.232934951782227

iterator 1800, D_Loss:0.7567312717437744, G_Loss:4.051979064941406

iterator 1900, D_Loss:0.683429479598999, G_Loss:4.238072395324707

iterator 2000, D_Loss:0.6651676297187805, G_Loss:4.246614456176758

iterator 2100, D_Loss:0.7067679166793823, G_Loss:4.677617073059082

iterator 2200, D_Loss:0.7386048436164856, G_Loss:4.181615352630615

iterator 2300, D_Loss:0.766486644744873, G_Loss:3.356959104537964

iterator 2400, D_Loss:0.6580369472503662, G_Loss:4.339085578918457

iterator 2500, D_Loss:0.7835928797721863, G_Loss:3.998138189315796

iterator 2600, D_Loss:0.7302695512771606, G_Loss:3.7055253982543945

iterator 2700, D_Loss:0.8310037851333618, G_Loss:3.0192699432373047

iterator 2800, D_Loss:0.7473048567771912, G_Loss:3.196195602416992

iterator 2900, D_Loss:0.7269320487976074, G_Loss:3.343151569366455

iterator 3000, D_Loss:0.9443540573120117, G_Loss:3.0586349964141846

iterator 3100, D_Loss:0.7993081212043762, G_Loss:3.6606333255767822

iterator 3200, D_Loss:0.7629467248916626, G_Loss:3.241412401199341

iterator 3300, D_Loss:0.9115793704986572, G_Loss:3.068026304244995

iterator 3400, D_Loss:0.9448250532150269, G_Loss:3.1177828311920166

iterator 3500, D_Loss:0.7979602813720703, G_Loss:2.5315608978271484

iterator 3600, D_Loss:0.9761431813240051, G_Loss:2.9081881046295166

iterator 3700, D_Loss:0.8505994081497192, G_Loss:2.6891720294952393

iterator 3800, D_Loss:0.876076340675354, G_Loss:3.011326313018799

iterator 3900, D_Loss:0.8891110420227051, G_Loss:2.705817699432373

iterator 4000, D_Loss:0.8715726137161255, G_Loss:2.5895631313323975

iterator 4100, D_Loss:0.8804258704185486, G_Loss:2.436819314956665

iterator 4200, D_Loss:0.9320127367973328, G_Loss:2.4634008407592773

iterator 4300, D_Loss:0.9882372617721558, G_Loss:2.3797597885131836

iterator 4400, D_Loss:0.877410888671875, G_Loss:2.0885448455810547

iterator 4500, D_Loss:0.9249617457389832, G_Loss:1.901523470878601

iterator 4600, D_Loss:1.0875736474990845, G_Loss:2.227196216583252

iterator 4700, D_Loss:0.9658632874488831, G_Loss:2.1172125339508057

iterator 4800, D_Loss:0.9791281819343567, G_Loss:1.7871791124343872

iterator 4900, D_Loss:1.1040151119232178, G_Loss:2.3152458667755127

iterator 5000, D_Loss:1.0285131931304932, G_Loss:2.091386556625366

-----------Epoch 1-----------
iterator 100, D_Loss:0.9123792052268982, G_Loss:1.9380314350128174

iterator 200, D_Loss:1.0727221965789795, G_Loss:2.1081855297088623

iterator 300, D_Loss:1.014389157295227, G_Loss:2.066927194595337

iterator 400, D_Loss:1.0405139923095703, G_Loss:1.8902829885482788

iterator 500, D_Loss:1.0650980472564697, G_Loss:1.9481985569000244

iterator 600, D_Loss:1.0825040340423584, G_Loss:1.97101891040802

iterator 700, D_Loss:1.0944828987121582, G_Loss:1.9540257453918457

iterator 800, D_Loss:1.0871882438659668, G_Loss:1.7560584545135498

iterator 900, D_Loss:1.090101718902588, G_Loss:1.8878923654556274

iterator 1000, D_Loss:1.031942367553711, G_Loss:1.730296015739441

iterator 1100, D_Loss:1.0954124927520752, G_Loss:1.64505934715271

iterator 1200, D_Loss:1.0612287521362305, G_Loss:1.6523576974868774

iterator 1300, D_Loss:0.9902715086936951, G_Loss:1.5286208391189575

iterator 1400, D_Loss:1.1383066177368164, G_Loss:1.7319934368133545

iterator 1500, D_Loss:1.15403151512146, G_Loss:1.6667921543121338

iterator 1600, D_Loss:1.1842418909072876, G_Loss:1.5060012340545654

iterator 1700, D_Loss:1.0924625396728516, G_Loss:1.6251444816589355

iterator 1800, D_Loss:1.103378176689148, G_Loss:1.5944325923919678

iterator 1900, D_Loss:1.1770565509796143, G_Loss:1.525861144065857

iterator 2000, D_Loss:1.105076551437378, G_Loss:1.4471919536590576

iterator 2100, D_Loss:1.0946760177612305, G_Loss:1.6818863153457642

iterator 2200, D_Loss:1.2088367938995361, G_Loss:1.5348976850509644

iterator 2300, D_Loss:1.105940580368042, G_Loss:1.6264861822128296

iterator 2400, D_Loss:1.1850903034210205, G_Loss:1.5090255737304688

iterator 2500, D_Loss:1.1266374588012695, G_Loss:1.817406415939331

iterator 2600, D_Loss:1.0685853958129883, G_Loss:1.5925755500793457

iterator 2700, D_Loss:1.0707957744598389, G_Loss:1.481170415878296

iterator 2800, D_Loss:1.1248750686645508, G_Loss:1.5219497680664062

iterator 2900, D_Loss:1.1443172693252563, G_Loss:1.7635191679000854

iterator 3000, D_Loss:1.117896318435669, G_Loss:1.5741082429885864

iterator 3100, D_Loss:1.20346999168396, G_Loss:1.6544603109359741

iterator 3200, D_Loss:1.2281709909439087, G_Loss:1.3832728862762451

iterator 3300, D_Loss:1.147881031036377, G_Loss:1.538440227508545

iterator 3400, D_Loss:1.1047391891479492, G_Loss:1.4875766038894653

iterator 3500, D_Loss:1.1818063259124756, G_Loss:1.407090425491333

iterator 3600, D_Loss:1.1934152841567993, G_Loss:1.8550474643707275

iterator 3700, D_Loss:1.1274640560150146, G_Loss:1.4295352697372437

iterator 3800, D_Loss:1.2449904680252075, G_Loss:1.4691367149353027

iterator 3900, D_Loss:1.1883525848388672, G_Loss:1.494543194770813

iterator 4000, D_Loss:1.1436073780059814, G_Loss:1.5084943771362305

iterator 4100, D_Loss:1.23433518409729, G_Loss:1.4314513206481934

iterator 4200, D_Loss:1.132003903388977, G_Loss:1.8180025815963745

iterator 4300, D_Loss:1.1139771938323975, G_Loss:1.3165056705474854

iterator 4400, D_Loss:1.161203145980835, G_Loss:1.4550682306289673

iterator 4500, D_Loss:1.1603835821151733, G_Loss:1.476920485496521

iterator 4600, D_Loss:1.1650680303573608, G_Loss:1.654890775680542

iterator 4700, D_Loss:1.1777489185333252, G_Loss:1.2736166715621948

iterator 4800, D_Loss:1.128607988357544, G_Loss:1.4072262048721313

iterator 4900, D_Loss:1.1408050060272217, G_Loss:1.6074928045272827

iterator 5000, D_Loss:1.1336482763290405, G_Loss:1.427429437637329

-----------Epoch 2-----------
iterator 100, D_Loss:1.126221776008606, G_Loss:1.2939398288726807

iterator 200, D_Loss:1.0712710618972778, G_Loss:1.5389947891235352

iterator 300, D_Loss:1.1582953929901123, G_Loss:1.355520248413086

iterator 400, D_Loss:1.1209673881530762, G_Loss:1.5447704792022705

iterator 500, D_Loss:1.2159299850463867, G_Loss:1.3886269330978394

iterator 600, D_Loss:1.1498746871948242, G_Loss:1.4324333667755127

iterator 700, D_Loss:1.1288790702819824, G_Loss:1.7024540901184082

iterator 800, D_Loss:1.23114013671875, G_Loss:1.485163927078247

iterator 900, D_Loss:1.1787896156311035, G_Loss:1.4950013160705566

iterator 1000, D_Loss:1.1829346418380737, G_Loss:1.4511891603469849

iterator 1100, D_Loss:1.2070338726043701, G_Loss:1.232789397239685

iterator 1200, D_Loss:1.1155283451080322, G_Loss:1.4520230293273926

iterator 1300, D_Loss:1.1893248558044434, G_Loss:1.4530487060546875

iterator 1400, D_Loss:1.1460394859313965, G_Loss:2.0590450763702393

iterator 1500, D_Loss:1.1787590980529785, G_Loss:1.3549567461013794

iterator 1600, D_Loss:1.1503329277038574, G_Loss:1.3408797979354858

iterator 1700, D_Loss:1.2302539348602295, G_Loss:1.444348692893982

iterator 1800, D_Loss:1.197586178779602, G_Loss:1.4320294857025146

iterator 1900, D_Loss:1.1619904041290283, G_Loss:1.2994977235794067

iterator 2000, D_Loss:1.203037977218628, G_Loss:1.5100847482681274

iterator 2100, D_Loss:1.1839320659637451, G_Loss:1.6129451990127563

iterator 2200, D_Loss:1.1544395685195923, G_Loss:1.433968186378479

iterator 2300, D_Loss:1.1453135013580322, G_Loss:1.4251772165298462

iterator 2400, D_Loss:1.1068733930587769, G_Loss:1.5630370378494263

iterator 2500, D_Loss:1.203878402709961, G_Loss:1.8476214408874512

iterator 2600, D_Loss:1.134455919265747, G_Loss:1.3833760023117065

iterator 2700, D_Loss:1.187103509902954, G_Loss:1.411231279373169

iterator 2800, D_Loss:1.0720961093902588, G_Loss:1.540461540222168

iterator 2900, D_Loss:1.1107274293899536, G_Loss:1.4635634422302246

iterator 3000, D_Loss:1.1461095809936523, G_Loss:1.5735374689102173

iterator 3100, D_Loss:1.1307272911071777, G_Loss:1.8488540649414062

iterator 3200, D_Loss:1.06782865524292, G_Loss:1.6917009353637695

iterator 3300, D_Loss:1.110466480255127, G_Loss:1.7382242679595947

iterator 3400, D_Loss:1.1220225095748901, G_Loss:1.741309642791748

iterator 3500, D_Loss:1.066885232925415, G_Loss:1.406814694404602

iterator 3600, D_Loss:1.0524394512176514, G_Loss:1.6784818172454834

iterator 3700, D_Loss:1.133336067199707, G_Loss:1.7098318338394165

iterator 3800, D_Loss:1.146798014640808, G_Loss:1.861950397491455

iterator 3900, D_Loss:1.119482159614563, G_Loss:1.7231111526489258

iterator 4000, D_Loss:1.1268270015716553, G_Loss:1.7062773704528809

iterator 4100, D_Loss:1.1248072385787964, G_Loss:1.7527798414230347

iterator 4200, D_Loss:1.09182870388031, G_Loss:1.827850103378296

iterator 4300, D_Loss:1.0541610717773438, G_Loss:1.634303331375122

iterator 4400, D_Loss:1.161938190460205, G_Loss:1.715531349182129

iterator 4500, D_Loss:1.0638418197631836, G_Loss:1.837804913520813

iterator 4600, D_Loss:1.13429856300354, G_Loss:1.6916289329528809

iterator 4700, D_Loss:1.1503701210021973, G_Loss:1.4173940420150757

iterator 4800, D_Loss:1.0751663446426392, G_Loss:1.5813664197921753

iterator 4900, D_Loss:1.071169137954712, G_Loss:1.7144412994384766

iterator 5000, D_Loss:1.152440071105957, G_Loss:1.747808575630188

-----------Epoch 3-----------
iterator 100, D_Loss:1.1009266376495361, G_Loss:1.751402735710144

iterator 200, D_Loss:1.033940315246582, G_Loss:1.488019347190857

iterator 300, D_Loss:1.1316797733306885, G_Loss:1.5322405099868774

iterator 400, D_Loss:1.1371992826461792, G_Loss:1.7554391622543335

iterator 500, D_Loss:1.1271809339523315, G_Loss:1.5621191263198853

iterator 600, D_Loss:1.0079305171966553, G_Loss:1.7519402503967285

iterator 700, D_Loss:1.1531692743301392, G_Loss:2.095841884613037

iterator 800, D_Loss:1.0922605991363525, G_Loss:1.6064099073410034

iterator 900, D_Loss:1.086618423461914, G_Loss:1.6421749591827393

iterator 1000, D_Loss:1.0663063526153564, G_Loss:1.6524982452392578

iterator 1100, D_Loss:1.2465393543243408, G_Loss:1.488714575767517

iterator 1200, D_Loss:1.1299858093261719, G_Loss:1.5962520837783813

iterator 1300, D_Loss:1.1247625350952148, G_Loss:1.5885252952575684

iterator 1400, D_Loss:1.1011067628860474, G_Loss:1.7724616527557373

iterator 1500, D_Loss:1.0081424713134766, G_Loss:1.7963228225708008

iterator 1600, D_Loss:1.0994200706481934, G_Loss:1.5124893188476562

iterator 1700, D_Loss:1.1090773344039917, G_Loss:1.6378482580184937

iterator 1800, D_Loss:1.0929702520370483, G_Loss:1.7951711416244507

iterator 1900, D_Loss:1.0692898035049438, G_Loss:1.5867745876312256

iterator 2000, D_Loss:1.092599630355835, G_Loss:1.635050892829895

iterator 2100, D_Loss:1.0652942657470703, G_Loss:1.8582803010940552

iterator 2200, D_Loss:1.1538138389587402, G_Loss:1.6371921300888062

iterator 2300, D_Loss:1.1213411092758179, G_Loss:1.6002699136734009

iterator 2400, D_Loss:1.042508602142334, G_Loss:1.7296688556671143

iterator 2500, D_Loss:1.036771535873413, G_Loss:1.612701177597046

iterator 2600, D_Loss:1.087641954421997, G_Loss:1.8847815990447998

iterator 2700, D_Loss:1.1206061840057373, G_Loss:1.4359608888626099

iterator 2800, D_Loss:1.0794562101364136, G_Loss:1.58583664894104

iterator 2900, D_Loss:1.1517046689987183, G_Loss:1.6945642232894897

iterator 3000, D_Loss:1.0992381572723389, G_Loss:1.4811264276504517

iterator 3100, D_Loss:1.0789990425109863, G_Loss:1.8198480606079102

iterator 3200, D_Loss:1.1236196756362915, G_Loss:1.7916189432144165

iterator 3300, D_Loss:1.1248162984848022, G_Loss:1.7841581106185913

iterator 3400, D_Loss:1.1315653324127197, G_Loss:1.65482497215271

iterator 3500, D_Loss:1.1062726974487305, G_Loss:1.4781081676483154

iterator 3600, D_Loss:1.0349986553192139, G_Loss:1.5707751512527466

iterator 3700, D_Loss:1.0581070184707642, G_Loss:1.846299409866333

iterator 3800, D_Loss:1.0967395305633545, G_Loss:1.7059454917907715

iterator 3900, D_Loss:1.0717213153839111, G_Loss:1.6115942001342773

iterator 4000, D_Loss:1.149612307548523, G_Loss:1.7511184215545654

iterator 4100, D_Loss:1.0501655340194702, G_Loss:1.5279514789581299

iterator 4200, D_Loss:1.0678339004516602, G_Loss:1.7159594297409058

iterator 4300, D_Loss:1.1241381168365479, G_Loss:1.5555421113967896

iterator 4400, D_Loss:1.0732345581054688, G_Loss:1.670304536819458

iterator 4500, D_Loss:1.0658893585205078, G_Loss:1.7562004327774048

iterator 4600, D_Loss:1.1723992824554443, G_Loss:1.726658582687378

iterator 4700, D_Loss:1.1245074272155762, G_Loss:1.4333701133728027

iterator 4800, D_Loss:1.1040496826171875, G_Loss:1.5826842784881592

iterator 4900, D_Loss:1.0779674053192139, G_Loss:1.831812858581543

iterator 5000, D_Loss:1.1187145709991455, G_Loss:1.674369215965271

-----------Epoch 4-----------
iterator 100, D_Loss:1.0665740966796875, G_Loss:1.5308058261871338

iterator 200, D_Loss:1.1730601787567139, G_Loss:1.6325684785842896

iterator 300, D_Loss:1.1292604207992554, G_Loss:1.7554494142532349

iterator 400, D_Loss:1.0218439102172852, G_Loss:1.5629405975341797

iterator 500, D_Loss:1.1750582456588745, G_Loss:1.5708404779434204

iterator 600, D_Loss:0.9800965785980225, G_Loss:1.687683343887329

iterator 700, D_Loss:1.0207401514053345, G_Loss:1.83330237865448

iterator 800, D_Loss:1.0916279554367065, G_Loss:1.619176983833313

iterator 900, D_Loss:1.03807532787323, G_Loss:1.7477192878723145

iterator 1000, D_Loss:1.0737591981887817, G_Loss:1.5122126340866089

iterator 1100, D_Loss:1.131771206855774, G_Loss:1.4585092067718506

iterator 1200, D_Loss:1.0857372283935547, G_Loss:1.6284557580947876

iterator 1300, D_Loss:1.038261890411377, G_Loss:1.7342952489852905

iterator 1400, D_Loss:1.076162576675415, G_Loss:1.884201169013977

iterator 1500, D_Loss:1.132844090461731, G_Loss:1.685634970664978

iterator 1600, D_Loss:1.0716979503631592, G_Loss:1.8418177366256714

iterator 1700, D_Loss:1.0759127140045166, G_Loss:1.8956538438796997

iterator 1800, D_Loss:1.0510163307189941, G_Loss:1.6200577020645142

iterator 1900, D_Loss:1.0139051675796509, G_Loss:1.7448809146881104

iterator 2000, D_Loss:1.019390344619751, G_Loss:1.68759286403656

iterator 2100, D_Loss:1.0330440998077393, G_Loss:1.784365177154541

iterator 2200, D_Loss:1.0957163572311401, G_Loss:1.8338968753814697

iterator 2300, D_Loss:1.0828176736831665, G_Loss:1.7843971252441406

iterator 2400, D_Loss:1.08687162399292, G_Loss:1.782991886138916

iterator 2500, D_Loss:1.0547730922698975, G_Loss:1.8399524688720703

iterator 2600, D_Loss:1.0852874517440796, G_Loss:1.8793015480041504

iterator 2700, D_Loss:1.13287353515625, G_Loss:1.7223368883132935

iterator 2800, D_Loss:1.0136433839797974, G_Loss:1.7624989748001099

iterator 2900, D_Loss:1.0405784845352173, G_Loss:1.7466909885406494

iterator 3000, D_Loss:1.1067076921463013, G_Loss:1.755280613899231

iterator 3100, D_Loss:1.091761589050293, G_Loss:1.7256935834884644

iterator 3200, D_Loss:1.07993483543396, G_Loss:1.8578091859817505

iterator 3300, D_Loss:1.0137054920196533, G_Loss:1.8831477165222168

iterator 3400, D_Loss:1.0500068664550781, G_Loss:1.638681411743164

iterator 3500, D_Loss:1.0452404022216797, G_Loss:1.6803174018859863

iterator 3600, D_Loss:1.107130765914917, G_Loss:1.711949348449707

iterator 3700, D_Loss:1.0971089601516724, G_Loss:1.7027325630187988

iterator 3800, D_Loss:1.0877015590667725, G_Loss:1.8048512935638428

iterator 3900, D_Loss:1.0341174602508545, G_Loss:2.0515098571777344

iterator 4000, D_Loss:1.1365361213684082, G_Loss:1.7007861137390137

iterator 4100, D_Loss:0.9801011085510254, G_Loss:1.8257580995559692

iterator 4200, D_Loss:1.011455774307251, G_Loss:1.8584429025650024

iterator 4300, D_Loss:1.0573699474334717, G_Loss:1.7604097127914429

iterator 4400, D_Loss:1.0087507963180542, G_Loss:2.093125820159912

iterator 4500, D_Loss:1.147383213043213, G_Loss:1.7178432941436768

iterator 4600, D_Loss:1.030705451965332, G_Loss:2.40028977394104

iterator 4700, D_Loss:1.0915507078170776, G_Loss:1.6818656921386719

iterator 4800, D_Loss:1.1193912029266357, G_Loss:1.612422227859497

iterator 4900, D_Loss:1.0726895332336426, G_Loss:1.8669501543045044

iterator 5000, D_Loss:1.1641278266906738, G_Loss:1.9978231191635132

-----------Epoch 5-----------
iterator 100, D_Loss:1.0555320978164673, G_Loss:1.7864243984222412

iterator 200, D_Loss:0.9758541584014893, G_Loss:1.7084146738052368

iterator 300, D_Loss:1.174331784248352, G_Loss:1.8552021980285645

iterator 400, D_Loss:1.0403391122817993, G_Loss:1.8476121425628662

iterator 500, D_Loss:1.0769426822662354, G_Loss:1.6492067575454712

iterator 600, D_Loss:0.9920938611030579, G_Loss:1.7030423879623413

iterator 700, D_Loss:0.9988405108451843, G_Loss:1.7856907844543457

iterator 800, D_Loss:1.0872858762741089, G_Loss:1.7527140378952026

iterator 900, D_Loss:0.9884387850761414, G_Loss:1.738344430923462

iterator 1000, D_Loss:1.1389241218566895, G_Loss:1.6859028339385986

iterator 1100, D_Loss:1.067711591720581, G_Loss:1.6114630699157715

iterator 1200, D_Loss:1.0319421291351318, G_Loss:1.4855586290359497

iterator 1300, D_Loss:1.085317850112915, G_Loss:1.7151718139648438

iterator 1400, D_Loss:1.1445286273956299, G_Loss:1.7468138933181763

iterator 1500, D_Loss:1.0542532205581665, G_Loss:1.6872146129608154

iterator 1600, D_Loss:1.014721155166626, G_Loss:1.6799508333206177

iterator 1700, D_Loss:1.0989491939544678, G_Loss:1.8621515035629272

iterator 1800, D_Loss:1.1514770984649658, G_Loss:1.5514365434646606

iterator 1900, D_Loss:1.1138616800308228, G_Loss:1.650431513786316

iterator 2000, D_Loss:1.0551677942276, G_Loss:1.8045930862426758

iterator 2100, D_Loss:1.053511619567871, G_Loss:1.686518907546997

iterator 2200, D_Loss:1.167036771774292, G_Loss:1.9964840412139893

iterator 2300, D_Loss:1.0542733669281006, G_Loss:1.8541842699050903

iterator 2400, D_Loss:1.0915395021438599, G_Loss:1.809248447418213

iterator 2500, D_Loss:1.0476233959197998, G_Loss:1.9446101188659668

iterator 2600, D_Loss:1.0852984189987183, G_Loss:1.6767884492874146

iterator 2700, D_Loss:1.0652122497558594, G_Loss:1.811659574508667

iterator 2800, D_Loss:1.07976233959198, G_Loss:1.6776931285858154

iterator 2900, D_Loss:1.0316449403762817, G_Loss:1.8618725538253784

iterator 3000, D_Loss:1.1537797451019287, G_Loss:1.6502419710159302

iterator 3100, D_Loss:1.0847259759902954, G_Loss:1.6134378910064697

iterator 3200, D_Loss:1.0321623086929321, G_Loss:1.681934118270874

iterator 3300, D_Loss:1.0627968311309814, G_Loss:1.7128361463546753

iterator 3400, D_Loss:0.9901545643806458, G_Loss:1.849216341972351

iterator 3500, D_Loss:0.995222806930542, G_Loss:1.7449030876159668

iterator 3600, D_Loss:0.9833762049674988, G_Loss:1.610931396484375

iterator 3700, D_Loss:1.1295424699783325, G_Loss:1.7431620359420776

iterator 3800, D_Loss:1.1084554195404053, G_Loss:1.556128740310669

iterator 3900, D_Loss:1.0689854621887207, G_Loss:1.7051724195480347

iterator 4000, D_Loss:1.1022700071334839, G_Loss:1.6927521228790283

iterator 4100, D_Loss:1.023396372795105, G_Loss:1.803823709487915

iterator 4200, D_Loss:1.0557310581207275, G_Loss:2.2776732444763184

iterator 4300, D_Loss:1.0235764980316162, G_Loss:1.7259761095046997

iterator 4400, D_Loss:1.1073967218399048, G_Loss:1.6224687099456787

iterator 4500, D_Loss:1.156983733177185, G_Loss:1.6629002094268799

iterator 4600, D_Loss:1.0895901918411255, G_Loss:1.8724299669265747

iterator 4700, D_Loss:1.1371554136276245, G_Loss:1.6902101039886475

iterator 4800, D_Loss:1.0974286794662476, G_Loss:1.724228024482727

iterator 4900, D_Loss:1.048474669456482, G_Loss:1.8969470262527466

iterator 5000, D_Loss:1.0750770568847656, G_Loss:1.6904163360595703

-----------Epoch 6-----------
iterator 100, D_Loss:1.0944764614105225, G_Loss:1.5162818431854248

iterator 200, D_Loss:1.1160824298858643, G_Loss:1.4722281694412231

iterator 300, D_Loss:1.122189998626709, G_Loss:1.7219592332839966

iterator 400, D_Loss:1.040218472480774, G_Loss:1.7187894582748413

iterator 500, D_Loss:1.1167020797729492, G_Loss:1.534296989440918

iterator 600, D_Loss:1.0542223453521729, G_Loss:1.7499054670333862

iterator 700, D_Loss:1.0976614952087402, G_Loss:1.547019124031067

iterator 800, D_Loss:1.0826700925827026, G_Loss:1.7950915098190308

iterator 900, D_Loss:1.039391279220581, G_Loss:1.8637373447418213

iterator 1000, D_Loss:1.102112889289856, G_Loss:1.742231011390686

iterator 1100, D_Loss:1.0564512014389038, G_Loss:1.7952520847320557

iterator 1200, D_Loss:1.0836524963378906, G_Loss:1.6440520286560059

iterator 1300, D_Loss:1.1237534284591675, G_Loss:1.61346435546875

iterator 1400, D_Loss:1.0902152061462402, G_Loss:1.4410228729248047

iterator 1500, D_Loss:1.139627456665039, G_Loss:1.7927165031433105

iterator 1600, D_Loss:1.0321656465530396, G_Loss:1.5235919952392578

iterator 1700, D_Loss:1.1564350128173828, G_Loss:1.6675509214401245

iterator 1800, D_Loss:1.044154405593872, G_Loss:1.8480240106582642

iterator 1900, D_Loss:1.0870800018310547, G_Loss:1.6289384365081787

iterator 2000, D_Loss:1.0814656019210815, G_Loss:1.6374328136444092

iterator 2100, D_Loss:1.0906825065612793, G_Loss:1.7208735942840576

iterator 2200, D_Loss:1.1001935005187988, G_Loss:1.6204837560653687

iterator 2300, D_Loss:1.1325602531433105, G_Loss:1.5276472568511963

iterator 2400, D_Loss:1.099426031112671, G_Loss:1.6751922369003296

iterator 2500, D_Loss:1.0955488681793213, G_Loss:1.8062657117843628

iterator 2600, D_Loss:1.0856361389160156, G_Loss:1.5977956056594849

iterator 2700, D_Loss:1.1269831657409668, G_Loss:1.6649000644683838

iterator 2800, D_Loss:1.0088590383529663, G_Loss:1.5392159223556519

iterator 2900, D_Loss:1.0792181491851807, G_Loss:1.6760042905807495

iterator 3000, D_Loss:1.1658470630645752, G_Loss:1.706467628479004

iterator 3100, D_Loss:1.075994610786438, G_Loss:1.5519182682037354

iterator 3200, D_Loss:1.1066662073135376, G_Loss:1.548094630241394

iterator 3300, D_Loss:1.0969572067260742, G_Loss:1.497028112411499

iterator 3400, D_Loss:1.0659757852554321, G_Loss:1.7282707691192627

iterator 3500, D_Loss:1.1035984754562378, G_Loss:1.6121877431869507

iterator 3600, D_Loss:1.1155304908752441, G_Loss:1.6246440410614014

iterator 3700, D_Loss:1.053368330001831, G_Loss:1.7814624309539795

iterator 3800, D_Loss:1.0532819032669067, G_Loss:1.7343698740005493

iterator 3900, D_Loss:1.1446876525878906, G_Loss:1.681547999382019

iterator 4000, D_Loss:1.0332872867584229, G_Loss:1.5177528858184814

iterator 4100, D_Loss:1.0558969974517822, G_Loss:1.5314068794250488

iterator 4200, D_Loss:1.1034702062606812, G_Loss:1.6630358695983887

iterator 4300, D_Loss:1.090983271598816, G_Loss:1.6012505292892456

iterator 4400, D_Loss:1.142883062362671, G_Loss:1.4352198839187622

iterator 4500, D_Loss:1.1336147785186768, G_Loss:1.7791099548339844

iterator 4600, D_Loss:1.1133792400360107, G_Loss:1.788062572479248

iterator 4700, D_Loss:1.1372737884521484, G_Loss:1.3805394172668457

iterator 4800, D_Loss:1.150782585144043, G_Loss:1.5998985767364502

iterator 4900, D_Loss:1.134916067123413, G_Loss:1.8548595905303955

iterator 5000, D_Loss:1.1089884042739868, G_Loss:1.7620761394500732

-----------Epoch 7-----------
iterator 100, D_Loss:1.0702701807022095, G_Loss:1.7756133079528809

iterator 200, D_Loss:1.0759754180908203, G_Loss:1.6060140132904053

iterator 300, D_Loss:1.087395191192627, G_Loss:1.549098014831543

iterator 400, D_Loss:1.0415540933609009, G_Loss:1.8168673515319824

iterator 500, D_Loss:1.0954506397247314, G_Loss:1.8919117450714111

iterator 600, D_Loss:1.0437579154968262, G_Loss:1.5732364654541016

iterator 700, D_Loss:1.10308837890625, G_Loss:1.621899127960205

iterator 800, D_Loss:1.082755446434021, G_Loss:1.4942270517349243

iterator 900, D_Loss:1.1049529314041138, G_Loss:1.6501426696777344

iterator 1000, D_Loss:1.065556526184082, G_Loss:1.5212814807891846

iterator 1100, D_Loss:1.021009087562561, G_Loss:1.7139281034469604

iterator 1200, D_Loss:1.034100890159607, G_Loss:1.5833759307861328

iterator 1300, D_Loss:1.0482492446899414, G_Loss:1.6056946516036987

iterator 1400, D_Loss:1.1183207035064697, G_Loss:1.579512119293213

iterator 1500, D_Loss:1.1137717962265015, G_Loss:1.570115327835083

iterator 1600, D_Loss:1.1509180068969727, G_Loss:1.5956971645355225

iterator 1700, D_Loss:1.0838959217071533, G_Loss:1.5204674005508423

iterator 1800, D_Loss:1.1638188362121582, G_Loss:1.766771674156189

iterator 1900, D_Loss:1.1044745445251465, G_Loss:1.5205678939819336

iterator 2000, D_Loss:1.1259043216705322, G_Loss:1.69455087184906

iterator 2100, D_Loss:1.1219775676727295, G_Loss:1.6529033184051514

iterator 2200, D_Loss:1.0871869325637817, G_Loss:1.9393242597579956

iterator 2300, D_Loss:1.0779739618301392, G_Loss:1.4897633790969849

iterator 2400, D_Loss:1.1122944355010986, G_Loss:1.6035202741622925

iterator 2500, D_Loss:1.0633947849273682, G_Loss:1.476914644241333

iterator 2600, D_Loss:1.105050802230835, G_Loss:1.693494439125061

iterator 2700, D_Loss:1.0591180324554443, G_Loss:1.5180020332336426

iterator 2800, D_Loss:1.0997931957244873, G_Loss:1.5187216997146606

iterator 2900, D_Loss:1.1336654424667358, G_Loss:1.940454125404358

iterator 3000, D_Loss:1.0924739837646484, G_Loss:1.7835499048233032

iterator 3100, D_Loss:1.0530149936676025, G_Loss:1.8954886198043823

iterator 3200, D_Loss:1.1290476322174072, G_Loss:1.5573585033416748

iterator 3300, D_Loss:1.144604206085205, G_Loss:1.5814685821533203

iterator 3400, D_Loss:1.1240785121917725, G_Loss:1.728989839553833

iterator 3500, D_Loss:1.1165776252746582, G_Loss:1.6797583103179932

iterator 3600, D_Loss:1.0006194114685059, G_Loss:1.6048383712768555

iterator 3700, D_Loss:1.0120042562484741, G_Loss:1.3972840309143066

iterator 3800, D_Loss:1.1319682598114014, G_Loss:1.520870566368103

iterator 3900, D_Loss:1.2031582593917847, G_Loss:1.69874107837677

iterator 4000, D_Loss:1.0692250728607178, G_Loss:1.4866348505020142

iterator 4100, D_Loss:1.0444366931915283, G_Loss:1.598730444908142

iterator 4200, D_Loss:0.9983352422714233, G_Loss:1.6558974981307983

iterator 4300, D_Loss:1.0628793239593506, G_Loss:1.6115750074386597

iterator 4400, D_Loss:1.1269373893737793, G_Loss:1.5371394157409668

iterator 4500, D_Loss:1.1790341138839722, G_Loss:1.57908034324646

iterator 4600, D_Loss:1.190409541130066, G_Loss:1.623555064201355

iterator 4700, D_Loss:1.1606005430221558, G_Loss:1.6307415962219238

iterator 4800, D_Loss:1.0319422483444214, G_Loss:1.6013566255569458

iterator 4900, D_Loss:1.1244795322418213, G_Loss:1.7982995510101318

iterator 5000, D_Loss:1.1670758724212646, G_Loss:1.593519687652588

-----------Epoch 8-----------
iterator 100, D_Loss:1.069368600845337, G_Loss:1.6709898710250854

iterator 200, D_Loss:1.087095856666565, G_Loss:1.7940733432769775

iterator 300, D_Loss:1.0942378044128418, G_Loss:1.57637619972229

iterator 400, D_Loss:1.0273501873016357, G_Loss:1.926303505897522

iterator 500, D_Loss:1.0683248043060303, G_Loss:1.7949494123458862

iterator 600, D_Loss:1.1474475860595703, G_Loss:1.6749728918075562

iterator 700, D_Loss:1.1739697456359863, G_Loss:1.5446064472198486

iterator 800, D_Loss:1.079638957977295, G_Loss:1.4909578561782837

iterator 900, D_Loss:1.1393473148345947, G_Loss:1.697847843170166

iterator 1000, D_Loss:1.0622541904449463, G_Loss:1.5978223085403442

iterator 1100, D_Loss:1.0825748443603516, G_Loss:1.5984113216400146

iterator 1200, D_Loss:1.129623293876648, G_Loss:1.749746561050415

iterator 1300, D_Loss:1.0575934648513794, G_Loss:1.6411731243133545

iterator 1400, D_Loss:1.1468520164489746, G_Loss:1.5489826202392578

iterator 1500, D_Loss:1.0597209930419922, G_Loss:1.5071120262145996

iterator 1600, D_Loss:1.0655239820480347, G_Loss:1.8026663064956665

iterator 1700, D_Loss:1.0700500011444092, G_Loss:1.6221803426742554

iterator 1800, D_Loss:1.1017875671386719, G_Loss:1.6371746063232422

iterator 1900, D_Loss:1.0881223678588867, G_Loss:1.66214120388031

iterator 2000, D_Loss:1.170534610748291, G_Loss:1.6942373514175415

iterator 2100, D_Loss:1.0370290279388428, G_Loss:1.7032933235168457

iterator 2200, D_Loss:1.0577967166900635, G_Loss:1.9754844903945923

iterator 2300, D_Loss:1.0807583332061768, G_Loss:1.5569127798080444

iterator 2400, D_Loss:1.153996229171753, G_Loss:1.560079574584961

iterator 2500, D_Loss:1.0553560256958008, G_Loss:1.7598074674606323

iterator 2600, D_Loss:1.0989611148834229, G_Loss:1.700932264328003

iterator 2700, D_Loss:1.0935863256454468, G_Loss:1.6019597053527832

iterator 2800, D_Loss:1.1018681526184082, G_Loss:1.6859828233718872

iterator 2900, D_Loss:1.0554932355880737, G_Loss:1.5752887725830078

iterator 3000, D_Loss:1.0971648693084717, G_Loss:1.5660243034362793

iterator 3100, D_Loss:0.9986623525619507, G_Loss:1.7573308944702148

iterator 3200, D_Loss:1.0898215770721436, G_Loss:1.5754978656768799

iterator 3300, D_Loss:1.1659725904464722, G_Loss:1.6886069774627686

iterator 3400, D_Loss:1.0966265201568604, G_Loss:1.5352435111999512

iterator 3500, D_Loss:1.1526086330413818, G_Loss:1.7022271156311035

iterator 3600, D_Loss:1.1238410472869873, G_Loss:1.5264209508895874

iterator 3700, D_Loss:1.051100254058838, G_Loss:1.6294163465499878

iterator 3800, D_Loss:1.1050945520401, G_Loss:1.9822577238082886

iterator 3900, D_Loss:1.2406468391418457, G_Loss:1.6327214241027832

iterator 4000, D_Loss:1.0568511486053467, G_Loss:1.6335797309875488

iterator 4100, D_Loss:1.1002000570297241, G_Loss:1.580717921257019

iterator 4200, D_Loss:1.0566186904907227, G_Loss:1.830033540725708

iterator 4300, D_Loss:1.050280213356018, G_Loss:1.771945595741272

iterator 4400, D_Loss:1.1420618295669556, G_Loss:1.5987244844436646

iterator 4500, D_Loss:1.1516259908676147, G_Loss:1.5289608240127563

iterator 4600, D_Loss:1.1288527250289917, G_Loss:1.7094982862472534

iterator 4700, D_Loss:1.1431070566177368, G_Loss:1.6527053117752075

iterator 4800, D_Loss:1.1289466619491577, G_Loss:1.6374292373657227

iterator 4900, D_Loss:1.1742932796478271, G_Loss:1.7100226879119873

iterator 5000, D_Loss:1.1298818588256836, G_Loss:1.6671760082244873

-----------Epoch 9-----------
iterator 100, D_Loss:1.0775997638702393, G_Loss:1.7623010873794556

iterator 200, D_Loss:1.1560544967651367, G_Loss:1.3731337785720825

iterator 300, D_Loss:1.083709478378296, G_Loss:1.8177435398101807

iterator 400, D_Loss:1.1228259801864624, G_Loss:1.746741771697998

iterator 500, D_Loss:1.1252119541168213, G_Loss:1.5857841968536377

iterator 600, D_Loss:1.0948148965835571, G_Loss:1.7553044557571411

iterator 700, D_Loss:1.0981183052062988, G_Loss:1.5386546850204468

iterator 800, D_Loss:1.1616570949554443, G_Loss:1.610431432723999

iterator 900, D_Loss:1.1275581121444702, G_Loss:1.648730993270874

iterator 1000, D_Loss:1.0824940204620361, G_Loss:1.543439507484436

iterator 1100, D_Loss:1.1842349767684937, G_Loss:1.562590479850769

iterator 1200, D_Loss:1.1331108808517456, G_Loss:1.6792876720428467

iterator 1300, D_Loss:1.1392467021942139, G_Loss:1.6920366287231445

iterator 1400, D_Loss:1.072777509689331, G_Loss:1.6611400842666626

iterator 1500, D_Loss:1.1174325942993164, G_Loss:1.6650201082229614

iterator 1600, D_Loss:1.1322705745697021, G_Loss:1.5363609790802002

iterator 1700, D_Loss:1.1052385568618774, G_Loss:1.5947420597076416

iterator 1800, D_Loss:1.0023189783096313, G_Loss:1.6756895780563354

iterator 1900, D_Loss:1.0870985984802246, G_Loss:1.7690924406051636

iterator 2000, D_Loss:1.0809054374694824, G_Loss:1.518731713294983

iterator 2100, D_Loss:1.1157562732696533, G_Loss:1.7044376134872437

iterator 2200, D_Loss:1.1497403383255005, G_Loss:1.5228935480117798

iterator 2300, D_Loss:1.1696726083755493, G_Loss:1.8860098123550415

iterator 2400, D_Loss:1.119544506072998, G_Loss:1.6568169593811035

iterator 2500, D_Loss:1.1607109308242798, G_Loss:1.8335474729537964

iterator 2600, D_Loss:1.1908031702041626, G_Loss:1.6328363418579102

iterator 2700, D_Loss:1.1157042980194092, G_Loss:1.5277459621429443

iterator 2800, D_Loss:1.0860013961791992, G_Loss:1.5906240940093994

iterator 2900, D_Loss:1.1151318550109863, G_Loss:1.789617896080017

iterator 3000, D_Loss:1.0963674783706665, G_Loss:1.6104390621185303

iterator 3100, D_Loss:1.0959300994873047, G_Loss:1.7225253582000732

iterator 3200, D_Loss:1.0971264839172363, G_Loss:1.7082104682922363

iterator 3300, D_Loss:1.0850322246551514, G_Loss:1.620011329650879

iterator 3400, D_Loss:1.118059754371643, G_Loss:1.6539658308029175

iterator 3500, D_Loss:1.0814061164855957, G_Loss:1.5574922561645508

iterator 3600, D_Loss:1.0100101232528687, G_Loss:1.7474329471588135

iterator 3700, D_Loss:1.0977729558944702, G_Loss:1.5726627111434937

iterator 3800, D_Loss:1.0472080707550049, G_Loss:1.7511197328567505

iterator 3900, D_Loss:1.1321079730987549, G_Loss:1.642826795578003

iterator 4000, D_Loss:1.0529448986053467, G_Loss:1.6959426403045654

iterator 4100, D_Loss:1.1218794584274292, G_Loss:1.6604464054107666

iterator 4200, D_Loss:1.0219182968139648, G_Loss:1.7627872228622437

iterator 4300, D_Loss:1.1390528678894043, G_Loss:1.6773221492767334

iterator 4400, D_Loss:1.1433093547821045, G_Loss:1.6464557647705078

iterator 4500, D_Loss:1.1259801387786865, G_Loss:1.7316731214523315

iterator 4600, D_Loss:1.0570082664489746, G_Loss:1.5810623168945312

iterator 4700, D_Loss:1.211632251739502, G_Loss:1.5341976881027222

iterator 4800, D_Loss:1.1399098634719849, G_Loss:1.6932637691497803

iterator 4900, D_Loss:1.0634526014328003, G_Loss:1.6664981842041016

iterator 5000, D_Loss:1.1038497686386108, G_Loss:1.6873009204864502

train row : 30148
sample row: 30148
VGAN_generator(
  (input): Linear(in_features=128, out_features=100, bias=True)
  (inputbn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=100, out_features=45, bias=True)
  (outputbn): BatchNorm1d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=45, out_features=400, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=400, out_features=400, bias=True)
  (output): Linear(in_features=400, out_features=1, bias=True)
)
(0, False, 45)
-----------Epoch 0-----------
iterator 100, D_Loss:0.591221809387207, G_Loss:9.146547317504883

iterator 200, D_Loss:0.5368943810462952, G_Loss:7.917807579040527

iterator 300, D_Loss:0.4852428436279297, G_Loss:8.532927513122559

iterator 400, D_Loss:0.4683663249015808, G_Loss:9.184212684631348

iterator 500, D_Loss:0.45229583978652954, G_Loss:10.894819259643555

iterator 600, D_Loss:0.44195252656936646, G_Loss:8.319770812988281

iterator 700, D_Loss:0.4390279948711395, G_Loss:9.004861831665039

iterator 800, D_Loss:0.4656333029270172, G_Loss:9.278910636901855

iterator 900, D_Loss:0.46119892597198486, G_Loss:9.660669326782227

iterator 1000, D_Loss:0.46256041526794434, G_Loss:9.668618202209473

iterator 1100, D_Loss:0.44887951016426086, G_Loss:9.539068222045898

iterator 1200, D_Loss:0.4250026047229767, G_Loss:9.985965728759766

iterator 1300, D_Loss:0.43081268668174744, G_Loss:10.150150299072266

iterator 1400, D_Loss:0.476215660572052, G_Loss:10.316768646240234

iterator 1500, D_Loss:0.4632706940174103, G_Loss:8.366272926330566

iterator 1600, D_Loss:0.4556276500225067, G_Loss:8.822598457336426

iterator 1700, D_Loss:0.46015599370002747, G_Loss:8.475924491882324

iterator 1800, D_Loss:0.4958118200302124, G_Loss:8.246487617492676

iterator 1900, D_Loss:0.44985851645469666, G_Loss:9.08069133758545

iterator 2000, D_Loss:0.44755175709724426, G_Loss:8.143672943115234

iterator 2100, D_Loss:0.46582892537117004, G_Loss:9.486034393310547

iterator 2200, D_Loss:0.446695476770401, G_Loss:8.610786437988281

iterator 2300, D_Loss:0.4625060558319092, G_Loss:8.663012504577637

iterator 2400, D_Loss:0.4420596957206726, G_Loss:9.579157829284668

iterator 2500, D_Loss:0.46620115637779236, G_Loss:10.130958557128906

iterator 2600, D_Loss:0.4690510928630829, G_Loss:8.745441436767578

iterator 2700, D_Loss:0.49311524629592896, G_Loss:9.293929100036621

iterator 2800, D_Loss:0.4595363438129425, G_Loss:8.99995231628418

iterator 2900, D_Loss:0.4228479266166687, G_Loss:9.820438385009766

iterator 3000, D_Loss:0.4791383147239685, G_Loss:8.202937126159668

iterator 3100, D_Loss:0.4408605396747589, G_Loss:8.762067794799805

iterator 3200, D_Loss:0.4279368817806244, G_Loss:9.07966136932373

iterator 3300, D_Loss:0.44246184825897217, G_Loss:8.707021713256836

iterator 3400, D_Loss:0.4452069103717804, G_Loss:8.823927879333496

iterator 3500, D_Loss:0.49241816997528076, G_Loss:8.886808395385742

iterator 3600, D_Loss:0.4730623662471771, G_Loss:8.61816120147705

iterator 3700, D_Loss:0.46879345178604126, G_Loss:8.012064933776855

iterator 3800, D_Loss:0.4603191614151001, G_Loss:7.864819526672363

iterator 3900, D_Loss:0.4539146423339844, G_Loss:8.182480812072754

iterator 4000, D_Loss:0.45498305559158325, G_Loss:8.343125343322754

iterator 4100, D_Loss:0.45508766174316406, G_Loss:7.74215841293335

iterator 4200, D_Loss:0.46391791105270386, G_Loss:7.593597412109375

iterator 4300, D_Loss:0.5004433989524841, G_Loss:8.219745635986328

iterator 4400, D_Loss:0.4892635643482208, G_Loss:7.229692459106445

iterator 4500, D_Loss:0.45926547050476074, G_Loss:8.471177101135254

iterator 4600, D_Loss:0.5097895860671997, G_Loss:7.358255386352539

iterator 4700, D_Loss:0.46545690298080444, G_Loss:7.290726184844971

iterator 4800, D_Loss:0.4742693603038788, G_Loss:7.496659278869629

iterator 4900, D_Loss:0.470994770526886, G_Loss:7.486687660217285

iterator 5000, D_Loss:0.47960108518600464, G_Loss:7.2919816970825195

-----------Epoch 1-----------
iterator 100, D_Loss:0.47947943210601807, G_Loss:7.812988758087158

iterator 200, D_Loss:0.4743073284626007, G_Loss:6.812375068664551

iterator 300, D_Loss:0.4515346586704254, G_Loss:6.968417167663574

iterator 400, D_Loss:0.47886860370635986, G_Loss:6.94575309753418

iterator 500, D_Loss:0.48671913146972656, G_Loss:7.631591796875

iterator 600, D_Loss:0.5088739395141602, G_Loss:7.616269588470459

iterator 700, D_Loss:0.48837634921073914, G_Loss:7.038265705108643

iterator 800, D_Loss:0.500713586807251, G_Loss:7.090723991394043

iterator 900, D_Loss:0.47823095321655273, G_Loss:6.692460060119629

iterator 1000, D_Loss:0.4997216463088989, G_Loss:7.189164638519287

iterator 1100, D_Loss:0.4592650532722473, G_Loss:6.589280605316162

iterator 1200, D_Loss:0.5090555548667908, G_Loss:7.015657901763916

iterator 1300, D_Loss:0.4900083541870117, G_Loss:6.913786888122559

iterator 1400, D_Loss:0.5188348889350891, G_Loss:7.08294677734375

iterator 1500, D_Loss:0.5302689075469971, G_Loss:6.690530776977539

iterator 1600, D_Loss:0.5088841915130615, G_Loss:6.867072582244873

iterator 1700, D_Loss:0.5231967568397522, G_Loss:6.94369649887085

iterator 1800, D_Loss:0.5182815194129944, G_Loss:6.744106769561768

iterator 1900, D_Loss:0.5237302184104919, G_Loss:6.188960075378418

iterator 2000, D_Loss:0.49766677618026733, G_Loss:6.760068893432617

iterator 2100, D_Loss:0.5044269561767578, G_Loss:6.955593585968018

iterator 2200, D_Loss:0.5002272725105286, G_Loss:6.185937404632568

iterator 2300, D_Loss:0.539842426776886, G_Loss:5.910228729248047

iterator 2400, D_Loss:0.5141414999961853, G_Loss:6.378115177154541

iterator 2500, D_Loss:0.5272807478904724, G_Loss:6.672492027282715

iterator 2600, D_Loss:0.5127156972885132, G_Loss:6.005086421966553

iterator 2700, D_Loss:0.4973871409893036, G_Loss:6.444157123565674

iterator 2800, D_Loss:0.493521124124527, G_Loss:6.238168716430664

iterator 2900, D_Loss:0.547309398651123, G_Loss:6.903148651123047

iterator 3000, D_Loss:0.5475363731384277, G_Loss:5.921412467956543

iterator 3100, D_Loss:0.5144495368003845, G_Loss:6.292213439941406

iterator 3200, D_Loss:0.49643683433532715, G_Loss:6.548254489898682

iterator 3300, D_Loss:0.4867815375328064, G_Loss:5.927183151245117

iterator 3400, D_Loss:0.48672062158584595, G_Loss:6.125767707824707

iterator 3500, D_Loss:0.4920075833797455, G_Loss:6.058803558349609

iterator 3600, D_Loss:0.5245947241783142, G_Loss:5.843515872955322

iterator 3700, D_Loss:0.5242671370506287, G_Loss:6.043044090270996

iterator 3800, D_Loss:0.4962631165981293, G_Loss:6.001921653747559

iterator 3900, D_Loss:0.49615901708602905, G_Loss:6.10287618637085

iterator 4000, D_Loss:0.6196447610855103, G_Loss:5.774493217468262

iterator 4100, D_Loss:0.6092596650123596, G_Loss:5.273891448974609

iterator 4200, D_Loss:0.571465015411377, G_Loss:5.849585056304932

iterator 4300, D_Loss:0.49993833899497986, G_Loss:5.600335121154785

iterator 4400, D_Loss:0.5818632245063782, G_Loss:5.811453819274902

iterator 4500, D_Loss:0.5185641646385193, G_Loss:6.2633748054504395

iterator 4600, D_Loss:0.4805985391139984, G_Loss:5.498112678527832

iterator 4700, D_Loss:0.5186941623687744, G_Loss:5.444719314575195

iterator 4800, D_Loss:0.5234942436218262, G_Loss:5.805123805999756

iterator 4900, D_Loss:0.5131183862686157, G_Loss:5.678746223449707

iterator 5000, D_Loss:0.5548571348190308, G_Loss:5.598259925842285

-----------Epoch 2-----------
iterator 100, D_Loss:0.605236291885376, G_Loss:5.5631608963012695

iterator 200, D_Loss:0.6090682148933411, G_Loss:5.014049530029297

iterator 300, D_Loss:0.5999799966812134, G_Loss:5.3922648429870605

iterator 400, D_Loss:0.49187812209129333, G_Loss:5.070461750030518

iterator 500, D_Loss:0.5448890924453735, G_Loss:5.723876476287842

iterator 600, D_Loss:0.5720195174217224, G_Loss:4.7282938957214355

iterator 700, D_Loss:0.5282962918281555, G_Loss:5.270542621612549

iterator 800, D_Loss:0.4949803948402405, G_Loss:4.977992534637451

iterator 900, D_Loss:0.5525082349777222, G_Loss:5.185303688049316

iterator 1000, D_Loss:0.6343334913253784, G_Loss:5.09939432144165

iterator 1100, D_Loss:0.5580622553825378, G_Loss:4.993597984313965

iterator 1200, D_Loss:0.5182498097419739, G_Loss:5.650815010070801

iterator 1300, D_Loss:0.5664524435997009, G_Loss:5.498351097106934

iterator 1400, D_Loss:0.5850422978401184, G_Loss:5.029449462890625

iterator 1500, D_Loss:0.6752455234527588, G_Loss:4.766494274139404

iterator 1600, D_Loss:0.6064760684967041, G_Loss:4.82757043838501

iterator 1700, D_Loss:0.5149029493331909, G_Loss:5.215129375457764

iterator 1800, D_Loss:0.5585848093032837, G_Loss:4.953470706939697

iterator 1900, D_Loss:0.5136229991912842, G_Loss:4.886849403381348

iterator 2000, D_Loss:0.625156819820404, G_Loss:4.7844557762146

iterator 2100, D_Loss:0.5897539854049683, G_Loss:5.371085166931152

iterator 2200, D_Loss:0.5702696442604065, G_Loss:4.669061183929443

iterator 2300, D_Loss:0.5681712627410889, G_Loss:4.499080657958984

iterator 2400, D_Loss:0.5226447582244873, G_Loss:5.513674736022949

iterator 2500, D_Loss:0.6029325127601624, G_Loss:5.081928730010986

iterator 2600, D_Loss:0.6290026903152466, G_Loss:4.990885257720947

iterator 2700, D_Loss:0.6241859793663025, G_Loss:5.096328258514404

iterator 2800, D_Loss:0.6243104934692383, G_Loss:4.885246276855469

iterator 2900, D_Loss:0.6740989089012146, G_Loss:5.1429595947265625

iterator 3000, D_Loss:0.5704732537269592, G_Loss:4.704324722290039

iterator 3100, D_Loss:0.6418003439903259, G_Loss:5.11535120010376

iterator 3200, D_Loss:0.5941533446311951, G_Loss:4.899638652801514

iterator 3300, D_Loss:0.5971431732177734, G_Loss:4.6936354637146

iterator 3400, D_Loss:0.5722408294677734, G_Loss:4.498955726623535

iterator 3500, D_Loss:0.6293829679489136, G_Loss:4.2117156982421875

iterator 3600, D_Loss:0.5606130957603455, G_Loss:4.435616970062256

iterator 3700, D_Loss:0.5892612934112549, G_Loss:4.201961040496826

iterator 3800, D_Loss:0.6324986815452576, G_Loss:4.155533313751221

iterator 3900, D_Loss:0.5760153532028198, G_Loss:4.5781331062316895

iterator 4000, D_Loss:0.5513066649436951, G_Loss:4.754011631011963

iterator 4100, D_Loss:0.6040618419647217, G_Loss:4.721644878387451

iterator 4200, D_Loss:0.5580873489379883, G_Loss:4.501401901245117

iterator 4300, D_Loss:0.6583139300346375, G_Loss:4.310589790344238

iterator 4400, D_Loss:0.6267317533493042, G_Loss:4.317944526672363

iterator 4500, D_Loss:0.6207714676856995, G_Loss:4.8016462326049805

iterator 4600, D_Loss:0.5801352858543396, G_Loss:4.2138471603393555

iterator 4700, D_Loss:0.5859379768371582, G_Loss:4.28368616104126

iterator 4800, D_Loss:0.6164297461509705, G_Loss:4.242578029632568

iterator 4900, D_Loss:0.5813747644424438, G_Loss:4.256388187408447

iterator 5000, D_Loss:0.5831504464149475, G_Loss:4.392818450927734

-----------Epoch 3-----------
iterator 100, D_Loss:0.6701370477676392, G_Loss:4.591113090515137

iterator 200, D_Loss:0.6615251898765564, G_Loss:3.967578411102295

iterator 300, D_Loss:0.5659533739089966, G_Loss:4.090088844299316

iterator 400, D_Loss:0.5976947546005249, G_Loss:4.553399562835693

iterator 500, D_Loss:0.6265782117843628, G_Loss:4.720677375793457

iterator 600, D_Loss:0.5969458222389221, G_Loss:3.9472098350524902

iterator 700, D_Loss:0.6472896933555603, G_Loss:4.008987903594971

iterator 800, D_Loss:0.6208935379981995, G_Loss:4.01371431350708

iterator 900, D_Loss:0.6235746741294861, G_Loss:4.732926368713379

iterator 1000, D_Loss:0.6089308261871338, G_Loss:4.107935905456543

iterator 1100, D_Loss:0.6171224117279053, G_Loss:3.765857219696045

iterator 1200, D_Loss:0.5572054386138916, G_Loss:4.0643439292907715

iterator 1300, D_Loss:0.6704139113426208, G_Loss:4.26045560836792

iterator 1400, D_Loss:0.6352330446243286, G_Loss:4.201578617095947

iterator 1500, D_Loss:0.5818246603012085, G_Loss:3.9022512435913086

iterator 1600, D_Loss:0.5873488187789917, G_Loss:4.093804359436035

iterator 1700, D_Loss:0.6008462309837341, G_Loss:4.135059356689453

iterator 1800, D_Loss:0.6182658672332764, G_Loss:3.722083330154419

iterator 1900, D_Loss:0.5525771975517273, G_Loss:4.297027111053467

iterator 2000, D_Loss:0.6074435114860535, G_Loss:3.924091339111328

iterator 2100, D_Loss:0.6099990606307983, G_Loss:4.0954813957214355

iterator 2200, D_Loss:0.5875921249389648, G_Loss:3.937251091003418

iterator 2300, D_Loss:0.6368131041526794, G_Loss:3.8852078914642334

iterator 2400, D_Loss:0.6258983612060547, G_Loss:4.48434591293335

iterator 2500, D_Loss:0.6255066394805908, G_Loss:4.098698616027832

iterator 2600, D_Loss:0.626034140586853, G_Loss:3.909592866897583

iterator 2700, D_Loss:0.5933170318603516, G_Loss:3.9868733882904053

iterator 2800, D_Loss:0.649321436882019, G_Loss:3.974083185195923

iterator 2900, D_Loss:0.6261645555496216, G_Loss:4.403627872467041

iterator 3000, D_Loss:0.6785839796066284, G_Loss:3.962153911590576

iterator 3100, D_Loss:0.6915338039398193, G_Loss:3.926652431488037

iterator 3200, D_Loss:0.645247220993042, G_Loss:3.882843017578125

iterator 3300, D_Loss:0.695549726486206, G_Loss:4.005687713623047

iterator 3400, D_Loss:0.642626166343689, G_Loss:4.124386787414551

iterator 3500, D_Loss:0.6716142892837524, G_Loss:3.8466031551361084

iterator 3600, D_Loss:0.6836374402046204, G_Loss:3.8775341510772705

iterator 3700, D_Loss:0.6094229221343994, G_Loss:3.7721023559570312

iterator 3800, D_Loss:0.6450542211532593, G_Loss:3.6997697353363037

iterator 3900, D_Loss:0.6335381269454956, G_Loss:3.530550718307495

iterator 4000, D_Loss:0.6474148035049438, G_Loss:3.682828426361084

iterator 4100, D_Loss:0.6701663732528687, G_Loss:4.0117387771606445

iterator 4200, D_Loss:0.6397440433502197, G_Loss:3.8877975940704346

iterator 4300, D_Loss:0.6494870185852051, G_Loss:3.788984537124634

iterator 4400, D_Loss:0.645851194858551, G_Loss:4.173781871795654

iterator 4500, D_Loss:0.6351815462112427, G_Loss:4.36804723739624

iterator 4600, D_Loss:0.6673431396484375, G_Loss:4.132333755493164

iterator 4700, D_Loss:0.6024696230888367, G_Loss:3.8773248195648193

iterator 4800, D_Loss:0.7140622138977051, G_Loss:3.5564188957214355

iterator 4900, D_Loss:0.6637035608291626, G_Loss:3.700662612915039

iterator 5000, D_Loss:0.6076534986495972, G_Loss:3.9091577529907227

-----------Epoch 4-----------
iterator 100, D_Loss:0.660775899887085, G_Loss:3.837062120437622

iterator 200, D_Loss:0.6744155287742615, G_Loss:3.7128591537475586

iterator 300, D_Loss:0.6177380681037903, G_Loss:3.7709436416625977

iterator 400, D_Loss:0.6194144487380981, G_Loss:4.080316543579102

iterator 500, D_Loss:0.7306579351425171, G_Loss:3.889699935913086

iterator 600, D_Loss:0.6383779048919678, G_Loss:3.446366310119629

iterator 700, D_Loss:0.674619734287262, G_Loss:3.695012331008911

iterator 800, D_Loss:0.6762993335723877, G_Loss:3.5527658462524414

iterator 900, D_Loss:0.6308523416519165, G_Loss:3.927785634994507

iterator 1000, D_Loss:0.6939179301261902, G_Loss:3.337639808654785

iterator 1100, D_Loss:0.6594433188438416, G_Loss:3.4454948902130127

iterator 1200, D_Loss:0.6914200782775879, G_Loss:3.69926381111145

iterator 1300, D_Loss:0.7012056708335876, G_Loss:3.3147060871124268

iterator 1400, D_Loss:0.7141871452331543, G_Loss:3.681004762649536

iterator 1500, D_Loss:0.6852481365203857, G_Loss:3.180433511734009

iterator 1600, D_Loss:0.7714610695838928, G_Loss:3.7598989009857178

iterator 1700, D_Loss:0.669501781463623, G_Loss:3.7710659503936768

iterator 1800, D_Loss:0.6576583981513977, G_Loss:3.6482882499694824

iterator 1900, D_Loss:0.6682831645011902, G_Loss:3.5464534759521484

iterator 2000, D_Loss:0.7109975814819336, G_Loss:3.7230377197265625

iterator 2100, D_Loss:0.6944296360015869, G_Loss:3.8796629905700684

iterator 2200, D_Loss:0.656007707118988, G_Loss:3.439653158187866

iterator 2300, D_Loss:0.7075402736663818, G_Loss:3.526437282562256

iterator 2400, D_Loss:0.6666942834854126, G_Loss:3.359985828399658

iterator 2500, D_Loss:0.6059615015983582, G_Loss:3.411386728286743

iterator 2600, D_Loss:0.6890687942504883, G_Loss:3.499728202819824

iterator 2700, D_Loss:0.6892210245132446, G_Loss:3.6511948108673096

iterator 2800, D_Loss:0.781903862953186, G_Loss:3.532341241836548

iterator 2900, D_Loss:0.7792536020278931, G_Loss:3.5271048545837402

iterator 3000, D_Loss:0.7457754611968994, G_Loss:3.62819766998291

iterator 3100, D_Loss:0.71873939037323, G_Loss:3.979901075363159

iterator 3200, D_Loss:0.7073562741279602, G_Loss:3.6085941791534424

iterator 3300, D_Loss:0.7295361161231995, G_Loss:3.6132845878601074

iterator 3400, D_Loss:0.7312720417976379, G_Loss:3.4379608631134033

iterator 3500, D_Loss:0.6372400522232056, G_Loss:3.163463830947876

iterator 3600, D_Loss:0.6851191520690918, G_Loss:3.5013070106506348

iterator 3700, D_Loss:0.6634550094604492, G_Loss:3.5771658420562744

iterator 3800, D_Loss:0.696379542350769, G_Loss:3.6158041954040527

iterator 3900, D_Loss:0.6823384761810303, G_Loss:3.676333427429199

iterator 4000, D_Loss:0.7589464783668518, G_Loss:3.7918620109558105

iterator 4100, D_Loss:0.6406105160713196, G_Loss:3.540271043777466

iterator 4200, D_Loss:0.7283982038497925, G_Loss:3.954669713973999

iterator 4300, D_Loss:0.6705758571624756, G_Loss:3.462627649307251

iterator 4400, D_Loss:0.7229803800582886, G_Loss:3.551805257797241

iterator 4500, D_Loss:0.6911842823028564, G_Loss:3.62246036529541

iterator 4600, D_Loss:0.6570826172828674, G_Loss:3.6101014614105225

iterator 4700, D_Loss:0.7242818474769592, G_Loss:3.2583084106445312

iterator 4800, D_Loss:0.7787308692932129, G_Loss:3.6887423992156982

iterator 4900, D_Loss:0.6672605276107788, G_Loss:3.766876459121704

iterator 5000, D_Loss:0.7057763338088989, G_Loss:3.2450613975524902

-----------Epoch 5-----------
iterator 100, D_Loss:0.6991368532180786, G_Loss:3.665388345718384

iterator 200, D_Loss:0.7478206157684326, G_Loss:3.1887197494506836

iterator 300, D_Loss:0.6380494832992554, G_Loss:3.9392290115356445

iterator 400, D_Loss:0.7063961625099182, G_Loss:3.473987102508545

iterator 500, D_Loss:0.8314688801765442, G_Loss:3.666902780532837

iterator 600, D_Loss:0.7590939402580261, G_Loss:3.2610929012298584

iterator 700, D_Loss:0.7483870983123779, G_Loss:3.564619779586792

iterator 800, D_Loss:0.6223052740097046, G_Loss:3.702610969543457

iterator 900, D_Loss:0.6849619150161743, G_Loss:3.536543369293213

iterator 1000, D_Loss:0.7058559656143188, G_Loss:3.2366080284118652

iterator 1100, D_Loss:0.7513634562492371, G_Loss:3.146739959716797

iterator 1200, D_Loss:0.6955853700637817, G_Loss:3.7149834632873535

iterator 1300, D_Loss:0.6700840592384338, G_Loss:3.399963140487671

iterator 1400, D_Loss:0.7738434076309204, G_Loss:3.3095479011535645

iterator 1500, D_Loss:0.622740626335144, G_Loss:3.456413745880127

iterator 1600, D_Loss:0.6761943697929382, G_Loss:3.3400866985321045

iterator 1700, D_Loss:0.6931878328323364, G_Loss:3.64674711227417

iterator 1800, D_Loss:0.7501175403594971, G_Loss:3.3840832710266113

iterator 1900, D_Loss:0.7532762289047241, G_Loss:3.735877752304077

iterator 2000, D_Loss:0.6474325060844421, G_Loss:3.482360363006592

iterator 2100, D_Loss:0.686603307723999, G_Loss:3.487788677215576

iterator 2200, D_Loss:0.7677336931228638, G_Loss:3.2876510620117188

iterator 2300, D_Loss:0.7028205394744873, G_Loss:3.33650279045105

iterator 2400, D_Loss:0.744364857673645, G_Loss:3.506991147994995

iterator 2500, D_Loss:0.746761679649353, G_Loss:3.4627206325531006

iterator 2600, D_Loss:0.7592431306838989, G_Loss:3.503838300704956

iterator 2700, D_Loss:0.7916815280914307, G_Loss:3.370786666870117

iterator 2800, D_Loss:0.6229945421218872, G_Loss:3.3154454231262207

iterator 2900, D_Loss:0.7511707544326782, G_Loss:3.497741937637329

iterator 3000, D_Loss:0.7577294111251831, G_Loss:3.5027129650115967

iterator 3100, D_Loss:0.7163021564483643, G_Loss:3.3893682956695557

iterator 3200, D_Loss:0.7563464641571045, G_Loss:3.119330406188965

iterator 3300, D_Loss:0.698337197303772, G_Loss:3.6291234493255615

iterator 3400, D_Loss:0.8476623296737671, G_Loss:3.722397804260254

iterator 3500, D_Loss:0.7033928036689758, G_Loss:3.6788010597229004

iterator 3600, D_Loss:0.7601489424705505, G_Loss:3.4332783222198486

iterator 3700, D_Loss:0.7010408639907837, G_Loss:3.5191776752471924

iterator 3800, D_Loss:0.7089049816131592, G_Loss:3.407277822494507

iterator 3900, D_Loss:0.7403460741043091, G_Loss:3.1188478469848633

iterator 4000, D_Loss:0.7615749835968018, G_Loss:3.44758677482605

iterator 4100, D_Loss:0.7101361155509949, G_Loss:3.0895438194274902

iterator 4200, D_Loss:0.775204062461853, G_Loss:3.740361213684082

iterator 4300, D_Loss:0.735183596611023, G_Loss:3.6630966663360596

iterator 4400, D_Loss:0.7219855785369873, G_Loss:2.996462821960449

iterator 4500, D_Loss:0.7072926163673401, G_Loss:3.776519298553467

iterator 4600, D_Loss:0.7014844417572021, G_Loss:3.537280321121216

iterator 4700, D_Loss:0.6706398725509644, G_Loss:3.492954730987549

iterator 4800, D_Loss:0.7259723544120789, G_Loss:2.958625078201294

iterator 4900, D_Loss:0.6095567941665649, G_Loss:3.4589383602142334

iterator 5000, D_Loss:0.7390439510345459, G_Loss:3.3675894737243652

-----------Epoch 6-----------
iterator 100, D_Loss:0.6845852732658386, G_Loss:3.877126932144165

iterator 200, D_Loss:0.6528794765472412, G_Loss:3.539283514022827

iterator 300, D_Loss:0.7451767325401306, G_Loss:3.6316142082214355

iterator 400, D_Loss:0.7622056007385254, G_Loss:3.668825149536133

iterator 500, D_Loss:0.6777567863464355, G_Loss:3.6621460914611816

iterator 600, D_Loss:0.7413387298583984, G_Loss:3.9819884300231934

iterator 700, D_Loss:0.7625834941864014, G_Loss:3.2218258380889893

iterator 800, D_Loss:0.6415987014770508, G_Loss:3.847691059112549

iterator 900, D_Loss:0.7099067568778992, G_Loss:3.9310710430145264

iterator 1000, D_Loss:0.7963361740112305, G_Loss:3.5435526371002197

iterator 1100, D_Loss:0.7612510919570923, G_Loss:3.3119425773620605

iterator 1200, D_Loss:0.7895682454109192, G_Loss:3.508739948272705

iterator 1300, D_Loss:0.7093069553375244, G_Loss:3.5632972717285156

iterator 1400, D_Loss:0.7642158269882202, G_Loss:3.4530398845672607

iterator 1500, D_Loss:0.7550851702690125, G_Loss:3.0546820163726807

iterator 1600, D_Loss:0.7756383419036865, G_Loss:3.331880807876587

iterator 1700, D_Loss:0.746734619140625, G_Loss:3.688246726989746

iterator 1800, D_Loss:0.7744157314300537, G_Loss:3.6050963401794434

iterator 1900, D_Loss:0.674534261226654, G_Loss:3.3111746311187744

iterator 2000, D_Loss:0.6350743174552917, G_Loss:4.094545364379883

iterator 2100, D_Loss:0.7345584630966187, G_Loss:3.588042974472046

iterator 2200, D_Loss:0.663253664970398, G_Loss:3.2301130294799805

iterator 2300, D_Loss:0.605842113494873, G_Loss:3.373974561691284

iterator 2400, D_Loss:0.695745050907135, G_Loss:3.92061185836792

iterator 2500, D_Loss:0.825844407081604, G_Loss:3.3588199615478516

iterator 2600, D_Loss:0.7176591157913208, G_Loss:3.531625986099243

iterator 2700, D_Loss:0.8239867687225342, G_Loss:3.1702985763549805

iterator 2800, D_Loss:0.7500607967376709, G_Loss:3.8868203163146973

iterator 2900, D_Loss:0.6992351412773132, G_Loss:3.64585280418396

iterator 3000, D_Loss:0.6875544786453247, G_Loss:3.6093697547912598

iterator 3100, D_Loss:0.7018650770187378, G_Loss:3.9649205207824707

iterator 3200, D_Loss:0.680053174495697, G_Loss:3.6800291538238525

iterator 3300, D_Loss:0.6994324922561646, G_Loss:3.385878086090088

iterator 3400, D_Loss:0.7200174927711487, G_Loss:3.2514536380767822

iterator 3500, D_Loss:0.7013661861419678, G_Loss:3.7491161823272705

iterator 3600, D_Loss:0.7243968844413757, G_Loss:4.035837173461914

iterator 3700, D_Loss:0.6366875171661377, G_Loss:3.6117103099823

iterator 3800, D_Loss:0.7830507755279541, G_Loss:3.4869422912597656

iterator 3900, D_Loss:0.6694751381874084, G_Loss:4.094428062438965

iterator 4000, D_Loss:0.7279940247535706, G_Loss:3.6412203311920166

iterator 4100, D_Loss:0.7334426641464233, G_Loss:4.039612770080566

iterator 4200, D_Loss:0.7088022232055664, G_Loss:3.1942384243011475

iterator 4300, D_Loss:0.759343147277832, G_Loss:3.713144302368164

iterator 4400, D_Loss:0.69798743724823, G_Loss:3.5174717903137207

iterator 4500, D_Loss:0.6848201751708984, G_Loss:3.455174684524536

iterator 4600, D_Loss:0.656627893447876, G_Loss:3.5296313762664795

iterator 4700, D_Loss:0.7030193209648132, G_Loss:3.7896034717559814

iterator 4800, D_Loss:0.6524890661239624, G_Loss:4.006067276000977

iterator 4900, D_Loss:0.6747667789459229, G_Loss:3.442952871322632

iterator 5000, D_Loss:0.7337369918823242, G_Loss:3.9030606746673584

-----------Epoch 7-----------
iterator 100, D_Loss:0.6712460517883301, G_Loss:3.403799295425415

iterator 200, D_Loss:0.6292187571525574, G_Loss:4.377117156982422

iterator 300, D_Loss:0.7343422770500183, G_Loss:3.401433229446411

iterator 400, D_Loss:0.6990729570388794, G_Loss:3.7672033309936523

iterator 500, D_Loss:0.6912353038787842, G_Loss:3.9189279079437256

iterator 600, D_Loss:0.7701894044876099, G_Loss:3.853468418121338

iterator 700, D_Loss:0.6611505150794983, G_Loss:3.563307046890259

iterator 800, D_Loss:0.677503228187561, G_Loss:4.456868648529053

iterator 900, D_Loss:0.7397013902664185, G_Loss:4.0961174964904785

iterator 1000, D_Loss:0.6699679493904114, G_Loss:4.182672023773193

iterator 1100, D_Loss:0.7718573808670044, G_Loss:3.98319935798645

iterator 1200, D_Loss:0.7637085914611816, G_Loss:3.94728946685791

iterator 1300, D_Loss:0.7709259986877441, G_Loss:3.511784791946411

iterator 1400, D_Loss:0.6748919486999512, G_Loss:3.9989309310913086

iterator 1500, D_Loss:0.669353187084198, G_Loss:3.9965341091156006

iterator 1600, D_Loss:0.6737656593322754, G_Loss:3.11991548538208

iterator 1700, D_Loss:0.6566358804702759, G_Loss:4.352225303649902

iterator 1800, D_Loss:0.6587808132171631, G_Loss:3.8654356002807617

iterator 1900, D_Loss:0.7656430006027222, G_Loss:4.541269779205322

iterator 2000, D_Loss:0.6609070897102356, G_Loss:4.302545070648193

iterator 2100, D_Loss:0.7226996421813965, G_Loss:4.14670991897583

iterator 2200, D_Loss:0.5808703303337097, G_Loss:3.1573312282562256

iterator 2300, D_Loss:0.7263258099555969, G_Loss:4.161399841308594

iterator 2400, D_Loss:0.7093360424041748, G_Loss:4.152486801147461

iterator 2500, D_Loss:0.7023710012435913, G_Loss:3.7393317222595215

iterator 2600, D_Loss:0.685387134552002, G_Loss:4.079251289367676

iterator 2700, D_Loss:0.7178422808647156, G_Loss:4.137657165527344

iterator 2800, D_Loss:0.7271393537521362, G_Loss:3.9080686569213867

iterator 2900, D_Loss:0.7576563358306885, G_Loss:3.932406187057495

iterator 3000, D_Loss:0.8092073798179626, G_Loss:3.789574146270752

iterator 3100, D_Loss:0.723404049873352, G_Loss:3.4623892307281494

iterator 3200, D_Loss:0.6031745672225952, G_Loss:3.6674180030822754

iterator 3300, D_Loss:0.7169729471206665, G_Loss:3.9321460723876953

iterator 3400, D_Loss:0.6433477401733398, G_Loss:4.133380889892578

iterator 3500, D_Loss:0.6917502880096436, G_Loss:3.729034185409546

iterator 3600, D_Loss:0.6430467367172241, G_Loss:3.840029001235962

iterator 3700, D_Loss:0.6697549819946289, G_Loss:4.3587236404418945

iterator 3800, D_Loss:0.677413821220398, G_Loss:3.959838628768921

iterator 3900, D_Loss:0.7006703019142151, G_Loss:4.292765140533447

iterator 4000, D_Loss:0.7135027050971985, G_Loss:3.9652326107025146

iterator 4100, D_Loss:0.6029057502746582, G_Loss:3.646456718444824

iterator 4200, D_Loss:0.7447329163551331, G_Loss:3.482119083404541

iterator 4300, D_Loss:0.6854128837585449, G_Loss:3.7246086597442627

iterator 4400, D_Loss:0.700812816619873, G_Loss:3.5401663780212402

iterator 4500, D_Loss:0.7002936601638794, G_Loss:3.5290727615356445

iterator 4600, D_Loss:0.6449281573295593, G_Loss:3.8006339073181152

iterator 4700, D_Loss:0.7220642566680908, G_Loss:4.065371036529541

iterator 4800, D_Loss:0.6383209228515625, G_Loss:3.957005262374878

iterator 4900, D_Loss:0.5888091325759888, G_Loss:4.448836326599121

iterator 5000, D_Loss:0.6502079367637634, G_Loss:4.022206783294678

-----------Epoch 8-----------
iterator 100, D_Loss:0.7089811563491821, G_Loss:4.021664619445801

iterator 200, D_Loss:0.6795293092727661, G_Loss:4.027655601501465

iterator 300, D_Loss:0.6673098206520081, G_Loss:4.007993221282959

iterator 400, D_Loss:0.6178576946258545, G_Loss:4.534104347229004

iterator 500, D_Loss:0.6928439140319824, G_Loss:3.960627794265747

iterator 600, D_Loss:0.6639359593391418, G_Loss:4.137558460235596

iterator 700, D_Loss:0.710405170917511, G_Loss:3.9844911098480225

iterator 800, D_Loss:0.5839417576789856, G_Loss:4.263679504394531

iterator 900, D_Loss:0.6595510840415955, G_Loss:4.6516523361206055

iterator 1000, D_Loss:0.6715016961097717, G_Loss:4.274774074554443

iterator 1100, D_Loss:0.6853228807449341, G_Loss:3.5849149227142334

iterator 1200, D_Loss:0.735759973526001, G_Loss:3.3982033729553223

iterator 1300, D_Loss:0.606544017791748, G_Loss:4.642659664154053

iterator 1400, D_Loss:0.7244329452514648, G_Loss:4.626310348510742

iterator 1500, D_Loss:0.6181908249855042, G_Loss:4.259644985198975

iterator 1600, D_Loss:0.6714365482330322, G_Loss:4.088800430297852

iterator 1700, D_Loss:0.618682324886322, G_Loss:4.040311813354492

iterator 1800, D_Loss:0.6817415952682495, G_Loss:4.135241508483887

iterator 1900, D_Loss:0.5819375514984131, G_Loss:4.61865234375

iterator 2000, D_Loss:0.5825232863426208, G_Loss:4.303470134735107

iterator 2100, D_Loss:0.6688815951347351, G_Loss:4.774237155914307

iterator 2200, D_Loss:0.7080285549163818, G_Loss:3.884939670562744

iterator 2300, D_Loss:0.6713622808456421, G_Loss:4.471217155456543

iterator 2400, D_Loss:0.7654005289077759, G_Loss:3.7209203243255615

iterator 2500, D_Loss:0.6961154937744141, G_Loss:3.994826555252075

iterator 2600, D_Loss:0.7351089715957642, G_Loss:4.370206832885742

iterator 2700, D_Loss:0.6735761165618896, G_Loss:4.303537845611572

iterator 2800, D_Loss:0.705804705619812, G_Loss:4.772660732269287

iterator 2900, D_Loss:0.6353134512901306, G_Loss:4.061962604522705

iterator 3000, D_Loss:0.6681150794029236, G_Loss:4.857929706573486

iterator 3100, D_Loss:0.6323545575141907, G_Loss:4.438930511474609

iterator 3200, D_Loss:0.6730055212974548, G_Loss:4.037530899047852

iterator 3300, D_Loss:0.6314312815666199, G_Loss:4.2927021980285645

iterator 3400, D_Loss:0.6092656850814819, G_Loss:3.9785850048065186

iterator 3500, D_Loss:0.6515489220619202, G_Loss:4.474687576293945

iterator 3600, D_Loss:0.6269248127937317, G_Loss:4.13122034072876

iterator 3700, D_Loss:0.644335150718689, G_Loss:4.506886005401611

iterator 3800, D_Loss:0.672906756401062, G_Loss:5.233994483947754

iterator 3900, D_Loss:0.7227346897125244, G_Loss:4.685344696044922

iterator 4000, D_Loss:0.6063266396522522, G_Loss:4.399580955505371

iterator 4100, D_Loss:0.6949720978736877, G_Loss:4.671746253967285

iterator 4200, D_Loss:0.6172005534172058, G_Loss:3.928420066833496

iterator 4300, D_Loss:0.6554715633392334, G_Loss:4.464745998382568

iterator 4400, D_Loss:0.6062812209129333, G_Loss:4.152533054351807

iterator 4500, D_Loss:0.6867488622665405, G_Loss:4.1310296058654785

iterator 4600, D_Loss:0.6491931080818176, G_Loss:3.9443581104278564

iterator 4700, D_Loss:0.6878110766410828, G_Loss:3.948152542114258

iterator 4800, D_Loss:0.6585321426391602, G_Loss:4.352294921875

iterator 4900, D_Loss:0.7061049938201904, G_Loss:4.485180854797363

iterator 5000, D_Loss:0.6924682855606079, G_Loss:4.754454612731934

-----------Epoch 9-----------
iterator 100, D_Loss:0.6485660672187805, G_Loss:3.992748260498047

iterator 200, D_Loss:0.6615522503852844, G_Loss:5.279630184173584

iterator 300, D_Loss:0.6636526584625244, G_Loss:4.717617034912109

iterator 400, D_Loss:0.6305078864097595, G_Loss:3.979710102081299

iterator 500, D_Loss:0.6723156571388245, G_Loss:4.2753190994262695

iterator 600, D_Loss:0.6551672220230103, G_Loss:4.734025955200195

iterator 700, D_Loss:0.6885127425193787, G_Loss:3.974491596221924

iterator 800, D_Loss:0.617217481136322, G_Loss:4.002614498138428

iterator 900, D_Loss:0.7592178583145142, G_Loss:3.905069351196289

iterator 1000, D_Loss:0.608698844909668, G_Loss:4.206925868988037

iterator 1100, D_Loss:0.5704736709594727, G_Loss:5.222729206085205

iterator 1200, D_Loss:0.64644855260849, G_Loss:4.48704719543457

iterator 1300, D_Loss:0.6452688574790955, G_Loss:4.561666965484619

iterator 1400, D_Loss:0.7321511507034302, G_Loss:4.472184181213379

iterator 1500, D_Loss:0.6426451802253723, G_Loss:4.14488410949707

iterator 1600, D_Loss:0.6624575853347778, G_Loss:4.003506183624268

iterator 1700, D_Loss:0.6030188798904419, G_Loss:4.267913818359375

iterator 1800, D_Loss:0.6772350668907166, G_Loss:3.7912802696228027

iterator 1900, D_Loss:0.6029318571090698, G_Loss:4.05694580078125

iterator 2000, D_Loss:0.6375148296356201, G_Loss:4.739396572113037

iterator 2100, D_Loss:0.64104163646698, G_Loss:4.0955328941345215

iterator 2200, D_Loss:0.6081706881523132, G_Loss:4.185107231140137

iterator 2300, D_Loss:0.6503461003303528, G_Loss:5.00250768661499

iterator 2400, D_Loss:0.5883422493934631, G_Loss:4.315467357635498

iterator 2500, D_Loss:0.6581541895866394, G_Loss:4.160971164703369

iterator 2600, D_Loss:0.6764633059501648, G_Loss:4.507413387298584

iterator 2700, D_Loss:0.6270999908447266, G_Loss:4.273421287536621

iterator 2800, D_Loss:0.6794012784957886, G_Loss:3.824155569076538

iterator 2900, D_Loss:0.5938849449157715, G_Loss:4.722595691680908

iterator 3000, D_Loss:0.7037090063095093, G_Loss:4.287454128265381

iterator 3100, D_Loss:0.6006243228912354, G_Loss:4.379443645477295

iterator 3200, D_Loss:0.6064425110816956, G_Loss:4.740775108337402

iterator 3300, D_Loss:0.5923451781272888, G_Loss:4.620317459106445

iterator 3400, D_Loss:0.7258054614067078, G_Loss:5.428689479827881

iterator 3500, D_Loss:0.6529445648193359, G_Loss:3.7131097316741943

iterator 3600, D_Loss:0.6901045441627502, G_Loss:4.951714515686035

iterator 3700, D_Loss:0.6170783042907715, G_Loss:4.395430088043213

iterator 3800, D_Loss:0.6642287373542786, G_Loss:4.50861120223999

iterator 3900, D_Loss:0.689306378364563, G_Loss:4.412028789520264

iterator 4000, D_Loss:0.6655964851379395, G_Loss:4.313702583312988

iterator 4100, D_Loss:0.5945490598678589, G_Loss:4.482672214508057

iterator 4200, D_Loss:0.6246857643127441, G_Loss:4.659280300140381

iterator 4300, D_Loss:0.649482011795044, G_Loss:5.244085788726807

iterator 4400, D_Loss:0.6239165663719177, G_Loss:3.7773964405059814

iterator 4500, D_Loss:0.6592556238174438, G_Loss:4.504708290100098

iterator 4600, D_Loss:0.6369808316230774, G_Loss:4.690707683563232

iterator 4700, D_Loss:0.6730660200119019, G_Loss:4.786681652069092

iterator 4800, D_Loss:0.683047354221344, G_Loss:4.998644828796387

iterator 4900, D_Loss:0.6042085886001587, G_Loss:3.8274009227752686

iterator 5000, D_Loss:0.6548545360565186, G_Loss:4.279157638549805

VGAN_generator(
  (input): Linear(in_features=128, out_features=300, bias=True)
  (inputbn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=300, out_features=300, bias=True)
  (bn0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=300, out_features=300, bias=True)
  (bn1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=300, out_features=45, bias=True)
  (outputbn): BatchNorm1d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
VGAN_discriminator(
  (input): Linear(in_features=45, out_features=100, bias=True)
  (Dropout): Dropout(p=0.5, inplace=False)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (output): Linear(in_features=100, out_features=1, bias=True)
)
(0, False, 45)
-----------Epoch 0-----------
iterator 100, D_Loss:1.098929762840271, G_Loss:6.675759792327881

iterator 200, D_Loss:0.6857707500457764, G_Loss:6.366072177886963

iterator 300, D_Loss:0.6056662201881409, G_Loss:6.597084999084473

iterator 400, D_Loss:0.5896742343902588, G_Loss:7.2866315841674805

iterator 500, D_Loss:0.6042817234992981, G_Loss:8.632875442504883

iterator 600, D_Loss:0.5544652342796326, G_Loss:6.123711585998535

iterator 700, D_Loss:0.5907881259918213, G_Loss:6.6594414710998535

iterator 800, D_Loss:0.5836273431777954, G_Loss:7.26659631729126

iterator 900, D_Loss:0.5937750935554504, G_Loss:7.765250205993652

iterator 1000, D_Loss:0.622801661491394, G_Loss:7.064539432525635

iterator 1100, D_Loss:0.5288794636726379, G_Loss:7.226361274719238

iterator 1200, D_Loss:0.5172498822212219, G_Loss:7.970102310180664

iterator 1300, D_Loss:0.5265975594520569, G_Loss:8.108734130859375

iterator 1400, D_Loss:0.5467591285705566, G_Loss:8.06324291229248

iterator 1500, D_Loss:0.5965240001678467, G_Loss:6.5458598136901855

iterator 1600, D_Loss:0.5371562838554382, G_Loss:6.841696739196777

iterator 1700, D_Loss:0.538620114326477, G_Loss:6.602360248565674

iterator 1800, D_Loss:0.533621072769165, G_Loss:6.8092451095581055

iterator 1900, D_Loss:0.5910196304321289, G_Loss:6.683651924133301

iterator 2000, D_Loss:0.5638236403465271, G_Loss:6.661019325256348

iterator 2100, D_Loss:0.5288065671920776, G_Loss:7.13218879699707

iterator 2200, D_Loss:0.6695975065231323, G_Loss:6.294663906097412

iterator 2300, D_Loss:0.5847414135932922, G_Loss:6.195489883422852

iterator 2400, D_Loss:0.5002825260162354, G_Loss:7.213243007659912

iterator 2500, D_Loss:0.5737879276275635, G_Loss:6.61440372467041

iterator 2600, D_Loss:0.5491642355918884, G_Loss:5.838831901550293

iterator 2700, D_Loss:0.5577095150947571, G_Loss:6.406373977661133

iterator 2800, D_Loss:0.611089289188385, G_Loss:6.055907249450684

iterator 2900, D_Loss:0.5298559069633484, G_Loss:6.72769021987915

iterator 3000, D_Loss:0.5523784756660461, G_Loss:5.966137886047363

iterator 3100, D_Loss:0.576988935470581, G_Loss:5.895263195037842

iterator 3200, D_Loss:0.5249882936477661, G_Loss:6.290203094482422

iterator 3300, D_Loss:0.5697839260101318, G_Loss:5.641086578369141

iterator 3400, D_Loss:0.500609278678894, G_Loss:5.512028694152832

iterator 3500, D_Loss:0.6145861148834229, G_Loss:5.2414655685424805

iterator 3600, D_Loss:0.5084039568901062, G_Loss:5.6912336349487305

iterator 3700, D_Loss:0.6153449416160583, G_Loss:4.9253764152526855

iterator 3800, D_Loss:0.5924742817878723, G_Loss:5.435868263244629

iterator 3900, D_Loss:0.5391789674758911, G_Loss:4.984360218048096

iterator 4000, D_Loss:0.4892611503601074, G_Loss:5.341027736663818

iterator 4100, D_Loss:0.5246115922927856, G_Loss:5.689228534698486

iterator 4200, D_Loss:0.5396181344985962, G_Loss:5.578056335449219

iterator 4300, D_Loss:0.5660060048103333, G_Loss:5.2496442794799805

iterator 4400, D_Loss:0.51990807056427, G_Loss:5.144477844238281

iterator 4500, D_Loss:0.5140248537063599, G_Loss:5.985452175140381

iterator 4600, D_Loss:0.5260282754898071, G_Loss:4.851020812988281

iterator 4700, D_Loss:0.5716971755027771, G_Loss:5.398262023925781

iterator 4800, D_Loss:0.531498908996582, G_Loss:5.313479900360107

iterator 4900, D_Loss:0.5404306650161743, G_Loss:5.092907428741455

iterator 5000, D_Loss:0.5540061593055725, G_Loss:4.772892475128174

-----------Epoch 1-----------
iterator 100, D_Loss:0.5690082311630249, G_Loss:5.3050665855407715

iterator 200, D_Loss:0.5752627849578857, G_Loss:4.819893836975098

iterator 300, D_Loss:0.5521339178085327, G_Loss:5.048284530639648

iterator 400, D_Loss:0.5335828065872192, G_Loss:5.048565864562988

iterator 500, D_Loss:0.5856369137763977, G_Loss:5.277642726898193

iterator 600, D_Loss:0.6081575155258179, G_Loss:4.501579761505127

iterator 700, D_Loss:0.5486918091773987, G_Loss:4.473759651184082

iterator 800, D_Loss:0.5384609699249268, G_Loss:4.480873107910156

iterator 900, D_Loss:0.5870417952537537, G_Loss:5.232274532318115

iterator 1000, D_Loss:0.5698862075805664, G_Loss:4.672638893127441

iterator 1100, D_Loss:0.5639644861221313, G_Loss:4.88224458694458

iterator 1200, D_Loss:0.5537430047988892, G_Loss:5.3135151863098145

iterator 1300, D_Loss:0.5667544007301331, G_Loss:5.0239434242248535

iterator 1400, D_Loss:0.5901886820793152, G_Loss:4.762476921081543

iterator 1500, D_Loss:0.5736087560653687, G_Loss:4.221455097198486

iterator 1600, D_Loss:0.57265305519104, G_Loss:4.408473491668701

iterator 1700, D_Loss:0.584601640701294, G_Loss:4.155312538146973

iterator 1800, D_Loss:0.6394590735435486, G_Loss:4.195159435272217

iterator 1900, D_Loss:0.6060271263122559, G_Loss:4.435286521911621

iterator 2000, D_Loss:0.5927963852882385, G_Loss:4.6867594718933105

iterator 2100, D_Loss:0.6234440803527832, G_Loss:5.057282447814941

iterator 2200, D_Loss:0.5867902040481567, G_Loss:4.333966255187988

iterator 2300, D_Loss:0.6325187087059021, G_Loss:4.271406650543213

iterator 2400, D_Loss:0.6065846681594849, G_Loss:4.747073173522949

iterator 2500, D_Loss:0.6064372062683105, G_Loss:4.816003322601318

iterator 2600, D_Loss:0.6541053056716919, G_Loss:4.131929874420166

iterator 2700, D_Loss:0.6444995999336243, G_Loss:4.527463436126709

iterator 2800, D_Loss:0.6205085515975952, G_Loss:3.9888627529144287

iterator 2900, D_Loss:0.5912598967552185, G_Loss:4.971973419189453

iterator 3000, D_Loss:0.6394057273864746, G_Loss:4.035083770751953

iterator 3100, D_Loss:0.6170830130577087, G_Loss:4.669241905212402

iterator 3200, D_Loss:0.6287211179733276, G_Loss:4.5035505294799805

iterator 3300, D_Loss:0.6026589274406433, G_Loss:4.111830711364746

iterator 3400, D_Loss:0.602157473564148, G_Loss:4.119168281555176

iterator 3500, D_Loss:0.6420388221740723, G_Loss:4.078790187835693

iterator 3600, D_Loss:0.6070325374603271, G_Loss:4.2244062423706055

iterator 3700, D_Loss:0.6117842197418213, G_Loss:4.32873010635376

iterator 3800, D_Loss:0.6437768340110779, G_Loss:4.05615758895874

iterator 3900, D_Loss:0.6004805564880371, G_Loss:4.2373046875

iterator 4000, D_Loss:0.6605473756790161, G_Loss:4.2136759757995605

iterator 4100, D_Loss:0.6301745772361755, G_Loss:4.017203330993652

iterator 4200, D_Loss:0.6662171483039856, G_Loss:4.059396743774414

iterator 4300, D_Loss:0.5322929620742798, G_Loss:4.177135944366455

iterator 4400, D_Loss:0.6836117506027222, G_Loss:4.222555160522461

iterator 4500, D_Loss:0.5365839004516602, G_Loss:4.603122711181641

iterator 4600, D_Loss:0.602523148059845, G_Loss:3.9110329151153564

iterator 4700, D_Loss:0.6511406898498535, G_Loss:4.1390557289123535

iterator 4800, D_Loss:0.5790128707885742, G_Loss:4.204432487487793

iterator 4900, D_Loss:0.6298635601997375, G_Loss:4.384249687194824

iterator 5000, D_Loss:0.663054347038269, G_Loss:3.9860198497772217

-----------Epoch 2-----------
iterator 100, D_Loss:0.6311048865318298, G_Loss:4.297101020812988

iterator 200, D_Loss:0.6673884391784668, G_Loss:4.095051288604736

iterator 300, D_Loss:0.614560067653656, G_Loss:3.9298765659332275

iterator 400, D_Loss:0.6335699558258057, G_Loss:4.126516342163086

iterator 500, D_Loss:0.6903459429740906, G_Loss:4.151077747344971

iterator 600, D_Loss:0.5938934683799744, G_Loss:3.703686237335205

iterator 700, D_Loss:0.6811679005622864, G_Loss:3.4915285110473633

iterator 800, D_Loss:0.6194935441017151, G_Loss:3.798814535140991

iterator 900, D_Loss:0.6564810872077942, G_Loss:3.963829517364502

iterator 1000, D_Loss:0.7559474110603333, G_Loss:3.408993721008301

iterator 1100, D_Loss:0.6764614582061768, G_Loss:3.3847413063049316

iterator 1200, D_Loss:0.7039104104042053, G_Loss:3.7433927059173584

iterator 1300, D_Loss:0.6648797988891602, G_Loss:3.9502649307250977

iterator 1400, D_Loss:0.638218879699707, G_Loss:3.776015281677246

iterator 1500, D_Loss:0.7020806074142456, G_Loss:3.3432044982910156

iterator 1600, D_Loss:0.6955157518386841, G_Loss:3.3571503162384033

iterator 1700, D_Loss:0.7060922384262085, G_Loss:3.1115756034851074

iterator 1800, D_Loss:0.646682620048523, G_Loss:3.3173375129699707

iterator 1900, D_Loss:0.6844673156738281, G_Loss:3.305328130722046

iterator 2000, D_Loss:0.6354769468307495, G_Loss:3.7055253982543945

iterator 2100, D_Loss:0.7896918058395386, G_Loss:3.9166126251220703

iterator 2200, D_Loss:0.6790152192115784, G_Loss:3.1461620330810547

iterator 2300, D_Loss:0.6566185355186462, G_Loss:3.1684060096740723

iterator 2400, D_Loss:0.7288869023323059, G_Loss:3.860156774520874

iterator 2500, D_Loss:0.712836503982544, G_Loss:3.4593846797943115

iterator 2600, D_Loss:0.6785987615585327, G_Loss:3.2045369148254395

iterator 2700, D_Loss:0.8129074573516846, G_Loss:3.141639232635498

iterator 2800, D_Loss:0.8062891960144043, G_Loss:3.2672572135925293

iterator 2900, D_Loss:0.8351495265960693, G_Loss:3.278984308242798

iterator 3000, D_Loss:0.7022939920425415, G_Loss:2.9958152770996094

iterator 3100, D_Loss:0.8107438683509827, G_Loss:2.9842982292175293

iterator 3200, D_Loss:0.7509050965309143, G_Loss:3.245626926422119

iterator 3300, D_Loss:0.7985208630561829, G_Loss:2.9562153816223145

iterator 3400, D_Loss:0.8148453831672668, G_Loss:3.1090550422668457

iterator 3500, D_Loss:0.8352525234222412, G_Loss:3.0337750911712646

iterator 3600, D_Loss:0.671751856803894, G_Loss:3.166585683822632

iterator 3700, D_Loss:0.6913416385650635, G_Loss:3.0633950233459473

iterator 3800, D_Loss:0.7078615427017212, G_Loss:2.787156820297241

iterator 3900, D_Loss:0.7297137975692749, G_Loss:3.1800436973571777

iterator 4000, D_Loss:0.7015745639801025, G_Loss:2.9681830406188965

iterator 4100, D_Loss:0.6895087361335754, G_Loss:3.124819278717041

iterator 4200, D_Loss:0.7918615937232971, G_Loss:2.981759786605835

iterator 4300, D_Loss:0.7445533871650696, G_Loss:3.14235258102417

iterator 4400, D_Loss:0.8855884671211243, G_Loss:2.7272534370422363

iterator 4500, D_Loss:0.7895309329032898, G_Loss:3.6349639892578125

iterator 4600, D_Loss:0.7359344959259033, G_Loss:2.9724903106689453

iterator 4700, D_Loss:0.728669285774231, G_Loss:3.0047528743743896

iterator 4800, D_Loss:0.6949104070663452, G_Loss:3.0252022743225098

iterator 4900, D_Loss:0.7738422155380249, G_Loss:2.9392900466918945

iterator 5000, D_Loss:0.7805180549621582, G_Loss:2.993011474609375

-----------Epoch 3-----------
iterator 100, D_Loss:0.8083536028862, G_Loss:3.0199108123779297

iterator 200, D_Loss:0.8414552807807922, G_Loss:2.6826672554016113

iterator 300, D_Loss:0.6604030728340149, G_Loss:2.8637146949768066

iterator 400, D_Loss:0.8419125080108643, G_Loss:2.877354860305786

iterator 500, D_Loss:0.762639582157135, G_Loss:3.1354143619537354

iterator 600, D_Loss:0.7624251246452332, G_Loss:2.6077489852905273

iterator 700, D_Loss:0.8260203003883362, G_Loss:2.552459478378296

iterator 800, D_Loss:0.8025720715522766, G_Loss:2.610520362854004

iterator 900, D_Loss:0.7924415469169617, G_Loss:2.6444590091705322

iterator 1000, D_Loss:0.8724676370620728, G_Loss:2.442939281463623

iterator 1100, D_Loss:0.6881163120269775, G_Loss:2.499051094055176

iterator 1200, D_Loss:0.8097802400588989, G_Loss:2.6082584857940674

iterator 1300, D_Loss:0.7506065368652344, G_Loss:2.6855766773223877

iterator 1400, D_Loss:0.9284968376159668, G_Loss:2.462214946746826

iterator 1500, D_Loss:0.8106976747512817, G_Loss:2.6707088947296143

iterator 1600, D_Loss:0.745800256729126, G_Loss:2.7164840698242188

iterator 1700, D_Loss:0.8436078429222107, G_Loss:2.5439929962158203

iterator 1800, D_Loss:0.7462772727012634, G_Loss:2.494527816772461

iterator 1900, D_Loss:0.7801852822303772, G_Loss:2.666543960571289

iterator 2000, D_Loss:0.8188700675964355, G_Loss:2.8214540481567383

iterator 2100, D_Loss:0.8068348169326782, G_Loss:2.8606326580047607

iterator 2200, D_Loss:0.7917776107788086, G_Loss:2.7639458179473877

iterator 2300, D_Loss:0.8764095902442932, G_Loss:2.286956548690796

iterator 2400, D_Loss:0.7723410129547119, G_Loss:2.67246413230896

iterator 2500, D_Loss:0.762607216835022, G_Loss:2.740696907043457

iterator 2600, D_Loss:0.826072633266449, G_Loss:2.5576860904693604

iterator 2700, D_Loss:0.8527959585189819, G_Loss:2.572291374206543

iterator 2800, D_Loss:0.858616054058075, G_Loss:2.459766387939453

iterator 2900, D_Loss:0.8602205514907837, G_Loss:2.5284502506256104

iterator 3000, D_Loss:0.9019622802734375, G_Loss:2.4955904483795166

iterator 3100, D_Loss:0.9193332195281982, G_Loss:2.471518039703369

iterator 3200, D_Loss:0.897088348865509, G_Loss:2.379809617996216

iterator 3300, D_Loss:0.9398657083511353, G_Loss:2.047182321548462

iterator 3400, D_Loss:0.914333164691925, G_Loss:2.4000072479248047

iterator 3500, D_Loss:0.9691137671470642, G_Loss:2.320160150527954

iterator 3600, D_Loss:0.7520352602005005, G_Loss:2.4713268280029297

iterator 3700, D_Loss:0.8736876249313354, G_Loss:2.4093117713928223

iterator 3800, D_Loss:0.8984925746917725, G_Loss:2.227790117263794

iterator 3900, D_Loss:0.8418742418289185, G_Loss:2.1714091300964355

iterator 4000, D_Loss:0.8740812540054321, G_Loss:2.3593828678131104

iterator 4100, D_Loss:0.8970086574554443, G_Loss:2.2421836853027344

iterator 4200, D_Loss:0.7777397632598877, G_Loss:2.5724692344665527

iterator 4300, D_Loss:0.8383676409721375, G_Loss:2.248817205429077

iterator 4400, D_Loss:0.8500304818153381, G_Loss:2.266474962234497

iterator 4500, D_Loss:0.8951529264450073, G_Loss:2.451274871826172

iterator 4600, D_Loss:0.7799361944198608, G_Loss:2.3807854652404785

iterator 4700, D_Loss:0.8443105220794678, G_Loss:2.2345926761627197

iterator 4800, D_Loss:0.8173283338546753, G_Loss:2.2585248947143555

iterator 4900, D_Loss:0.9264459609985352, G_Loss:2.2935125827789307

iterator 5000, D_Loss:0.8407520651817322, G_Loss:2.345538377761841

-----------Epoch 4-----------
iterator 100, D_Loss:0.8856775760650635, G_Loss:2.3892858028411865

iterator 200, D_Loss:0.8620432615280151, G_Loss:2.2644059658050537

iterator 300, D_Loss:0.8159459829330444, G_Loss:2.2801074981689453

iterator 400, D_Loss:0.7799550294876099, G_Loss:2.3995981216430664

iterator 500, D_Loss:0.881500780582428, G_Loss:2.3628134727478027

iterator 600, D_Loss:0.9274826049804688, G_Loss:2.2702178955078125

iterator 700, D_Loss:1.0167887210845947, G_Loss:2.12595272064209

iterator 800, D_Loss:0.8902417421340942, G_Loss:2.132084608078003

iterator 900, D_Loss:0.9778956770896912, G_Loss:2.4716689586639404

iterator 1000, D_Loss:0.9127632975578308, G_Loss:2.358020782470703

iterator 1100, D_Loss:0.8956903219223022, G_Loss:2.181414842605591

iterator 1200, D_Loss:0.844498336315155, G_Loss:2.3189408779144287

iterator 1300, D_Loss:0.8959449529647827, G_Loss:2.2244269847869873

iterator 1400, D_Loss:0.8876367211341858, G_Loss:2.3223206996917725

iterator 1500, D_Loss:0.8382354378700256, G_Loss:2.4160914421081543

iterator 1600, D_Loss:0.851688027381897, G_Loss:2.335942506790161

iterator 1700, D_Loss:0.8712125420570374, G_Loss:2.442018747329712

iterator 1800, D_Loss:0.9148433208465576, G_Loss:2.433539390563965

iterator 1900, D_Loss:0.8402636647224426, G_Loss:2.4428579807281494

iterator 2000, D_Loss:0.9242329597473145, G_Loss:2.3225033283233643

iterator 2100, D_Loss:0.8862282037734985, G_Loss:2.45310640335083

iterator 2200, D_Loss:0.8378045558929443, G_Loss:2.1186041831970215

iterator 2300, D_Loss:0.9099750518798828, G_Loss:2.0852999687194824

iterator 2400, D_Loss:0.8475428819656372, G_Loss:2.2919819355010986

iterator 2500, D_Loss:0.7918475270271301, G_Loss:2.3519020080566406

iterator 2600, D_Loss:0.9499331712722778, G_Loss:2.2768123149871826

iterator 2700, D_Loss:0.9811346530914307, G_Loss:2.133509635925293

iterator 2800, D_Loss:0.8983314037322998, G_Loss:2.3081283569335938

iterator 2900, D_Loss:0.9498581886291504, G_Loss:2.3207011222839355

iterator 3000, D_Loss:0.8333106637001038, G_Loss:2.4179999828338623

iterator 3100, D_Loss:0.8619591593742371, G_Loss:2.6212987899780273

iterator 3200, D_Loss:0.8042750358581543, G_Loss:2.577057123184204

iterator 3300, D_Loss:0.7974459528923035, G_Loss:2.4056313037872314

iterator 3400, D_Loss:0.8437380194664001, G_Loss:2.3358612060546875

iterator 3500, D_Loss:0.8529788851737976, G_Loss:2.301345109939575

iterator 3600, D_Loss:0.8962948322296143, G_Loss:2.3876895904541016

iterator 3700, D_Loss:0.8660963773727417, G_Loss:2.3182320594787598

iterator 3800, D_Loss:0.7748241424560547, G_Loss:2.204542636871338

iterator 3900, D_Loss:0.9213945865631104, G_Loss:2.33858585357666

iterator 4000, D_Loss:0.9502795338630676, G_Loss:2.376129627227783

iterator 4100, D_Loss:0.9153072834014893, G_Loss:2.2352848052978516

iterator 4200, D_Loss:0.9890791177749634, G_Loss:2.1721267700195312

iterator 4300, D_Loss:0.8743497133255005, G_Loss:2.2898013591766357

iterator 4400, D_Loss:0.8789204955101013, G_Loss:2.241973638534546

iterator 4500, D_Loss:0.8099044561386108, G_Loss:2.291297435760498

iterator 4600, D_Loss:0.9160370826721191, G_Loss:2.0410940647125244

iterator 4700, D_Loss:0.8355511426925659, G_Loss:2.045865774154663

iterator 4800, D_Loss:0.8094671964645386, G_Loss:2.283078193664551

iterator 4900, D_Loss:0.9048231840133667, G_Loss:2.2145910263061523

iterator 5000, D_Loss:0.9346327781677246, G_Loss:2.25992751121521

-----------Epoch 5-----------
iterator 100, D_Loss:0.7942783832550049, G_Loss:2.377251148223877

iterator 200, D_Loss:0.9623023867607117, G_Loss:2.1565470695495605

iterator 300, D_Loss:0.87126624584198, G_Loss:2.118741989135742

iterator 400, D_Loss:1.0087296962738037, G_Loss:2.354321002960205

iterator 500, D_Loss:0.9065203666687012, G_Loss:2.239293336868286

iterator 600, D_Loss:0.8591638803482056, G_Loss:2.0313706398010254

iterator 700, D_Loss:0.8497456908226013, G_Loss:2.1200363636016846

iterator 800, D_Loss:0.856908917427063, G_Loss:2.2703113555908203

iterator 900, D_Loss:0.9123568534851074, G_Loss:2.135601043701172

iterator 1000, D_Loss:0.9356994032859802, G_Loss:2.0904722213745117

iterator 1100, D_Loss:0.8942857384681702, G_Loss:2.1127376556396484

iterator 1200, D_Loss:0.8660103678703308, G_Loss:2.2302064895629883

iterator 1300, D_Loss:0.8698528409004211, G_Loss:2.2409005165100098

iterator 1400, D_Loss:0.8274035453796387, G_Loss:2.316695213317871

iterator 1500, D_Loss:0.9316627383232117, G_Loss:2.171088695526123

iterator 1600, D_Loss:0.8897020816802979, G_Loss:2.0104079246520996

iterator 1700, D_Loss:0.8702366948127747, G_Loss:2.2410924434661865

iterator 1800, D_Loss:0.8829188942909241, G_Loss:2.2921369075775146

iterator 1900, D_Loss:0.9250063300132751, G_Loss:2.228358745574951

iterator 2000, D_Loss:0.961174726486206, G_Loss:2.31668758392334

iterator 2100, D_Loss:0.9562892913818359, G_Loss:2.1257596015930176

iterator 2200, D_Loss:0.8762788772583008, G_Loss:2.1693849563598633

iterator 2300, D_Loss:0.8562254309654236, G_Loss:2.194716215133667

iterator 2400, D_Loss:0.8344473242759705, G_Loss:2.3223321437835693

iterator 2500, D_Loss:0.877677321434021, G_Loss:2.1622416973114014

iterator 2600, D_Loss:0.905778706073761, G_Loss:2.146480083465576

iterator 2700, D_Loss:0.9261485934257507, G_Loss:2.2761194705963135

iterator 2800, D_Loss:0.8306258916854858, G_Loss:2.2403266429901123

iterator 2900, D_Loss:1.038638949394226, G_Loss:2.257399559020996

iterator 3000, D_Loss:0.9241507649421692, G_Loss:2.0780270099639893

iterator 3100, D_Loss:0.8922303915023804, G_Loss:1.9118157625198364

iterator 3200, D_Loss:0.985439121723175, G_Loss:2.0851287841796875

iterator 3300, D_Loss:1.0173734426498413, G_Loss:1.9719347953796387

iterator 3400, D_Loss:0.9156343340873718, G_Loss:2.254926919937134

iterator 3500, D_Loss:0.92142653465271, G_Loss:2.203286647796631

iterator 3600, D_Loss:0.9096634387969971, G_Loss:2.175750255584717

iterator 3700, D_Loss:0.9254343509674072, G_Loss:2.268003225326538

iterator 3800, D_Loss:1.0130647420883179, G_Loss:2.081941604614258

iterator 3900, D_Loss:0.9385496377944946, G_Loss:2.0176665782928467

iterator 4000, D_Loss:0.9723191857337952, G_Loss:2.1380374431610107

iterator 4100, D_Loss:0.8390569686889648, G_Loss:2.158754825592041

iterator 4200, D_Loss:0.9240253567695618, G_Loss:2.1672921180725098

iterator 4300, D_Loss:0.976151168346405, G_Loss:2.286841869354248

iterator 4400, D_Loss:0.9182796478271484, G_Loss:2.0681657791137695

iterator 4500, D_Loss:0.8523234128952026, G_Loss:2.272949695587158

iterator 4600, D_Loss:1.0689787864685059, G_Loss:2.1472079753875732

iterator 4700, D_Loss:0.8809919357299805, G_Loss:2.0662078857421875

iterator 4800, D_Loss:0.8727266788482666, G_Loss:2.1744651794433594

iterator 4900, D_Loss:0.8757120370864868, G_Loss:2.1714820861816406

iterator 5000, D_Loss:0.9247071743011475, G_Loss:2.3466036319732666

-----------Epoch 6-----------
iterator 100, D_Loss:0.8694854378700256, G_Loss:2.2762410640716553

iterator 200, D_Loss:0.9186941981315613, G_Loss:2.263836145401001

iterator 300, D_Loss:0.9363443851470947, G_Loss:2.169296979904175

iterator 400, D_Loss:0.9139436483383179, G_Loss:2.3306636810302734

iterator 500, D_Loss:0.9289878606796265, G_Loss:2.3742427825927734

iterator 600, D_Loss:0.8177613019943237, G_Loss:2.238219976425171

iterator 700, D_Loss:0.9894146919250488, G_Loss:2.047457456588745

iterator 800, D_Loss:0.8081232309341431, G_Loss:2.1033430099487305

iterator 900, D_Loss:0.8851746320724487, G_Loss:2.1681787967681885

iterator 1000, D_Loss:0.9605914354324341, G_Loss:1.9707012176513672

iterator 1100, D_Loss:0.9395381808280945, G_Loss:2.171190023422241

iterator 1200, D_Loss:0.8446350693702698, G_Loss:2.1621079444885254

iterator 1300, D_Loss:0.9456782937049866, G_Loss:2.3668696880340576

iterator 1400, D_Loss:0.9260245561599731, G_Loss:2.10036039352417

iterator 1500, D_Loss:0.9024786353111267, G_Loss:2.134658098220825

iterator 1600, D_Loss:0.9063090085983276, G_Loss:2.348531484603882

iterator 1700, D_Loss:0.8682542443275452, G_Loss:2.2721199989318848

iterator 1800, D_Loss:0.8709025979042053, G_Loss:2.1526362895965576

iterator 1900, D_Loss:0.8901097774505615, G_Loss:2.286935567855835

iterator 2000, D_Loss:0.8925858736038208, G_Loss:2.3216419219970703

iterator 2100, D_Loss:0.9498377442359924, G_Loss:2.162745475769043

iterator 2200, D_Loss:0.8699246048927307, G_Loss:2.1494863033294678

iterator 2300, D_Loss:0.8426668047904968, G_Loss:2.310439348220825

iterator 2400, D_Loss:0.8968217968940735, G_Loss:2.325500965118408

iterator 2500, D_Loss:0.7863481640815735, G_Loss:2.2552030086517334

iterator 2600, D_Loss:0.8909540772438049, G_Loss:2.2154459953308105

iterator 2700, D_Loss:0.8831926584243774, G_Loss:1.9482457637786865

iterator 2800, D_Loss:0.9978151321411133, G_Loss:2.154527425765991

iterator 2900, D_Loss:0.8726840615272522, G_Loss:2.333446502685547

iterator 3000, D_Loss:0.9113386273384094, G_Loss:2.0671675205230713

iterator 3100, D_Loss:0.9228612780570984, G_Loss:2.0913589000701904

iterator 3200, D_Loss:0.8093833923339844, G_Loss:2.273986577987671

iterator 3300, D_Loss:0.8501107692718506, G_Loss:2.304425001144409

iterator 3400, D_Loss:0.9284288883209229, G_Loss:2.236077070236206

iterator 3500, D_Loss:0.9602442979812622, G_Loss:2.1411478519439697

iterator 3600, D_Loss:0.9119486808776855, G_Loss:2.26163387298584

iterator 3700, D_Loss:0.8443493247032166, G_Loss:2.3213648796081543

iterator 3800, D_Loss:0.9513697028160095, G_Loss:2.3471813201904297

iterator 3900, D_Loss:0.883206844329834, G_Loss:2.2884671688079834

iterator 4000, D_Loss:0.8797469735145569, G_Loss:2.232700824737549

iterator 4100, D_Loss:0.9587048888206482, G_Loss:1.8469680547714233

iterator 4200, D_Loss:0.8623270392417908, G_Loss:1.95763099193573

iterator 4300, D_Loss:1.007646918296814, G_Loss:2.0471506118774414

iterator 4400, D_Loss:0.9514869451522827, G_Loss:2.0980427265167236

iterator 4500, D_Loss:0.898265540599823, G_Loss:2.4083268642425537

iterator 4600, D_Loss:0.9376272559165955, G_Loss:2.3523082733154297

iterator 4700, D_Loss:0.9615189433097839, G_Loss:2.201930522918701

iterator 4800, D_Loss:0.9576559066772461, G_Loss:2.1157541275024414

iterator 4900, D_Loss:0.9608097076416016, G_Loss:2.111631393432617

iterator 5000, D_Loss:0.9425424337387085, G_Loss:2.269155740737915

-----------Epoch 7-----------
iterator 100, D_Loss:0.9566264152526855, G_Loss:1.9573482275009155

iterator 200, D_Loss:0.9774133563041687, G_Loss:2.1867332458496094

iterator 300, D_Loss:1.009297490119934, G_Loss:2.1468636989593506

iterator 400, D_Loss:0.9115756750106812, G_Loss:2.0364627838134766

iterator 500, D_Loss:0.8964314460754395, G_Loss:2.1248891353607178

iterator 600, D_Loss:0.9509141445159912, G_Loss:2.124431610107422

iterator 700, D_Loss:0.8228912353515625, G_Loss:2.1041274070739746

iterator 800, D_Loss:0.8422884941101074, G_Loss:2.0593369007110596

iterator 900, D_Loss:1.0158865451812744, G_Loss:2.3785958290100098

iterator 1000, D_Loss:0.8909913301467896, G_Loss:2.340474843978882

iterator 1100, D_Loss:0.8683367967605591, G_Loss:2.2463464736938477

iterator 1200, D_Loss:0.8972976207733154, G_Loss:2.271019458770752

iterator 1300, D_Loss:0.9122856855392456, G_Loss:2.1145901679992676

iterator 1400, D_Loss:0.9050251841545105, G_Loss:2.07392954826355

iterator 1500, D_Loss:0.9015929698944092, G_Loss:2.2728512287139893

iterator 1600, D_Loss:0.9568653702735901, G_Loss:2.238551378250122

iterator 1700, D_Loss:0.8259865045547485, G_Loss:2.319808006286621

iterator 1800, D_Loss:0.7893099784851074, G_Loss:2.5079922676086426

iterator 1900, D_Loss:0.8151230216026306, G_Loss:2.2950897216796875

iterator 2000, D_Loss:0.8705470561981201, G_Loss:2.2807652950286865

iterator 2100, D_Loss:0.82431960105896, G_Loss:2.450676918029785

iterator 2200, D_Loss:0.9409200549125671, G_Loss:2.127113103866577

iterator 2300, D_Loss:0.980681836605072, G_Loss:2.0099263191223145

iterator 2400, D_Loss:0.7889199256896973, G_Loss:2.3300700187683105

iterator 2500, D_Loss:0.8230094909667969, G_Loss:2.229505777359009

iterator 2600, D_Loss:0.8521751165390015, G_Loss:2.209624767303467

iterator 2700, D_Loss:0.881590723991394, G_Loss:2.462913990020752

iterator 2800, D_Loss:0.9416700005531311, G_Loss:2.3821170330047607

iterator 2900, D_Loss:0.9002662897109985, G_Loss:2.388329029083252

iterator 3000, D_Loss:0.9170151352882385, G_Loss:2.240105152130127

iterator 3100, D_Loss:0.9182183742523193, G_Loss:2.2471923828125

iterator 3200, D_Loss:0.9288269281387329, G_Loss:2.038782835006714

iterator 3300, D_Loss:0.9415206909179688, G_Loss:2.3206756114959717

iterator 3400, D_Loss:0.9713589549064636, G_Loss:2.251664638519287

iterator 3500, D_Loss:0.9032489061355591, G_Loss:2.02707839012146

iterator 3600, D_Loss:0.9218391180038452, G_Loss:2.0751917362213135

iterator 3700, D_Loss:0.902917742729187, G_Loss:2.128976345062256

iterator 3800, D_Loss:1.003732442855835, G_Loss:2.236698865890503

iterator 3900, D_Loss:0.8045044541358948, G_Loss:2.256192922592163

iterator 4000, D_Loss:0.8562350869178772, G_Loss:2.263638734817505

iterator 4100, D_Loss:1.0002100467681885, G_Loss:2.018247127532959

iterator 4200, D_Loss:0.7899215221405029, G_Loss:2.180814027786255

iterator 4300, D_Loss:0.9977824687957764, G_Loss:2.260329008102417

iterator 4400, D_Loss:0.8462128639221191, G_Loss:2.035219430923462

iterator 4500, D_Loss:1.0185208320617676, G_Loss:2.2769851684570312

iterator 4600, D_Loss:0.7939810156822205, G_Loss:2.2009851932525635

iterator 4700, D_Loss:0.996120035648346, G_Loss:2.039417028427124

iterator 4800, D_Loss:1.0055391788482666, G_Loss:2.0324931144714355

iterator 4900, D_Loss:0.8803038597106934, G_Loss:2.2193384170532227

iterator 5000, D_Loss:0.9260890483856201, G_Loss:2.2304022312164307

-----------Epoch 8-----------
iterator 100, D_Loss:0.8508791923522949, G_Loss:2.1107184886932373

iterator 200, D_Loss:0.9063408970832825, G_Loss:2.176717519760132

iterator 300, D_Loss:0.8937237858772278, G_Loss:2.2987706661224365

iterator 400, D_Loss:0.9073572754859924, G_Loss:2.069124460220337

iterator 500, D_Loss:0.8906446695327759, G_Loss:2.1037333011627197

iterator 600, D_Loss:0.8747693300247192, G_Loss:2.31259822845459

iterator 700, D_Loss:0.8380347490310669, G_Loss:2.2701706886291504

iterator 800, D_Loss:0.8644601702690125, G_Loss:2.1622729301452637

iterator 900, D_Loss:0.8710804581642151, G_Loss:2.2293777465820312

iterator 1000, D_Loss:0.8776988983154297, G_Loss:2.3538663387298584

iterator 1100, D_Loss:0.8904211521148682, G_Loss:2.207587480545044

iterator 1200, D_Loss:0.8816184401512146, G_Loss:2.1644554138183594

iterator 1300, D_Loss:0.8699790239334106, G_Loss:2.2190589904785156

iterator 1400, D_Loss:0.8654240965843201, G_Loss:2.054649591445923

iterator 1500, D_Loss:0.8220288157463074, G_Loss:2.3871378898620605

iterator 1600, D_Loss:0.952411413192749, G_Loss:2.2815964221954346

iterator 1700, D_Loss:0.8542315363883972, G_Loss:2.252720594406128

iterator 1800, D_Loss:0.8345358371734619, G_Loss:2.4228804111480713

iterator 1900, D_Loss:0.829628586769104, G_Loss:2.1832451820373535

iterator 2000, D_Loss:0.9802080392837524, G_Loss:2.3148138523101807

iterator 2100, D_Loss:0.8100765943527222, G_Loss:2.034696340560913

iterator 2200, D_Loss:0.8846559524536133, G_Loss:2.4749503135681152

iterator 2300, D_Loss:0.825531005859375, G_Loss:2.4301071166992188

iterator 2400, D_Loss:0.9119071364402771, G_Loss:2.6374282836914062

iterator 2500, D_Loss:0.7976377010345459, G_Loss:2.279057502746582

iterator 2600, D_Loss:0.8133794069290161, G_Loss:2.275055408477783

iterator 2700, D_Loss:0.9213154911994934, G_Loss:2.3102192878723145

iterator 2800, D_Loss:0.8289654850959778, G_Loss:2.360057830810547

iterator 2900, D_Loss:0.7956132292747498, G_Loss:2.3824639320373535

iterator 3000, D_Loss:0.9000424146652222, G_Loss:2.3682444095611572

iterator 3100, D_Loss:0.8567789196968079, G_Loss:2.379765748977661

iterator 3200, D_Loss:0.7973893880844116, G_Loss:2.2251977920532227

iterator 3300, D_Loss:0.8074227571487427, G_Loss:2.452613353729248

iterator 3400, D_Loss:0.9275158643722534, G_Loss:2.403186798095703

iterator 3500, D_Loss:0.8780491352081299, G_Loss:2.442337989807129

iterator 3600, D_Loss:0.9593680500984192, G_Loss:2.5076534748077393

iterator 3700, D_Loss:0.7958643436431885, G_Loss:2.4517297744750977

iterator 3800, D_Loss:0.8203791379928589, G_Loss:2.3374035358428955

iterator 3900, D_Loss:0.9728856086730957, G_Loss:2.3380956649780273

iterator 4000, D_Loss:0.827004611492157, G_Loss:2.3259072303771973

iterator 4100, D_Loss:0.8784854412078857, G_Loss:2.61212420463562

iterator 4200, D_Loss:0.9223433136940002, G_Loss:2.24212908744812

iterator 4300, D_Loss:0.8451316356658936, G_Loss:2.569035291671753

iterator 4400, D_Loss:0.8308873176574707, G_Loss:2.328230619430542

iterator 4500, D_Loss:0.7802240252494812, G_Loss:2.2853691577911377

iterator 4600, D_Loss:0.8470091819763184, G_Loss:2.3200252056121826

iterator 4700, D_Loss:0.9005115032196045, G_Loss:2.3715085983276367

iterator 4800, D_Loss:0.823843240737915, G_Loss:2.3499386310577393

iterator 4900, D_Loss:0.8204331994056702, G_Loss:2.307528257369995

iterator 5000, D_Loss:0.8331254720687866, G_Loss:2.3363888263702393

-----------Epoch 9-----------
iterator 100, D_Loss:0.8161764740943909, G_Loss:2.549536943435669

iterator 200, D_Loss:0.8827388286590576, G_Loss:2.3829030990600586

iterator 300, D_Loss:0.7981826066970825, G_Loss:2.565624713897705

iterator 400, D_Loss:0.8591811060905457, G_Loss:2.408712148666382

iterator 500, D_Loss:0.8450188636779785, G_Loss:2.3669283390045166

iterator 600, D_Loss:0.9087228775024414, G_Loss:2.2908356189727783

iterator 700, D_Loss:0.9096585512161255, G_Loss:2.220757246017456

iterator 800, D_Loss:0.7366511225700378, G_Loss:2.210927724838257

iterator 900, D_Loss:0.8536628484725952, G_Loss:2.6572465896606445

iterator 1000, D_Loss:0.9466509819030762, G_Loss:2.1430532932281494

iterator 1100, D_Loss:0.7922664284706116, G_Loss:2.3534135818481445

iterator 1200, D_Loss:0.9002729654312134, G_Loss:2.4144697189331055

iterator 1300, D_Loss:0.9092919230461121, G_Loss:2.179204225540161

iterator 1400, D_Loss:0.869219183921814, G_Loss:2.3887786865234375

iterator 1500, D_Loss:0.7928323149681091, G_Loss:2.314136505126953

iterator 1600, D_Loss:0.9673857092857361, G_Loss:2.6342649459838867

iterator 1700, D_Loss:0.8524534702301025, G_Loss:2.41203236579895

iterator 1800, D_Loss:0.8194986581802368, G_Loss:2.763921022415161

iterator 1900, D_Loss:0.861059308052063, G_Loss:2.298163890838623

iterator 2000, D_Loss:0.7950850129127502, G_Loss:2.5630788803100586

iterator 2100, D_Loss:0.8249948024749756, G_Loss:2.5594451427459717

iterator 2200, D_Loss:0.9078510403633118, G_Loss:2.4688169956207275

iterator 2300, D_Loss:0.8379144668579102, G_Loss:2.158351182937622

iterator 2400, D_Loss:0.871912956237793, G_Loss:2.181896209716797

iterator 2500, D_Loss:0.8758996725082397, G_Loss:2.2381129264831543

iterator 2600, D_Loss:0.8753588199615479, G_Loss:2.386012554168701

iterator 2700, D_Loss:0.948604166507721, G_Loss:2.2003366947174072

iterator 2800, D_Loss:0.8557103872299194, G_Loss:2.4411802291870117

iterator 2900, D_Loss:0.8547937870025635, G_Loss:2.363675117492676

iterator 3000, D_Loss:0.9397749900817871, G_Loss:2.286313533782959

iterator 3100, D_Loss:0.799252986907959, G_Loss:2.6098930835723877

iterator 3200, D_Loss:0.838565468788147, G_Loss:2.569906711578369

iterator 3300, D_Loss:0.8657904863357544, G_Loss:2.3013792037963867

iterator 3400, D_Loss:0.901650607585907, G_Loss:2.3506999015808105

iterator 3500, D_Loss:0.8973455429077148, G_Loss:2.3208916187286377

iterator 3600, D_Loss:0.8668855428695679, G_Loss:2.447004556655884

iterator 3700, D_Loss:0.8545226454734802, G_Loss:2.5635650157928467

iterator 3800, D_Loss:0.776576042175293, G_Loss:2.2578377723693848

iterator 3900, D_Loss:0.8614471554756165, G_Loss:2.301234483718872

iterator 4000, D_Loss:0.860641360282898, G_Loss:2.539246082305908

iterator 4100, D_Loss:0.820502758026123, G_Loss:2.20685076713562

iterator 4200, D_Loss:0.756149411201477, G_Loss:2.429285764694214

iterator 4300, D_Loss:0.9149569272994995, G_Loss:2.6627449989318848

iterator 4400, D_Loss:0.8855473399162292, G_Loss:2.4628171920776367

iterator 4500, D_Loss:0.7938352823257446, G_Loss:2.7315573692321777

iterator 4600, D_Loss:0.8096815347671509, G_Loss:2.7175774574279785

iterator 4700, D_Loss:0.8489673137664795, G_Loss:2.23966908454895

iterator 4800, D_Loss:0.8346239328384399, G_Loss:2.683380365371704

iterator 4900, D_Loss:0.828105092048645, G_Loss:2.6070399284362793

iterator 5000, D_Loss:0.7943896055221558, G_Loss:2.303537368774414

train row : 30148
sample row: 30148
LGAN_generator(
  (LSTM): LSTMCell(700, 300)
  (gmfc00): Linear(in_features=300, out_features=1, bias=True)
  (gmfc01): Linear(in_features=300, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=300, bias=True)
  (gmfe00): Linear(in_features=300, out_features=300, bias=True)
  (gmfe01): Linear(in_features=300, out_features=300, bias=True)
  (fc10): Linear(in_features=300, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=300, bias=True)
  (fe1): Linear(in_features=300, out_features=300, bias=True)
  (gmfc20): Linear(in_features=300, out_features=1, bias=True)
  (gmfc21): Linear(in_features=300, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=300, bias=True)
  (gmfe20): Linear(in_features=300, out_features=300, bias=True)
  (gmfe21): Linear(in_features=300, out_features=300, bias=True)
  (fc30): Linear(in_features=300, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=300, bias=True)
  (fe3): Linear(in_features=300, out_features=300, bias=True)
  (gmfc40): Linear(in_features=300, out_features=1, bias=True)
  (gmfc41): Linear(in_features=300, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=300, bias=True)
  (gmfe40): Linear(in_features=300, out_features=300, bias=True)
  (gmfe41): Linear(in_features=300, out_features=300, bias=True)
  (fc50): Linear(in_features=300, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=300, bias=True)
  (fe5): Linear(in_features=300, out_features=300, bias=True)
  (fc60): Linear(in_features=300, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=300, bias=True)
  (fe6): Linear(in_features=300, out_features=300, bias=True)
  (fc70): Linear(in_features=300, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=300, bias=True)
  (fe7): Linear(in_features=300, out_features=300, bias=True)
  (fc80): Linear(in_features=300, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=300, bias=True)
  (fe8): Linear(in_features=300, out_features=300, bias=True)
  (fc90): Linear(in_features=300, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=300, bias=True)
  (fe9): Linear(in_features=300, out_features=300, bias=True)
  (gmfc100): Linear(in_features=300, out_features=1, bias=True)
  (gmfc101): Linear(in_features=300, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=300, bias=True)
  (gmfe100): Linear(in_features=300, out_features=300, bias=True)
  (gmfe101): Linear(in_features=300, out_features=300, bias=True)
  (gmfc110): Linear(in_features=300, out_features=1, bias=True)
  (gmfc111): Linear(in_features=300, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=300, bias=True)
  (gmfe110): Linear(in_features=300, out_features=300, bias=True)
  (gmfe111): Linear(in_features=300, out_features=300, bias=True)
  (gmfc120): Linear(in_features=300, out_features=1, bias=True)
  (gmfc121): Linear(in_features=300, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=300, bias=True)
  (gmfe120): Linear(in_features=300, out_features=300, bias=True)
  (gmfe121): Linear(in_features=300, out_features=300, bias=True)
  (fc130): Linear(in_features=300, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=300, bias=True)
  (fe13): Linear(in_features=300, out_features=300, bias=True)
  (fc140): Linear(in_features=300, out_features=2, bias=True)
  (fc141): Linear(in_features=2, out_features=300, bias=True)
  (fe14): Linear(in_features=300, out_features=300, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=300, bias=True)
  (inputbn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=300, out_features=300, bias=True)
  (bn0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=300, out_features=300, bias=True)
  (bn1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=300, out_features=300, bias=True)
  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=300, out_features=1, bias=True)
)
(0, False, 135)
-----------Epoch 0-----------
iterator 100, D_Loss:1.3915011882781982, G_Loss:1.178507924079895

iterator 200, D_Loss:1.4171653985977173, G_Loss:1.1005460023880005

iterator 300, D_Loss:1.3976788520812988, G_Loss:1.1102280616760254

iterator 400, D_Loss:1.3803735971450806, G_Loss:1.0944604873657227

iterator 500, D_Loss:1.3958487510681152, G_Loss:1.0870693922042847

iterator 600, D_Loss:1.378446102142334, G_Loss:1.2395246028900146

iterator 700, D_Loss:1.3584684133529663, G_Loss:1.071969747543335

iterator 800, D_Loss:1.410409927368164, G_Loss:1.0578522682189941

iterator 900, D_Loss:1.3600060939788818, G_Loss:1.0342354774475098

iterator 1000, D_Loss:1.3780730962753296, G_Loss:1.0773460865020752

iterator 1100, D_Loss:1.376457929611206, G_Loss:1.1855745315551758

iterator 1200, D_Loss:1.3653810024261475, G_Loss:1.1629087924957275

iterator 1300, D_Loss:1.3544836044311523, G_Loss:1.2857015132904053

iterator 1400, D_Loss:1.3521848917007446, G_Loss:1.1105467081069946

iterator 1500, D_Loss:1.3540983200073242, G_Loss:1.086317539215088

iterator 1600, D_Loss:1.363908052444458, G_Loss:1.169782280921936

iterator 1700, D_Loss:1.3600778579711914, G_Loss:1.1264491081237793

iterator 1800, D_Loss:1.3489739894866943, G_Loss:1.100050687789917

iterator 1900, D_Loss:1.3146940469741821, G_Loss:1.0756891965866089

iterator 2000, D_Loss:1.2751994132995605, G_Loss:1.1989552974700928

iterator 2100, D_Loss:1.3040523529052734, G_Loss:1.2667858600616455

iterator 2200, D_Loss:1.3361117839813232, G_Loss:1.1811466217041016

iterator 2300, D_Loss:1.2498891353607178, G_Loss:1.2497221231460571

iterator 2400, D_Loss:1.2413586378097534, G_Loss:1.411025047302246

iterator 2500, D_Loss:1.3283748626708984, G_Loss:1.3833754062652588

iterator 2600, D_Loss:1.2358081340789795, G_Loss:1.3641223907470703

iterator 2700, D_Loss:1.1574398279190063, G_Loss:1.3512210845947266

iterator 2800, D_Loss:1.1382856369018555, G_Loss:1.5319815874099731

iterator 2900, D_Loss:1.2151367664337158, G_Loss:1.1657112836837769

iterator 3000, D_Loss:1.4112284183502197, G_Loss:1.4398713111877441

iterator 3100, D_Loss:1.2112153768539429, G_Loss:1.2154695987701416

iterator 3200, D_Loss:1.1407675743103027, G_Loss:1.3463268280029297

iterator 3300, D_Loss:1.1302642822265625, G_Loss:1.3970060348510742

iterator 3400, D_Loss:1.048676609992981, G_Loss:1.8448947668075562

iterator 3500, D_Loss:0.9065614938735962, G_Loss:1.5505622625350952

iterator 3600, D_Loss:0.8835793733596802, G_Loss:1.6320176124572754

iterator 3700, D_Loss:0.9722466468811035, G_Loss:1.8367681503295898

iterator 3800, D_Loss:0.7927961349487305, G_Loss:1.9203433990478516

iterator 3900, D_Loss:0.6754195690155029, G_Loss:2.139033555984497

iterator 4000, D_Loss:0.8533267974853516, G_Loss:1.770429015159607

iterator 4100, D_Loss:0.830209493637085, G_Loss:2.320845365524292

iterator 4200, D_Loss:0.8078928589820862, G_Loss:2.2459092140197754

iterator 4300, D_Loss:0.6556640267372131, G_Loss:2.339474678039551

iterator 4400, D_Loss:0.810799241065979, G_Loss:2.6449947357177734

iterator 4500, D_Loss:0.7493362426757812, G_Loss:2.9202184677124023

iterator 4600, D_Loss:0.7318087816238403, G_Loss:2.894178628921509

iterator 4700, D_Loss:0.6099252700805664, G_Loss:3.0507116317749023

iterator 4800, D_Loss:0.5909422039985657, G_Loss:3.757495880126953

iterator 4900, D_Loss:0.5820598006248474, G_Loss:3.2186224460601807

iterator 5000, D_Loss:0.5094642043113708, G_Loss:3.760067939758301

-----------Epoch 1-----------
iterator 100, D_Loss:0.5671041011810303, G_Loss:2.3549392223358154

iterator 200, D_Loss:0.9437564015388489, G_Loss:4.012272834777832

iterator 300, D_Loss:0.6529595851898193, G_Loss:3.2935047149658203

iterator 400, D_Loss:0.5283188223838806, G_Loss:3.123051166534424

iterator 500, D_Loss:0.6232940554618835, G_Loss:4.305732250213623

iterator 600, D_Loss:0.538936197757721, G_Loss:4.589339733123779

iterator 700, D_Loss:0.49109795689582825, G_Loss:6.063438415527344

iterator 800, D_Loss:0.641907811164856, G_Loss:4.270572185516357

iterator 900, D_Loss:0.5290929079055786, G_Loss:4.539878845214844

iterator 1000, D_Loss:0.4889475703239441, G_Loss:4.178147315979004

iterator 1100, D_Loss:0.491754412651062, G_Loss:4.669101715087891

iterator 1200, D_Loss:0.5109092593193054, G_Loss:4.116392135620117

iterator 1300, D_Loss:0.5572813153266907, G_Loss:4.501223564147949

iterator 1400, D_Loss:0.49451857805252075, G_Loss:2.9819159507751465

iterator 1500, D_Loss:0.5488391518592834, G_Loss:4.100557327270508

iterator 1600, D_Loss:0.5846407413482666, G_Loss:2.65817928314209

iterator 1700, D_Loss:0.5917638540267944, G_Loss:4.234947681427002

iterator 1800, D_Loss:0.6811306476593018, G_Loss:2.944343090057373

iterator 1900, D_Loss:0.5572483539581299, G_Loss:3.9674930572509766

iterator 2000, D_Loss:0.5215474367141724, G_Loss:3.276552677154541

iterator 2100, D_Loss:0.578885018825531, G_Loss:4.280118942260742

iterator 2200, D_Loss:0.7511704564094543, G_Loss:4.523340702056885

iterator 2300, D_Loss:0.5551996827125549, G_Loss:4.592586517333984

iterator 2400, D_Loss:0.912053644657135, G_Loss:4.732616424560547

iterator 2500, D_Loss:0.4987899661064148, G_Loss:4.63193416595459

iterator 2600, D_Loss:0.4878280758857727, G_Loss:4.8998494148254395

iterator 2700, D_Loss:0.5096639394760132, G_Loss:5.0612616539001465

iterator 2800, D_Loss:0.5249533653259277, G_Loss:5.808516025543213

iterator 2900, D_Loss:0.8345782160758972, G_Loss:1.5189833641052246

iterator 3000, D_Loss:0.6350375413894653, G_Loss:4.460063457489014

iterator 3100, D_Loss:0.6925415992736816, G_Loss:5.284146308898926

iterator 3200, D_Loss:0.5379531383514404, G_Loss:3.9308230876922607

iterator 3300, D_Loss:0.43940961360931396, G_Loss:5.1568403244018555

iterator 3400, D_Loss:0.5184736847877502, G_Loss:3.853593349456787

iterator 3500, D_Loss:0.5440479516983032, G_Loss:4.887845516204834

iterator 3600, D_Loss:0.45690277218818665, G_Loss:4.743776321411133

iterator 3700, D_Loss:0.5698224902153015, G_Loss:5.719967365264893

iterator 3800, D_Loss:0.5629324316978455, G_Loss:5.379117488861084

iterator 3900, D_Loss:0.5623088479042053, G_Loss:3.2918732166290283

iterator 4000, D_Loss:0.8495736718177795, G_Loss:2.7926316261291504

iterator 4100, D_Loss:0.9160535931587219, G_Loss:5.034117221832275

iterator 4200, D_Loss:0.8866037130355835, G_Loss:3.4720685482025146

iterator 4300, D_Loss:0.7968217730522156, G_Loss:4.763449668884277

iterator 4400, D_Loss:0.6927693486213684, G_Loss:2.772639513015747

iterator 4500, D_Loss:0.6519767642021179, G_Loss:3.861370325088501

iterator 4600, D_Loss:0.5251568555831909, G_Loss:2.3783864974975586

iterator 4700, D_Loss:0.5543105006217957, G_Loss:5.317139625549316

iterator 4800, D_Loss:1.1002521514892578, G_Loss:1.6531184911727905

iterator 4900, D_Loss:0.5154190063476562, G_Loss:3.2336764335632324

iterator 5000, D_Loss:0.5573945045471191, G_Loss:1.979607105255127

-----------Epoch 2-----------
iterator 100, D_Loss:0.5591350197792053, G_Loss:1.8048230409622192

iterator 200, D_Loss:0.7778691053390503, G_Loss:4.325650215148926

iterator 300, D_Loss:0.6590375900268555, G_Loss:5.738954067230225

iterator 400, D_Loss:0.9051594138145447, G_Loss:3.893364906311035

iterator 500, D_Loss:0.6297635436058044, G_Loss:3.1348793506622314

iterator 600, D_Loss:0.6640397310256958, G_Loss:4.0816850662231445

iterator 700, D_Loss:0.5569449067115784, G_Loss:5.038895606994629

iterator 800, D_Loss:0.6418688893318176, G_Loss:3.569180965423584

iterator 900, D_Loss:0.652250349521637, G_Loss:4.7675323486328125

iterator 1000, D_Loss:0.5324245095252991, G_Loss:4.944505214691162

iterator 1100, D_Loss:0.5396584868431091, G_Loss:2.9585044384002686

iterator 1200, D_Loss:0.5401765704154968, G_Loss:3.307246446609497

iterator 1300, D_Loss:0.6725749373435974, G_Loss:4.249922752380371

iterator 1400, D_Loss:0.6640400886535645, G_Loss:5.954018592834473

iterator 1500, D_Loss:0.5510726571083069, G_Loss:2.705369234085083

iterator 1600, D_Loss:0.5067858695983887, G_Loss:4.154995441436768

iterator 1700, D_Loss:0.6357617974281311, G_Loss:5.252378463745117

iterator 1800, D_Loss:0.5617201328277588, G_Loss:4.293063163757324

iterator 1900, D_Loss:0.49085965752601624, G_Loss:5.4493608474731445

iterator 2000, D_Loss:0.49208614230155945, G_Loss:2.2110753059387207

iterator 2100, D_Loss:0.6043741106987, G_Loss:4.199582099914551

iterator 2200, D_Loss:0.5525301694869995, G_Loss:4.776796340942383

iterator 2300, D_Loss:0.5278086066246033, G_Loss:4.79884672164917

iterator 2400, D_Loss:0.6049696207046509, G_Loss:5.636702060699463

iterator 2500, D_Loss:0.5030300617218018, G_Loss:5.478583812713623

iterator 2600, D_Loss:0.9887678623199463, G_Loss:4.854535102844238

iterator 2700, D_Loss:0.5121857523918152, G_Loss:5.534368991851807

iterator 2800, D_Loss:0.6990116238594055, G_Loss:5.6389594078063965

iterator 2900, D_Loss:0.5056824088096619, G_Loss:6.06990909576416

iterator 3000, D_Loss:0.6052085757255554, G_Loss:4.4639973640441895

iterator 3100, D_Loss:0.41462838649749756, G_Loss:3.7161946296691895

iterator 3200, D_Loss:0.5081729888916016, G_Loss:5.138165473937988

iterator 3300, D_Loss:0.4642118215560913, G_Loss:5.546416282653809

iterator 3400, D_Loss:0.46828600764274597, G_Loss:5.575273513793945

iterator 3500, D_Loss:0.5125900506973267, G_Loss:5.398036003112793

iterator 3600, D_Loss:0.5046343803405762, G_Loss:5.550414562225342

iterator 3700, D_Loss:0.4487677216529846, G_Loss:4.77501106262207

iterator 3800, D_Loss:0.47072291374206543, G_Loss:5.207470417022705

iterator 3900, D_Loss:0.4783245921134949, G_Loss:3.277527332305908

iterator 4000, D_Loss:0.5610529184341431, G_Loss:5.779764175415039

iterator 4100, D_Loss:0.4755096435546875, G_Loss:5.4420366287231445

iterator 4200, D_Loss:0.5601335763931274, G_Loss:1.9932236671447754

iterator 4300, D_Loss:0.4801650643348694, G_Loss:6.044734477996826

iterator 4400, D_Loss:0.4748276472091675, G_Loss:3.656339168548584

iterator 4500, D_Loss:1.028870701789856, G_Loss:5.567209720611572

iterator 4600, D_Loss:0.509014368057251, G_Loss:6.05504035949707

iterator 4700, D_Loss:0.5383135676383972, G_Loss:6.756932258605957

iterator 4800, D_Loss:0.5310648679733276, G_Loss:4.2540974617004395

iterator 4900, D_Loss:0.5595844984054565, G_Loss:2.786569595336914

iterator 5000, D_Loss:0.5451017618179321, G_Loss:5.383991241455078

-----------Epoch 3-----------
iterator 100, D_Loss:0.4681396186351776, G_Loss:7.007246494293213

iterator 200, D_Loss:0.510489821434021, G_Loss:4.281280040740967

iterator 300, D_Loss:0.45169875025749207, G_Loss:5.4393815994262695

iterator 400, D_Loss:0.5103047490119934, G_Loss:6.874772071838379

iterator 500, D_Loss:0.7498219609260559, G_Loss:4.012429714202881

iterator 600, D_Loss:0.45490843057632446, G_Loss:6.412398815155029

iterator 700, D_Loss:0.46748214960098267, G_Loss:6.965723514556885

iterator 800, D_Loss:0.4681437015533447, G_Loss:2.2660200595855713

iterator 900, D_Loss:0.5126505494117737, G_Loss:6.353755950927734

iterator 1000, D_Loss:0.44591450691223145, G_Loss:6.896575450897217

iterator 1100, D_Loss:0.4838302731513977, G_Loss:5.047556400299072

iterator 1200, D_Loss:0.4963691532611847, G_Loss:6.091464042663574

iterator 1300, D_Loss:0.4717881679534912, G_Loss:4.717024326324463

iterator 1400, D_Loss:0.5012496113777161, G_Loss:3.8940484523773193

iterator 1500, D_Loss:0.5649463534355164, G_Loss:6.793910980224609

iterator 1600, D_Loss:0.517799437046051, G_Loss:7.630868434906006

iterator 1700, D_Loss:0.45083045959472656, G_Loss:5.8449602127075195

iterator 1800, D_Loss:0.5023611783981323, G_Loss:6.063046455383301

iterator 1900, D_Loss:0.44275516271591187, G_Loss:6.44534158706665

iterator 2000, D_Loss:0.45634084939956665, G_Loss:8.981451034545898

iterator 2100, D_Loss:0.5127969980239868, G_Loss:7.560535907745361

iterator 2200, D_Loss:0.46821272373199463, G_Loss:7.338650226593018

iterator 2300, D_Loss:0.45222488045692444, G_Loss:7.659886360168457

iterator 2400, D_Loss:0.47149625420570374, G_Loss:9.767474174499512

iterator 2500, D_Loss:0.43931493163108826, G_Loss:8.469385147094727

iterator 2600, D_Loss:0.5548288226127625, G_Loss:6.625233173370361

iterator 2700, D_Loss:0.46161213517189026, G_Loss:8.708720207214355

iterator 2800, D_Loss:0.44523417949676514, G_Loss:6.960850715637207

iterator 2900, D_Loss:0.4794608950614929, G_Loss:11.174091339111328

iterator 3000, D_Loss:0.449712336063385, G_Loss:7.826426982879639

iterator 3100, D_Loss:0.6128183603286743, G_Loss:6.1222405433654785

iterator 3200, D_Loss:0.49434778094291687, G_Loss:7.766867637634277

iterator 3300, D_Loss:0.4781692624092102, G_Loss:8.658884048461914

iterator 3400, D_Loss:0.5055860280990601, G_Loss:8.220039367675781

iterator 3500, D_Loss:0.4682549834251404, G_Loss:6.588980197906494

iterator 3600, D_Loss:0.47912636399269104, G_Loss:7.988654136657715

iterator 3700, D_Loss:0.4733072519302368, G_Loss:7.871884346008301

iterator 3800, D_Loss:0.44415006041526794, G_Loss:8.169708251953125

iterator 3900, D_Loss:0.4453774690628052, G_Loss:8.754108428955078

iterator 4000, D_Loss:0.4269876480102539, G_Loss:9.785175323486328

iterator 4100, D_Loss:0.44088584184646606, G_Loss:7.508309841156006

iterator 4200, D_Loss:0.506060779094696, G_Loss:8.158820152282715

iterator 4300, D_Loss:0.4564255475997925, G_Loss:9.200396537780762

iterator 4400, D_Loss:0.44646698236465454, G_Loss:9.06120491027832

iterator 4500, D_Loss:0.4418575167655945, G_Loss:6.693710803985596

iterator 4600, D_Loss:0.4627179801464081, G_Loss:10.815760612487793

iterator 4700, D_Loss:0.4604552090167999, G_Loss:8.447514533996582

iterator 4800, D_Loss:0.4199891984462738, G_Loss:8.231815338134766

iterator 4900, D_Loss:0.45817527174949646, G_Loss:8.662569999694824

iterator 5000, D_Loss:0.4473273754119873, G_Loss:7.198785305023193

-----------Epoch 4-----------
iterator 100, D_Loss:0.42006418108940125, G_Loss:7.928926467895508

iterator 200, D_Loss:0.4618881344795227, G_Loss:9.857126235961914

iterator 300, D_Loss:0.4321644902229309, G_Loss:9.584624290466309

iterator 400, D_Loss:0.4507206082344055, G_Loss:9.088321685791016

iterator 500, D_Loss:0.46266865730285645, G_Loss:11.374932289123535

iterator 600, D_Loss:0.43003466725349426, G_Loss:10.645710945129395

iterator 700, D_Loss:0.43957406282424927, G_Loss:10.00622272491455

iterator 800, D_Loss:0.46638748049736023, G_Loss:9.291154861450195

iterator 900, D_Loss:0.47074928879737854, G_Loss:9.958660125732422

iterator 1000, D_Loss:0.42179831862449646, G_Loss:8.677499771118164

iterator 1100, D_Loss:0.43444010615348816, G_Loss:8.493583679199219

iterator 1200, D_Loss:0.4444003701210022, G_Loss:8.73968505859375

iterator 1300, D_Loss:0.4596611559391022, G_Loss:8.666910171508789

iterator 1400, D_Loss:0.42329761385917664, G_Loss:8.97945785522461

iterator 1500, D_Loss:0.44247207045555115, G_Loss:8.908366203308105

iterator 1600, D_Loss:0.44373294711112976, G_Loss:9.284619331359863

iterator 1700, D_Loss:0.41876837611198425, G_Loss:8.622615814208984

iterator 1800, D_Loss:0.43934041261672974, G_Loss:12.50367259979248

iterator 1900, D_Loss:0.44231125712394714, G_Loss:10.70397663116455

iterator 2000, D_Loss:0.41420796513557434, G_Loss:10.688874244689941

iterator 2100, D_Loss:0.4210813343524933, G_Loss:11.218871116638184

iterator 2200, D_Loss:0.4205043315887451, G_Loss:10.350945472717285

iterator 2300, D_Loss:0.42534807324409485, G_Loss:12.582807540893555

iterator 2400, D_Loss:0.43523791432380676, G_Loss:9.453832626342773

iterator 2500, D_Loss:0.45558884739875793, G_Loss:10.747636795043945

iterator 2600, D_Loss:0.4447498619556427, G_Loss:9.20678997039795

iterator 2700, D_Loss:0.4486807584762573, G_Loss:12.150543212890625

iterator 2800, D_Loss:0.4112198054790497, G_Loss:10.55458927154541

iterator 2900, D_Loss:0.4399715065956116, G_Loss:8.979754447937012

iterator 3000, D_Loss:0.4340137243270874, G_Loss:12.834107398986816

iterator 3100, D_Loss:0.4357820153236389, G_Loss:9.388447761535645

iterator 3200, D_Loss:0.4013386070728302, G_Loss:10.145235061645508

iterator 3300, D_Loss:0.4162806570529938, G_Loss:10.21863842010498

iterator 3400, D_Loss:0.4143577218055725, G_Loss:10.863256454467773

iterator 3500, D_Loss:0.460004061460495, G_Loss:8.577241897583008

iterator 3600, D_Loss:0.4283922016620636, G_Loss:9.971414566040039

iterator 3700, D_Loss:0.45346325635910034, G_Loss:10.007585525512695

iterator 3800, D_Loss:0.4484301507472992, G_Loss:10.241003036499023

iterator 3900, D_Loss:0.4717119038105011, G_Loss:9.498788833618164

iterator 4000, D_Loss:0.4133957624435425, G_Loss:10.44909954071045

iterator 4100, D_Loss:0.43073537945747375, G_Loss:9.98123836517334

iterator 4200, D_Loss:0.42030107975006104, G_Loss:10.138985633850098

iterator 4300, D_Loss:0.42356598377227783, G_Loss:10.611818313598633

iterator 4400, D_Loss:0.4510575830936432, G_Loss:11.261262893676758

iterator 4500, D_Loss:0.42299091815948486, G_Loss:10.268636703491211

iterator 4600, D_Loss:0.4194626212120056, G_Loss:9.173378944396973

iterator 4700, D_Loss:0.41793155670166016, G_Loss:11.335987091064453

iterator 4800, D_Loss:0.4319007694721222, G_Loss:10.64985466003418

iterator 4900, D_Loss:0.4307228624820709, G_Loss:9.808833122253418

iterator 5000, D_Loss:0.4135492146015167, G_Loss:10.449773788452148

-----------Epoch 5-----------
iterator 100, D_Loss:0.4199669063091278, G_Loss:11.620445251464844

iterator 200, D_Loss:0.4014361500740051, G_Loss:13.023599624633789

iterator 300, D_Loss:0.4380423426628113, G_Loss:11.72691822052002

iterator 400, D_Loss:0.4293064475059509, G_Loss:11.180299758911133

iterator 500, D_Loss:0.43376633524894714, G_Loss:11.697136878967285

iterator 600, D_Loss:0.4460419714450836, G_Loss:10.748259544372559

iterator 700, D_Loss:0.4395896792411804, G_Loss:10.493103981018066

iterator 800, D_Loss:0.43952301144599915, G_Loss:11.720734596252441

iterator 900, D_Loss:0.4355872571468353, G_Loss:10.293611526489258

iterator 1000, D_Loss:0.4451552927494049, G_Loss:10.083623886108398

iterator 1100, D_Loss:0.45253729820251465, G_Loss:11.61781120300293

iterator 1200, D_Loss:0.42854076623916626, G_Loss:11.049235343933105

iterator 1300, D_Loss:0.45548388361930847, G_Loss:12.035139083862305

iterator 1400, D_Loss:0.43136799335479736, G_Loss:12.747482299804688

iterator 1500, D_Loss:0.4298561215400696, G_Loss:10.7854642868042

iterator 1600, D_Loss:0.42043352127075195, G_Loss:10.567475318908691

iterator 1700, D_Loss:0.43061572313308716, G_Loss:11.355541229248047

iterator 1800, D_Loss:0.4443422257900238, G_Loss:9.994073867797852

iterator 1900, D_Loss:0.4227963984012604, G_Loss:12.05064868927002

iterator 2000, D_Loss:0.4201454818248749, G_Loss:11.624839782714844

iterator 2100, D_Loss:0.44660136103630066, G_Loss:11.707826614379883

iterator 2200, D_Loss:0.4338769316673279, G_Loss:11.1853609085083

iterator 2300, D_Loss:0.43983718752861023, G_Loss:11.514605522155762

iterator 2400, D_Loss:0.41556888818740845, G_Loss:9.970613479614258

iterator 2500, D_Loss:0.4217526614665985, G_Loss:12.211334228515625

iterator 2600, D_Loss:0.409392386674881, G_Loss:12.625852584838867

iterator 2700, D_Loss:0.42453309893608093, G_Loss:12.336014747619629

iterator 2800, D_Loss:0.4411144554615021, G_Loss:13.832539558410645

iterator 2900, D_Loss:0.44723209738731384, G_Loss:13.951733589172363

iterator 3000, D_Loss:0.4547552764415741, G_Loss:13.775187492370605

iterator 3100, D_Loss:0.440816730260849, G_Loss:13.981890678405762

iterator 3200, D_Loss:0.43717771768569946, G_Loss:12.85181999206543

iterator 3300, D_Loss:0.43001002073287964, G_Loss:12.154986381530762

iterator 3400, D_Loss:0.43435192108154297, G_Loss:11.7225923538208

iterator 3500, D_Loss:0.4318012595176697, G_Loss:13.423260688781738

iterator 3600, D_Loss:0.43324241042137146, G_Loss:11.6607084274292

iterator 3700, D_Loss:0.4192884862422943, G_Loss:12.05179214477539

iterator 3800, D_Loss:0.40727514028549194, G_Loss:12.143263816833496

iterator 3900, D_Loss:0.42689386010169983, G_Loss:11.283945083618164

iterator 4000, D_Loss:0.4272063970565796, G_Loss:14.0636625289917

iterator 4100, D_Loss:0.40477433800697327, G_Loss:12.995436668395996

iterator 4200, D_Loss:0.42279407382011414, G_Loss:12.863520622253418

iterator 4300, D_Loss:0.43436259031295776, G_Loss:12.660307884216309

iterator 4400, D_Loss:0.4226965010166168, G_Loss:13.120292663574219

iterator 4500, D_Loss:0.43691158294677734, G_Loss:13.516450881958008

iterator 4600, D_Loss:0.423571914434433, G_Loss:14.474656105041504

iterator 4700, D_Loss:0.41313791275024414, G_Loss:13.304512023925781

iterator 4800, D_Loss:0.45142248272895813, G_Loss:13.847335815429688

iterator 4900, D_Loss:0.4371050298213959, G_Loss:13.152026176452637

iterator 5000, D_Loss:0.4053329825401306, G_Loss:10.337409019470215

-----------Epoch 6-----------
iterator 100, D_Loss:0.42125797271728516, G_Loss:12.267210960388184

iterator 200, D_Loss:0.4091751277446747, G_Loss:11.889968872070312

iterator 300, D_Loss:0.4590606093406677, G_Loss:13.423717498779297

iterator 400, D_Loss:0.42987462878227234, G_Loss:13.673789024353027

iterator 500, D_Loss:0.4307049810886383, G_Loss:13.385640144348145

iterator 600, D_Loss:0.409353643655777, G_Loss:13.597514152526855

iterator 700, D_Loss:0.43114280700683594, G_Loss:13.23095417022705

iterator 800, D_Loss:0.42895421385765076, G_Loss:12.699567794799805

iterator 900, D_Loss:0.43264591693878174, G_Loss:12.447895050048828

iterator 1000, D_Loss:0.4036951959133148, G_Loss:12.144288063049316

iterator 1100, D_Loss:0.43523696064949036, G_Loss:12.067137718200684

iterator 1200, D_Loss:0.4317692220211029, G_Loss:12.876385688781738

iterator 1300, D_Loss:0.4076973795890808, G_Loss:13.554457664489746

iterator 1400, D_Loss:0.428096204996109, G_Loss:13.377108573913574

iterator 1500, D_Loss:0.4323303997516632, G_Loss:12.857681274414062

iterator 1600, D_Loss:0.43939509987831116, G_Loss:13.165735244750977

iterator 1700, D_Loss:0.39814725518226624, G_Loss:9.543062210083008

iterator 1800, D_Loss:0.4076082110404968, G_Loss:12.620863914489746

iterator 1900, D_Loss:0.44142404198646545, G_Loss:12.203546524047852

iterator 2000, D_Loss:0.4359859228134155, G_Loss:11.790589332580566

iterator 2100, D_Loss:0.43672052025794983, G_Loss:12.970616340637207

iterator 2200, D_Loss:0.4421148896217346, G_Loss:12.402490615844727

iterator 2300, D_Loss:0.43810343742370605, G_Loss:13.517407417297363

iterator 2400, D_Loss:0.4119924306869507, G_Loss:13.598934173583984

iterator 2500, D_Loss:0.4047416150569916, G_Loss:14.178915977478027

iterator 2600, D_Loss:0.40694311261177063, G_Loss:13.873186111450195

iterator 2700, D_Loss:0.3969542980194092, G_Loss:12.985278129577637

iterator 2800, D_Loss:0.43738919496536255, G_Loss:12.796337127685547

iterator 2900, D_Loss:0.42846012115478516, G_Loss:13.035225868225098

iterator 3000, D_Loss:0.4200575649738312, G_Loss:12.73671817779541

iterator 3100, D_Loss:0.3975123167037964, G_Loss:15.020543098449707

iterator 3200, D_Loss:0.4339703917503357, G_Loss:14.895893096923828

iterator 3300, D_Loss:0.4176092743873596, G_Loss:14.169014930725098

iterator 3400, D_Loss:0.4374884068965912, G_Loss:14.136800765991211

iterator 3500, D_Loss:0.40950992703437805, G_Loss:14.151348114013672

iterator 3600, D_Loss:0.44543689489364624, G_Loss:13.74891471862793

iterator 3700, D_Loss:0.4074598550796509, G_Loss:13.597021102905273

iterator 3800, D_Loss:0.4233802258968353, G_Loss:12.511773109436035

iterator 3900, D_Loss:0.4348832666873932, G_Loss:13.213469505310059

iterator 4000, D_Loss:0.41104117035865784, G_Loss:12.900782585144043

iterator 4100, D_Loss:0.4183599054813385, G_Loss:14.070307731628418

iterator 4200, D_Loss:0.4005284309387207, G_Loss:12.902793884277344

iterator 4300, D_Loss:0.42345237731933594, G_Loss:12.866698265075684

iterator 4400, D_Loss:0.42960473895072937, G_Loss:14.024213790893555

iterator 4500, D_Loss:0.42198655009269714, G_Loss:14.349374771118164

iterator 4600, D_Loss:0.45476290583610535, G_Loss:13.216341018676758

iterator 4700, D_Loss:0.4328726530075073, G_Loss:13.67660140991211

iterator 4800, D_Loss:0.4216492176055908, G_Loss:12.173476219177246

iterator 4900, D_Loss:0.4686029255390167, G_Loss:13.171601295471191

iterator 5000, D_Loss:0.4208269715309143, G_Loss:13.557076454162598

-----------Epoch 7-----------
iterator 100, D_Loss:0.42961928248405457, G_Loss:14.100253105163574

iterator 200, D_Loss:0.4104963541030884, G_Loss:14.011913299560547

iterator 300, D_Loss:0.4100892245769501, G_Loss:12.6115140914917

iterator 400, D_Loss:0.40433430671691895, G_Loss:13.213061332702637

iterator 500, D_Loss:0.42060285806655884, G_Loss:15.121338844299316

iterator 600, D_Loss:0.4328608810901642, G_Loss:15.107221603393555

iterator 700, D_Loss:0.4559476375579834, G_Loss:13.321686744689941

iterator 800, D_Loss:0.4287911653518677, G_Loss:10.711919784545898

iterator 900, D_Loss:0.4211008548736572, G_Loss:13.978806495666504

iterator 1000, D_Loss:0.42563295364379883, G_Loss:13.069741249084473

iterator 1100, D_Loss:0.4388182759284973, G_Loss:13.62489128112793

iterator 1200, D_Loss:0.44869285821914673, G_Loss:14.724400520324707

iterator 1300, D_Loss:0.4304664134979248, G_Loss:13.165023803710938

iterator 1400, D_Loss:0.4190143942832947, G_Loss:13.200450897216797

iterator 1500, D_Loss:0.41281190514564514, G_Loss:14.507320404052734

iterator 1600, D_Loss:0.41638806462287903, G_Loss:12.96583366394043

iterator 1700, D_Loss:0.41543835401535034, G_Loss:13.259568214416504

iterator 1800, D_Loss:0.42690056562423706, G_Loss:13.649789810180664

iterator 1900, D_Loss:0.4299297332763672, G_Loss:13.4820556640625

iterator 2000, D_Loss:0.4093017876148224, G_Loss:13.318307876586914

iterator 2100, D_Loss:0.4147548973560333, G_Loss:12.876482009887695

iterator 2200, D_Loss:0.445639967918396, G_Loss:14.19260025024414

iterator 2300, D_Loss:0.42899027466773987, G_Loss:15.989375114440918

iterator 2400, D_Loss:0.4481102526187897, G_Loss:12.6325044631958

iterator 2500, D_Loss:0.42274969816207886, G_Loss:10.888873100280762

iterator 2600, D_Loss:0.4246659576892853, G_Loss:14.2221040725708

iterator 2700, D_Loss:0.4150920808315277, G_Loss:14.335407257080078

iterator 2800, D_Loss:0.4314027428627014, G_Loss:14.73632526397705

iterator 2900, D_Loss:0.40214574337005615, G_Loss:13.8562650680542

iterator 3000, D_Loss:0.4148154556751251, G_Loss:13.591236114501953

iterator 3100, D_Loss:0.4330718517303467, G_Loss:15.392657279968262

iterator 3200, D_Loss:0.4299549460411072, G_Loss:12.868045806884766

iterator 3300, D_Loss:0.4124883711338043, G_Loss:13.673052787780762

iterator 3400, D_Loss:0.3984067738056183, G_Loss:12.446276664733887

iterator 3500, D_Loss:0.4310862123966217, G_Loss:15.783611297607422

iterator 3600, D_Loss:0.4315136969089508, G_Loss:14.89437484741211

iterator 3700, D_Loss:0.45241039991378784, G_Loss:13.806939125061035

iterator 3800, D_Loss:0.42102718353271484, G_Loss:13.73370361328125

iterator 3900, D_Loss:0.452534019947052, G_Loss:12.784480094909668

iterator 4000, D_Loss:0.44152459502220154, G_Loss:12.38579273223877

iterator 4100, D_Loss:0.42365676164627075, G_Loss:14.802038192749023

iterator 4200, D_Loss:0.44184446334838867, G_Loss:12.704133987426758

iterator 4300, D_Loss:0.4415663182735443, G_Loss:14.558306694030762

iterator 4400, D_Loss:0.4615721106529236, G_Loss:14.126582145690918

iterator 4500, D_Loss:0.4135884940624237, G_Loss:15.641000747680664

iterator 4600, D_Loss:0.42406192421913147, G_Loss:13.583632469177246

iterator 4700, D_Loss:0.4278864860534668, G_Loss:12.184541702270508

iterator 4800, D_Loss:0.4383034110069275, G_Loss:13.053204536437988

iterator 4900, D_Loss:0.45949190855026245, G_Loss:13.521675109863281

iterator 5000, D_Loss:0.41684749722480774, G_Loss:15.416425704956055

-----------Epoch 8-----------
iterator 100, D_Loss:0.44448480010032654, G_Loss:12.374122619628906

iterator 200, D_Loss:0.42429327964782715, G_Loss:14.655162811279297

iterator 300, D_Loss:0.4346774220466614, G_Loss:15.270502090454102

iterator 400, D_Loss:0.41519686579704285, G_Loss:12.827556610107422

iterator 500, D_Loss:0.45646989345550537, G_Loss:15.646421432495117

iterator 600, D_Loss:0.42442649602890015, G_Loss:11.622537612915039

iterator 700, D_Loss:0.42354410886764526, G_Loss:15.261392593383789

iterator 800, D_Loss:0.4294232130050659, G_Loss:14.787094116210938

iterator 900, D_Loss:0.4441070854663849, G_Loss:14.22266960144043

iterator 1000, D_Loss:0.4202736020088196, G_Loss:13.939005851745605

iterator 1100, D_Loss:0.3955839276313782, G_Loss:12.755707740783691

iterator 1200, D_Loss:0.45857149362564087, G_Loss:14.557328224182129

iterator 1300, D_Loss:0.4413970112800598, G_Loss:14.3941068649292

iterator 1400, D_Loss:0.40635359287261963, G_Loss:13.054922103881836

iterator 1500, D_Loss:0.4119933247566223, G_Loss:14.446701049804688

iterator 1600, D_Loss:0.42709824442863464, G_Loss:12.28970718383789

iterator 1700, D_Loss:0.44415584206581116, G_Loss:15.336009979248047

iterator 1800, D_Loss:0.4128722846508026, G_Loss:14.878935813903809

iterator 1900, D_Loss:0.4181942641735077, G_Loss:14.803563117980957

iterator 2000, D_Loss:0.4250919222831726, G_Loss:13.57193374633789

iterator 2100, D_Loss:0.40167808532714844, G_Loss:13.712930679321289

iterator 2200, D_Loss:0.4428367018699646, G_Loss:14.445961952209473

iterator 2300, D_Loss:0.43795961141586304, G_Loss:14.101454734802246

iterator 2400, D_Loss:0.4243791699409485, G_Loss:14.343608856201172

iterator 2500, D_Loss:0.4394513666629791, G_Loss:10.14215087890625

iterator 2600, D_Loss:0.40814584493637085, G_Loss:14.696234703063965

iterator 2700, D_Loss:0.4103134274482727, G_Loss:14.67861557006836

iterator 2800, D_Loss:0.42969053983688354, G_Loss:12.97210693359375

iterator 2900, D_Loss:0.4410737156867981, G_Loss:13.863146781921387

iterator 3000, D_Loss:0.4166344106197357, G_Loss:13.44246768951416

iterator 3100, D_Loss:0.4179641008377075, G_Loss:14.624188423156738

iterator 3200, D_Loss:0.4215843975543976, G_Loss:15.034635543823242

iterator 3300, D_Loss:0.4247683584690094, G_Loss:14.316762924194336

iterator 3400, D_Loss:0.4180332124233246, G_Loss:13.671177864074707

iterator 3500, D_Loss:0.42399799823760986, G_Loss:11.282877922058105

iterator 3600, D_Loss:0.4319121837615967, G_Loss:15.978303909301758

iterator 3700, D_Loss:0.426973432302475, G_Loss:13.883049964904785

iterator 3800, D_Loss:0.4265991449356079, G_Loss:15.36430549621582

iterator 3900, D_Loss:0.40466657280921936, G_Loss:15.770459175109863

iterator 4000, D_Loss:0.4395389258861542, G_Loss:13.537994384765625

iterator 4100, D_Loss:0.4372004270553589, G_Loss:14.004087448120117

iterator 4200, D_Loss:0.4287629723548889, G_Loss:13.669116973876953

iterator 4300, D_Loss:0.4169960916042328, G_Loss:14.3901948928833

iterator 4400, D_Loss:0.43225958943367004, G_Loss:12.868227005004883

iterator 4500, D_Loss:0.4275996685028076, G_Loss:14.372733116149902

iterator 4600, D_Loss:0.4303656816482544, G_Loss:15.121299743652344

iterator 4700, D_Loss:0.43628817796707153, G_Loss:14.946002006530762

iterator 4800, D_Loss:0.3966660797595978, G_Loss:13.885296821594238

iterator 4900, D_Loss:0.42617499828338623, G_Loss:13.980644226074219

iterator 5000, D_Loss:0.44597959518432617, G_Loss:10.054983139038086

-----------Epoch 9-----------
iterator 100, D_Loss:0.4072660803794861, G_Loss:16.429304122924805

iterator 200, D_Loss:0.4226379096508026, G_Loss:13.741053581237793

iterator 300, D_Loss:0.40115100145339966, G_Loss:14.477655410766602

iterator 400, D_Loss:0.4109112024307251, G_Loss:14.069117546081543

iterator 500, D_Loss:0.4141576290130615, G_Loss:15.18505859375

iterator 600, D_Loss:0.43312403559684753, G_Loss:15.048992156982422

iterator 700, D_Loss:0.4194673001766205, G_Loss:13.553337097167969

iterator 800, D_Loss:0.4105340242385864, G_Loss:14.608382225036621

iterator 900, D_Loss:0.4522963762283325, G_Loss:15.83154582977295

iterator 1000, D_Loss:0.4156114161014557, G_Loss:14.16147232055664

iterator 1100, D_Loss:0.43222135305404663, G_Loss:14.548978805541992

iterator 1200, D_Loss:0.42318084836006165, G_Loss:13.543428421020508

iterator 1300, D_Loss:0.4193437695503235, G_Loss:12.864861488342285

iterator 1400, D_Loss:0.42748937010765076, G_Loss:13.621950149536133

iterator 1500, D_Loss:0.4400659501552582, G_Loss:14.274688720703125

iterator 1600, D_Loss:0.42884016036987305, G_Loss:13.370452880859375

iterator 1700, D_Loss:0.41715601086616516, G_Loss:12.702445030212402

iterator 1800, D_Loss:0.44146883487701416, G_Loss:15.387779235839844

iterator 1900, D_Loss:0.41851621866226196, G_Loss:14.835620880126953

iterator 2000, D_Loss:0.4275705814361572, G_Loss:16.753145217895508

iterator 2100, D_Loss:0.42074188590049744, G_Loss:15.43956470489502

iterator 2200, D_Loss:0.40850287675857544, G_Loss:13.919394493103027

iterator 2300, D_Loss:0.4281937777996063, G_Loss:13.84921932220459

iterator 2400, D_Loss:0.4252166748046875, G_Loss:14.14195442199707

iterator 2500, D_Loss:0.41890156269073486, G_Loss:13.991935729980469

iterator 2600, D_Loss:0.4165104925632477, G_Loss:13.471158981323242

iterator 2700, D_Loss:0.4498005211353302, G_Loss:14.048308372497559

iterator 2800, D_Loss:0.41345465183258057, G_Loss:14.608945846557617

iterator 2900, D_Loss:0.43715375661849976, G_Loss:14.208352088928223

iterator 3000, D_Loss:0.44225332140922546, G_Loss:14.08879280090332

iterator 3100, D_Loss:0.44736260175704956, G_Loss:14.935508728027344

iterator 3200, D_Loss:0.41585755348205566, G_Loss:16.105316162109375

iterator 3300, D_Loss:0.42460161447525024, G_Loss:15.812420845031738

iterator 3400, D_Loss:0.3993649482727051, G_Loss:14.801665306091309

iterator 3500, D_Loss:0.41727250814437866, G_Loss:14.95505428314209

iterator 3600, D_Loss:0.45071396231651306, G_Loss:14.970474243164062

iterator 3700, D_Loss:0.4518359899520874, G_Loss:14.881965637207031

iterator 3800, D_Loss:0.4357506334781647, G_Loss:13.593347549438477

iterator 3900, D_Loss:0.4160180687904358, G_Loss:12.045754432678223

iterator 4000, D_Loss:0.4213443994522095, G_Loss:13.852471351623535

iterator 4100, D_Loss:0.40475744009017944, G_Loss:15.036842346191406

iterator 4200, D_Loss:0.43775537610054016, G_Loss:13.684037208557129

iterator 4300, D_Loss:0.4367499351501465, G_Loss:12.848081588745117

iterator 4400, D_Loss:0.4601169228553772, G_Loss:14.88064956665039

iterator 4500, D_Loss:0.4350399076938629, G_Loss:15.034483909606934

iterator 4600, D_Loss:0.4069828391075134, G_Loss:14.189059257507324

iterator 4700, D_Loss:0.4112483263015747, G_Loss:14.69972038269043

iterator 4800, D_Loss:0.41875705122947693, G_Loss:14.577383995056152

iterator 4900, D_Loss:0.4145534634590149, G_Loss:13.509323120117188

iterator 5000, D_Loss:0.44989848136901855, G_Loss:15.938072204589844

LGAN_generator(
  (LSTM): LSTMCell(700, 200)
  (gmfc00): Linear(in_features=300, out_features=1, bias=True)
  (gmfc01): Linear(in_features=300, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=300, bias=True)
  (gmfe00): Linear(in_features=200, out_features=300, bias=True)
  (gmfe01): Linear(in_features=200, out_features=300, bias=True)
  (fc10): Linear(in_features=300, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=300, bias=True)
  (fe1): Linear(in_features=200, out_features=300, bias=True)
  (gmfc20): Linear(in_features=300, out_features=1, bias=True)
  (gmfc21): Linear(in_features=300, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=300, bias=True)
  (gmfe20): Linear(in_features=200, out_features=300, bias=True)
  (gmfe21): Linear(in_features=200, out_features=300, bias=True)
  (fc30): Linear(in_features=300, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=300, bias=True)
  (fe3): Linear(in_features=200, out_features=300, bias=True)
  (gmfc40): Linear(in_features=300, out_features=1, bias=True)
  (gmfc41): Linear(in_features=300, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=300, bias=True)
  (gmfe40): Linear(in_features=200, out_features=300, bias=True)
  (gmfe41): Linear(in_features=200, out_features=300, bias=True)
  (fc50): Linear(in_features=300, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=300, bias=True)
  (fe5): Linear(in_features=200, out_features=300, bias=True)
  (fc60): Linear(in_features=300, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=300, bias=True)
  (fe6): Linear(in_features=200, out_features=300, bias=True)
  (fc70): Linear(in_features=300, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=300, bias=True)
  (fe7): Linear(in_features=200, out_features=300, bias=True)
  (fc80): Linear(in_features=300, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=300, bias=True)
  (fe8): Linear(in_features=200, out_features=300, bias=True)
  (fc90): Linear(in_features=300, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=300, bias=True)
  (fe9): Linear(in_features=200, out_features=300, bias=True)
  (gmfc100): Linear(in_features=300, out_features=1, bias=True)
  (gmfc101): Linear(in_features=300, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=300, bias=True)
  (gmfe100): Linear(in_features=200, out_features=300, bias=True)
  (gmfe101): Linear(in_features=200, out_features=300, bias=True)
  (gmfc110): Linear(in_features=300, out_features=1, bias=True)
  (gmfc111): Linear(in_features=300, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=300, bias=True)
  (gmfe110): Linear(in_features=200, out_features=300, bias=True)
  (gmfe111): Linear(in_features=200, out_features=300, bias=True)
  (gmfc120): Linear(in_features=300, out_features=1, bias=True)
  (gmfc121): Linear(in_features=300, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=300, bias=True)
  (gmfe120): Linear(in_features=200, out_features=300, bias=True)
  (gmfe121): Linear(in_features=200, out_features=300, bias=True)
  (fc130): Linear(in_features=300, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=300, bias=True)
  (fe13): Linear(in_features=200, out_features=300, bias=True)
  (fc140): Linear(in_features=300, out_features=2, bias=True)
  (fc141): Linear(in_features=2, out_features=300, bias=True)
  (fe14): Linear(in_features=200, out_features=300, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=400, bias=True)
  (inputbn): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=400, out_features=400, bias=True)
  (bn0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=400, bias=True)
  (bn1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=400, out_features=1, bias=True)
)
(0, False, 135)
-----------Epoch 0-----------
iterator 100, D_Loss:1.3908119201660156, G_Loss:1.0221434831619263

iterator 200, D_Loss:1.3456177711486816, G_Loss:1.0317655801773071

iterator 300, D_Loss:1.2631945610046387, G_Loss:1.1608613729476929

iterator 400, D_Loss:1.1927037239074707, G_Loss:1.3803164958953857

iterator 500, D_Loss:1.070823311805725, G_Loss:1.4426556825637817

iterator 600, D_Loss:1.1276072263717651, G_Loss:1.95980703830719

iterator 700, D_Loss:0.9042019844055176, G_Loss:2.4937429428100586

iterator 800, D_Loss:0.8059965372085571, G_Loss:1.3273433446884155

iterator 900, D_Loss:0.6722528338432312, G_Loss:3.9968628883361816

iterator 1000, D_Loss:0.6258904933929443, G_Loss:3.0959346294403076

iterator 1100, D_Loss:0.7039092183113098, G_Loss:2.83626127243042

iterator 1200, D_Loss:0.5822652578353882, G_Loss:3.686842203140259

iterator 1300, D_Loss:0.5218231081962585, G_Loss:4.397302150726318

iterator 1400, D_Loss:0.5422735214233398, G_Loss:4.076982021331787

iterator 1500, D_Loss:0.5602715015411377, G_Loss:4.579020023345947

iterator 1600, D_Loss:0.5485900640487671, G_Loss:4.659805774688721

iterator 1700, D_Loss:0.5569840669631958, G_Loss:3.270369291305542

iterator 1800, D_Loss:0.5859912633895874, G_Loss:4.455564498901367

iterator 1900, D_Loss:0.5025745034217834, G_Loss:5.587836265563965

iterator 2000, D_Loss:0.4969673156738281, G_Loss:4.266477108001709

iterator 2100, D_Loss:0.4958168864250183, G_Loss:4.8793559074401855

iterator 2200, D_Loss:0.49721258878707886, G_Loss:4.105836868286133

iterator 2300, D_Loss:0.5367079973220825, G_Loss:4.566453456878662

iterator 2400, D_Loss:0.5177165269851685, G_Loss:5.0653252601623535

iterator 2500, D_Loss:0.4922182857990265, G_Loss:4.532366752624512

iterator 2600, D_Loss:0.492422491312027, G_Loss:5.265653610229492

iterator 2700, D_Loss:0.502755880355835, G_Loss:5.16873025894165

iterator 2800, D_Loss:0.5501154661178589, G_Loss:5.296962261199951

iterator 2900, D_Loss:0.4924097955226898, G_Loss:4.988107204437256

iterator 3000, D_Loss:0.47677573561668396, G_Loss:5.652472972869873

iterator 3100, D_Loss:0.46927016973495483, G_Loss:5.546763896942139

iterator 3200, D_Loss:0.5252659320831299, G_Loss:4.153069972991943

iterator 3300, D_Loss:0.5355699062347412, G_Loss:6.8441009521484375

iterator 3400, D_Loss:0.5305928587913513, G_Loss:4.26616096496582

iterator 3500, D_Loss:0.4702576994895935, G_Loss:4.263834476470947

iterator 3600, D_Loss:0.5222597718238831, G_Loss:3.9627182483673096

iterator 3700, D_Loss:0.4819183647632599, G_Loss:5.152249336242676

iterator 3800, D_Loss:0.47836390137672424, G_Loss:5.181969165802002

iterator 3900, D_Loss:0.47379186749458313, G_Loss:4.608805179595947

iterator 4000, D_Loss:0.4906769394874573, G_Loss:4.5269341468811035

iterator 4100, D_Loss:0.4733092784881592, G_Loss:5.620060920715332

iterator 4200, D_Loss:0.48749080300331116, G_Loss:5.986203670501709

iterator 4300, D_Loss:0.4987342655658722, G_Loss:5.923679351806641

iterator 4400, D_Loss:0.4947812259197235, G_Loss:5.777425765991211

iterator 4500, D_Loss:0.4657810628414154, G_Loss:5.165050029754639

iterator 4600, D_Loss:0.48885378241539, G_Loss:5.8450398445129395

iterator 4700, D_Loss:0.4605458378791809, G_Loss:6.317364692687988

iterator 4800, D_Loss:0.45807352662086487, G_Loss:5.659513473510742

iterator 4900, D_Loss:0.48742353916168213, G_Loss:6.108470916748047

iterator 5000, D_Loss:0.4409130811691284, G_Loss:6.076016426086426

-----------Epoch 1-----------
iterator 100, D_Loss:0.4689328968524933, G_Loss:6.058305740356445

iterator 200, D_Loss:0.455465704202652, G_Loss:6.733245849609375

iterator 300, D_Loss:0.4835430383682251, G_Loss:6.221107006072998

iterator 400, D_Loss:0.4647446572780609, G_Loss:6.412877082824707

iterator 500, D_Loss:0.44707706570625305, G_Loss:7.054902076721191

iterator 600, D_Loss:0.45206040143966675, G_Loss:6.67626428604126

iterator 700, D_Loss:0.45859184861183167, G_Loss:7.034317493438721

iterator 800, D_Loss:0.4329739809036255, G_Loss:6.813776969909668

iterator 900, D_Loss:0.46697866916656494, G_Loss:6.98964262008667

iterator 1000, D_Loss:0.4284086525440216, G_Loss:7.385704040527344

iterator 1100, D_Loss:0.43897008895874023, G_Loss:8.373319625854492

iterator 1200, D_Loss:0.4594030976295471, G_Loss:7.651120185852051

iterator 1300, D_Loss:0.45625901222229004, G_Loss:5.4840288162231445

iterator 1400, D_Loss:0.43564221262931824, G_Loss:8.220741271972656

iterator 1500, D_Loss:0.44670987129211426, G_Loss:7.319628715515137

iterator 1600, D_Loss:0.42341047525405884, G_Loss:9.107270240783691

iterator 1700, D_Loss:0.4322061836719513, G_Loss:8.192922592163086

iterator 1800, D_Loss:0.4543113112449646, G_Loss:10.384992599487305

iterator 1900, D_Loss:0.4440595507621765, G_Loss:7.811772346496582

iterator 2000, D_Loss:0.4197820723056793, G_Loss:7.688231468200684

iterator 2100, D_Loss:0.43590980768203735, G_Loss:6.9238176345825195

iterator 2200, D_Loss:0.4382511079311371, G_Loss:8.401293754577637

iterator 2300, D_Loss:0.460845410823822, G_Loss:8.798397064208984

iterator 2400, D_Loss:0.4271680414676666, G_Loss:9.942811965942383

iterator 2500, D_Loss:0.4421326518058777, G_Loss:8.967622756958008

iterator 2600, D_Loss:0.4363396465778351, G_Loss:8.796817779541016

iterator 2700, D_Loss:0.4313826262950897, G_Loss:7.705536365509033

iterator 2800, D_Loss:0.4438655376434326, G_Loss:8.706197738647461

iterator 2900, D_Loss:0.43234920501708984, G_Loss:9.250922203063965

iterator 3000, D_Loss:0.4384195804595947, G_Loss:10.057051658630371

iterator 3100, D_Loss:0.41904354095458984, G_Loss:9.855149269104004

iterator 3200, D_Loss:0.4384807050228119, G_Loss:8.739032745361328

iterator 3300, D_Loss:0.4268777668476105, G_Loss:10.623809814453125

iterator 3400, D_Loss:0.433586984872818, G_Loss:10.004504203796387

iterator 3500, D_Loss:0.41112658381462097, G_Loss:9.246925354003906

iterator 3600, D_Loss:0.41589128971099854, G_Loss:8.17850112915039

iterator 3700, D_Loss:0.4175433814525604, G_Loss:9.249378204345703

iterator 3800, D_Loss:0.44307419657707214, G_Loss:10.270392417907715

iterator 3900, D_Loss:0.41253525018692017, G_Loss:9.665032386779785

iterator 4000, D_Loss:0.43720826506614685, G_Loss:9.273341178894043

iterator 4100, D_Loss:0.4301415979862213, G_Loss:11.45413875579834

iterator 4200, D_Loss:0.42582041025161743, G_Loss:9.340688705444336

iterator 4300, D_Loss:0.43937137722969055, G_Loss:9.032032012939453

iterator 4400, D_Loss:0.4272707998752594, G_Loss:9.518051147460938

iterator 4500, D_Loss:0.43089714646339417, G_Loss:11.827264785766602

iterator 4600, D_Loss:0.4229644536972046, G_Loss:9.64628791809082

iterator 4700, D_Loss:0.43142038583755493, G_Loss:8.948447227478027

iterator 4800, D_Loss:0.4387308359146118, G_Loss:9.053507804870605

iterator 4900, D_Loss:0.4336121082305908, G_Loss:11.743640899658203

iterator 5000, D_Loss:0.4481639862060547, G_Loss:7.66241455078125

-----------Epoch 2-----------
iterator 100, D_Loss:0.43484336137771606, G_Loss:12.4974946975708

iterator 200, D_Loss:0.4214900732040405, G_Loss:12.212746620178223

iterator 300, D_Loss:0.42690736055374146, G_Loss:9.868281364440918

iterator 400, D_Loss:0.4347017705440521, G_Loss:10.347578048706055

iterator 500, D_Loss:0.42512577772140503, G_Loss:9.99384593963623

iterator 600, D_Loss:0.4304652512073517, G_Loss:11.218063354492188

iterator 700, D_Loss:0.45476123690605164, G_Loss:9.96402645111084

iterator 800, D_Loss:0.4423961639404297, G_Loss:10.367908477783203

iterator 900, D_Loss:0.45017728209495544, G_Loss:11.6544828414917

iterator 1000, D_Loss:0.410241961479187, G_Loss:11.619647979736328

iterator 1100, D_Loss:0.44424018263816833, G_Loss:10.519184112548828

iterator 1200, D_Loss:0.43150216341018677, G_Loss:12.34885025024414

iterator 1300, D_Loss:0.4294617474079132, G_Loss:9.594446182250977

iterator 1400, D_Loss:0.4343726634979248, G_Loss:12.768829345703125

iterator 1500, D_Loss:0.45242980122566223, G_Loss:8.98792552947998

iterator 1600, D_Loss:0.4306640923023224, G_Loss:11.450786590576172

iterator 1700, D_Loss:0.43562132120132446, G_Loss:14.510923385620117

iterator 1800, D_Loss:0.4177778661251068, G_Loss:8.78540325164795

iterator 1900, D_Loss:0.43491390347480774, G_Loss:10.87247085571289

iterator 2000, D_Loss:0.42999497056007385, G_Loss:13.00174331665039

iterator 2100, D_Loss:0.4327182471752167, G_Loss:10.724172592163086

iterator 2200, D_Loss:0.4354742467403412, G_Loss:11.42259407043457

iterator 2300, D_Loss:0.42080453038215637, G_Loss:9.382464408874512

iterator 2400, D_Loss:0.4245084822177887, G_Loss:12.051968574523926

iterator 2500, D_Loss:0.43133461475372314, G_Loss:12.449175834655762

iterator 2600, D_Loss:0.4490390121936798, G_Loss:14.43471908569336

iterator 2700, D_Loss:0.4216182827949524, G_Loss:10.900861740112305

iterator 2800, D_Loss:0.4402428865432739, G_Loss:10.55195140838623

iterator 2900, D_Loss:0.43764638900756836, G_Loss:8.754609107971191

iterator 3000, D_Loss:0.4315018057823181, G_Loss:12.106555938720703

iterator 3100, D_Loss:0.42299607396125793, G_Loss:11.999617576599121

iterator 3200, D_Loss:0.4218684732913971, G_Loss:9.29832649230957

iterator 3300, D_Loss:0.4301988184452057, G_Loss:10.586325645446777

iterator 3400, D_Loss:0.41552165150642395, G_Loss:11.866239547729492

iterator 3500, D_Loss:0.42688798904418945, G_Loss:10.056356430053711

iterator 3600, D_Loss:0.4340689778327942, G_Loss:13.480607032775879

iterator 3700, D_Loss:0.42550474405288696, G_Loss:15.419578552246094

iterator 3800, D_Loss:0.43525928258895874, G_Loss:13.348064422607422

iterator 3900, D_Loss:0.4314407408237457, G_Loss:13.896530151367188

iterator 4000, D_Loss:0.4520120918750763, G_Loss:16.08525848388672

iterator 4100, D_Loss:0.4087583124637604, G_Loss:14.28305435180664

iterator 4200, D_Loss:0.42984285950660706, G_Loss:13.421561241149902

iterator 4300, D_Loss:0.4123401939868927, G_Loss:10.083617210388184

iterator 4400, D_Loss:0.4220406115055084, G_Loss:12.84676742553711

iterator 4500, D_Loss:0.4346828758716583, G_Loss:12.21619987487793

iterator 4600, D_Loss:0.44112181663513184, G_Loss:11.359933853149414

iterator 4700, D_Loss:0.4449259340763092, G_Loss:10.248618125915527

iterator 4800, D_Loss:0.4241582453250885, G_Loss:15.251288414001465

iterator 4900, D_Loss:0.43490156531333923, G_Loss:10.294331550598145

iterator 5000, D_Loss:0.44634249806404114, G_Loss:9.802750587463379

-----------Epoch 3-----------
iterator 100, D_Loss:0.4347155690193176, G_Loss:12.660106658935547

iterator 200, D_Loss:0.4238133132457733, G_Loss:15.117971420288086

iterator 300, D_Loss:0.42536333203315735, G_Loss:11.812345504760742

iterator 400, D_Loss:0.4132228493690491, G_Loss:12.149275779724121

iterator 500, D_Loss:0.42492425441741943, G_Loss:10.808650970458984

iterator 600, D_Loss:0.4181625247001648, G_Loss:10.637725830078125

iterator 700, D_Loss:0.45228102803230286, G_Loss:14.651524543762207

iterator 800, D_Loss:0.44140979647636414, G_Loss:14.229731559753418

iterator 900, D_Loss:0.4374348819255829, G_Loss:14.169715881347656

iterator 1000, D_Loss:0.42811912298202515, G_Loss:11.966680526733398

iterator 1100, D_Loss:0.42295199632644653, G_Loss:12.115433692932129

iterator 1200, D_Loss:0.4290074110031128, G_Loss:12.964925765991211

iterator 1300, D_Loss:0.42145276069641113, G_Loss:15.136481285095215

iterator 1400, D_Loss:0.4251347780227661, G_Loss:12.694424629211426

iterator 1500, D_Loss:0.43498530983924866, G_Loss:12.667478561401367

iterator 1600, D_Loss:0.43867307901382446, G_Loss:12.415013313293457

iterator 1700, D_Loss:0.4312118887901306, G_Loss:13.73715591430664

iterator 1800, D_Loss:0.4257941246032715, G_Loss:12.897822380065918

iterator 1900, D_Loss:0.4331740438938141, G_Loss:12.032638549804688

iterator 2000, D_Loss:0.4246973991394043, G_Loss:13.911436080932617

iterator 2100, D_Loss:0.4331567585468292, G_Loss:15.544469833374023

iterator 2200, D_Loss:0.44392499327659607, G_Loss:10.150253295898438

iterator 2300, D_Loss:0.4152776300907135, G_Loss:16.974069595336914

iterator 2400, D_Loss:0.4135897755622864, G_Loss:14.94823932647705

iterator 2500, D_Loss:0.435150146484375, G_Loss:8.08792781829834

iterator 2600, D_Loss:0.43302154541015625, G_Loss:11.251388549804688

iterator 2700, D_Loss:0.415988028049469, G_Loss:15.207232475280762

iterator 2800, D_Loss:0.4272007942199707, G_Loss:14.145063400268555

iterator 2900, D_Loss:0.43615540862083435, G_Loss:13.284950256347656

iterator 3000, D_Loss:0.40809255838394165, G_Loss:11.773964881896973

iterator 3100, D_Loss:0.41315722465515137, G_Loss:11.721389770507812

iterator 3200, D_Loss:0.4420735538005829, G_Loss:12.007421493530273

iterator 3300, D_Loss:0.40586817264556885, G_Loss:12.915876388549805

iterator 3400, D_Loss:0.41393837332725525, G_Loss:13.915801048278809

iterator 3500, D_Loss:0.42840325832366943, G_Loss:14.654613494873047

iterator 3600, D_Loss:0.4433242380619049, G_Loss:12.86579418182373

iterator 3700, D_Loss:0.440581738948822, G_Loss:8.215978622436523

iterator 3800, D_Loss:0.4219872057437897, G_Loss:14.935250282287598

iterator 3900, D_Loss:0.42272505164146423, G_Loss:14.723871231079102

iterator 4000, D_Loss:0.42590174078941345, G_Loss:8.59088134765625

iterator 4100, D_Loss:0.4127170443534851, G_Loss:12.621109008789062

iterator 4200, D_Loss:0.4296596348285675, G_Loss:14.163414001464844

iterator 4300, D_Loss:0.4357673227787018, G_Loss:13.110777854919434

iterator 4400, D_Loss:0.43104586005210876, G_Loss:15.871805191040039

iterator 4500, D_Loss:0.42045721411705017, G_Loss:10.295353889465332

iterator 4600, D_Loss:0.42960384488105774, G_Loss:8.159814834594727

iterator 4700, D_Loss:0.42584413290023804, G_Loss:12.152223587036133

iterator 4800, D_Loss:0.43682146072387695, G_Loss:11.428664207458496

iterator 4900, D_Loss:0.4245871305465698, G_Loss:14.683882713317871

iterator 5000, D_Loss:0.4246186912059784, G_Loss:11.79944896697998

-----------Epoch 4-----------
iterator 100, D_Loss:0.4240358769893646, G_Loss:14.073222160339355

iterator 200, D_Loss:0.41026541590690613, G_Loss:13.615943908691406

iterator 300, D_Loss:0.419089674949646, G_Loss:12.719420433044434

iterator 400, D_Loss:0.4312710165977478, G_Loss:13.883759498596191

iterator 500, D_Loss:0.4145754873752594, G_Loss:12.523719787597656

iterator 600, D_Loss:0.4232526123523712, G_Loss:12.48641586303711

iterator 700, D_Loss:0.41348907351493835, G_Loss:12.341974258422852

iterator 800, D_Loss:0.43742650747299194, G_Loss:14.20067024230957

iterator 900, D_Loss:0.41632676124572754, G_Loss:14.334630966186523

iterator 1000, D_Loss:0.42740023136138916, G_Loss:12.161709785461426

iterator 1100, D_Loss:0.42686381936073303, G_Loss:13.41298770904541

iterator 1200, D_Loss:0.43244895339012146, G_Loss:15.448657035827637

iterator 1300, D_Loss:0.4288482069969177, G_Loss:15.984947204589844

iterator 1400, D_Loss:0.43046805262565613, G_Loss:10.85898208618164

iterator 1500, D_Loss:0.4147995710372925, G_Loss:13.342768669128418

iterator 1600, D_Loss:0.41525155305862427, G_Loss:13.484600067138672

iterator 1700, D_Loss:0.44517362117767334, G_Loss:12.807002067565918

iterator 1800, D_Loss:0.39942675828933716, G_Loss:13.939987182617188

iterator 1900, D_Loss:0.4185124933719635, G_Loss:11.466259002685547

iterator 2000, D_Loss:0.4191785752773285, G_Loss:15.261707305908203

iterator 2100, D_Loss:0.4338431656360626, G_Loss:13.149312973022461

iterator 2200, D_Loss:0.4222094714641571, G_Loss:8.599289894104004

iterator 2300, D_Loss:0.4061383008956909, G_Loss:14.398916244506836

iterator 2400, D_Loss:0.42516830563545227, G_Loss:13.240680694580078

iterator 2500, D_Loss:0.4564540386199951, G_Loss:13.474028587341309

iterator 2600, D_Loss:0.4242205023765564, G_Loss:14.516768455505371

iterator 2700, D_Loss:0.4391779899597168, G_Loss:11.944513320922852

iterator 2800, D_Loss:0.4405995309352875, G_Loss:12.008094787597656

iterator 2900, D_Loss:0.42423468828201294, G_Loss:15.320629119873047

iterator 3000, D_Loss:0.44690126180648804, G_Loss:11.10175895690918

iterator 3100, D_Loss:0.4143640995025635, G_Loss:12.477169036865234

iterator 3200, D_Loss:0.4209883213043213, G_Loss:14.048015594482422

iterator 3300, D_Loss:0.4209570586681366, G_Loss:13.44438648223877

iterator 3400, D_Loss:0.4144427180290222, G_Loss:13.896530151367188

iterator 3500, D_Loss:0.44823598861694336, G_Loss:13.6563081741333

iterator 3600, D_Loss:0.41797780990600586, G_Loss:10.857991218566895

iterator 3700, D_Loss:0.4281231462955475, G_Loss:13.12943172454834

iterator 3800, D_Loss:0.41226083040237427, G_Loss:13.293915748596191

iterator 3900, D_Loss:0.4160861670970917, G_Loss:13.306901931762695

iterator 4000, D_Loss:0.42872822284698486, G_Loss:12.550497055053711

iterator 4100, D_Loss:0.4124322831630707, G_Loss:12.239673614501953

iterator 4200, D_Loss:0.4237775206565857, G_Loss:10.24498462677002

iterator 4300, D_Loss:0.4219520688056946, G_Loss:12.684593200683594

iterator 4400, D_Loss:0.42995744943618774, G_Loss:11.706040382385254

iterator 4500, D_Loss:0.4257136583328247, G_Loss:12.831602096557617

iterator 4600, D_Loss:0.42567986249923706, G_Loss:12.672850608825684

iterator 4700, D_Loss:0.4321579039096832, G_Loss:13.997066497802734

iterator 4800, D_Loss:0.4104732275009155, G_Loss:13.775402069091797

iterator 4900, D_Loss:0.42658528685569763, G_Loss:16.202383041381836

iterator 5000, D_Loss:0.46442070603370667, G_Loss:12.21114730834961

-----------Epoch 5-----------
iterator 100, D_Loss:0.4231317937374115, G_Loss:13.101642608642578

iterator 200, D_Loss:0.4408600926399231, G_Loss:16.930583953857422

iterator 300, D_Loss:0.42119595408439636, G_Loss:11.598381042480469

iterator 400, D_Loss:0.4183189272880554, G_Loss:14.200921058654785

iterator 500, D_Loss:0.41534683108329773, G_Loss:12.177140235900879

iterator 600, D_Loss:0.43405023217201233, G_Loss:13.711753845214844

iterator 700, D_Loss:0.43610116839408875, G_Loss:14.046186447143555

iterator 800, D_Loss:0.4385799467563629, G_Loss:9.9006929397583

iterator 900, D_Loss:0.4370361864566803, G_Loss:10.309182167053223

iterator 1000, D_Loss:0.4459623694419861, G_Loss:13.248567581176758

iterator 1100, D_Loss:0.4294434189796448, G_Loss:10.634708404541016

iterator 1200, D_Loss:0.41177406907081604, G_Loss:15.060454368591309

iterator 1300, D_Loss:0.4427693784236908, G_Loss:14.338136672973633

iterator 1400, D_Loss:0.40776658058166504, G_Loss:9.432233810424805

iterator 1500, D_Loss:0.4218197762966156, G_Loss:12.549083709716797

iterator 1600, D_Loss:0.4279409348964691, G_Loss:16.198165893554688

iterator 1700, D_Loss:0.43080705404281616, G_Loss:16.009624481201172

iterator 1800, D_Loss:0.42514801025390625, G_Loss:11.826375961303711

iterator 1900, D_Loss:0.4229414463043213, G_Loss:10.000496864318848

iterator 2000, D_Loss:0.42228519916534424, G_Loss:13.043973922729492

iterator 2100, D_Loss:0.4224660396575928, G_Loss:12.450339317321777

iterator 2200, D_Loss:0.4319455027580261, G_Loss:13.465118408203125

iterator 2300, D_Loss:0.44683384895324707, G_Loss:11.452889442443848

iterator 2400, D_Loss:0.4251652956008911, G_Loss:14.731816291809082

iterator 2500, D_Loss:0.43544185161590576, G_Loss:14.92187786102295

iterator 2600, D_Loss:0.43933528661727905, G_Loss:12.854957580566406

iterator 2700, D_Loss:0.4258994162082672, G_Loss:16.47838592529297

iterator 2800, D_Loss:0.43290507793426514, G_Loss:11.055831909179688

iterator 2900, D_Loss:0.4311344027519226, G_Loss:11.241890907287598

iterator 3000, D_Loss:0.43836671113967896, G_Loss:11.566067695617676

iterator 3100, D_Loss:0.4026455581188202, G_Loss:15.18437385559082

iterator 3200, D_Loss:0.4430187940597534, G_Loss:12.838445663452148

iterator 3300, D_Loss:0.42973822355270386, G_Loss:12.784923553466797

iterator 3400, D_Loss:0.43608367443084717, G_Loss:15.289361953735352

iterator 3500, D_Loss:0.41974276304244995, G_Loss:10.766698837280273

iterator 3600, D_Loss:0.4218406677246094, G_Loss:14.838683128356934

iterator 3700, D_Loss:0.4443932771682739, G_Loss:17.060226440429688

iterator 3800, D_Loss:0.43586111068725586, G_Loss:13.057239532470703

iterator 3900, D_Loss:0.40858614444732666, G_Loss:13.196699142456055

iterator 4000, D_Loss:0.42769861221313477, G_Loss:17.414323806762695

iterator 4100, D_Loss:0.4278810918331146, G_Loss:13.269744873046875

iterator 4200, D_Loss:0.44020694494247437, G_Loss:8.960396766662598

iterator 4300, D_Loss:0.4306950867176056, G_Loss:8.031826972961426

iterator 4400, D_Loss:0.44210323691368103, G_Loss:15.119904518127441

iterator 4500, D_Loss:0.40628424286842346, G_Loss:14.170174598693848

iterator 4600, D_Loss:0.4227719306945801, G_Loss:11.72984790802002

iterator 4700, D_Loss:0.4218001365661621, G_Loss:12.039259910583496

iterator 4800, D_Loss:0.4299302399158478, G_Loss:10.80717945098877

iterator 4900, D_Loss:0.41737619042396545, G_Loss:11.993831634521484

iterator 5000, D_Loss:0.42559927701950073, G_Loss:11.897709846496582

-----------Epoch 6-----------
iterator 100, D_Loss:0.436727374792099, G_Loss:10.575815200805664

iterator 200, D_Loss:0.4211544990539551, G_Loss:12.711812973022461

iterator 300, D_Loss:0.4429740905761719, G_Loss:12.12796688079834

iterator 400, D_Loss:0.43566015362739563, G_Loss:10.231907844543457

iterator 500, D_Loss:0.41963064670562744, G_Loss:11.333873748779297

iterator 600, D_Loss:0.41591891646385193, G_Loss:14.195612907409668

iterator 700, D_Loss:0.42294204235076904, G_Loss:13.889671325683594

iterator 800, D_Loss:0.45292216539382935, G_Loss:5.832430362701416

iterator 900, D_Loss:0.43953776359558105, G_Loss:9.256816864013672

iterator 1000, D_Loss:0.4417210519313812, G_Loss:12.561539649963379

iterator 1100, D_Loss:0.44532090425491333, G_Loss:10.094310760498047

iterator 1200, D_Loss:0.43719908595085144, G_Loss:13.058588981628418

iterator 1300, D_Loss:0.429718554019928, G_Loss:11.979190826416016

iterator 1400, D_Loss:0.43068063259124756, G_Loss:16.010822296142578

iterator 1500, D_Loss:0.424312561750412, G_Loss:7.94256067276001

iterator 1600, D_Loss:0.41905221343040466, G_Loss:19.016324996948242

iterator 1700, D_Loss:0.41154593229293823, G_Loss:13.631638526916504

iterator 1800, D_Loss:0.42759543657302856, G_Loss:14.337411880493164

iterator 1900, D_Loss:0.44370386004447937, G_Loss:15.082379341125488

iterator 2000, D_Loss:0.4137733578681946, G_Loss:11.16064739227295

iterator 2100, D_Loss:0.4361346960067749, G_Loss:14.814146995544434

iterator 2200, D_Loss:0.41966962814331055, G_Loss:14.885998725891113

iterator 2300, D_Loss:0.4284105896949768, G_Loss:9.694051742553711

iterator 2400, D_Loss:0.4253247082233429, G_Loss:12.558028221130371

iterator 2500, D_Loss:0.4290514290332794, G_Loss:16.507762908935547

iterator 2600, D_Loss:0.40847504138946533, G_Loss:15.306440353393555

iterator 2700, D_Loss:0.40736550092697144, G_Loss:9.260689735412598

iterator 2800, D_Loss:0.4180844724178314, G_Loss:14.397600173950195

iterator 2900, D_Loss:0.42890486121177673, G_Loss:14.817668914794922

iterator 3000, D_Loss:0.4319427013397217, G_Loss:14.94044303894043

iterator 3100, D_Loss:0.40933114290237427, G_Loss:15.169696807861328

iterator 3200, D_Loss:0.42780524492263794, G_Loss:17.08867645263672

iterator 3300, D_Loss:0.42817023396492004, G_Loss:13.336042404174805

iterator 3400, D_Loss:0.41969531774520874, G_Loss:14.009272575378418

iterator 3500, D_Loss:0.463262140750885, G_Loss:10.7808198928833

iterator 3600, D_Loss:0.4201447665691376, G_Loss:12.589183807373047

iterator 3700, D_Loss:0.4283764064311981, G_Loss:15.413131713867188

iterator 3800, D_Loss:0.42195549607276917, G_Loss:15.530632019042969

iterator 3900, D_Loss:0.4243367612361908, G_Loss:15.859819412231445

iterator 4000, D_Loss:0.40745827555656433, G_Loss:12.649435043334961

iterator 4100, D_Loss:0.4255712330341339, G_Loss:7.470040321350098

iterator 4200, D_Loss:0.4289667308330536, G_Loss:10.167726516723633

iterator 4300, D_Loss:0.4510367810726166, G_Loss:6.515673637390137

iterator 4400, D_Loss:0.421956330537796, G_Loss:11.418957710266113

iterator 4500, D_Loss:0.4440363645553589, G_Loss:11.125228881835938

iterator 4600, D_Loss:0.43750980496406555, G_Loss:15.332347869873047

iterator 4700, D_Loss:0.43334975838661194, G_Loss:15.261577606201172

iterator 4800, D_Loss:0.4356650710105896, G_Loss:15.63055419921875

iterator 4900, D_Loss:0.4364660680294037, G_Loss:13.063586235046387

iterator 5000, D_Loss:0.4275948107242584, G_Loss:11.755544662475586

-----------Epoch 7-----------
iterator 100, D_Loss:0.44009432196617126, G_Loss:15.639717102050781

iterator 200, D_Loss:0.43553224205970764, G_Loss:12.429459571838379

iterator 300, D_Loss:0.42545434832572937, G_Loss:11.546059608459473

iterator 400, D_Loss:0.4192235469818115, G_Loss:10.59486198425293

iterator 500, D_Loss:0.4176728129386902, G_Loss:13.193334579467773

iterator 600, D_Loss:0.4351022243499756, G_Loss:13.809812545776367

iterator 700, D_Loss:0.4281601309776306, G_Loss:11.125862121582031

iterator 800, D_Loss:0.4419005215167999, G_Loss:15.512711524963379

iterator 900, D_Loss:0.43580326437950134, G_Loss:13.021339416503906

iterator 1000, D_Loss:0.40811800956726074, G_Loss:13.700825691223145

iterator 1100, D_Loss:0.43084728717803955, G_Loss:14.158910751342773

iterator 1200, D_Loss:0.4090907871723175, G_Loss:15.881103515625

iterator 1300, D_Loss:0.42965182662010193, G_Loss:15.09544849395752

iterator 1400, D_Loss:0.4171445071697235, G_Loss:12.928565979003906

iterator 1500, D_Loss:0.42227745056152344, G_Loss:12.586718559265137

iterator 1600, D_Loss:0.4254944324493408, G_Loss:15.889434814453125

iterator 1700, D_Loss:0.4306240379810333, G_Loss:13.607796669006348

iterator 1800, D_Loss:0.4326099157333374, G_Loss:13.757835388183594

iterator 1900, D_Loss:0.4147404432296753, G_Loss:14.987682342529297

iterator 2000, D_Loss:0.4302120506763458, G_Loss:14.98082447052002

iterator 2100, D_Loss:0.4321984052658081, G_Loss:11.015680313110352

iterator 2200, D_Loss:0.4361666142940521, G_Loss:16.49270248413086

iterator 2300, D_Loss:0.427735298871994, G_Loss:13.24200439453125

iterator 2400, D_Loss:0.41801732778549194, G_Loss:18.0500545501709

iterator 2500, D_Loss:0.4485367238521576, G_Loss:17.64227294921875

iterator 2600, D_Loss:0.42414402961730957, G_Loss:18.016334533691406

iterator 2700, D_Loss:0.42353034019470215, G_Loss:20.886953353881836

iterator 2800, D_Loss:0.4368554949760437, G_Loss:16.81595802307129

iterator 2900, D_Loss:0.42378976941108704, G_Loss:18.143951416015625

iterator 3000, D_Loss:0.40974435210227966, G_Loss:14.39645004272461

iterator 3100, D_Loss:0.44880422949790955, G_Loss:14.323991775512695

iterator 3200, D_Loss:0.43140414357185364, G_Loss:15.399065017700195

iterator 3300, D_Loss:0.4290909469127655, G_Loss:18.769081115722656

iterator 3400, D_Loss:0.42574256658554077, G_Loss:18.97886848449707

iterator 3500, D_Loss:0.43475112318992615, G_Loss:14.437202453613281

iterator 3600, D_Loss:0.4318998456001282, G_Loss:15.761388778686523

iterator 3700, D_Loss:0.42294207215309143, G_Loss:16.222536087036133

iterator 3800, D_Loss:0.4199066460132599, G_Loss:17.226465225219727

iterator 3900, D_Loss:0.43529415130615234, G_Loss:17.00251007080078

iterator 4000, D_Loss:0.4175736904144287, G_Loss:11.137825012207031

iterator 4100, D_Loss:0.42836862802505493, G_Loss:16.075088500976562

iterator 4200, D_Loss:0.4403162896633148, G_Loss:14.973405838012695

iterator 4300, D_Loss:0.4318784475326538, G_Loss:17.357324600219727

iterator 4400, D_Loss:0.4417223334312439, G_Loss:15.24367904663086

iterator 4500, D_Loss:0.4274168014526367, G_Loss:16.575214385986328

iterator 4600, D_Loss:0.42361515760421753, G_Loss:14.793159484863281

iterator 4700, D_Loss:0.45004111528396606, G_Loss:15.564189910888672

iterator 4800, D_Loss:0.4320400059223175, G_Loss:14.752466201782227

iterator 4900, D_Loss:0.43097764253616333, G_Loss:13.50898551940918

iterator 5000, D_Loss:0.432728111743927, G_Loss:13.810123443603516

-----------Epoch 8-----------
iterator 100, D_Loss:0.4042629301548004, G_Loss:19.015689849853516

iterator 200, D_Loss:0.40226635336875916, G_Loss:15.66694164276123

iterator 300, D_Loss:0.4345552921295166, G_Loss:12.107563972473145

iterator 400, D_Loss:0.42202168703079224, G_Loss:16.482511520385742

iterator 500, D_Loss:0.4165235161781311, G_Loss:13.593559265136719

iterator 600, D_Loss:0.41900739073753357, G_Loss:17.769227981567383

iterator 700, D_Loss:0.4328673183917999, G_Loss:14.829357147216797

iterator 800, D_Loss:0.4241114854812622, G_Loss:14.592045783996582

iterator 900, D_Loss:0.430757611989975, G_Loss:13.988457679748535

iterator 1000, D_Loss:0.4142688810825348, G_Loss:12.455072402954102

iterator 1100, D_Loss:0.4238544702529907, G_Loss:12.039146423339844

iterator 1200, D_Loss:0.4250091314315796, G_Loss:12.688998222351074

iterator 1300, D_Loss:0.4044939875602722, G_Loss:14.311636924743652

iterator 1400, D_Loss:0.4221806824207306, G_Loss:14.500722885131836

iterator 1500, D_Loss:0.4243358075618744, G_Loss:15.024561882019043

iterator 1600, D_Loss:0.4219054579734802, G_Loss:12.082216262817383

iterator 1700, D_Loss:0.4269263744354248, G_Loss:12.955845832824707

iterator 1800, D_Loss:0.43133407831192017, G_Loss:11.91185188293457

iterator 1900, D_Loss:0.4112292528152466, G_Loss:16.534143447875977

iterator 2000, D_Loss:0.43036383390426636, G_Loss:12.379010200500488

iterator 2100, D_Loss:0.4244382083415985, G_Loss:15.631537437438965

iterator 2200, D_Loss:0.4404856264591217, G_Loss:16.75722885131836

iterator 2300, D_Loss:0.4066864848136902, G_Loss:16.592470169067383

iterator 2400, D_Loss:0.43746793270111084, G_Loss:16.29385757446289

iterator 2500, D_Loss:0.43570101261138916, G_Loss:14.68879508972168

iterator 2600, D_Loss:0.42364242672920227, G_Loss:14.656685829162598

iterator 2700, D_Loss:0.4380580484867096, G_Loss:15.554959297180176

iterator 2800, D_Loss:0.44314831495285034, G_Loss:14.16162395477295

iterator 2900, D_Loss:0.41670024394989014, G_Loss:17.77297592163086

iterator 3000, D_Loss:0.42397862672805786, G_Loss:12.57158374786377

iterator 3100, D_Loss:0.4221412241458893, G_Loss:9.997645378112793

iterator 3200, D_Loss:0.42430129647254944, G_Loss:15.321002006530762

iterator 3300, D_Loss:0.42714521288871765, G_Loss:14.21723747253418

iterator 3400, D_Loss:0.43595534563064575, G_Loss:15.250724792480469

iterator 3500, D_Loss:0.4123704731464386, G_Loss:12.452037811279297

iterator 3600, D_Loss:0.42031970620155334, G_Loss:17.55560302734375

iterator 3700, D_Loss:0.4272436797618866, G_Loss:12.256165504455566

iterator 3800, D_Loss:0.43063220381736755, G_Loss:10.251065254211426

iterator 3900, D_Loss:0.42831745743751526, G_Loss:14.237290382385254

iterator 4000, D_Loss:0.436544269323349, G_Loss:13.392182350158691

iterator 4100, D_Loss:0.4355209171772003, G_Loss:12.063573837280273

iterator 4200, D_Loss:0.4356760084629059, G_Loss:14.655452728271484

iterator 4300, D_Loss:0.4187121093273163, G_Loss:14.75249195098877

iterator 4400, D_Loss:0.42434409260749817, G_Loss:14.535170555114746

iterator 4500, D_Loss:0.4271191358566284, G_Loss:15.763154029846191

iterator 4600, D_Loss:0.4244999587535858, G_Loss:14.887348175048828

iterator 4700, D_Loss:0.4124796390533447, G_Loss:15.43369197845459

iterator 4800, D_Loss:0.43132084608078003, G_Loss:9.299500465393066

iterator 4900, D_Loss:0.4447076916694641, G_Loss:12.30514144897461

iterator 5000, D_Loss:0.41890931129455566, G_Loss:9.818495750427246

-----------Epoch 9-----------
iterator 100, D_Loss:0.4183039367198944, G_Loss:15.62598991394043

iterator 200, D_Loss:0.435174822807312, G_Loss:16.145198822021484

iterator 300, D_Loss:0.4320068657398224, G_Loss:13.735137939453125

iterator 400, D_Loss:0.423401415348053, G_Loss:15.230393409729004

iterator 500, D_Loss:0.42316797375679016, G_Loss:8.818824768066406

iterator 600, D_Loss:0.4518783390522003, G_Loss:12.361433029174805

iterator 700, D_Loss:0.4413411617279053, G_Loss:13.617310523986816

iterator 800, D_Loss:0.44390684366226196, G_Loss:15.574851989746094

iterator 900, D_Loss:0.4275844395160675, G_Loss:12.4740629196167

iterator 1000, D_Loss:0.408852756023407, G_Loss:14.928729057312012

iterator 1100, D_Loss:0.42820119857788086, G_Loss:9.289896011352539

iterator 1200, D_Loss:0.4281495213508606, G_Loss:11.560993194580078

iterator 1300, D_Loss:0.42761170864105225, G_Loss:15.18883228302002

iterator 1400, D_Loss:0.4278203845024109, G_Loss:10.790313720703125

iterator 1500, D_Loss:0.43573424220085144, G_Loss:12.634840965270996

iterator 1600, D_Loss:0.4485127329826355, G_Loss:10.4204683303833

iterator 1700, D_Loss:0.43022558093070984, G_Loss:9.159040451049805

iterator 1800, D_Loss:0.41725122928619385, G_Loss:11.55286693572998

iterator 1900, D_Loss:0.41907113790512085, G_Loss:15.520431518554688

iterator 2000, D_Loss:0.42299336194992065, G_Loss:15.726858139038086

iterator 2100, D_Loss:0.4012235403060913, G_Loss:15.370906829833984

iterator 2200, D_Loss:0.43397146463394165, G_Loss:9.795659065246582

iterator 2300, D_Loss:0.42763006687164307, G_Loss:11.63179874420166

iterator 2400, D_Loss:0.4157032072544098, G_Loss:11.050606727600098

iterator 2500, D_Loss:0.42884305119514465, G_Loss:13.227784156799316

iterator 2600, D_Loss:0.4251595139503479, G_Loss:14.323902130126953

iterator 2700, D_Loss:0.41885101795196533, G_Loss:11.00756549835205

iterator 2800, D_Loss:0.43134620785713196, G_Loss:7.846991062164307

iterator 2900, D_Loss:0.4243175685405731, G_Loss:13.972273826599121

iterator 3000, D_Loss:0.4252227544784546, G_Loss:16.014930725097656

iterator 3100, D_Loss:0.44557470083236694, G_Loss:12.816145896911621

iterator 3200, D_Loss:0.4361349940299988, G_Loss:12.874150276184082

iterator 3300, D_Loss:0.45021677017211914, G_Loss:16.171621322631836

iterator 3400, D_Loss:0.4058223366737366, G_Loss:15.756503105163574

iterator 3500, D_Loss:0.42313626408576965, G_Loss:14.925045013427734

iterator 3600, D_Loss:0.43339651823043823, G_Loss:16.592811584472656

iterator 3700, D_Loss:0.4259767532348633, G_Loss:15.939019203186035

iterator 3800, D_Loss:0.431025892496109, G_Loss:11.693033218383789

iterator 3900, D_Loss:0.4228663742542267, G_Loss:10.088377952575684

iterator 4000, D_Loss:0.42573150992393494, G_Loss:14.50236701965332

iterator 4100, D_Loss:0.4314024746417999, G_Loss:13.121499061584473

iterator 4200, D_Loss:0.44490161538124084, G_Loss:12.241073608398438

iterator 4300, D_Loss:0.4415944516658783, G_Loss:12.477262496948242

iterator 4400, D_Loss:0.4159161150455475, G_Loss:13.382781028747559

iterator 4500, D_Loss:0.42089155316352844, G_Loss:11.889130592346191

iterator 4600, D_Loss:0.4402821362018585, G_Loss:14.478981971740723

iterator 4700, D_Loss:0.437240332365036, G_Loss:12.130517959594727

iterator 4800, D_Loss:0.4195033311843872, G_Loss:16.332857131958008

iterator 4900, D_Loss:0.4300900995731354, G_Loss:15.980154037475586

iterator 5000, D_Loss:0.43483614921569824, G_Loss:13.339092254638672

train row : 30148
sample row: 30148
LGAN_generator(
  (LSTM): LSTMCell(300, 200)
  (gmfc00): Linear(in_features=100, out_features=1, bias=True)
  (gmfc01): Linear(in_features=100, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=100, bias=True)
  (gmfe00): Linear(in_features=200, out_features=100, bias=True)
  (gmfe01): Linear(in_features=200, out_features=100, bias=True)
  (fc10): Linear(in_features=100, out_features=1, bias=True)
  (fc11): Linear(in_features=1, out_features=100, bias=True)
  (fe1): Linear(in_features=200, out_features=100, bias=True)
  (gmfc20): Linear(in_features=100, out_features=1, bias=True)
  (gmfc21): Linear(in_features=100, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=100, bias=True)
  (gmfe20): Linear(in_features=200, out_features=100, bias=True)
  (gmfe21): Linear(in_features=200, out_features=100, bias=True)
  (fc30): Linear(in_features=100, out_features=1, bias=True)
  (fc31): Linear(in_features=1, out_features=100, bias=True)
  (fe3): Linear(in_features=200, out_features=100, bias=True)
  (gmfc40): Linear(in_features=100, out_features=1, bias=True)
  (gmfc41): Linear(in_features=100, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=100, bias=True)
  (gmfe40): Linear(in_features=200, out_features=100, bias=True)
  (gmfe41): Linear(in_features=200, out_features=100, bias=True)
  (fc50): Linear(in_features=100, out_features=1, bias=True)
  (fc51): Linear(in_features=1, out_features=100, bias=True)
  (fe5): Linear(in_features=200, out_features=100, bias=True)
  (fc60): Linear(in_features=100, out_features=1, bias=True)
  (fc61): Linear(in_features=1, out_features=100, bias=True)
  (fe6): Linear(in_features=200, out_features=100, bias=True)
  (fc70): Linear(in_features=100, out_features=1, bias=True)
  (fc71): Linear(in_features=1, out_features=100, bias=True)
  (fe7): Linear(in_features=200, out_features=100, bias=True)
  (fc80): Linear(in_features=100, out_features=1, bias=True)
  (fc81): Linear(in_features=1, out_features=100, bias=True)
  (fe8): Linear(in_features=200, out_features=100, bias=True)
  (fc90): Linear(in_features=100, out_features=1, bias=True)
  (fc91): Linear(in_features=1, out_features=100, bias=True)
  (fe9): Linear(in_features=200, out_features=100, bias=True)
  (gmfc100): Linear(in_features=100, out_features=1, bias=True)
  (gmfc101): Linear(in_features=100, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=100, bias=True)
  (gmfe100): Linear(in_features=200, out_features=100, bias=True)
  (gmfe101): Linear(in_features=200, out_features=100, bias=True)
  (gmfc110): Linear(in_features=100, out_features=1, bias=True)
  (gmfc111): Linear(in_features=100, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=100, bias=True)
  (gmfe110): Linear(in_features=200, out_features=100, bias=True)
  (gmfe111): Linear(in_features=200, out_features=100, bias=True)
  (gmfc120): Linear(in_features=100, out_features=1, bias=True)
  (gmfc121): Linear(in_features=100, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=100, bias=True)
  (gmfe120): Linear(in_features=200, out_features=100, bias=True)
  (gmfe121): Linear(in_features=200, out_features=100, bias=True)
  (fc130): Linear(in_features=100, out_features=1, bias=True)
  (fc131): Linear(in_features=1, out_features=100, bias=True)
  (fe13): Linear(in_features=200, out_features=100, bias=True)
  (fc140): Linear(in_features=100, out_features=1, bias=True)
  (fc141): Linear(in_features=1, out_features=100, bias=True)
  (fe14): Linear(in_features=200, out_features=100, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=45, out_features=100, bias=True)
  (inputbn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=100, out_features=100, bias=True)
  (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=100, out_features=1, bias=True)
)
(0, False, 45)
-----------Epoch 0-----------
iterator 100, D_Loss:1.4488718509674072, G_Loss:0.920722246170044

iterator 200, D_Loss:1.3860572576522827, G_Loss:0.9179213643074036

iterator 300, D_Loss:1.3822085857391357, G_Loss:0.9113709926605225

iterator 400, D_Loss:1.382975697517395, G_Loss:0.9129321575164795

iterator 500, D_Loss:1.37900710105896, G_Loss:0.8790580630302429

iterator 600, D_Loss:1.383246660232544, G_Loss:0.9786170125007629

iterator 700, D_Loss:1.3467795848846436, G_Loss:0.9426355957984924

iterator 800, D_Loss:1.3527617454528809, G_Loss:0.924182653427124

iterator 900, D_Loss:1.4051837921142578, G_Loss:0.8410054445266724

iterator 1000, D_Loss:1.3377829790115356, G_Loss:0.8349477052688599

iterator 1100, D_Loss:1.358471155166626, G_Loss:0.8829805254936218

iterator 1200, D_Loss:1.3550360202789307, G_Loss:0.9149484634399414

iterator 1300, D_Loss:1.353226661682129, G_Loss:0.9191931486129761

iterator 1400, D_Loss:1.3507359027862549, G_Loss:0.898292064666748

iterator 1500, D_Loss:1.277944803237915, G_Loss:0.9739421606063843

iterator 1600, D_Loss:1.331484079360962, G_Loss:0.9334807395935059

iterator 1700, D_Loss:1.3429934978485107, G_Loss:0.9039615988731384

iterator 1800, D_Loss:1.2873384952545166, G_Loss:1.0231480598449707

iterator 1900, D_Loss:1.304104208946228, G_Loss:1.0748783349990845

iterator 2000, D_Loss:1.2653127908706665, G_Loss:1.0381375551223755

iterator 2100, D_Loss:1.251301646232605, G_Loss:0.9023340940475464

iterator 2200, D_Loss:1.2848052978515625, G_Loss:1.0727139711380005

iterator 2300, D_Loss:1.326190710067749, G_Loss:0.9648245573043823

iterator 2400, D_Loss:1.2492566108703613, G_Loss:1.1157622337341309

iterator 2500, D_Loss:1.3060414791107178, G_Loss:0.9944719076156616

iterator 2600, D_Loss:1.3908600807189941, G_Loss:1.0340898036956787

iterator 2700, D_Loss:1.2208466529846191, G_Loss:0.9790470004081726

iterator 2800, D_Loss:1.3474528789520264, G_Loss:1.0062154531478882

iterator 2900, D_Loss:1.2361884117126465, G_Loss:1.1015775203704834

iterator 3000, D_Loss:1.4574894905090332, G_Loss:1.073122501373291

iterator 3100, D_Loss:1.2970659732818604, G_Loss:1.0116381645202637

iterator 3200, D_Loss:1.2970716953277588, G_Loss:0.9769473075866699

iterator 3300, D_Loss:1.243330478668213, G_Loss:1.143164038658142

iterator 3400, D_Loss:1.229172706604004, G_Loss:1.0486953258514404

iterator 3500, D_Loss:1.1685891151428223, G_Loss:1.1099889278411865

iterator 3600, D_Loss:1.1633871793746948, G_Loss:1.2214876413345337

iterator 3700, D_Loss:1.2226788997650146, G_Loss:1.0368218421936035

iterator 3800, D_Loss:1.2746084928512573, G_Loss:1.1003878116607666

iterator 3900, D_Loss:1.2213739156723022, G_Loss:1.108683705329895

iterator 4000, D_Loss:1.2606743574142456, G_Loss:1.1808767318725586

iterator 4100, D_Loss:1.1087987422943115, G_Loss:1.086998701095581

iterator 4200, D_Loss:1.380645513534546, G_Loss:1.0692859888076782

iterator 4300, D_Loss:1.2763476371765137, G_Loss:1.124796748161316

iterator 4400, D_Loss:1.371805191040039, G_Loss:1.0154179334640503

iterator 4500, D_Loss:1.329530119895935, G_Loss:0.95419842004776

iterator 4600, D_Loss:1.344118356704712, G_Loss:0.9257321357727051

iterator 4700, D_Loss:1.249263048171997, G_Loss:1.0220601558685303

iterator 4800, D_Loss:1.2952924966812134, G_Loss:1.0875006914138794

iterator 4900, D_Loss:1.2712764739990234, G_Loss:1.0293004512786865

iterator 5000, D_Loss:1.2684996128082275, G_Loss:1.1977646350860596

-----------Epoch 1-----------
iterator 100, D_Loss:1.337123155593872, G_Loss:1.0505197048187256

iterator 200, D_Loss:1.2139043807983398, G_Loss:1.15118408203125

iterator 300, D_Loss:1.1852269172668457, G_Loss:1.036423683166504

iterator 400, D_Loss:1.1964654922485352, G_Loss:1.0749844312667847

iterator 500, D_Loss:1.2396607398986816, G_Loss:1.1342779397964478

iterator 600, D_Loss:1.1792073249816895, G_Loss:1.1391987800598145

iterator 700, D_Loss:1.1941497325897217, G_Loss:1.2005547285079956

iterator 800, D_Loss:1.1493850946426392, G_Loss:1.3110789060592651

iterator 900, D_Loss:1.2396214008331299, G_Loss:1.2484136819839478

iterator 1000, D_Loss:1.2705553770065308, G_Loss:1.1150617599487305

iterator 1100, D_Loss:1.2639819383621216, G_Loss:1.143662452697754

iterator 1200, D_Loss:1.2243008613586426, G_Loss:1.0965111255645752

iterator 1300, D_Loss:1.3182694911956787, G_Loss:1.0667041540145874

iterator 1400, D_Loss:1.1834454536437988, G_Loss:1.0045710802078247

iterator 1500, D_Loss:1.347077488899231, G_Loss:1.2509077787399292

iterator 1600, D_Loss:1.2174975872039795, G_Loss:1.108102798461914

iterator 1700, D_Loss:1.1770999431610107, G_Loss:1.1406728029251099

iterator 1800, D_Loss:1.2135214805603027, G_Loss:1.136212706565857

iterator 1900, D_Loss:1.276672124862671, G_Loss:1.0396742820739746

iterator 2000, D_Loss:1.1539171934127808, G_Loss:1.2110929489135742

iterator 2100, D_Loss:1.254004955291748, G_Loss:1.1351438760757446

iterator 2200, D_Loss:1.3031573295593262, G_Loss:1.2633016109466553

iterator 2300, D_Loss:1.030122995376587, G_Loss:1.3645187616348267

iterator 2400, D_Loss:1.2081913948059082, G_Loss:1.1843054294586182

iterator 2500, D_Loss:1.0718673467636108, G_Loss:1.3225053548812866

iterator 2600, D_Loss:1.0808029174804688, G_Loss:1.396030306816101

iterator 2700, D_Loss:0.9557821750640869, G_Loss:1.4041392803192139

iterator 2800, D_Loss:1.045560359954834, G_Loss:1.4853465557098389

iterator 2900, D_Loss:0.8138327598571777, G_Loss:1.7283124923706055

iterator 3000, D_Loss:0.8092556595802307, G_Loss:1.4887033700942993

iterator 3100, D_Loss:0.8568421006202698, G_Loss:1.6933557987213135

iterator 3200, D_Loss:0.8007789850234985, G_Loss:1.8416520357131958

iterator 3300, D_Loss:0.7644370794296265, G_Loss:2.2112996578216553

iterator 3400, D_Loss:0.6938574314117432, G_Loss:2.3483283519744873

iterator 3500, D_Loss:0.6235345005989075, G_Loss:2.377497911453247

iterator 3600, D_Loss:1.1253238916397095, G_Loss:1.8842849731445312

iterator 3700, D_Loss:0.6988269090652466, G_Loss:2.5878448486328125

iterator 3800, D_Loss:0.7043371200561523, G_Loss:2.2972989082336426

iterator 3900, D_Loss:0.6644152402877808, G_Loss:2.5124404430389404

iterator 4000, D_Loss:0.7002838850021362, G_Loss:2.369008779525757

iterator 4100, D_Loss:0.704833984375, G_Loss:2.338071823120117

iterator 4200, D_Loss:0.6293421983718872, G_Loss:2.517117977142334

iterator 4300, D_Loss:0.7371752262115479, G_Loss:1.9342225790023804

iterator 4400, D_Loss:0.732450008392334, G_Loss:2.1902716159820557

iterator 4500, D_Loss:0.7066913843154907, G_Loss:2.306922197341919

iterator 4600, D_Loss:0.7484781742095947, G_Loss:2.5372533798217773

iterator 4700, D_Loss:0.5971026420593262, G_Loss:2.6058707237243652

iterator 4800, D_Loss:0.7073694467544556, G_Loss:2.646336078643799

iterator 4900, D_Loss:0.6667709946632385, G_Loss:2.62162709236145

iterator 5000, D_Loss:0.6828204989433289, G_Loss:3.0390942096710205

-----------Epoch 2-----------
iterator 100, D_Loss:0.6702210307121277, G_Loss:2.743849039077759

iterator 200, D_Loss:0.6549108028411865, G_Loss:2.239778995513916

iterator 300, D_Loss:0.6680899858474731, G_Loss:3.4679880142211914

iterator 400, D_Loss:0.6213756203651428, G_Loss:2.3901870250701904

iterator 500, D_Loss:0.6011203527450562, G_Loss:2.926459550857544

iterator 600, D_Loss:0.6856774091720581, G_Loss:3.775578260421753

iterator 700, D_Loss:0.6007475256919861, G_Loss:3.578150749206543

iterator 800, D_Loss:0.687048077583313, G_Loss:3.72346830368042

iterator 900, D_Loss:0.6439908146858215, G_Loss:2.482448101043701

iterator 1000, D_Loss:0.7143897414207458, G_Loss:2.311357021331787

iterator 1100, D_Loss:0.6336833834648132, G_Loss:2.6581223011016846

iterator 1200, D_Loss:0.6629768013954163, G_Loss:3.5068321228027344

iterator 1300, D_Loss:0.6332597136497498, G_Loss:2.3175015449523926

iterator 1400, D_Loss:0.659286379814148, G_Loss:2.6579911708831787

iterator 1500, D_Loss:0.606162428855896, G_Loss:2.959599494934082

iterator 1600, D_Loss:0.6334779858589172, G_Loss:3.2702038288116455

iterator 1700, D_Loss:0.6434434056282043, G_Loss:2.805607795715332

iterator 1800, D_Loss:0.6335914134979248, G_Loss:2.759674549102783

iterator 1900, D_Loss:0.6267277002334595, G_Loss:2.9078595638275146

iterator 2000, D_Loss:0.6162724494934082, G_Loss:2.8322103023529053

iterator 2100, D_Loss:0.618150532245636, G_Loss:3.021498680114746

iterator 2200, D_Loss:0.582609236240387, G_Loss:3.0790390968322754

iterator 2300, D_Loss:0.5793783068656921, G_Loss:3.4739227294921875

iterator 2400, D_Loss:0.577438473701477, G_Loss:4.477345943450928

iterator 2500, D_Loss:0.5851649641990662, G_Loss:2.937897205352783

iterator 2600, D_Loss:0.6228083372116089, G_Loss:3.2880122661590576

iterator 2700, D_Loss:0.6231449246406555, G_Loss:3.1315624713897705

iterator 2800, D_Loss:0.6414766311645508, G_Loss:3.526902914047241

iterator 2900, D_Loss:0.5961555242538452, G_Loss:3.863982915878296

iterator 3000, D_Loss:0.6108709573745728, G_Loss:3.488893985748291

iterator 3100, D_Loss:0.5723004937171936, G_Loss:3.4044647216796875

iterator 3200, D_Loss:0.5742943286895752, G_Loss:3.4435136318206787

iterator 3300, D_Loss:0.614539623260498, G_Loss:3.4934842586517334

iterator 3400, D_Loss:0.5749664306640625, G_Loss:3.3580710887908936

iterator 3500, D_Loss:0.5608087182044983, G_Loss:3.4714531898498535

iterator 3600, D_Loss:0.6021527051925659, G_Loss:3.5756731033325195

iterator 3700, D_Loss:0.5858216285705566, G_Loss:3.6137948036193848

iterator 3800, D_Loss:0.5917180776596069, G_Loss:3.597118616104126

iterator 3900, D_Loss:0.60491943359375, G_Loss:2.9962351322174072

iterator 4000, D_Loss:0.629504919052124, G_Loss:3.3894081115722656

iterator 4100, D_Loss:0.5942805409431458, G_Loss:3.166548490524292

iterator 4200, D_Loss:0.6120254397392273, G_Loss:2.5543181896209717

iterator 4300, D_Loss:0.552303671836853, G_Loss:2.9299988746643066

iterator 4400, D_Loss:0.5927965044975281, G_Loss:3.803032636642456

iterator 4500, D_Loss:0.589755654335022, G_Loss:3.5365161895751953

iterator 4600, D_Loss:0.5804808735847473, G_Loss:3.2234838008880615

iterator 4700, D_Loss:0.6411875486373901, G_Loss:4.148624897003174

iterator 4800, D_Loss:0.5536331534385681, G_Loss:3.378352165222168

iterator 4900, D_Loss:0.579801082611084, G_Loss:2.5700883865356445

iterator 5000, D_Loss:0.5903706550598145, G_Loss:3.1602654457092285

-----------Epoch 3-----------
iterator 100, D_Loss:0.6268477439880371, G_Loss:3.775827646255493

iterator 200, D_Loss:0.5849704742431641, G_Loss:3.845320463180542

iterator 300, D_Loss:0.5938796997070312, G_Loss:3.140174388885498

iterator 400, D_Loss:0.5371386408805847, G_Loss:3.1816582679748535

iterator 500, D_Loss:0.5617335438728333, G_Loss:3.0196290016174316

iterator 600, D_Loss:0.547851026058197, G_Loss:3.2410404682159424

iterator 700, D_Loss:0.5946743488311768, G_Loss:3.5919456481933594

iterator 800, D_Loss:0.5845510363578796, G_Loss:3.1126537322998047

iterator 900, D_Loss:0.5979112982749939, G_Loss:4.128002643585205

iterator 1000, D_Loss:0.5717033743858337, G_Loss:3.642702341079712

iterator 1100, D_Loss:0.5636247396469116, G_Loss:3.4343373775482178

iterator 1200, D_Loss:0.5963559150695801, G_Loss:3.936598539352417

iterator 1300, D_Loss:0.5601399540901184, G_Loss:3.738163948059082

iterator 1400, D_Loss:0.5452280640602112, G_Loss:3.6761207580566406

iterator 1500, D_Loss:0.5805214047431946, G_Loss:3.483488082885742

iterator 1600, D_Loss:0.5886619091033936, G_Loss:3.416210174560547

iterator 1700, D_Loss:0.555233359336853, G_Loss:3.972339391708374

iterator 1800, D_Loss:0.6466618776321411, G_Loss:3.859144687652588

iterator 1900, D_Loss:0.5735936164855957, G_Loss:3.2071783542633057

iterator 2000, D_Loss:0.5771529674530029, G_Loss:3.510594129562378

iterator 2100, D_Loss:0.5826871991157532, G_Loss:3.423483371734619

iterator 2200, D_Loss:0.5668925046920776, G_Loss:4.208130359649658

iterator 2300, D_Loss:0.5455472469329834, G_Loss:3.34999418258667

iterator 2400, D_Loss:0.5230738520622253, G_Loss:3.48175048828125

iterator 2500, D_Loss:0.5736792683601379, G_Loss:3.554945945739746

iterator 2600, D_Loss:0.5579853057861328, G_Loss:3.9331140518188477

iterator 2700, D_Loss:0.5585719347000122, G_Loss:3.820814847946167

iterator 2800, D_Loss:0.567664623260498, G_Loss:3.6752750873565674

iterator 2900, D_Loss:0.5417305827140808, G_Loss:3.361783504486084

iterator 3000, D_Loss:0.5442924499511719, G_Loss:3.624075174331665

iterator 3100, D_Loss:0.5248032212257385, G_Loss:3.6164724826812744

iterator 3200, D_Loss:0.5748925805091858, G_Loss:3.7434113025665283

iterator 3300, D_Loss:0.5468310713768005, G_Loss:3.623161792755127

iterator 3400, D_Loss:0.5411713719367981, G_Loss:4.036381721496582

iterator 3500, D_Loss:0.5651100277900696, G_Loss:4.081727981567383

iterator 3600, D_Loss:0.5622453689575195, G_Loss:3.4564831256866455

iterator 3700, D_Loss:0.5348706841468811, G_Loss:3.607450008392334

iterator 3800, D_Loss:0.5346115231513977, G_Loss:3.5800302028656006

iterator 3900, D_Loss:0.5553232431411743, G_Loss:3.455479383468628

iterator 4000, D_Loss:0.5467473864555359, G_Loss:3.6762423515319824

iterator 4100, D_Loss:0.5295194387435913, G_Loss:4.229919910430908

iterator 4200, D_Loss:0.5494426488876343, G_Loss:3.610638380050659

iterator 4300, D_Loss:0.5455928444862366, G_Loss:3.2792305946350098

iterator 4400, D_Loss:0.5546295046806335, G_Loss:3.6142990589141846

iterator 4500, D_Loss:0.5404422879219055, G_Loss:3.4066667556762695

iterator 4600, D_Loss:0.5409411787986755, G_Loss:3.7388999462127686

iterator 4700, D_Loss:0.5522375106811523, G_Loss:4.065560340881348

iterator 4800, D_Loss:0.5494338274002075, G_Loss:3.654801845550537

iterator 4900, D_Loss:0.5574374198913574, G_Loss:3.926220178604126

iterator 5000, D_Loss:0.5479633212089539, G_Loss:3.959822177886963

-----------Epoch 4-----------
iterator 100, D_Loss:0.5569232702255249, G_Loss:3.703169107437134

iterator 200, D_Loss:0.543135941028595, G_Loss:3.787590265274048

iterator 300, D_Loss:0.516770601272583, G_Loss:3.8521625995635986

iterator 400, D_Loss:0.5400232672691345, G_Loss:4.110545635223389

iterator 500, D_Loss:0.5278096795082092, G_Loss:3.6879255771636963

iterator 600, D_Loss:0.53922039270401, G_Loss:4.015817165374756

iterator 700, D_Loss:0.5114927291870117, G_Loss:4.512517929077148

iterator 800, D_Loss:0.553166389465332, G_Loss:4.461869239807129

iterator 900, D_Loss:0.5184504389762878, G_Loss:3.9904346466064453

iterator 1000, D_Loss:0.6023606657981873, G_Loss:3.9019336700439453

iterator 1100, D_Loss:0.5549493432044983, G_Loss:4.072364807128906

iterator 1200, D_Loss:0.5269686579704285, G_Loss:4.754776477813721

iterator 1300, D_Loss:0.6083630323410034, G_Loss:4.260768413543701

iterator 1400, D_Loss:0.5369628667831421, G_Loss:3.504655599594116

iterator 1500, D_Loss:0.4986538887023926, G_Loss:4.044342041015625

iterator 1600, D_Loss:0.5184320211410522, G_Loss:4.3079142570495605

iterator 1700, D_Loss:0.5786274075508118, G_Loss:4.047140121459961

iterator 1800, D_Loss:0.5102254748344421, G_Loss:4.536464691162109

iterator 1900, D_Loss:0.5445790886878967, G_Loss:4.847492218017578

iterator 2000, D_Loss:0.49948886036872864, G_Loss:4.485348701477051

iterator 2100, D_Loss:0.5253451466560364, G_Loss:4.037639141082764

iterator 2200, D_Loss:0.5532330870628357, G_Loss:5.357303142547607

iterator 2300, D_Loss:0.5003623366355896, G_Loss:4.2363200187683105

iterator 2400, D_Loss:0.5243503451347351, G_Loss:4.946126461029053

iterator 2500, D_Loss:0.5389622449874878, G_Loss:4.125105381011963

iterator 2600, D_Loss:0.5483968257904053, G_Loss:4.823041915893555

iterator 2700, D_Loss:0.5316872596740723, G_Loss:4.9244561195373535

iterator 2800, D_Loss:0.5231297612190247, G_Loss:5.275504112243652

iterator 2900, D_Loss:0.4925186038017273, G_Loss:4.0547590255737305

iterator 3000, D_Loss:0.5314066410064697, G_Loss:4.796947002410889

iterator 3100, D_Loss:0.5086897015571594, G_Loss:5.18540096282959

iterator 3200, D_Loss:0.5091962218284607, G_Loss:5.149816036224365

iterator 3300, D_Loss:0.5144098401069641, G_Loss:4.660504341125488

iterator 3400, D_Loss:0.5118294358253479, G_Loss:5.125157356262207

iterator 3500, D_Loss:0.5209658741950989, G_Loss:5.374399662017822

iterator 3600, D_Loss:0.5041530728340149, G_Loss:6.055804252624512

iterator 3700, D_Loss:0.5173708200454712, G_Loss:4.626980781555176

iterator 3800, D_Loss:0.5238109827041626, G_Loss:5.57088041305542

iterator 3900, D_Loss:0.48148301243782043, G_Loss:4.830721378326416

iterator 4000, D_Loss:0.49850916862487793, G_Loss:4.615141868591309

iterator 4100, D_Loss:0.5006792545318604, G_Loss:5.314635276794434

iterator 4200, D_Loss:0.4939762055873871, G_Loss:4.825057029724121

iterator 4300, D_Loss:0.5024060010910034, G_Loss:6.560450077056885

iterator 4400, D_Loss:0.4946449398994446, G_Loss:5.937057018280029

iterator 4500, D_Loss:0.5304219126701355, G_Loss:5.376118183135986

iterator 4600, D_Loss:0.5011981725692749, G_Loss:5.274259567260742

iterator 4700, D_Loss:0.4953586161136627, G_Loss:5.826197624206543

iterator 4800, D_Loss:0.49069347977638245, G_Loss:4.82001256942749

iterator 4900, D_Loss:0.4802321493625641, G_Loss:5.6021318435668945

iterator 5000, D_Loss:0.5632036924362183, G_Loss:4.190446853637695

-----------Epoch 5-----------
iterator 100, D_Loss:0.5397567749023438, G_Loss:4.444643020629883

iterator 200, D_Loss:0.5048639178276062, G_Loss:5.0737528800964355

iterator 300, D_Loss:0.49186569452285767, G_Loss:5.282875061035156

iterator 400, D_Loss:0.49332818388938904, G_Loss:5.580821990966797

iterator 500, D_Loss:0.5185398459434509, G_Loss:5.033769607543945

iterator 600, D_Loss:0.48980847001075745, G_Loss:5.786159992218018

iterator 700, D_Loss:0.4971815347671509, G_Loss:4.444910526275635

iterator 800, D_Loss:0.5262159109115601, G_Loss:5.620407581329346

iterator 900, D_Loss:0.5280836820602417, G_Loss:6.437819480895996

iterator 1000, D_Loss:0.5141733884811401, G_Loss:6.968846321105957

iterator 1100, D_Loss:0.5099095702171326, G_Loss:5.688686370849609

iterator 1200, D_Loss:0.5015525221824646, G_Loss:5.95606803894043

iterator 1300, D_Loss:0.5135668516159058, G_Loss:4.733900547027588

iterator 1400, D_Loss:0.4800301194190979, G_Loss:5.399837970733643

iterator 1500, D_Loss:0.4985732138156891, G_Loss:4.461852073669434

iterator 1600, D_Loss:0.51833575963974, G_Loss:6.191464900970459

iterator 1700, D_Loss:0.5141951441764832, G_Loss:5.991086006164551

iterator 1800, D_Loss:0.5056666731834412, G_Loss:5.133700370788574

iterator 1900, D_Loss:0.4911101758480072, G_Loss:4.873126983642578

iterator 2000, D_Loss:0.49109116196632385, G_Loss:5.65693473815918

iterator 2100, D_Loss:0.4894852936267853, G_Loss:6.258962631225586

iterator 2200, D_Loss:0.5189124345779419, G_Loss:6.276406764984131

iterator 2300, D_Loss:0.5197248458862305, G_Loss:4.7762603759765625

iterator 2400, D_Loss:0.5012784004211426, G_Loss:6.24906587600708

iterator 2500, D_Loss:0.5009316205978394, G_Loss:7.725834846496582

iterator 2600, D_Loss:0.5349034070968628, G_Loss:4.7167205810546875

iterator 2700, D_Loss:0.504845380783081, G_Loss:5.306713581085205

iterator 2800, D_Loss:0.48640912771224976, G_Loss:6.640144348144531

iterator 2900, D_Loss:0.5143959522247314, G_Loss:5.976179122924805

iterator 3000, D_Loss:0.5119492411613464, G_Loss:4.627793788909912

iterator 3100, D_Loss:0.4908340573310852, G_Loss:4.409675598144531

iterator 3200, D_Loss:0.5122336745262146, G_Loss:7.635323524475098

iterator 3300, D_Loss:0.5095323324203491, G_Loss:6.2203240394592285

iterator 3400, D_Loss:0.5109365582466125, G_Loss:5.098500728607178

iterator 3500, D_Loss:0.49786022305488586, G_Loss:6.34847354888916

iterator 3600, D_Loss:0.48450207710266113, G_Loss:6.416638374328613

iterator 3700, D_Loss:0.5094756484031677, G_Loss:6.963863849639893

iterator 3800, D_Loss:0.5132344961166382, G_Loss:7.063167572021484

iterator 3900, D_Loss:0.46285736560821533, G_Loss:5.871496200561523

iterator 4000, D_Loss:0.5147123336791992, G_Loss:4.989923477172852

iterator 4100, D_Loss:0.48569416999816895, G_Loss:8.223067283630371

iterator 4200, D_Loss:0.4995766282081604, G_Loss:5.931636810302734

iterator 4300, D_Loss:0.48433175683021545, G_Loss:4.776544570922852

iterator 4400, D_Loss:0.5253576040267944, G_Loss:4.950778007507324

iterator 4500, D_Loss:0.4602126479148865, G_Loss:4.854674339294434

iterator 4600, D_Loss:0.4950762391090393, G_Loss:4.525570392608643

iterator 4700, D_Loss:0.4871317148208618, G_Loss:4.549614906311035

iterator 4800, D_Loss:0.5152079463005066, G_Loss:9.10999584197998

iterator 4900, D_Loss:0.47752678394317627, G_Loss:4.964809894561768

iterator 5000, D_Loss:0.4735146462917328, G_Loss:5.662495136260986

-----------Epoch 6-----------
iterator 100, D_Loss:0.4963740408420563, G_Loss:5.264020919799805

iterator 200, D_Loss:0.5012967586517334, G_Loss:6.1778178215026855

iterator 300, D_Loss:0.49924546480178833, G_Loss:5.98219633102417

iterator 400, D_Loss:0.49103909730911255, G_Loss:6.45065975189209

iterator 500, D_Loss:0.4781120717525482, G_Loss:5.329488277435303

iterator 600, D_Loss:0.4769485592842102, G_Loss:5.916366100311279

iterator 700, D_Loss:0.47618523240089417, G_Loss:6.709303379058838

iterator 800, D_Loss:0.5059719085693359, G_Loss:5.7971110343933105

iterator 900, D_Loss:0.5055766701698303, G_Loss:4.984863758087158

iterator 1000, D_Loss:0.5451763272285461, G_Loss:4.418536186218262

iterator 1100, D_Loss:0.5216645002365112, G_Loss:5.890870094299316

iterator 1200, D_Loss:0.4879930317401886, G_Loss:6.231419563293457

iterator 1300, D_Loss:0.499674528837204, G_Loss:6.295690536499023

iterator 1400, D_Loss:0.5105366706848145, G_Loss:5.818512916564941

iterator 1500, D_Loss:0.4874778687953949, G_Loss:7.724796772003174

iterator 1600, D_Loss:0.48894163966178894, G_Loss:6.500735759735107

iterator 1700, D_Loss:0.45946019887924194, G_Loss:6.313269138336182

iterator 1800, D_Loss:0.4899411201477051, G_Loss:8.40481948852539

iterator 1900, D_Loss:0.5415598750114441, G_Loss:7.286561489105225

iterator 2000, D_Loss:0.48271727561950684, G_Loss:6.356189727783203

iterator 2100, D_Loss:0.5085396766662598, G_Loss:6.275299072265625

iterator 2200, D_Loss:0.46102577447891235, G_Loss:6.843958854675293

iterator 2300, D_Loss:0.4799945056438446, G_Loss:7.057375431060791

iterator 2400, D_Loss:0.4776593744754791, G_Loss:5.181588649749756

iterator 2500, D_Loss:0.5232009291648865, G_Loss:6.9661993980407715

iterator 2600, D_Loss:0.549553632736206, G_Loss:5.684784889221191

iterator 2700, D_Loss:0.46222907304763794, G_Loss:7.151478290557861

iterator 2800, D_Loss:0.4781007170677185, G_Loss:5.658303737640381

iterator 2900, D_Loss:0.5251970887184143, G_Loss:8.059917449951172

iterator 3000, D_Loss:0.4970925748348236, G_Loss:5.3272600173950195

iterator 3100, D_Loss:0.501678466796875, G_Loss:7.179285526275635

iterator 3200, D_Loss:0.49629276990890503, G_Loss:5.725609302520752

iterator 3300, D_Loss:0.49642568826675415, G_Loss:7.167141914367676

iterator 3400, D_Loss:0.47994017601013184, G_Loss:6.835263729095459

iterator 3500, D_Loss:0.49269792437553406, G_Loss:6.637885093688965

iterator 3600, D_Loss:0.46976155042648315, G_Loss:6.745504379272461

iterator 3700, D_Loss:0.4830770492553711, G_Loss:7.6093316078186035

iterator 3800, D_Loss:0.4709964394569397, G_Loss:7.24642276763916

iterator 3900, D_Loss:0.48580512404441833, G_Loss:5.987281799316406

iterator 4000, D_Loss:0.499142050743103, G_Loss:5.9261274337768555

iterator 4100, D_Loss:0.47565340995788574, G_Loss:4.89731502532959

iterator 4200, D_Loss:0.5057516098022461, G_Loss:7.276241302490234

iterator 4300, D_Loss:0.5031418204307556, G_Loss:5.261382579803467

iterator 4400, D_Loss:0.5000970363616943, G_Loss:5.865425109863281

iterator 4500, D_Loss:0.49972453713417053, G_Loss:6.1372551918029785

iterator 4600, D_Loss:0.5203886032104492, G_Loss:6.670488357543945

iterator 4700, D_Loss:0.5059031844139099, G_Loss:7.996687889099121

iterator 4800, D_Loss:0.4807809591293335, G_Loss:8.649643898010254

iterator 4900, D_Loss:0.49035847187042236, G_Loss:7.412902355194092

iterator 5000, D_Loss:0.48300233483314514, G_Loss:8.016617774963379

-----------Epoch 7-----------
iterator 100, D_Loss:0.4994562268257141, G_Loss:8.407320022583008

iterator 200, D_Loss:0.5100631713867188, G_Loss:5.927794933319092

iterator 300, D_Loss:0.48067229986190796, G_Loss:8.309825897216797

iterator 400, D_Loss:0.4533955454826355, G_Loss:9.655479431152344

iterator 500, D_Loss:0.4651729464530945, G_Loss:7.965121269226074

iterator 600, D_Loss:0.49704718589782715, G_Loss:4.49421501159668

iterator 700, D_Loss:0.46485432982444763, G_Loss:7.4574809074401855

iterator 800, D_Loss:0.4932611286640167, G_Loss:8.521571159362793

iterator 900, D_Loss:0.4968126118183136, G_Loss:5.852120399475098

iterator 1000, D_Loss:0.49507057666778564, G_Loss:7.525670528411865

iterator 1100, D_Loss:0.48455873131752014, G_Loss:5.350876808166504

iterator 1200, D_Loss:0.45877301692962646, G_Loss:4.565123081207275

iterator 1300, D_Loss:0.5003304481506348, G_Loss:5.341946125030518

iterator 1400, D_Loss:0.4676803946495056, G_Loss:7.2651472091674805

iterator 1500, D_Loss:0.47349050641059875, G_Loss:7.9648871421813965

iterator 1600, D_Loss:0.5010831952095032, G_Loss:6.075402736663818

iterator 1700, D_Loss:0.49369746446609497, G_Loss:6.984890460968018

iterator 1800, D_Loss:0.5086827278137207, G_Loss:5.456484794616699

iterator 1900, D_Loss:0.4805913269519806, G_Loss:5.979617595672607

iterator 2000, D_Loss:0.4801711440086365, G_Loss:9.183568954467773

iterator 2100, D_Loss:0.4643159508705139, G_Loss:8.261099815368652

iterator 2200, D_Loss:0.4983122944831848, G_Loss:7.032562732696533

iterator 2300, D_Loss:0.48008376359939575, G_Loss:8.2911958694458

iterator 2400, D_Loss:0.46962979435920715, G_Loss:6.676064491271973

iterator 2500, D_Loss:0.4993933141231537, G_Loss:6.455728530883789

iterator 2600, D_Loss:0.4811612665653229, G_Loss:5.700943946838379

iterator 2700, D_Loss:0.4890212118625641, G_Loss:7.724400043487549

iterator 2800, D_Loss:0.49341657757759094, G_Loss:5.574156284332275

iterator 2900, D_Loss:0.49980494379997253, G_Loss:6.743468761444092

iterator 3000, D_Loss:0.486031711101532, G_Loss:5.427027225494385

iterator 3100, D_Loss:0.49535027146339417, G_Loss:8.102310180664062

iterator 3200, D_Loss:0.5035596489906311, G_Loss:9.453878402709961

iterator 3300, D_Loss:0.4753207564353943, G_Loss:11.607893943786621

iterator 3400, D_Loss:0.47691619396209717, G_Loss:10.348579406738281

iterator 3500, D_Loss:0.5157190561294556, G_Loss:8.679332733154297

iterator 3600, D_Loss:0.48481038212776184, G_Loss:8.888049125671387

iterator 3700, D_Loss:0.4792032837867737, G_Loss:7.629663467407227

iterator 3800, D_Loss:0.4830721914768219, G_Loss:6.301717758178711

iterator 3900, D_Loss:0.4921233654022217, G_Loss:8.37011432647705

iterator 4000, D_Loss:0.46309638023376465, G_Loss:8.063557624816895

iterator 4100, D_Loss:0.4809281826019287, G_Loss:7.107342720031738

iterator 4200, D_Loss:0.4715266823768616, G_Loss:7.6513895988464355

iterator 4300, D_Loss:0.4779198169708252, G_Loss:9.418646812438965

iterator 4400, D_Loss:0.5320159196853638, G_Loss:5.586434841156006

iterator 4500, D_Loss:0.4753692150115967, G_Loss:5.47707986831665

iterator 4600, D_Loss:0.4895446300506592, G_Loss:11.434659957885742

iterator 4700, D_Loss:0.5523136258125305, G_Loss:7.225399017333984

iterator 4800, D_Loss:0.4947240948677063, G_Loss:6.5981292724609375

iterator 4900, D_Loss:0.5006265640258789, G_Loss:5.950303554534912

iterator 5000, D_Loss:0.496592253446579, G_Loss:7.449573040008545

-----------Epoch 8-----------
iterator 100, D_Loss:0.46811577677726746, G_Loss:4.760078430175781

iterator 200, D_Loss:0.4542289972305298, G_Loss:9.39447021484375

iterator 300, D_Loss:0.5144959688186646, G_Loss:5.828981876373291

iterator 400, D_Loss:0.4978412389755249, G_Loss:5.153419494628906

iterator 500, D_Loss:0.46860402822494507, G_Loss:7.424633502960205

iterator 600, D_Loss:0.46955960988998413, G_Loss:7.825752258300781

iterator 700, D_Loss:0.49783211946487427, G_Loss:6.720440864562988

iterator 800, D_Loss:0.49092966318130493, G_Loss:7.576229095458984

iterator 900, D_Loss:0.505222499370575, G_Loss:8.857691764831543

iterator 1000, D_Loss:0.47523534297943115, G_Loss:6.583189487457275

iterator 1100, D_Loss:0.48231199383735657, G_Loss:6.2738566398620605

iterator 1200, D_Loss:0.47776010632514954, G_Loss:8.062712669372559

iterator 1300, D_Loss:0.46755582094192505, G_Loss:8.39930248260498

iterator 1400, D_Loss:0.4724162817001343, G_Loss:8.266977310180664

iterator 1500, D_Loss:0.47412964701652527, G_Loss:4.205145835876465

iterator 1600, D_Loss:0.4929402470588684, G_Loss:6.352800369262695

iterator 1700, D_Loss:0.5012909173965454, G_Loss:8.211601257324219

iterator 1800, D_Loss:0.4789968430995941, G_Loss:5.811123371124268

iterator 1900, D_Loss:0.4737030863761902, G_Loss:5.728080749511719

iterator 2000, D_Loss:0.5008402466773987, G_Loss:5.026953220367432

iterator 2100, D_Loss:0.4740995764732361, G_Loss:5.953507423400879

iterator 2200, D_Loss:0.5129740238189697, G_Loss:6.12060022354126

iterator 2300, D_Loss:0.45617255568504333, G_Loss:7.892560958862305

iterator 2400, D_Loss:0.4962535500526428, G_Loss:5.593874931335449

iterator 2500, D_Loss:0.5130792260169983, G_Loss:7.626589775085449

iterator 2600, D_Loss:0.47977370023727417, G_Loss:6.744743824005127

iterator 2700, D_Loss:0.483735054731369, G_Loss:8.386181831359863

iterator 2800, D_Loss:0.48095282912254333, G_Loss:8.897709846496582

iterator 2900, D_Loss:0.4561612904071808, G_Loss:6.953145503997803

iterator 3000, D_Loss:0.462655633687973, G_Loss:7.153571128845215

iterator 3100, D_Loss:0.47804343700408936, G_Loss:8.122614860534668

iterator 3200, D_Loss:0.4700999855995178, G_Loss:7.003032207489014

iterator 3300, D_Loss:0.4792201519012451, G_Loss:6.059455394744873

iterator 3400, D_Loss:0.4747350513935089, G_Loss:6.023085117340088

iterator 3500, D_Loss:0.4653877317905426, G_Loss:8.109196662902832

iterator 3600, D_Loss:0.47853872179985046, G_Loss:7.869754791259766

iterator 3700, D_Loss:0.4738534390926361, G_Loss:7.745702743530273

iterator 3800, D_Loss:0.48924538493156433, G_Loss:9.091230392456055

iterator 3900, D_Loss:0.49425262212753296, G_Loss:5.898058891296387

iterator 4000, D_Loss:0.4777475893497467, G_Loss:9.98176097869873

iterator 4100, D_Loss:0.4862261116504669, G_Loss:10.03176498413086

iterator 4200, D_Loss:0.4702371656894684, G_Loss:8.804966926574707

iterator 4300, D_Loss:0.456741601228714, G_Loss:7.513369560241699

iterator 4400, D_Loss:0.4809451401233673, G_Loss:8.173420906066895

iterator 4500, D_Loss:0.4799881875514984, G_Loss:6.767224311828613

iterator 4600, D_Loss:0.4728025197982788, G_Loss:8.979759216308594

iterator 4700, D_Loss:0.46168461441993713, G_Loss:11.00025463104248

iterator 4800, D_Loss:0.47472822666168213, G_Loss:8.275602340698242

iterator 4900, D_Loss:0.48070740699768066, G_Loss:8.07254409790039

iterator 5000, D_Loss:0.4623684585094452, G_Loss:6.257567882537842

-----------Epoch 9-----------
iterator 100, D_Loss:0.459677129983902, G_Loss:7.434681415557861

iterator 200, D_Loss:0.5253496170043945, G_Loss:5.104608535766602

iterator 300, D_Loss:0.47225987911224365, G_Loss:7.007289409637451

iterator 400, D_Loss:0.45274966955184937, G_Loss:9.95340347290039

iterator 500, D_Loss:0.471129834651947, G_Loss:8.24858283996582

iterator 600, D_Loss:0.5319664478302002, G_Loss:5.116705417633057

iterator 700, D_Loss:0.47781285643577576, G_Loss:6.967639923095703

iterator 800, D_Loss:0.4917965829372406, G_Loss:7.141744613647461

iterator 900, D_Loss:0.4681679606437683, G_Loss:7.476648807525635

iterator 1000, D_Loss:0.4444601237773895, G_Loss:6.840221881866455

iterator 1100, D_Loss:0.47353824973106384, G_Loss:10.015196800231934

iterator 1200, D_Loss:0.47534868121147156, G_Loss:7.24091911315918

iterator 1300, D_Loss:0.4622381031513214, G_Loss:7.959929466247559

iterator 1400, D_Loss:0.4627431035041809, G_Loss:7.917025566101074

iterator 1500, D_Loss:0.4786008596420288, G_Loss:9.192001342773438

iterator 1600, D_Loss:0.47883403301239014, G_Loss:7.691370487213135

iterator 1700, D_Loss:0.5069359540939331, G_Loss:8.056635856628418

iterator 1800, D_Loss:0.4484330117702484, G_Loss:8.952545166015625

iterator 1900, D_Loss:0.4653858244419098, G_Loss:7.960049152374268

iterator 2000, D_Loss:0.45892754197120667, G_Loss:7.264116287231445

iterator 2100, D_Loss:0.4313878118991852, G_Loss:9.960138320922852

iterator 2200, D_Loss:0.485858678817749, G_Loss:7.793615341186523

iterator 2300, D_Loss:0.46654367446899414, G_Loss:11.024392127990723

iterator 2400, D_Loss:0.44789379835128784, G_Loss:7.806834697723389

iterator 2500, D_Loss:0.47895190119743347, G_Loss:9.361529350280762

iterator 2600, D_Loss:0.4802124798297882, G_Loss:6.934152126312256

iterator 2700, D_Loss:0.4937497079372406, G_Loss:8.55134105682373

iterator 2800, D_Loss:0.4741000533103943, G_Loss:9.21904468536377

iterator 2900, D_Loss:0.4717342257499695, G_Loss:7.404307842254639

iterator 3000, D_Loss:0.47275933623313904, G_Loss:8.972223281860352

iterator 3100, D_Loss:0.5054522156715393, G_Loss:8.766736030578613

iterator 3200, D_Loss:0.48382630944252014, G_Loss:8.994279861450195

iterator 3300, D_Loss:0.481154203414917, G_Loss:8.864352226257324

iterator 3400, D_Loss:0.4319618046283722, G_Loss:9.547855377197266

iterator 3500, D_Loss:0.4888571500778198, G_Loss:9.632011413574219

iterator 3600, D_Loss:0.4716298282146454, G_Loss:10.685572624206543

iterator 3700, D_Loss:0.466533899307251, G_Loss:6.708041667938232

iterator 3800, D_Loss:0.4596385061740875, G_Loss:9.861814498901367

iterator 3900, D_Loss:0.4637174904346466, G_Loss:10.124266624450684

iterator 4000, D_Loss:0.47896242141723633, G_Loss:7.53116512298584

iterator 4100, D_Loss:0.4960276484489441, G_Loss:8.470536231994629

iterator 4200, D_Loss:0.4825022518634796, G_Loss:6.55944299697876

iterator 4300, D_Loss:0.4930797219276428, G_Loss:10.016314506530762

iterator 4400, D_Loss:0.4655422866344452, G_Loss:7.151505947113037

iterator 4500, D_Loss:0.4654025733470917, G_Loss:7.922590255737305

iterator 4600, D_Loss:0.4775279462337494, G_Loss:11.751285552978516

iterator 4700, D_Loss:0.47725072503089905, G_Loss:8.187824249267578

iterator 4800, D_Loss:0.46967434883117676, G_Loss:10.649581909179688

iterator 4900, D_Loss:0.4809521436691284, G_Loss:6.94133186340332

iterator 5000, D_Loss:0.4662265479564667, G_Loss:8.365447044372559

LGAN_generator(
  (LSTM): LSTMCell(400, 300)
  (gmfc00): Linear(in_features=300, out_features=1, bias=True)
  (gmfc01): Linear(in_features=300, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=300, bias=True)
  (gmfe00): Linear(in_features=300, out_features=300, bias=True)
  (gmfe01): Linear(in_features=300, out_features=300, bias=True)
  (fc10): Linear(in_features=300, out_features=1, bias=True)
  (fc11): Linear(in_features=1, out_features=300, bias=True)
  (fe1): Linear(in_features=300, out_features=300, bias=True)
  (gmfc20): Linear(in_features=300, out_features=1, bias=True)
  (gmfc21): Linear(in_features=300, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=300, bias=True)
  (gmfe20): Linear(in_features=300, out_features=300, bias=True)
  (gmfe21): Linear(in_features=300, out_features=300, bias=True)
  (fc30): Linear(in_features=300, out_features=1, bias=True)
  (fc31): Linear(in_features=1, out_features=300, bias=True)
  (fe3): Linear(in_features=300, out_features=300, bias=True)
  (gmfc40): Linear(in_features=300, out_features=1, bias=True)
  (gmfc41): Linear(in_features=300, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=300, bias=True)
  (gmfe40): Linear(in_features=300, out_features=300, bias=True)
  (gmfe41): Linear(in_features=300, out_features=300, bias=True)
  (fc50): Linear(in_features=300, out_features=1, bias=True)
  (fc51): Linear(in_features=1, out_features=300, bias=True)
  (fe5): Linear(in_features=300, out_features=300, bias=True)
  (fc60): Linear(in_features=300, out_features=1, bias=True)
  (fc61): Linear(in_features=1, out_features=300, bias=True)
  (fe6): Linear(in_features=300, out_features=300, bias=True)
  (fc70): Linear(in_features=300, out_features=1, bias=True)
  (fc71): Linear(in_features=1, out_features=300, bias=True)
  (fe7): Linear(in_features=300, out_features=300, bias=True)
  (fc80): Linear(in_features=300, out_features=1, bias=True)
  (fc81): Linear(in_features=1, out_features=300, bias=True)
  (fe8): Linear(in_features=300, out_features=300, bias=True)
  (fc90): Linear(in_features=300, out_features=1, bias=True)
  (fc91): Linear(in_features=1, out_features=300, bias=True)
  (fe9): Linear(in_features=300, out_features=300, bias=True)
  (gmfc100): Linear(in_features=300, out_features=1, bias=True)
  (gmfc101): Linear(in_features=300, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=300, bias=True)
  (gmfe100): Linear(in_features=300, out_features=300, bias=True)
  (gmfe101): Linear(in_features=300, out_features=300, bias=True)
  (gmfc110): Linear(in_features=300, out_features=1, bias=True)
  (gmfc111): Linear(in_features=300, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=300, bias=True)
  (gmfe110): Linear(in_features=300, out_features=300, bias=True)
  (gmfe111): Linear(in_features=300, out_features=300, bias=True)
  (gmfc120): Linear(in_features=300, out_features=1, bias=True)
  (gmfc121): Linear(in_features=300, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=300, bias=True)
  (gmfe120): Linear(in_features=300, out_features=300, bias=True)
  (gmfe121): Linear(in_features=300, out_features=300, bias=True)
  (fc130): Linear(in_features=300, out_features=1, bias=True)
  (fc131): Linear(in_features=1, out_features=300, bias=True)
  (fe13): Linear(in_features=300, out_features=300, bias=True)
  (fc140): Linear(in_features=300, out_features=1, bias=True)
  (fc141): Linear(in_features=1, out_features=300, bias=True)
  (fe14): Linear(in_features=300, out_features=300, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=45, out_features=100, bias=True)
  (inputbn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=100, out_features=100, bias=True)
  (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=100, out_features=100, bias=True)
  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=100, out_features=100, bias=True)
  (bn3): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=100, out_features=1, bias=True)
)
(0, False, 45)
-----------Epoch 0-----------
iterator 100, D_Loss:1.3970388174057007, G_Loss:1.0133743286132812

iterator 200, D_Loss:1.3852629661560059, G_Loss:0.9351262450218201

iterator 300, D_Loss:1.376731276512146, G_Loss:0.9674330353736877

iterator 400, D_Loss:1.370076298713684, G_Loss:0.9936434030532837

iterator 500, D_Loss:1.3600249290466309, G_Loss:0.9759552478790283

iterator 600, D_Loss:1.3106411695480347, G_Loss:1.073003888130188

iterator 700, D_Loss:1.331658124923706, G_Loss:0.9268097877502441

iterator 800, D_Loss:1.3562963008880615, G_Loss:1.019105315208435

iterator 900, D_Loss:1.318740725517273, G_Loss:1.026854157447815

iterator 1000, D_Loss:1.2814239263534546, G_Loss:1.0911495685577393

iterator 1100, D_Loss:1.2303098440170288, G_Loss:1.3685126304626465

iterator 1200, D_Loss:1.0879560708999634, G_Loss:1.4328629970550537

iterator 1300, D_Loss:1.1790170669555664, G_Loss:0.9668048024177551

iterator 1400, D_Loss:0.9264088273048401, G_Loss:1.3500819206237793

iterator 1500, D_Loss:0.9144798517227173, G_Loss:2.1019797325134277

iterator 1600, D_Loss:0.7165652513504028, G_Loss:2.6134450435638428

iterator 1700, D_Loss:0.6432899236679077, G_Loss:2.7376701831817627

iterator 1800, D_Loss:0.5739011764526367, G_Loss:2.5680038928985596

iterator 1900, D_Loss:0.7651433944702148, G_Loss:3.8882362842559814

iterator 2000, D_Loss:0.6299331784248352, G_Loss:3.5143260955810547

iterator 2100, D_Loss:0.5704565048217773, G_Loss:3.9554507732391357

iterator 2200, D_Loss:0.5334325432777405, G_Loss:2.7111306190490723

iterator 2300, D_Loss:0.5348967909812927, G_Loss:3.6389832496643066

iterator 2400, D_Loss:0.4892757833003998, G_Loss:2.824432849884033

iterator 2500, D_Loss:0.5063132643699646, G_Loss:4.778135776519775

iterator 2600, D_Loss:0.48543715476989746, G_Loss:3.18308687210083

iterator 2700, D_Loss:0.516822099685669, G_Loss:5.85797119140625

iterator 2800, D_Loss:0.5409173965454102, G_Loss:5.396268844604492

iterator 2900, D_Loss:0.46392327547073364, G_Loss:5.942112922668457

iterator 3000, D_Loss:0.4636416733264923, G_Loss:5.8183770179748535

iterator 3100, D_Loss:0.4842396378517151, G_Loss:5.5039591789245605

iterator 3200, D_Loss:0.4622265696525574, G_Loss:5.41720724105835

iterator 3300, D_Loss:0.4656459391117096, G_Loss:6.201720237731934

iterator 3400, D_Loss:0.48289331793785095, G_Loss:6.713637828826904

iterator 3500, D_Loss:0.460073858499527, G_Loss:2.885274887084961

iterator 3600, D_Loss:0.4719054400920868, G_Loss:5.539882183074951

iterator 3700, D_Loss:0.4394994378089905, G_Loss:7.944332599639893

iterator 3800, D_Loss:0.44591912627220154, G_Loss:3.455197334289551

iterator 3900, D_Loss:0.4844174385070801, G_Loss:6.8344855308532715

iterator 4000, D_Loss:0.49077239632606506, G_Loss:6.92352294921875

iterator 4100, D_Loss:0.49584877490997314, G_Loss:8.21176815032959

iterator 4200, D_Loss:0.4339450001716614, G_Loss:7.596412658691406

iterator 4300, D_Loss:0.44027435779571533, G_Loss:6.7156877517700195

iterator 4400, D_Loss:0.45090994238853455, G_Loss:7.333011150360107

iterator 4500, D_Loss:0.4546477794647217, G_Loss:7.175127029418945

iterator 4600, D_Loss:0.5011880397796631, G_Loss:6.404162406921387

iterator 4700, D_Loss:0.4649963676929474, G_Loss:6.572729110717773

iterator 4800, D_Loss:0.4575769901275635, G_Loss:7.3697075843811035

iterator 4900, D_Loss:0.4475423991680145, G_Loss:6.869333744049072

iterator 5000, D_Loss:0.42559540271759033, G_Loss:8.932538032531738

-----------Epoch 1-----------
iterator 100, D_Loss:0.4436192810535431, G_Loss:7.725584983825684

iterator 200, D_Loss:0.4574458599090576, G_Loss:6.905977249145508

iterator 300, D_Loss:0.4471096992492676, G_Loss:7.5148749351501465

iterator 400, D_Loss:0.4382063150405884, G_Loss:8.295870780944824

iterator 500, D_Loss:0.4426559805870056, G_Loss:7.554747104644775

iterator 600, D_Loss:0.4583503305912018, G_Loss:6.829113960266113

iterator 700, D_Loss:0.4217592179775238, G_Loss:9.115194320678711

iterator 800, D_Loss:0.45949968695640564, G_Loss:6.713041305541992

iterator 900, D_Loss:0.43224722146987915, G_Loss:8.006979942321777

iterator 1000, D_Loss:0.440449059009552, G_Loss:7.471689224243164

iterator 1100, D_Loss:0.43252503871917725, G_Loss:9.469955444335938

iterator 1200, D_Loss:0.4544427990913391, G_Loss:8.926901817321777

iterator 1300, D_Loss:0.44817695021629333, G_Loss:6.252526760101318

iterator 1400, D_Loss:0.44587963819503784, G_Loss:8.052063941955566

iterator 1500, D_Loss:0.4919011890888214, G_Loss:8.579776763916016

iterator 1600, D_Loss:0.4523887038230896, G_Loss:9.922758102416992

iterator 1700, D_Loss:0.4538162648677826, G_Loss:7.563700199127197

iterator 1800, D_Loss:0.4075610041618347, G_Loss:8.602002143859863

iterator 1900, D_Loss:0.43855664134025574, G_Loss:7.700221061706543

iterator 2000, D_Loss:0.4061322808265686, G_Loss:7.925643444061279

iterator 2100, D_Loss:0.42022886872291565, G_Loss:9.029242515563965

iterator 2200, D_Loss:0.4357422888278961, G_Loss:10.259696006774902

iterator 2300, D_Loss:0.4543011784553528, G_Loss:9.708296775817871

iterator 2400, D_Loss:0.436254620552063, G_Loss:10.276811599731445

iterator 2500, D_Loss:0.42938709259033203, G_Loss:12.069190979003906

iterator 2600, D_Loss:0.41987866163253784, G_Loss:11.471487998962402

iterator 2700, D_Loss:0.45348620414733887, G_Loss:9.981524467468262

iterator 2800, D_Loss:0.4079890251159668, G_Loss:10.925599098205566

iterator 2900, D_Loss:0.4514748752117157, G_Loss:11.122856140136719

iterator 3000, D_Loss:0.43047434091567993, G_Loss:9.455879211425781

iterator 3100, D_Loss:0.42286810278892517, G_Loss:9.972244262695312

iterator 3200, D_Loss:0.41430413722991943, G_Loss:10.968748092651367

iterator 3300, D_Loss:0.40855398774147034, G_Loss:10.115006446838379

iterator 3400, D_Loss:0.42197185754776, G_Loss:10.971983909606934

iterator 3500, D_Loss:0.39636164903640747, G_Loss:9.720625877380371

iterator 3600, D_Loss:0.40523266792297363, G_Loss:10.7930908203125

iterator 3700, D_Loss:0.41253960132598877, G_Loss:10.301198959350586

iterator 3800, D_Loss:0.4507279396057129, G_Loss:10.482187271118164

iterator 3900, D_Loss:0.4207279682159424, G_Loss:7.234704971313477

iterator 4000, D_Loss:0.45525801181793213, G_Loss:11.524253845214844

iterator 4100, D_Loss:0.4330417811870575, G_Loss:10.99416446685791

iterator 4200, D_Loss:0.48627153038978577, G_Loss:10.744900703430176

iterator 4300, D_Loss:0.40134596824645996, G_Loss:11.501842498779297

iterator 4400, D_Loss:0.436545193195343, G_Loss:11.07900333404541

iterator 4500, D_Loss:0.4373135566711426, G_Loss:12.147444725036621

iterator 4600, D_Loss:0.4229626953601837, G_Loss:11.664067268371582

iterator 4700, D_Loss:0.4312545657157898, G_Loss:10.067973136901855

iterator 4800, D_Loss:0.432608038187027, G_Loss:10.232583045959473

iterator 4900, D_Loss:0.41088834404945374, G_Loss:13.09060287475586

iterator 5000, D_Loss:0.42740440368652344, G_Loss:12.27155876159668

-----------Epoch 2-----------
iterator 100, D_Loss:0.4172839820384979, G_Loss:10.865708351135254

iterator 200, D_Loss:0.42748379707336426, G_Loss:10.092793464660645

iterator 300, D_Loss:0.4299480617046356, G_Loss:10.312650680541992

iterator 400, D_Loss:0.429832398891449, G_Loss:12.286028861999512

iterator 500, D_Loss:0.4063836336135864, G_Loss:11.121773719787598

iterator 600, D_Loss:0.4255450665950775, G_Loss:10.923442840576172

iterator 700, D_Loss:0.4339945912361145, G_Loss:10.646295547485352

iterator 800, D_Loss:0.42200958728790283, G_Loss:8.908683776855469

iterator 900, D_Loss:0.4483969509601593, G_Loss:10.475672721862793

iterator 1000, D_Loss:0.40018802881240845, G_Loss:14.082160949707031

iterator 1100, D_Loss:0.39951691031455994, G_Loss:13.838476181030273

iterator 1200, D_Loss:0.46705567836761475, G_Loss:11.27466869354248

iterator 1300, D_Loss:0.42339831590652466, G_Loss:13.078445434570312

iterator 1400, D_Loss:0.42783093452453613, G_Loss:13.805876731872559

iterator 1500, D_Loss:0.46362441778182983, G_Loss:11.671591758728027

iterator 1600, D_Loss:0.4244150221347809, G_Loss:11.260890007019043

iterator 1700, D_Loss:0.39477381110191345, G_Loss:13.506457328796387

iterator 1800, D_Loss:0.4491277039051056, G_Loss:13.218528747558594

iterator 1900, D_Loss:0.4167366623878479, G_Loss:9.733023643493652

iterator 2000, D_Loss:0.44438931345939636, G_Loss:11.93077278137207

iterator 2100, D_Loss:0.4538159668445587, G_Loss:10.13182258605957

iterator 2200, D_Loss:0.42675691843032837, G_Loss:14.182707786560059

iterator 2300, D_Loss:0.4424981474876404, G_Loss:12.96889877319336

iterator 2400, D_Loss:0.4181622564792633, G_Loss:12.621188163757324

iterator 2500, D_Loss:0.43214064836502075, G_Loss:10.006866455078125

iterator 2600, D_Loss:0.4204624593257904, G_Loss:10.016498565673828

iterator 2700, D_Loss:0.4217924177646637, G_Loss:13.962275505065918

iterator 2800, D_Loss:0.42994430661201477, G_Loss:14.460225105285645

iterator 2900, D_Loss:0.43345117568969727, G_Loss:8.308002471923828

iterator 3000, D_Loss:0.4338868260383606, G_Loss:10.092338562011719

iterator 3100, D_Loss:0.38939619064331055, G_Loss:11.932902336120605

iterator 3200, D_Loss:0.4372794032096863, G_Loss:14.412827491760254

iterator 3300, D_Loss:0.4284433424472809, G_Loss:15.4392728805542

iterator 3400, D_Loss:0.4292389750480652, G_Loss:11.054707527160645

iterator 3500, D_Loss:0.42835676670074463, G_Loss:13.5635986328125

iterator 3600, D_Loss:0.43904054164886475, G_Loss:11.587843894958496

iterator 3700, D_Loss:0.40725067257881165, G_Loss:11.793017387390137

iterator 3800, D_Loss:0.42464184761047363, G_Loss:14.143080711364746

iterator 3900, D_Loss:0.3829861581325531, G_Loss:11.294347763061523

iterator 4000, D_Loss:0.4260900020599365, G_Loss:11.42933177947998

iterator 4100, D_Loss:0.4235736131668091, G_Loss:13.920295715332031

iterator 4200, D_Loss:0.4033389091491699, G_Loss:13.667778015136719

iterator 4300, D_Loss:0.40997442603111267, G_Loss:15.158418655395508

iterator 4400, D_Loss:0.4368797540664673, G_Loss:14.700748443603516

iterator 4500, D_Loss:0.4510060250759125, G_Loss:15.45892333984375

iterator 4600, D_Loss:0.4472464323043823, G_Loss:13.887475967407227

iterator 4700, D_Loss:0.44245633482933044, G_Loss:13.883940696716309

iterator 4800, D_Loss:0.4158679246902466, G_Loss:14.116097450256348

iterator 4900, D_Loss:0.4431104362010956, G_Loss:13.77173900604248

iterator 5000, D_Loss:0.44584423303604126, G_Loss:13.321894645690918

-----------Epoch 3-----------
iterator 100, D_Loss:0.4329627752304077, G_Loss:12.939430236816406

iterator 200, D_Loss:0.43345001339912415, G_Loss:13.723941802978516

iterator 300, D_Loss:0.4004824459552765, G_Loss:14.377677917480469

iterator 400, D_Loss:0.41896647214889526, G_Loss:15.331957817077637

iterator 500, D_Loss:0.43194296956062317, G_Loss:13.765212059020996

iterator 600, D_Loss:0.4002363979816437, G_Loss:11.961159706115723

iterator 700, D_Loss:0.4287739396095276, G_Loss:13.588113784790039

iterator 800, D_Loss:0.4283999800682068, G_Loss:12.467571258544922

iterator 900, D_Loss:0.4358823299407959, G_Loss:11.336087226867676

iterator 1000, D_Loss:0.41774120926856995, G_Loss:12.307182312011719

iterator 1100, D_Loss:0.41934749484062195, G_Loss:11.747745513916016

iterator 1200, D_Loss:0.4301052987575531, G_Loss:12.021492958068848

iterator 1300, D_Loss:0.4207143783569336, G_Loss:11.985933303833008

iterator 1400, D_Loss:0.42123523354530334, G_Loss:12.375028610229492

iterator 1500, D_Loss:0.4579330086708069, G_Loss:13.436100006103516

iterator 1600, D_Loss:0.443193256855011, G_Loss:10.658879280090332

iterator 1700, D_Loss:0.4339699149131775, G_Loss:13.64041805267334

iterator 1800, D_Loss:0.42655906081199646, G_Loss:15.38028335571289

iterator 1900, D_Loss:0.3987937569618225, G_Loss:15.551192283630371

iterator 2000, D_Loss:0.4152688682079315, G_Loss:16.01926040649414

iterator 2100, D_Loss:0.4379468262195587, G_Loss:7.117189884185791

iterator 2200, D_Loss:0.4304906129837036, G_Loss:16.207216262817383

iterator 2300, D_Loss:0.4154510200023651, G_Loss:15.488692283630371

iterator 2400, D_Loss:0.43167105317115784, G_Loss:16.584917068481445

iterator 2500, D_Loss:0.42779842019081116, G_Loss:14.353086471557617

iterator 2600, D_Loss:0.45078638195991516, G_Loss:12.362699508666992

iterator 2700, D_Loss:0.4327656626701355, G_Loss:15.000938415527344

iterator 2800, D_Loss:0.39490392804145813, G_Loss:14.282045364379883

iterator 2900, D_Loss:0.428877592086792, G_Loss:12.140924453735352

iterator 3000, D_Loss:0.43001821637153625, G_Loss:14.996888160705566

iterator 3100, D_Loss:0.4368380308151245, G_Loss:13.400924682617188

iterator 3200, D_Loss:0.42724910378456116, G_Loss:15.057971000671387

iterator 3300, D_Loss:0.4161657691001892, G_Loss:14.305821418762207

iterator 3400, D_Loss:0.4384020268917084, G_Loss:13.879358291625977

iterator 3500, D_Loss:0.41974523663520813, G_Loss:14.204498291015625

iterator 3600, D_Loss:0.4263684153556824, G_Loss:16.75066375732422

iterator 3700, D_Loss:0.42399632930755615, G_Loss:17.935176849365234

iterator 3800, D_Loss:0.4313298463821411, G_Loss:14.059325218200684

iterator 3900, D_Loss:0.412949800491333, G_Loss:17.489532470703125

iterator 4000, D_Loss:0.38651329278945923, G_Loss:16.719636917114258

iterator 4100, D_Loss:0.4208239018917084, G_Loss:14.830475807189941

iterator 4200, D_Loss:0.4519928991794586, G_Loss:14.893878936767578

iterator 4300, D_Loss:0.41714322566986084, G_Loss:14.588983535766602

iterator 4400, D_Loss:0.43631795048713684, G_Loss:12.825045585632324

iterator 4500, D_Loss:0.4107317626476288, G_Loss:13.229867935180664

iterator 4600, D_Loss:0.44082018733024597, G_Loss:14.77093505859375

iterator 4700, D_Loss:0.43101704120635986, G_Loss:11.925382614135742

iterator 4800, D_Loss:0.3979146480560303, G_Loss:13.540535926818848

iterator 4900, D_Loss:0.43506062030792236, G_Loss:14.826311111450195

iterator 5000, D_Loss:0.4206496477127075, G_Loss:15.297392845153809

-----------Epoch 4-----------
iterator 100, D_Loss:0.40341243147850037, G_Loss:14.15219497680664

iterator 200, D_Loss:0.4318290650844574, G_Loss:13.157539367675781

iterator 300, D_Loss:0.4158064126968384, G_Loss:11.02320384979248

iterator 400, D_Loss:0.4305247664451599, G_Loss:10.843052864074707

iterator 500, D_Loss:0.44202691316604614, G_Loss:12.334122657775879

iterator 600, D_Loss:0.4033183157444, G_Loss:11.298211097717285

iterator 700, D_Loss:0.4167039692401886, G_Loss:12.686599731445312

iterator 800, D_Loss:0.45244255661964417, G_Loss:13.292594909667969

iterator 900, D_Loss:0.43303582072257996, G_Loss:15.24048900604248

iterator 1000, D_Loss:0.4047583341598511, G_Loss:14.610822677612305

iterator 1100, D_Loss:0.42077741026878357, G_Loss:17.349885940551758

iterator 1200, D_Loss:0.4210098385810852, G_Loss:11.93116283416748

iterator 1300, D_Loss:0.43890321254730225, G_Loss:13.351144790649414

iterator 1400, D_Loss:0.41164374351501465, G_Loss:12.069153785705566

iterator 1500, D_Loss:0.4414733350276947, G_Loss:12.369950294494629

iterator 1600, D_Loss:0.43282467126846313, G_Loss:14.241497993469238

iterator 1700, D_Loss:0.41612708568573, G_Loss:15.288911819458008

iterator 1800, D_Loss:0.41153693199157715, G_Loss:13.975591659545898

iterator 1900, D_Loss:0.419458270072937, G_Loss:16.755245208740234

iterator 2000, D_Loss:0.40297242999076843, G_Loss:14.076236724853516

iterator 2100, D_Loss:0.410533607006073, G_Loss:12.769298553466797

iterator 2200, D_Loss:0.4179488718509674, G_Loss:16.092222213745117

iterator 2300, D_Loss:0.41580498218536377, G_Loss:14.606791496276855

iterator 2400, D_Loss:0.4139023423194885, G_Loss:16.004459381103516

iterator 2500, D_Loss:0.4433031678199768, G_Loss:14.664497375488281

iterator 2600, D_Loss:0.4146302342414856, G_Loss:15.111223220825195

iterator 2700, D_Loss:0.4421473741531372, G_Loss:13.114415168762207

iterator 2800, D_Loss:0.4077739715576172, G_Loss:14.307879447937012

iterator 2900, D_Loss:0.43407386541366577, G_Loss:13.770561218261719

iterator 3000, D_Loss:0.42300257086753845, G_Loss:13.582908630371094

iterator 3100, D_Loss:0.4290468692779541, G_Loss:14.519923210144043

iterator 3200, D_Loss:0.3890853524208069, G_Loss:14.044350624084473

iterator 3300, D_Loss:0.40415897965431213, G_Loss:14.551765441894531

iterator 3400, D_Loss:0.4044419825077057, G_Loss:14.253374099731445

iterator 3500, D_Loss:0.45648902654647827, G_Loss:14.232828140258789

iterator 3600, D_Loss:0.43086475133895874, G_Loss:13.793556213378906

iterator 3700, D_Loss:0.446351021528244, G_Loss:14.596501350402832

iterator 3800, D_Loss:0.43113771080970764, G_Loss:10.696365356445312

iterator 3900, D_Loss:0.46384796500205994, G_Loss:11.869385719299316

iterator 4000, D_Loss:0.4049367904663086, G_Loss:12.183313369750977

iterator 4100, D_Loss:0.42432013154029846, G_Loss:10.589238166809082

iterator 4200, D_Loss:0.4106527268886566, G_Loss:11.820219993591309

iterator 4300, D_Loss:0.4178334176540375, G_Loss:13.737771034240723

iterator 4400, D_Loss:0.43407586216926575, G_Loss:12.15395450592041

iterator 4500, D_Loss:0.4173555076122284, G_Loss:11.231820106506348

iterator 4600, D_Loss:0.4112318456172943, G_Loss:12.47793197631836

iterator 4700, D_Loss:0.41571664810180664, G_Loss:14.917341232299805

iterator 4800, D_Loss:0.42012593150138855, G_Loss:12.177623748779297

iterator 4900, D_Loss:0.42622461915016174, G_Loss:12.196486473083496

iterator 5000, D_Loss:0.3985360860824585, G_Loss:11.44198989868164

-----------Epoch 5-----------
iterator 100, D_Loss:0.4197922945022583, G_Loss:12.782294273376465

iterator 200, D_Loss:0.4028868079185486, G_Loss:13.852409362792969

iterator 300, D_Loss:0.4335986077785492, G_Loss:13.770367622375488

iterator 400, D_Loss:0.4266672730445862, G_Loss:14.178801536560059

iterator 500, D_Loss:0.4248911738395691, G_Loss:16.045644760131836

iterator 600, D_Loss:0.44484415650367737, G_Loss:12.46373176574707

iterator 700, D_Loss:0.43718549609184265, G_Loss:13.855040550231934

iterator 800, D_Loss:0.428387850522995, G_Loss:14.433296203613281

iterator 900, D_Loss:0.4199507236480713, G_Loss:13.037439346313477

iterator 1000, D_Loss:0.43539345264434814, G_Loss:16.18768882751465

iterator 1100, D_Loss:0.4443533718585968, G_Loss:11.833756446838379

iterator 1200, D_Loss:0.4242687225341797, G_Loss:12.996892929077148

iterator 1300, D_Loss:0.45023980736732483, G_Loss:13.328661918640137

iterator 1400, D_Loss:0.42934897541999817, G_Loss:12.768731117248535

iterator 1500, D_Loss:0.42724931240081787, G_Loss:12.716012954711914

iterator 1600, D_Loss:0.412374883890152, G_Loss:12.956130027770996

iterator 1700, D_Loss:0.42920979857444763, G_Loss:16.288679122924805

iterator 1800, D_Loss:0.43903613090515137, G_Loss:11.615856170654297

iterator 1900, D_Loss:0.41720184683799744, G_Loss:13.171911239624023

iterator 2000, D_Loss:0.41151055693626404, G_Loss:5.9446797370910645

iterator 2100, D_Loss:0.4433196187019348, G_Loss:14.942590713500977

iterator 2200, D_Loss:0.42425966262817383, G_Loss:14.664522171020508

iterator 2300, D_Loss:0.4416961073875427, G_Loss:12.824962615966797

iterator 2400, D_Loss:0.40688785910606384, G_Loss:13.895105361938477

iterator 2500, D_Loss:0.41569897532463074, G_Loss:13.495864868164062

iterator 2600, D_Loss:0.40590912103652954, G_Loss:12.054753303527832

iterator 2700, D_Loss:0.4204145073890686, G_Loss:11.5687837600708

iterator 2800, D_Loss:0.4362240731716156, G_Loss:14.86572551727295

iterator 2900, D_Loss:0.4450708031654358, G_Loss:14.067976951599121

iterator 3000, D_Loss:0.44780582189559937, G_Loss:16.523502349853516

iterator 3100, D_Loss:0.43767476081848145, G_Loss:13.04203987121582

iterator 3200, D_Loss:0.43855297565460205, G_Loss:14.71614933013916

iterator 3300, D_Loss:0.4253532588481903, G_Loss:15.337472915649414

iterator 3400, D_Loss:0.43773430585861206, G_Loss:14.687885284423828

iterator 3500, D_Loss:0.4286386966705322, G_Loss:14.291502952575684

iterator 3600, D_Loss:0.43120265007019043, G_Loss:12.634008407592773

iterator 3700, D_Loss:0.4154518246650696, G_Loss:14.720809936523438

iterator 3800, D_Loss:0.40222060680389404, G_Loss:14.025579452514648

iterator 3900, D_Loss:0.4210222661495209, G_Loss:13.876514434814453

iterator 4000, D_Loss:0.4278176724910736, G_Loss:15.760321617126465

iterator 4100, D_Loss:0.4075565040111542, G_Loss:16.224918365478516

iterator 4200, D_Loss:0.4220137298107147, G_Loss:14.411569595336914

iterator 4300, D_Loss:0.4268224835395813, G_Loss:13.881978988647461

iterator 4400, D_Loss:0.4191921651363373, G_Loss:14.87129020690918

iterator 4500, D_Loss:0.43459761142730713, G_Loss:13.157169342041016

iterator 4600, D_Loss:0.42030760645866394, G_Loss:12.584108352661133

iterator 4700, D_Loss:0.41353729367256165, G_Loss:12.935028076171875

iterator 4800, D_Loss:0.44579076766967773, G_Loss:12.496761322021484

iterator 4900, D_Loss:0.4325213134288788, G_Loss:13.101754188537598

iterator 5000, D_Loss:0.4031916856765747, G_Loss:15.94830322265625

-----------Epoch 6-----------
iterator 100, D_Loss:0.4225728213787079, G_Loss:14.171016693115234

iterator 200, D_Loss:0.3984217047691345, G_Loss:11.79372501373291

iterator 300, D_Loss:0.45811551809310913, G_Loss:12.969932556152344

iterator 400, D_Loss:0.42886707186698914, G_Loss:14.003376007080078

iterator 500, D_Loss:0.4236212968826294, G_Loss:14.68807315826416

iterator 600, D_Loss:0.4072008430957794, G_Loss:14.074172019958496

iterator 700, D_Loss:0.43113017082214355, G_Loss:12.92015266418457

iterator 800, D_Loss:0.4386814832687378, G_Loss:13.28886890411377

iterator 900, D_Loss:0.4274076223373413, G_Loss:13.841018676757812

iterator 1000, D_Loss:0.4014064073562622, G_Loss:13.257022857666016

iterator 1100, D_Loss:0.4312936067581177, G_Loss:10.936421394348145

iterator 1200, D_Loss:0.4240339398384094, G_Loss:12.744294166564941

iterator 1300, D_Loss:0.39584144949913025, G_Loss:14.89437198638916

iterator 1400, D_Loss:0.4329586923122406, G_Loss:17.053604125976562

iterator 1500, D_Loss:0.4818308651447296, G_Loss:15.898601531982422

iterator 1600, D_Loss:0.43528613448143005, G_Loss:15.300230026245117

iterator 1700, D_Loss:0.3967342972755432, G_Loss:14.449339866638184

iterator 1800, D_Loss:0.3978946805000305, G_Loss:15.302566528320312

iterator 1900, D_Loss:0.4396110773086548, G_Loss:14.373228073120117

iterator 2000, D_Loss:0.4368742108345032, G_Loss:15.326112747192383

iterator 2100, D_Loss:0.4258931279182434, G_Loss:11.48496150970459

iterator 2200, D_Loss:0.43784239888191223, G_Loss:12.326929092407227

iterator 2300, D_Loss:0.4380989074707031, G_Loss:13.788738250732422

iterator 2400, D_Loss:0.4116019308567047, G_Loss:15.407635688781738

iterator 2500, D_Loss:0.4016907215118408, G_Loss:12.645370483398438

iterator 2600, D_Loss:0.4082961082458496, G_Loss:13.293749809265137

iterator 2700, D_Loss:0.393242746591568, G_Loss:15.04749870300293

iterator 2800, D_Loss:0.42971426248550415, G_Loss:15.701313972473145

iterator 2900, D_Loss:0.4276845455169678, G_Loss:14.365705490112305

iterator 3000, D_Loss:0.4186963438987732, G_Loss:14.420642852783203

iterator 3100, D_Loss:0.3956921398639679, G_Loss:14.129520416259766

iterator 3200, D_Loss:0.4337095618247986, G_Loss:14.436309814453125

iterator 3300, D_Loss:0.4122334122657776, G_Loss:16.000185012817383

iterator 3400, D_Loss:0.4281582534313202, G_Loss:15.604057312011719

iterator 3500, D_Loss:0.40672674775123596, G_Loss:14.921280860900879

iterator 3600, D_Loss:0.44119781255722046, G_Loss:14.838980674743652

iterator 3700, D_Loss:0.4078284502029419, G_Loss:14.07595443725586

iterator 3800, D_Loss:0.41851162910461426, G_Loss:15.64095687866211

iterator 3900, D_Loss:0.4331449568271637, G_Loss:15.500936508178711

iterator 4000, D_Loss:0.398120641708374, G_Loss:14.332276344299316

iterator 4100, D_Loss:0.422489196062088, G_Loss:15.392975807189941

iterator 4200, D_Loss:0.3984198570251465, G_Loss:15.963056564331055

iterator 4300, D_Loss:0.4154231548309326, G_Loss:15.227222442626953

iterator 4400, D_Loss:0.4288122057914734, G_Loss:14.228693962097168

iterator 4500, D_Loss:0.425451397895813, G_Loss:14.15611457824707

iterator 4600, D_Loss:0.448012113571167, G_Loss:13.690364837646484

iterator 4700, D_Loss:0.43311214447021484, G_Loss:14.261618614196777

iterator 4800, D_Loss:0.42144834995269775, G_Loss:12.598478317260742

iterator 4900, D_Loss:0.463029146194458, G_Loss:13.300325393676758

iterator 5000, D_Loss:0.4190840721130371, G_Loss:14.855916023254395

-----------Epoch 7-----------
iterator 100, D_Loss:0.4316830039024353, G_Loss:11.971267700195312

iterator 200, D_Loss:0.4133158326148987, G_Loss:13.596453666687012

iterator 300, D_Loss:0.40516015887260437, G_Loss:14.287906646728516

iterator 400, D_Loss:0.40222060680389404, G_Loss:8.76371955871582

iterator 500, D_Loss:0.418209969997406, G_Loss:15.116514205932617

iterator 600, D_Loss:0.4354448616504669, G_Loss:13.523900985717773

iterator 700, D_Loss:0.4510514736175537, G_Loss:12.609082221984863

iterator 800, D_Loss:0.4278751611709595, G_Loss:12.43305492401123

iterator 900, D_Loss:0.4228884279727936, G_Loss:12.172113418579102

iterator 1000, D_Loss:0.41804981231689453, G_Loss:12.550117492675781

iterator 1100, D_Loss:0.4351702034473419, G_Loss:11.843283653259277

iterator 1200, D_Loss:0.44642144441604614, G_Loss:14.15412425994873

iterator 1300, D_Loss:0.4233740568161011, G_Loss:11.860881805419922

iterator 1400, D_Loss:0.4201328456401825, G_Loss:11.801946640014648

iterator 1500, D_Loss:0.41147974133491516, G_Loss:12.743511199951172

iterator 1600, D_Loss:0.41952642798423767, G_Loss:12.9879150390625

iterator 1700, D_Loss:0.4157862365245819, G_Loss:12.868672370910645

iterator 1800, D_Loss:0.4230806529521942, G_Loss:12.646610260009766

iterator 1900, D_Loss:0.421661913394928, G_Loss:10.570392608642578

iterator 2000, D_Loss:0.4055475890636444, G_Loss:14.420988082885742

iterator 2100, D_Loss:0.41154611110687256, G_Loss:15.114415168762207

iterator 2200, D_Loss:0.4463121294975281, G_Loss:13.82715892791748

iterator 2300, D_Loss:0.44634726643562317, G_Loss:7.823465347290039

iterator 2400, D_Loss:0.44103774428367615, G_Loss:16.745410919189453

iterator 2500, D_Loss:0.4224790632724762, G_Loss:16.030580520629883

iterator 2600, D_Loss:0.421391099691391, G_Loss:13.354459762573242

iterator 2700, D_Loss:0.41830503940582275, G_Loss:14.946084022521973

iterator 2800, D_Loss:0.43308693170547485, G_Loss:13.920714378356934

iterator 2900, D_Loss:0.3992023766040802, G_Loss:15.629229545593262

iterator 3000, D_Loss:0.42470216751098633, G_Loss:13.597768783569336

iterator 3100, D_Loss:0.4302031695842743, G_Loss:12.817244529724121

iterator 3200, D_Loss:0.42869672179222107, G_Loss:15.133293151855469

iterator 3300, D_Loss:0.4091694951057434, G_Loss:15.238455772399902

iterator 3400, D_Loss:0.39734914898872375, G_Loss:15.10495376586914

iterator 3500, D_Loss:0.4315692186355591, G_Loss:15.847909927368164

iterator 3600, D_Loss:0.43633535504341125, G_Loss:14.399298667907715

iterator 3700, D_Loss:0.45209741592407227, G_Loss:14.659137725830078

iterator 3800, D_Loss:0.4197755455970764, G_Loss:14.36721134185791

iterator 3900, D_Loss:0.45153525471687317, G_Loss:14.143243789672852

iterator 4000, D_Loss:0.4360591769218445, G_Loss:12.770651817321777

iterator 4100, D_Loss:0.42105087637901306, G_Loss:13.496421813964844

iterator 4200, D_Loss:0.4425438642501831, G_Loss:13.927140235900879

iterator 4300, D_Loss:0.44072219729423523, G_Loss:14.105158805847168

iterator 4400, D_Loss:0.4653832018375397, G_Loss:14.072564125061035

iterator 4500, D_Loss:0.41374313831329346, G_Loss:13.5365571975708

iterator 4600, D_Loss:0.4282016158103943, G_Loss:11.667518615722656

iterator 4700, D_Loss:0.42903560400009155, G_Loss:15.350226402282715

iterator 4800, D_Loss:0.4389166235923767, G_Loss:15.053869247436523

iterator 4900, D_Loss:0.46080780029296875, G_Loss:14.142508506774902

iterator 5000, D_Loss:0.4125369191169739, G_Loss:15.742842674255371

-----------Epoch 8-----------
iterator 100, D_Loss:0.44505125284194946, G_Loss:14.346864700317383

iterator 200, D_Loss:0.42005690932273865, G_Loss:14.786394119262695

iterator 300, D_Loss:0.4178440272808075, G_Loss:14.025257110595703

iterator 400, D_Loss:0.4146795868873596, G_Loss:15.09459400177002

iterator 500, D_Loss:0.4524676203727722, G_Loss:16.579822540283203

iterator 600, D_Loss:0.4225539565086365, G_Loss:14.193533897399902

iterator 700, D_Loss:0.4181827902793884, G_Loss:16.21979522705078

iterator 800, D_Loss:0.4304790198802948, G_Loss:15.705474853515625

iterator 900, D_Loss:0.4441334307193756, G_Loss:14.1555757522583

iterator 1000, D_Loss:0.4186142086982727, G_Loss:11.390349388122559

iterator 1100, D_Loss:0.39507436752319336, G_Loss:14.318775177001953

iterator 1200, D_Loss:0.4577586054801941, G_Loss:13.431180953979492

iterator 1300, D_Loss:0.44113925099372864, G_Loss:15.458389282226562

iterator 1400, D_Loss:0.40280210971832275, G_Loss:13.667845726013184

iterator 1500, D_Loss:0.4672538638114929, G_Loss:14.609952926635742

iterator 1600, D_Loss:0.4233647584915161, G_Loss:15.051970481872559

iterator 1700, D_Loss:0.4405544698238373, G_Loss:12.335236549377441

iterator 1800, D_Loss:0.40990450978279114, G_Loss:13.174166679382324

iterator 1900, D_Loss:0.42255839705467224, G_Loss:15.571282386779785

iterator 2000, D_Loss:0.4231875538825989, G_Loss:14.834851264953613

iterator 2100, D_Loss:0.4030955731868744, G_Loss:12.488048553466797

iterator 2200, D_Loss:0.44215527176856995, G_Loss:15.57040786743164

iterator 2300, D_Loss:0.43301334977149963, G_Loss:12.23998737335205

iterator 2400, D_Loss:0.4285551905632019, G_Loss:13.418018341064453

iterator 2500, D_Loss:0.43807873129844666, G_Loss:14.415099143981934

iterator 2600, D_Loss:0.4045919179916382, G_Loss:14.575281143188477

iterator 2700, D_Loss:0.42654600739479065, G_Loss:15.932723045349121

iterator 2800, D_Loss:0.4248669147491455, G_Loss:14.948348999023438

iterator 2900, D_Loss:0.43621626496315, G_Loss:14.28681755065918

iterator 3000, D_Loss:0.41266772150993347, G_Loss:13.920238494873047

iterator 3100, D_Loss:0.4146338999271393, G_Loss:12.827661514282227

iterator 3200, D_Loss:0.41701680421829224, G_Loss:13.024347305297852

iterator 3300, D_Loss:0.42220646142959595, G_Loss:11.505556106567383

iterator 3400, D_Loss:0.417402058839798, G_Loss:12.636762619018555

iterator 3500, D_Loss:0.4213651418685913, G_Loss:15.806227684020996

iterator 3600, D_Loss:0.43055644631385803, G_Loss:14.210959434509277

iterator 3700, D_Loss:0.43311309814453125, G_Loss:13.823474884033203

iterator 3800, D_Loss:0.4298532009124756, G_Loss:14.185831069946289

iterator 3900, D_Loss:0.41762492060661316, G_Loss:15.393113136291504

iterator 4000, D_Loss:0.44320958852767944, G_Loss:15.140225410461426

iterator 4100, D_Loss:0.43636584281921387, G_Loss:13.994192123413086

iterator 4200, D_Loss:0.4253661036491394, G_Loss:15.298457145690918

iterator 4300, D_Loss:0.4133799374103546, G_Loss:13.544659614562988

iterator 4400, D_Loss:0.42764538526535034, G_Loss:14.394474029541016

iterator 4500, D_Loss:0.4305435121059418, G_Loss:13.049275398254395

iterator 4600, D_Loss:0.42781123518943787, G_Loss:14.105022430419922

iterator 4700, D_Loss:0.43157175183296204, G_Loss:12.341894149780273

iterator 4800, D_Loss:0.3941600024700165, G_Loss:13.736872673034668

iterator 4900, D_Loss:0.4241567850112915, G_Loss:13.611767768859863

iterator 5000, D_Loss:0.4462628960609436, G_Loss:14.845372200012207

-----------Epoch 9-----------
iterator 100, D_Loss:0.40720927715301514, G_Loss:15.292450904846191

iterator 200, D_Loss:0.4205308258533478, G_Loss:13.86698055267334

iterator 300, D_Loss:0.4008389115333557, G_Loss:14.641398429870605

iterator 400, D_Loss:0.4096130430698395, G_Loss:14.362285614013672

iterator 500, D_Loss:0.41085636615753174, G_Loss:13.571503639221191

iterator 600, D_Loss:0.4331108033657074, G_Loss:14.955509185791016

iterator 700, D_Loss:0.4254249036312103, G_Loss:13.919591903686523

iterator 800, D_Loss:0.4050629138946533, G_Loss:14.494816780090332

iterator 900, D_Loss:0.44809094071388245, G_Loss:13.846960067749023

iterator 1000, D_Loss:0.4167719781398773, G_Loss:13.74262523651123

iterator 1100, D_Loss:0.4231213927268982, G_Loss:14.394434928894043

iterator 1200, D_Loss:0.42297258973121643, G_Loss:14.426308631896973

iterator 1300, D_Loss:0.4198635518550873, G_Loss:14.19247055053711

iterator 1400, D_Loss:0.4226699769496918, G_Loss:13.697325706481934

iterator 1500, D_Loss:0.4396559000015259, G_Loss:12.085829734802246

iterator 1600, D_Loss:0.42944347858428955, G_Loss:13.568819999694824

iterator 1700, D_Loss:0.41740596294403076, G_Loss:13.35234260559082

iterator 1800, D_Loss:0.4382120668888092, G_Loss:13.158437728881836

iterator 1900, D_Loss:0.41877686977386475, G_Loss:12.430039405822754

iterator 2000, D_Loss:0.43059948086738586, G_Loss:13.193013191223145

iterator 2100, D_Loss:0.4182455837726593, G_Loss:13.407068252563477

iterator 2200, D_Loss:0.4052582383155823, G_Loss:14.15664005279541

iterator 2300, D_Loss:0.4292159676551819, G_Loss:12.637823104858398

iterator 2400, D_Loss:0.4215330481529236, G_Loss:12.872787475585938

iterator 2500, D_Loss:0.42277199029922485, G_Loss:12.35753059387207

iterator 2600, D_Loss:0.41512173414230347, G_Loss:11.554996490478516

iterator 2700, D_Loss:0.4482794404029846, G_Loss:12.646096229553223

iterator 2800, D_Loss:0.4234004616737366, G_Loss:15.24523639678955

iterator 2900, D_Loss:0.4370909035205841, G_Loss:14.26751708984375

iterator 3000, D_Loss:0.4416232705116272, G_Loss:13.57076644897461

iterator 3100, D_Loss:0.4435529112815857, G_Loss:13.521526336669922

iterator 3200, D_Loss:0.4147513508796692, G_Loss:13.424858093261719

iterator 3300, D_Loss:0.42142346501350403, G_Loss:13.628000259399414

iterator 3400, D_Loss:0.39744386076927185, G_Loss:14.243826866149902

iterator 3500, D_Loss:0.420669287443161, G_Loss:14.599434852600098

iterator 3600, D_Loss:0.4573781192302704, G_Loss:13.213532447814941

iterator 3700, D_Loss:0.45018884539604187, G_Loss:14.418866157531738

iterator 3800, D_Loss:0.44076991081237793, G_Loss:13.78734016418457

iterator 3900, D_Loss:0.4126431345939636, G_Loss:12.748403549194336

iterator 4000, D_Loss:0.4187701940536499, G_Loss:11.799029350280762

iterator 4100, D_Loss:0.40677544474601746, G_Loss:13.799034118652344

iterator 4200, D_Loss:0.4387443959712982, G_Loss:13.516911506652832

iterator 4300, D_Loss:0.4340037405490875, G_Loss:13.228658676147461

iterator 4400, D_Loss:0.4544548988342285, G_Loss:12.722991943359375

iterator 4500, D_Loss:0.43564683198928833, G_Loss:12.951395034790039

iterator 4600, D_Loss:0.4060099720954895, G_Loss:13.817622184753418

iterator 4700, D_Loss:0.41327714920043945, G_Loss:14.745573997497559

iterator 4800, D_Loss:0.42939940094947815, G_Loss:12.82724666595459

iterator 4900, D_Loss:0.4193907380104065, G_Loss:12.58964729309082

iterator 5000, D_Loss:0.4570992887020111, G_Loss:11.348609924316406

train row : 30148
sample row: 30148
LGAN_generator(
  (LSTM): LSTMCell(350, 500)
  (fc00): Linear(in_features=300, out_features=1, bias=True)
  (fc01): Linear(in_features=1, out_features=300, bias=True)
  (fe0): Linear(in_features=500, out_features=300, bias=True)
  (fc10): Linear(in_features=300, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=300, bias=True)
  (fe1): Linear(in_features=500, out_features=300, bias=True)
  (fc20): Linear(in_features=300, out_features=1, bias=True)
  (fc21): Linear(in_features=1, out_features=300, bias=True)
  (fe2): Linear(in_features=500, out_features=300, bias=True)
  (fc30): Linear(in_features=300, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=300, bias=True)
  (fe3): Linear(in_features=500, out_features=300, bias=True)
  (fc40): Linear(in_features=300, out_features=1, bias=True)
  (fc41): Linear(in_features=1, out_features=300, bias=True)
  (fe4): Linear(in_features=500, out_features=300, bias=True)
  (fc50): Linear(in_features=300, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=300, bias=True)
  (fe5): Linear(in_features=500, out_features=300, bias=True)
  (fc60): Linear(in_features=300, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=300, bias=True)
  (fe6): Linear(in_features=500, out_features=300, bias=True)
  (fc70): Linear(in_features=300, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=300, bias=True)
  (fe7): Linear(in_features=500, out_features=300, bias=True)
  (fc80): Linear(in_features=300, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=300, bias=True)
  (fe8): Linear(in_features=500, out_features=300, bias=True)
  (fc90): Linear(in_features=300, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=300, bias=True)
  (fe9): Linear(in_features=500, out_features=300, bias=True)
  (fc100): Linear(in_features=300, out_features=1, bias=True)
  (fc101): Linear(in_features=1, out_features=300, bias=True)
  (fe10): Linear(in_features=500, out_features=300, bias=True)
  (fc110): Linear(in_features=300, out_features=1, bias=True)
  (fc111): Linear(in_features=1, out_features=300, bias=True)
  (fe11): Linear(in_features=500, out_features=300, bias=True)
  (fc120): Linear(in_features=300, out_features=1, bias=True)
  (fc121): Linear(in_features=1, out_features=300, bias=True)
  (fe12): Linear(in_features=500, out_features=300, bias=True)
  (fc130): Linear(in_features=300, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=300, bias=True)
  (fe13): Linear(in_features=500, out_features=300, bias=True)
  (fc140): Linear(in_features=300, out_features=2, bias=True)
  (fc141): Linear(in_features=2, out_features=300, bias=True)
  (fe14): Linear(in_features=500, out_features=300, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=105, out_features=100, bias=True)
  (inputbn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=100, out_features=100, bias=True)
  (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=100, out_features=100, bias=True)
  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=100, out_features=100, bias=True)
  (bn3): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc4): Linear(in_features=100, out_features=100, bias=True)
  (bn4): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=100, out_features=1, bias=True)
)
(0, False, 105)
-----------Epoch 0-----------
iterator 100, D_Loss:1.4511244297027588, G_Loss:0.8639132976531982

iterator 200, D_Loss:1.3901383876800537, G_Loss:0.9581358432769775

iterator 300, D_Loss:1.4048211574554443, G_Loss:0.9830396175384521

iterator 400, D_Loss:1.4149093627929688, G_Loss:0.9517834186553955

iterator 500, D_Loss:1.429990291595459, G_Loss:0.9935945272445679

iterator 600, D_Loss:1.384635090827942, G_Loss:0.9481886625289917

iterator 700, D_Loss:1.3937528133392334, G_Loss:0.9643617272377014

iterator 800, D_Loss:1.3872946500778198, G_Loss:0.9518077373504639

iterator 900, D_Loss:1.3917241096496582, G_Loss:1.0186806917190552

iterator 1000, D_Loss:1.3574728965759277, G_Loss:0.9357986450195312

iterator 1100, D_Loss:1.3875380754470825, G_Loss:1.0240137577056885

iterator 1200, D_Loss:1.3842666149139404, G_Loss:1.0277339220046997

iterator 1300, D_Loss:1.3662073612213135, G_Loss:0.9842421412467957

iterator 1400, D_Loss:1.370764970779419, G_Loss:0.922500729560852

iterator 1500, D_Loss:1.3560521602630615, G_Loss:1.0436627864837646

iterator 1600, D_Loss:1.3729374408721924, G_Loss:0.9841863512992859

iterator 1700, D_Loss:1.360242247581482, G_Loss:0.968840479850769

iterator 1800, D_Loss:1.3566298484802246, G_Loss:0.9477530717849731

iterator 1900, D_Loss:1.3794314861297607, G_Loss:0.9954354166984558

iterator 2000, D_Loss:1.3766982555389404, G_Loss:1.0622228384017944

iterator 2100, D_Loss:1.3646090030670166, G_Loss:1.0104622840881348

iterator 2200, D_Loss:1.3599907159805298, G_Loss:0.9611518383026123

iterator 2300, D_Loss:1.348465919494629, G_Loss:0.992306113243103

iterator 2400, D_Loss:1.3779890537261963, G_Loss:1.0571322441101074

iterator 2500, D_Loss:1.3715572357177734, G_Loss:0.9931064248085022

iterator 2600, D_Loss:1.3720380067825317, G_Loss:1.0119149684906006

iterator 2700, D_Loss:1.3584483861923218, G_Loss:1.0707794427871704

iterator 2800, D_Loss:1.3645257949829102, G_Loss:0.9970775246620178

iterator 2900, D_Loss:1.3897743225097656, G_Loss:1.0046204328536987

iterator 3000, D_Loss:1.3792139291763306, G_Loss:1.0587060451507568

iterator 3100, D_Loss:1.375585913658142, G_Loss:1.0169775485992432

iterator 3200, D_Loss:1.3612151145935059, G_Loss:1.0499119758605957

iterator 3300, D_Loss:1.354322910308838, G_Loss:1.039723515510559

iterator 3400, D_Loss:1.3388664722442627, G_Loss:1.033377766609192

iterator 3500, D_Loss:1.3432492017745972, G_Loss:1.011202096939087

iterator 3600, D_Loss:1.321415901184082, G_Loss:1.0540235042572021

iterator 3700, D_Loss:1.3326643705368042, G_Loss:1.0238780975341797

iterator 3800, D_Loss:1.351222038269043, G_Loss:1.0476055145263672

iterator 3900, D_Loss:1.3555326461791992, G_Loss:1.112600326538086

iterator 4000, D_Loss:1.3090747594833374, G_Loss:1.103913426399231

iterator 4100, D_Loss:1.340072512626648, G_Loss:1.0841543674468994

iterator 4200, D_Loss:1.3172237873077393, G_Loss:1.1273880004882812

iterator 4300, D_Loss:1.3053383827209473, G_Loss:1.0869776010513306

iterator 4400, D_Loss:1.3253519535064697, G_Loss:0.9732499122619629

iterator 4500, D_Loss:1.3346238136291504, G_Loss:1.1176856756210327

iterator 4600, D_Loss:1.305068016052246, G_Loss:1.0923421382904053

iterator 4700, D_Loss:1.3175268173217773, G_Loss:0.9787243008613586

iterator 4800, D_Loss:1.237318515777588, G_Loss:1.1610281467437744

iterator 4900, D_Loss:1.4216368198394775, G_Loss:0.9941692352294922

iterator 5000, D_Loss:1.2551630735397339, G_Loss:1.1643319129943848

-----------Epoch 1-----------
iterator 100, D_Loss:1.4500529766082764, G_Loss:1.1522691249847412

iterator 200, D_Loss:1.2745860815048218, G_Loss:1.181512713432312

iterator 300, D_Loss:1.3659497499465942, G_Loss:1.2170394659042358

iterator 400, D_Loss:1.2050684690475464, G_Loss:1.1991652250289917

iterator 500, D_Loss:1.3239636421203613, G_Loss:1.1082863807678223

iterator 600, D_Loss:1.275331974029541, G_Loss:1.0592319965362549

iterator 700, D_Loss:1.369053602218628, G_Loss:1.1368615627288818

iterator 800, D_Loss:1.2866339683532715, G_Loss:1.3152791261672974

iterator 900, D_Loss:1.1934478282928467, G_Loss:1.3127493858337402

iterator 1000, D_Loss:1.200987696647644, G_Loss:1.2842352390289307

iterator 1100, D_Loss:1.3370676040649414, G_Loss:1.1174945831298828

iterator 1200, D_Loss:1.1660164594650269, G_Loss:1.3557628393173218

iterator 1300, D_Loss:1.1721923351287842, G_Loss:1.3217747211456299

iterator 1400, D_Loss:1.1077097654342651, G_Loss:1.384667992591858

iterator 1500, D_Loss:1.2006454467773438, G_Loss:1.271905541419983

iterator 1600, D_Loss:1.5121610164642334, G_Loss:1.147784948348999

iterator 1700, D_Loss:1.2271687984466553, G_Loss:1.0981500148773193

iterator 1800, D_Loss:1.1953399181365967, G_Loss:1.1784409284591675

iterator 1900, D_Loss:1.3473434448242188, G_Loss:1.4385051727294922

iterator 2000, D_Loss:1.2069064378738403, G_Loss:1.081785798072815

iterator 2100, D_Loss:1.5515575408935547, G_Loss:1.4423524141311646

iterator 2200, D_Loss:1.0906965732574463, G_Loss:1.3768808841705322

iterator 2300, D_Loss:1.4365742206573486, G_Loss:1.107213020324707

iterator 2400, D_Loss:1.2008049488067627, G_Loss:1.2706491947174072

iterator 2500, D_Loss:1.0779762268066406, G_Loss:1.2019566297531128

iterator 2600, D_Loss:0.9988014698028564, G_Loss:1.4625213146209717

iterator 2700, D_Loss:0.9674445390701294, G_Loss:1.3886085748672485

iterator 2800, D_Loss:1.140432357788086, G_Loss:1.5613551139831543

iterator 2900, D_Loss:1.5431734323501587, G_Loss:1.7591290473937988

iterator 3000, D_Loss:1.353755235671997, G_Loss:1.425523042678833

iterator 3100, D_Loss:1.1317417621612549, G_Loss:1.1604139804840088

iterator 3200, D_Loss:1.475600004196167, G_Loss:1.3781704902648926

iterator 3300, D_Loss:1.4164063930511475, G_Loss:1.516040563583374

iterator 3400, D_Loss:0.9662817716598511, G_Loss:1.2133945226669312

iterator 3500, D_Loss:0.9525510668754578, G_Loss:1.2249729633331299

iterator 3600, D_Loss:1.4374383687973022, G_Loss:1.336296796798706

iterator 3700, D_Loss:0.9057841300964355, G_Loss:1.145521879196167

iterator 3800, D_Loss:1.4267690181732178, G_Loss:1.5518889427185059

iterator 3900, D_Loss:1.1772496700286865, G_Loss:1.414682149887085

iterator 4000, D_Loss:1.0787348747253418, G_Loss:1.419707179069519

iterator 4100, D_Loss:1.0765864849090576, G_Loss:1.5544633865356445

iterator 4200, D_Loss:1.603518009185791, G_Loss:1.8216075897216797

iterator 4300, D_Loss:1.2553737163543701, G_Loss:2.0560142993927

iterator 4400, D_Loss:1.185002326965332, G_Loss:1.4423167705535889

iterator 4500, D_Loss:0.9859946966171265, G_Loss:2.0076475143432617

iterator 4600, D_Loss:0.920807957649231, G_Loss:1.457240104675293

iterator 4700, D_Loss:1.1211879253387451, G_Loss:1.3833386898040771

iterator 4800, D_Loss:1.2236419916152954, G_Loss:1.909907341003418

iterator 4900, D_Loss:0.9449222087860107, G_Loss:1.4417535066604614

iterator 5000, D_Loss:0.8932061195373535, G_Loss:2.226475954055786

-----------Epoch 2-----------
iterator 100, D_Loss:1.027654767036438, G_Loss:0.9395688772201538

iterator 200, D_Loss:1.2495968341827393, G_Loss:2.52900767326355

iterator 300, D_Loss:1.1132630109786987, G_Loss:1.619998812675476

iterator 400, D_Loss:0.9947347640991211, G_Loss:0.941032350063324

iterator 500, D_Loss:1.3245805501937866, G_Loss:0.9403902888298035

iterator 600, D_Loss:1.5643727779388428, G_Loss:1.3330827951431274

iterator 700, D_Loss:1.099489688873291, G_Loss:0.8656286001205444

iterator 800, D_Loss:0.7698248624801636, G_Loss:1.1942087411880493

iterator 900, D_Loss:1.1710413694381714, G_Loss:1.5977516174316406

iterator 1000, D_Loss:0.8345325589179993, G_Loss:2.3312551975250244

iterator 1100, D_Loss:1.5426663160324097, G_Loss:1.6801739931106567

iterator 1200, D_Loss:0.8994958996772766, G_Loss:1.204310417175293

iterator 1300, D_Loss:1.1034777164459229, G_Loss:1.6004244089126587

iterator 1400, D_Loss:1.0343611240386963, G_Loss:1.441758155822754

iterator 1500, D_Loss:1.2242834568023682, G_Loss:1.7816370725631714

iterator 1600, D_Loss:0.9854824542999268, G_Loss:1.805551528930664

iterator 1700, D_Loss:1.2187914848327637, G_Loss:1.9412660598754883

iterator 1800, D_Loss:1.5895648002624512, G_Loss:1.7699271440505981

iterator 1900, D_Loss:1.4472763538360596, G_Loss:2.9088668823242188

iterator 2000, D_Loss:1.2306950092315674, G_Loss:1.45135498046875

iterator 2100, D_Loss:0.7579034566879272, G_Loss:1.6957008838653564

iterator 2200, D_Loss:0.9726870059967041, G_Loss:1.9971837997436523

iterator 2300, D_Loss:0.7131907939910889, G_Loss:2.353065013885498

iterator 2400, D_Loss:0.7792442440986633, G_Loss:1.9624054431915283

iterator 2500, D_Loss:1.2479212284088135, G_Loss:2.7667653560638428

iterator 2600, D_Loss:1.1357295513153076, G_Loss:2.287130355834961

iterator 2700, D_Loss:1.5107545852661133, G_Loss:3.024186611175537

iterator 2800, D_Loss:0.8740556836128235, G_Loss:3.2716920375823975

iterator 2900, D_Loss:1.4931480884552002, G_Loss:2.2044944763183594

iterator 3000, D_Loss:0.7900955080986023, G_Loss:2.660892963409424

iterator 3100, D_Loss:0.7400840520858765, G_Loss:2.552304744720459

iterator 3200, D_Loss:0.9521574974060059, G_Loss:2.7646522521972656

iterator 3300, D_Loss:1.2209877967834473, G_Loss:3.4831860065460205

iterator 3400, D_Loss:1.3569023609161377, G_Loss:1.014884352684021

iterator 3500, D_Loss:0.9265385866165161, G_Loss:2.3321452140808105

iterator 3600, D_Loss:1.0826336145401, G_Loss:2.7156925201416016

iterator 3700, D_Loss:1.090475082397461, G_Loss:1.5311188697814941

iterator 3800, D_Loss:0.7271016836166382, G_Loss:2.147334337234497

iterator 3900, D_Loss:0.9580110907554626, G_Loss:1.8492813110351562

iterator 4000, D_Loss:0.7449932098388672, G_Loss:1.688136100769043

iterator 4100, D_Loss:1.3065192699432373, G_Loss:2.6148841381073

iterator 4200, D_Loss:0.8691419959068298, G_Loss:1.7256864309310913

iterator 4300, D_Loss:1.2490291595458984, G_Loss:3.058722496032715

iterator 4400, D_Loss:1.2367342710494995, G_Loss:1.445570707321167

iterator 4500, D_Loss:1.001805067062378, G_Loss:1.5285141468048096

iterator 4600, D_Loss:1.0123196840286255, G_Loss:2.5503652095794678

iterator 4700, D_Loss:1.098555326461792, G_Loss:1.6440391540527344

iterator 4800, D_Loss:1.3774386644363403, G_Loss:2.3306639194488525

iterator 4900, D_Loss:0.693641722202301, G_Loss:3.3804879188537598

iterator 5000, D_Loss:0.7144104838371277, G_Loss:2.2131896018981934

-----------Epoch 3-----------
iterator 100, D_Loss:0.697659969329834, G_Loss:1.5588741302490234

iterator 200, D_Loss:1.5851428508758545, G_Loss:2.067686080932617

iterator 300, D_Loss:0.8345444202423096, G_Loss:1.774127721786499

iterator 400, D_Loss:0.8162181973457336, G_Loss:1.3771049976348877

iterator 500, D_Loss:0.9208799600601196, G_Loss:1.8685436248779297

iterator 600, D_Loss:1.1080485582351685, G_Loss:2.1583642959594727

iterator 700, D_Loss:0.9678568840026855, G_Loss:1.3650972843170166

iterator 800, D_Loss:0.9845331907272339, G_Loss:2.6258609294891357

iterator 900, D_Loss:0.70361328125, G_Loss:1.1692935228347778

iterator 1000, D_Loss:0.9268530607223511, G_Loss:2.7500860691070557

iterator 1100, D_Loss:1.2220338582992554, G_Loss:1.493506669998169

iterator 1200, D_Loss:0.9762977361679077, G_Loss:1.0856754779815674

iterator 1300, D_Loss:0.9160886406898499, G_Loss:3.40624737739563

iterator 1400, D_Loss:1.7174733877182007, G_Loss:2.826550245285034

iterator 1500, D_Loss:1.4677205085754395, G_Loss:3.084106683731079

iterator 1600, D_Loss:0.7325057983398438, G_Loss:1.673620343208313

iterator 1700, D_Loss:0.7846649885177612, G_Loss:1.7758259773254395

iterator 1800, D_Loss:1.3825207948684692, G_Loss:1.3648710250854492

iterator 1900, D_Loss:0.6759057641029358, G_Loss:3.6293396949768066

iterator 2000, D_Loss:0.8780627846717834, G_Loss:2.770625591278076

iterator 2100, D_Loss:0.9780791401863098, G_Loss:1.123131513595581

iterator 2200, D_Loss:1.6582913398742676, G_Loss:1.9344180822372437

iterator 2300, D_Loss:1.0037827491760254, G_Loss:2.1700150966644287

iterator 2400, D_Loss:1.5528711080551147, G_Loss:2.2899563312530518

iterator 2500, D_Loss:1.067185640335083, G_Loss:1.806672215461731

iterator 2600, D_Loss:1.0352451801300049, G_Loss:1.4637348651885986

iterator 2700, D_Loss:0.9395616054534912, G_Loss:1.9359484910964966

iterator 2800, D_Loss:0.7021616697311401, G_Loss:2.245797872543335

iterator 2900, D_Loss:0.9165021181106567, G_Loss:2.551137685775757

iterator 3000, D_Loss:0.845829963684082, G_Loss:2.607363224029541

iterator 3100, D_Loss:0.7488421201705933, G_Loss:1.386306643486023

iterator 3200, D_Loss:1.6418437957763672, G_Loss:1.1565279960632324

iterator 3300, D_Loss:0.7878166437149048, G_Loss:1.0981594324111938

iterator 3400, D_Loss:0.990740180015564, G_Loss:1.5082982778549194

iterator 3500, D_Loss:1.5770652294158936, G_Loss:1.2799196243286133

iterator 3600, D_Loss:1.1015093326568604, G_Loss:2.117258310317993

iterator 3700, D_Loss:0.8245496153831482, G_Loss:1.5084867477416992

iterator 3800, D_Loss:0.7377101182937622, G_Loss:1.424776315689087

iterator 3900, D_Loss:2.43892765045166, G_Loss:1.7984294891357422

iterator 4000, D_Loss:0.9203189611434937, G_Loss:1.5311872959136963

iterator 4100, D_Loss:1.3956162929534912, G_Loss:1.4047260284423828

iterator 4200, D_Loss:1.18369460105896, G_Loss:1.7591674327850342

iterator 4300, D_Loss:0.9699892997741699, G_Loss:2.9083142280578613

iterator 4400, D_Loss:0.7619075775146484, G_Loss:1.1651815176010132

iterator 4500, D_Loss:1.0445497035980225, G_Loss:1.954540491104126

iterator 4600, D_Loss:1.249819278717041, G_Loss:1.7348227500915527

iterator 4700, D_Loss:1.3397221565246582, G_Loss:1.001453161239624

iterator 4800, D_Loss:1.6197253465652466, G_Loss:1.836940884590149

iterator 4900, D_Loss:1.2051018476486206, G_Loss:1.9590165615081787

iterator 5000, D_Loss:0.9676717519760132, G_Loss:1.7294220924377441

-----------Epoch 4-----------
iterator 100, D_Loss:0.6927692890167236, G_Loss:3.646804094314575

iterator 200, D_Loss:1.6302024126052856, G_Loss:3.7216951847076416

iterator 300, D_Loss:0.9935455322265625, G_Loss:1.5671234130859375

iterator 400, D_Loss:0.682335376739502, G_Loss:1.216265320777893

iterator 500, D_Loss:0.7572153806686401, G_Loss:1.5230278968811035

iterator 600, D_Loss:0.8630963563919067, G_Loss:2.2016236782073975

iterator 700, D_Loss:1.1031861305236816, G_Loss:1.5729831457138062

iterator 800, D_Loss:0.9390695095062256, G_Loss:3.1759109497070312

iterator 900, D_Loss:1.7732821702957153, G_Loss:2.458740711212158

iterator 1000, D_Loss:0.947931706905365, G_Loss:1.3954455852508545

iterator 1100, D_Loss:1.1852977275848389, G_Loss:1.7884306907653809

iterator 1200, D_Loss:1.4587783813476562, G_Loss:2.566584348678589

iterator 1300, D_Loss:0.8631134033203125, G_Loss:2.3710360527038574

iterator 1400, D_Loss:0.8603235483169556, G_Loss:3.3669979572296143

iterator 1500, D_Loss:0.7176399230957031, G_Loss:2.8227696418762207

iterator 1600, D_Loss:1.1890380382537842, G_Loss:2.0922765731811523

iterator 1700, D_Loss:0.7019097208976746, G_Loss:4.382397651672363

iterator 1800, D_Loss:0.9128769636154175, G_Loss:2.6821584701538086

iterator 1900, D_Loss:1.275984764099121, G_Loss:2.3712329864501953

iterator 2000, D_Loss:0.780177116394043, G_Loss:3.4663591384887695

iterator 2100, D_Loss:1.0955268144607544, G_Loss:1.7395143508911133

iterator 2200, D_Loss:1.5548242330551147, G_Loss:1.424286127090454

iterator 2300, D_Loss:1.1731312274932861, G_Loss:0.9837321639060974

iterator 2400, D_Loss:0.8667310476303101, G_Loss:1.8059449195861816

iterator 2500, D_Loss:1.3271145820617676, G_Loss:2.809256076812744

iterator 2600, D_Loss:2.095022678375244, G_Loss:2.3306126594543457

iterator 2700, D_Loss:1.1584665775299072, G_Loss:3.064622163772583

iterator 2800, D_Loss:0.8740403056144714, G_Loss:2.537665605545044

iterator 2900, D_Loss:1.7670358419418335, G_Loss:1.1944301128387451

iterator 3000, D_Loss:0.8970094323158264, G_Loss:1.970241904258728

iterator 3100, D_Loss:1.1851332187652588, G_Loss:1.5892999172210693

iterator 3200, D_Loss:0.7906035780906677, G_Loss:1.8218058347702026

iterator 3300, D_Loss:1.4705371856689453, G_Loss:2.9420313835144043

iterator 3400, D_Loss:0.7007271647453308, G_Loss:0.9649558663368225

iterator 3500, D_Loss:1.069831132888794, G_Loss:2.4299018383026123

iterator 3600, D_Loss:1.3848894834518433, G_Loss:1.4849621057510376

iterator 3700, D_Loss:1.1674425601959229, G_Loss:2.1114373207092285

iterator 3800, D_Loss:1.7676936388015747, G_Loss:1.3369131088256836

iterator 3900, D_Loss:1.1293787956237793, G_Loss:1.3776969909667969

iterator 4000, D_Loss:1.7325150966644287, G_Loss:1.4110133647918701

iterator 4100, D_Loss:1.8119251728057861, G_Loss:1.9538979530334473

iterator 4200, D_Loss:1.7774477005004883, G_Loss:2.7628371715545654

iterator 4300, D_Loss:1.2340444326400757, G_Loss:1.3324851989746094

iterator 4400, D_Loss:1.2402644157409668, G_Loss:3.556333541870117

iterator 4500, D_Loss:1.4163494110107422, G_Loss:1.3803319931030273

iterator 4600, D_Loss:0.7881026864051819, G_Loss:1.3812074661254883

iterator 4700, D_Loss:1.481562852859497, G_Loss:3.3380343914031982

iterator 4800, D_Loss:0.7960411310195923, G_Loss:3.0067481994628906

iterator 4900, D_Loss:0.9510916471481323, G_Loss:1.752474308013916

iterator 5000, D_Loss:2.084826946258545, G_Loss:2.2355549335479736

-----------Epoch 5-----------
iterator 100, D_Loss:0.7832717895507812, G_Loss:1.0289247035980225

iterator 200, D_Loss:1.1587164402008057, G_Loss:2.7147748470306396

iterator 300, D_Loss:0.7511922121047974, G_Loss:1.2707948684692383

iterator 400, D_Loss:0.7907981872558594, G_Loss:3.596295118331909

iterator 500, D_Loss:1.1489431858062744, G_Loss:2.9405601024627686

iterator 600, D_Loss:1.6492445468902588, G_Loss:1.4913166761398315

iterator 700, D_Loss:2.026730537414551, G_Loss:2.6166186332702637

iterator 800, D_Loss:0.984265923500061, G_Loss:4.623013019561768

iterator 900, D_Loss:1.1688616275787354, G_Loss:3.0109174251556396

iterator 1000, D_Loss:0.9692357778549194, G_Loss:2.0478317737579346

iterator 1100, D_Loss:0.874173104763031, G_Loss:1.6844829320907593

iterator 1200, D_Loss:1.3283257484436035, G_Loss:2.0800909996032715

iterator 1300, D_Loss:1.1768362522125244, G_Loss:2.875422477722168

iterator 1400, D_Loss:0.7012627720832825, G_Loss:1.3722862005233765

iterator 1500, D_Loss:1.4860105514526367, G_Loss:1.9953056573867798

iterator 1600, D_Loss:1.212998390197754, G_Loss:1.8505715131759644

iterator 1700, D_Loss:1.09621262550354, G_Loss:2.197044849395752

iterator 1800, D_Loss:0.6703259944915771, G_Loss:1.660670518875122

iterator 1900, D_Loss:1.1419795751571655, G_Loss:2.2255101203918457

iterator 2000, D_Loss:0.6676715612411499, G_Loss:1.9455281496047974

iterator 2100, D_Loss:0.9676718711853027, G_Loss:3.115083694458008

iterator 2200, D_Loss:0.6731491684913635, G_Loss:2.167478084564209

iterator 2300, D_Loss:2.3909921646118164, G_Loss:2.456908702850342

iterator 2400, D_Loss:0.8849904537200928, G_Loss:2.92647647857666

iterator 2500, D_Loss:0.6324458122253418, G_Loss:2.0379536151885986

iterator 2600, D_Loss:1.601649522781372, G_Loss:2.032818555831909

iterator 2700, D_Loss:0.8794577121734619, G_Loss:1.314208745956421

iterator 2800, D_Loss:0.9000221490859985, G_Loss:1.8694348335266113

iterator 2900, D_Loss:0.9048246741294861, G_Loss:2.3610401153564453

iterator 3000, D_Loss:0.8151997327804565, G_Loss:1.6959927082061768

iterator 3100, D_Loss:1.242206335067749, G_Loss:1.5393363237380981

iterator 3200, D_Loss:1.529815912246704, G_Loss:2.68271541595459

iterator 3300, D_Loss:0.7881758809089661, G_Loss:1.4326677322387695

iterator 3400, D_Loss:0.9010539650917053, G_Loss:2.5887763500213623

iterator 3500, D_Loss:1.4972764253616333, G_Loss:1.1910078525543213

iterator 3600, D_Loss:1.6683416366577148, G_Loss:3.076089859008789

iterator 3700, D_Loss:1.3168513774871826, G_Loss:2.488999843597412

iterator 3800, D_Loss:1.0753364562988281, G_Loss:2.629784107208252

iterator 3900, D_Loss:0.8687973618507385, G_Loss:2.6263771057128906

iterator 4000, D_Loss:0.7208248972892761, G_Loss:1.962621808052063

iterator 4100, D_Loss:0.7615501880645752, G_Loss:2.135178327560425

iterator 4200, D_Loss:0.8700709342956543, G_Loss:1.2212915420532227

iterator 4300, D_Loss:1.0183453559875488, G_Loss:3.5049192905426025

iterator 4400, D_Loss:0.7805261611938477, G_Loss:2.7790768146514893

iterator 4500, D_Loss:1.207802414894104, G_Loss:3.0473203659057617

iterator 4600, D_Loss:2.1753878593444824, G_Loss:1.4913748502731323

iterator 4700, D_Loss:0.9513300657272339, G_Loss:1.2487366199493408

iterator 4800, D_Loss:0.784568727016449, G_Loss:1.4712088108062744

iterator 4900, D_Loss:1.12765371799469, G_Loss:1.2476686239242554

iterator 5000, D_Loss:0.6384958624839783, G_Loss:2.7030043601989746

-----------Epoch 6-----------
iterator 100, D_Loss:1.0223476886749268, G_Loss:2.2764317989349365

iterator 200, D_Loss:0.7047261595726013, G_Loss:1.9878971576690674

iterator 300, D_Loss:2.238722801208496, G_Loss:2.448645830154419

iterator 400, D_Loss:1.2769478559494019, G_Loss:2.265007972717285

iterator 500, D_Loss:0.8180001974105835, G_Loss:1.3634312152862549

iterator 600, D_Loss:1.2281200885772705, G_Loss:1.5091251134872437

iterator 700, D_Loss:1.0913856029510498, G_Loss:3.6769962310791016

iterator 800, D_Loss:0.9839699268341064, G_Loss:1.6245944499969482

iterator 900, D_Loss:2.101123094558716, G_Loss:2.632242202758789

iterator 1000, D_Loss:1.1374189853668213, G_Loss:2.1345245838165283

iterator 1100, D_Loss:0.702121376991272, G_Loss:1.9911408424377441

iterator 1200, D_Loss:0.6812587976455688, G_Loss:1.9272420406341553

iterator 1300, D_Loss:0.8908810615539551, G_Loss:1.6136538982391357

iterator 1400, D_Loss:0.9237431883811951, G_Loss:1.2886630296707153

iterator 1500, D_Loss:0.8493951559066772, G_Loss:4.065423011779785

iterator 1600, D_Loss:0.679561197757721, G_Loss:1.655836820602417

iterator 1700, D_Loss:1.4484987258911133, G_Loss:0.9913881421089172

iterator 1800, D_Loss:1.4921305179595947, G_Loss:2.4679534435272217

iterator 1900, D_Loss:1.2040255069732666, G_Loss:2.636704444885254

iterator 2000, D_Loss:0.8653678297996521, G_Loss:2.421656608581543

iterator 2100, D_Loss:0.6406532526016235, G_Loss:1.3151336908340454

iterator 2200, D_Loss:0.7647591829299927, G_Loss:3.1514687538146973

iterator 2300, D_Loss:1.862149715423584, G_Loss:1.1749452352523804

iterator 2400, D_Loss:0.8524733185768127, G_Loss:1.1768370866775513

iterator 2500, D_Loss:0.6202778816223145, G_Loss:2.3094968795776367

iterator 2600, D_Loss:2.4885852336883545, G_Loss:1.9183001518249512

iterator 2700, D_Loss:1.4962140321731567, G_Loss:2.13747239112854

iterator 2800, D_Loss:0.7983877062797546, G_Loss:1.6774978637695312

iterator 2900, D_Loss:0.7517154216766357, G_Loss:2.158034324645996

iterator 3000, D_Loss:1.410564661026001, G_Loss:2.9277217388153076

iterator 3100, D_Loss:1.3684782981872559, G_Loss:1.5108604431152344

iterator 3200, D_Loss:0.6998551487922668, G_Loss:1.4194235801696777

iterator 3300, D_Loss:0.9462543725967407, G_Loss:2.808582067489624

iterator 3400, D_Loss:1.5330908298492432, G_Loss:1.6014630794525146

iterator 3500, D_Loss:1.1340621709823608, G_Loss:1.894927978515625

iterator 3600, D_Loss:0.883836030960083, G_Loss:1.5875544548034668

iterator 3700, D_Loss:1.3033018112182617, G_Loss:2.4768309593200684

iterator 3800, D_Loss:0.5734334588050842, G_Loss:3.6201906204223633

iterator 3900, D_Loss:1.3322328329086304, G_Loss:3.5107107162475586

iterator 4000, D_Loss:1.5998485088348389, G_Loss:3.402676582336426

iterator 4100, D_Loss:1.7436044216156006, G_Loss:2.5414626598358154

iterator 4200, D_Loss:0.6171133518218994, G_Loss:2.5388126373291016

iterator 4300, D_Loss:0.9547179937362671, G_Loss:2.164783477783203

iterator 4400, D_Loss:1.3379042148590088, G_Loss:3.331193685531616

iterator 4500, D_Loss:1.4429056644439697, G_Loss:4.0438232421875

iterator 4600, D_Loss:0.8197520971298218, G_Loss:1.8902347087860107

iterator 4700, D_Loss:0.6574991941452026, G_Loss:3.185112476348877

iterator 4800, D_Loss:0.9021061658859253, G_Loss:3.554905414581299

iterator 4900, D_Loss:0.6462036371231079, G_Loss:4.207542896270752

iterator 5000, D_Loss:0.9198954105377197, G_Loss:1.7427059412002563

-----------Epoch 7-----------
iterator 100, D_Loss:1.6129841804504395, G_Loss:1.1323037147521973

iterator 200, D_Loss:1.1923480033874512, G_Loss:3.0630059242248535

iterator 300, D_Loss:1.0288686752319336, G_Loss:3.565762519836426

iterator 400, D_Loss:0.9930904507637024, G_Loss:1.394972562789917

iterator 500, D_Loss:0.6826419234275818, G_Loss:2.0208287239074707

iterator 600, D_Loss:1.106154441833496, G_Loss:1.0404644012451172

iterator 700, D_Loss:1.360245704650879, G_Loss:1.668718695640564

iterator 800, D_Loss:1.5763614177703857, G_Loss:1.5794813632965088

iterator 900, D_Loss:0.7675114274024963, G_Loss:3.589090585708618

iterator 1000, D_Loss:1.2951908111572266, G_Loss:2.3107645511627197

iterator 1100, D_Loss:0.9652023315429688, G_Loss:1.724761962890625

iterator 1200, D_Loss:0.886769711971283, G_Loss:2.2564754486083984

iterator 1300, D_Loss:2.177532196044922, G_Loss:2.810229778289795

iterator 1400, D_Loss:0.6159201264381409, G_Loss:2.955047130584717

iterator 1500, D_Loss:0.8223828077316284, G_Loss:3.731462001800537

iterator 1600, D_Loss:0.7617940306663513, G_Loss:1.830985188484192

iterator 1700, D_Loss:1.4200586080551147, G_Loss:3.175349712371826

iterator 1800, D_Loss:0.6162603497505188, G_Loss:3.378770589828491

iterator 1900, D_Loss:1.4287775754928589, G_Loss:2.2019426822662354

iterator 2000, D_Loss:1.055424451828003, G_Loss:1.740828037261963

iterator 2100, D_Loss:1.6597223281860352, G_Loss:1.5639159679412842

iterator 2200, D_Loss:0.9928050637245178, G_Loss:2.279879331588745

iterator 2300, D_Loss:1.1051063537597656, G_Loss:3.312791109085083

iterator 2400, D_Loss:0.8596116304397583, G_Loss:2.47432541847229

iterator 2500, D_Loss:1.114205241203308, G_Loss:1.6514654159545898

iterator 2600, D_Loss:1.518977403640747, G_Loss:1.9156087636947632

iterator 2700, D_Loss:1.82253098487854, G_Loss:1.48476243019104

iterator 2800, D_Loss:0.6498007774353027, G_Loss:1.7484190464019775

iterator 2900, D_Loss:1.4631690979003906, G_Loss:1.6839534044265747

iterator 3000, D_Loss:0.6206990480422974, G_Loss:2.0156214237213135

iterator 3100, D_Loss:1.1873726844787598, G_Loss:4.838310241699219

iterator 3200, D_Loss:1.1752207279205322, G_Loss:2.659489631652832

iterator 3300, D_Loss:0.6788758039474487, G_Loss:1.259216070175171

iterator 3400, D_Loss:1.6144697666168213, G_Loss:2.2937495708465576

iterator 3500, D_Loss:0.8457562923431396, G_Loss:3.628620147705078

iterator 3600, D_Loss:1.2414984703063965, G_Loss:1.1115341186523438

iterator 3700, D_Loss:1.288135290145874, G_Loss:1.2630608081817627

iterator 3800, D_Loss:0.9299010038375854, G_Loss:1.2874045372009277

iterator 3900, D_Loss:0.790734052658081, G_Loss:3.9419009685516357

iterator 4000, D_Loss:0.8387454748153687, G_Loss:1.6501891613006592

iterator 4100, D_Loss:0.9599669575691223, G_Loss:2.5168986320495605

iterator 4200, D_Loss:1.2986934185028076, G_Loss:1.194806694984436

iterator 4300, D_Loss:0.8197895884513855, G_Loss:3.8223798274993896

iterator 4400, D_Loss:0.6455179452896118, G_Loss:1.5158288478851318

iterator 4500, D_Loss:1.3843945264816284, G_Loss:3.093228816986084

iterator 4600, D_Loss:1.4127836227416992, G_Loss:3.512305498123169

iterator 4700, D_Loss:2.6666274070739746, G_Loss:4.516070365905762

iterator 4800, D_Loss:0.8353596925735474, G_Loss:2.5287933349609375

iterator 4900, D_Loss:1.4366668462753296, G_Loss:1.6136224269866943

iterator 5000, D_Loss:0.7761540412902832, G_Loss:1.6788408756256104

-----------Epoch 8-----------
iterator 100, D_Loss:0.8728578090667725, G_Loss:2.73830509185791

iterator 200, D_Loss:0.8850255012512207, G_Loss:4.715130805969238

iterator 300, D_Loss:0.5953525900840759, G_Loss:3.862776279449463

iterator 400, D_Loss:1.5206904411315918, G_Loss:3.367873430252075

iterator 500, D_Loss:0.6423247456550598, G_Loss:3.3139281272888184

iterator 600, D_Loss:1.267195224761963, G_Loss:1.9475945234298706

iterator 700, D_Loss:1.341029167175293, G_Loss:1.8999234437942505

iterator 800, D_Loss:1.1604044437408447, G_Loss:2.473263740539551

iterator 900, D_Loss:0.9956935048103333, G_Loss:3.9674060344696045

iterator 1000, D_Loss:0.7789322137832642, G_Loss:2.6806108951568604

iterator 1100, D_Loss:0.6038821935653687, G_Loss:1.5052391290664673

iterator 1200, D_Loss:0.9017049074172974, G_Loss:2.8398756980895996

iterator 1300, D_Loss:0.6040573120117188, G_Loss:3.1643810272216797

iterator 1400, D_Loss:0.6033230423927307, G_Loss:2.4234867095947266

iterator 1500, D_Loss:0.7416317462921143, G_Loss:1.1543283462524414

iterator 1600, D_Loss:0.6401326656341553, G_Loss:2.7080695629119873

iterator 1700, D_Loss:0.9148596525192261, G_Loss:3.6523823738098145

iterator 1800, D_Loss:1.0323179960250854, G_Loss:2.2859857082366943

iterator 1900, D_Loss:1.1953028440475464, G_Loss:3.7848124504089355

iterator 2000, D_Loss:1.127262830734253, G_Loss:2.7659568786621094

iterator 2100, D_Loss:0.9472850561141968, G_Loss:1.8417654037475586

iterator 2200, D_Loss:1.5989234447479248, G_Loss:2.3710315227508545

iterator 2300, D_Loss:0.8189889192581177, G_Loss:2.0076241493225098

iterator 2400, D_Loss:0.802923858165741, G_Loss:1.5014584064483643

iterator 2500, D_Loss:1.0575323104858398, G_Loss:2.33675479888916

iterator 2600, D_Loss:0.868473470211029, G_Loss:0.9784029722213745

iterator 2700, D_Loss:0.5504612326622009, G_Loss:1.482581377029419

iterator 2800, D_Loss:1.2627625465393066, G_Loss:2.285249710083008

iterator 2900, D_Loss:0.6353669166564941, G_Loss:2.2495622634887695

iterator 3000, D_Loss:2.0895943641662598, G_Loss:2.4165778160095215

iterator 3100, D_Loss:2.278254508972168, G_Loss:2.8297858238220215

iterator 3200, D_Loss:0.8966416716575623, G_Loss:3.0351366996765137

iterator 3300, D_Loss:1.5281829833984375, G_Loss:1.8809428215026855

iterator 3400, D_Loss:0.622637927532196, G_Loss:2.726504325866699

iterator 3500, D_Loss:1.0997353792190552, G_Loss:3.0555953979492188

iterator 3600, D_Loss:0.6774502396583557, G_Loss:1.6758968830108643

iterator 3700, D_Loss:0.9719840884208679, G_Loss:3.316572666168213

iterator 3800, D_Loss:1.0444869995117188, G_Loss:3.8325366973876953

iterator 3900, D_Loss:0.8917142152786255, G_Loss:2.675426483154297

iterator 4000, D_Loss:1.2638297080993652, G_Loss:2.659346580505371

iterator 4100, D_Loss:0.7756253480911255, G_Loss:3.068019151687622

iterator 4200, D_Loss:0.6437003016471863, G_Loss:2.923163652420044

iterator 4300, D_Loss:0.9160339832305908, G_Loss:2.3375494480133057

iterator 4400, D_Loss:0.6561765074729919, G_Loss:2.61724853515625

iterator 4500, D_Loss:1.4965362548828125, G_Loss:3.372407913208008

iterator 4600, D_Loss:1.5942511558532715, G_Loss:4.697330474853516

iterator 4700, D_Loss:1.0942190885543823, G_Loss:2.5912563800811768

iterator 4800, D_Loss:2.331697463989258, G_Loss:1.624860167503357

iterator 4900, D_Loss:0.7263681292533875, G_Loss:3.825775146484375

iterator 5000, D_Loss:1.7289118766784668, G_Loss:3.299483299255371

-----------Epoch 9-----------
iterator 100, D_Loss:0.6299808025360107, G_Loss:4.935835838317871

iterator 200, D_Loss:0.6239602565765381, G_Loss:2.039167881011963

iterator 300, D_Loss:0.5031266212463379, G_Loss:3.0026063919067383

iterator 400, D_Loss:0.5794614553451538, G_Loss:5.034344673156738

iterator 500, D_Loss:0.6596471071243286, G_Loss:2.230229377746582

iterator 600, D_Loss:0.6340646147727966, G_Loss:2.130809783935547

iterator 700, D_Loss:1.1367655992507935, G_Loss:1.965753436088562

iterator 800, D_Loss:1.0963523387908936, G_Loss:4.590437889099121

iterator 900, D_Loss:0.6748780012130737, G_Loss:1.861083984375

iterator 1000, D_Loss:0.5505045056343079, G_Loss:4.183345317840576

iterator 1100, D_Loss:0.8320029377937317, G_Loss:1.6656923294067383

iterator 1200, D_Loss:0.5670609474182129, G_Loss:4.351067543029785

iterator 1300, D_Loss:0.7781814336776733, G_Loss:5.468076229095459

iterator 1400, D_Loss:0.7900180816650391, G_Loss:1.7175490856170654

iterator 1500, D_Loss:0.6397932767868042, G_Loss:1.4703805446624756

iterator 1600, D_Loss:1.9159069061279297, G_Loss:4.11161470413208

iterator 1700, D_Loss:0.7143089771270752, G_Loss:1.4694371223449707

iterator 1800, D_Loss:0.53230881690979, G_Loss:3.0534827709198

iterator 1900, D_Loss:0.7092319130897522, G_Loss:3.2233009338378906

iterator 2000, D_Loss:0.6216586828231812, G_Loss:2.669067144393921

iterator 2100, D_Loss:1.065967321395874, G_Loss:4.218996524810791

iterator 2200, D_Loss:0.727189302444458, G_Loss:1.4684425592422485

iterator 2300, D_Loss:1.5554956197738647, G_Loss:2.37733793258667

iterator 2400, D_Loss:0.642175555229187, G_Loss:3.79447865486145

iterator 2500, D_Loss:0.9665783643722534, G_Loss:1.6753509044647217

iterator 2600, D_Loss:0.5689742565155029, G_Loss:3.3997745513916016

iterator 2700, D_Loss:0.9362054467201233, G_Loss:2.408776044845581

iterator 2800, D_Loss:0.6406610012054443, G_Loss:5.90031623840332

iterator 2900, D_Loss:0.8598670959472656, G_Loss:1.45805025100708

iterator 3000, D_Loss:0.9655553698539734, G_Loss:2.170640230178833

iterator 3100, D_Loss:0.8408294916152954, G_Loss:1.544515609741211

iterator 3200, D_Loss:0.7440165877342224, G_Loss:3.9578046798706055

iterator 3300, D_Loss:0.5415339469909668, G_Loss:3.394744873046875

iterator 3400, D_Loss:0.6121103167533875, G_Loss:3.3704833984375

iterator 3500, D_Loss:1.122446060180664, G_Loss:4.5475873947143555

iterator 3600, D_Loss:1.8746628761291504, G_Loss:4.3410210609436035

iterator 3700, D_Loss:0.9819968342781067, G_Loss:5.956353187561035

iterator 3800, D_Loss:1.4143812656402588, G_Loss:1.700443983078003

iterator 3900, D_Loss:0.9346502423286438, G_Loss:4.8671159744262695

iterator 4000, D_Loss:0.5248339176177979, G_Loss:3.8611605167388916

iterator 4100, D_Loss:1.7175519466400146, G_Loss:2.1099610328674316

iterator 4200, D_Loss:2.6473512649536133, G_Loss:2.829550266265869

iterator 4300, D_Loss:0.6925521492958069, G_Loss:3.380664348602295

iterator 4400, D_Loss:0.5740512013435364, G_Loss:4.41641902923584

iterator 4500, D_Loss:1.2304103374481201, G_Loss:1.2855689525604248

iterator 4600, D_Loss:1.6978715658187866, G_Loss:2.7810981273651123

iterator 4700, D_Loss:0.824849545955658, G_Loss:3.0263659954071045

iterator 4800, D_Loss:0.8160388469696045, G_Loss:4.652487277984619

iterator 4900, D_Loss:0.9429136514663696, G_Loss:2.0285677909851074

iterator 5000, D_Loss:0.6493150591850281, G_Loss:4.402533531188965

LGAN_generator(
  (LSTM): LSTMCell(600, 500)
  (fc00): Linear(in_features=200, out_features=1, bias=True)
  (fc01): Linear(in_features=1, out_features=200, bias=True)
  (fe0): Linear(in_features=500, out_features=200, bias=True)
  (fc10): Linear(in_features=200, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=200, bias=True)
  (fe1): Linear(in_features=500, out_features=200, bias=True)
  (fc20): Linear(in_features=200, out_features=1, bias=True)
  (fc21): Linear(in_features=1, out_features=200, bias=True)
  (fe2): Linear(in_features=500, out_features=200, bias=True)
  (fc30): Linear(in_features=200, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=200, bias=True)
  (fe3): Linear(in_features=500, out_features=200, bias=True)
  (fc40): Linear(in_features=200, out_features=1, bias=True)
  (fc41): Linear(in_features=1, out_features=200, bias=True)
  (fe4): Linear(in_features=500, out_features=200, bias=True)
  (fc50): Linear(in_features=200, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=200, bias=True)
  (fe5): Linear(in_features=500, out_features=200, bias=True)
  (fc60): Linear(in_features=200, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=200, bias=True)
  (fe6): Linear(in_features=500, out_features=200, bias=True)
  (fc70): Linear(in_features=200, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=200, bias=True)
  (fe7): Linear(in_features=500, out_features=200, bias=True)
  (fc80): Linear(in_features=200, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=200, bias=True)
  (fe8): Linear(in_features=500, out_features=200, bias=True)
  (fc90): Linear(in_features=200, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=200, bias=True)
  (fe9): Linear(in_features=500, out_features=200, bias=True)
  (fc100): Linear(in_features=200, out_features=1, bias=True)
  (fc101): Linear(in_features=1, out_features=200, bias=True)
  (fe10): Linear(in_features=500, out_features=200, bias=True)
  (fc110): Linear(in_features=200, out_features=1, bias=True)
  (fc111): Linear(in_features=1, out_features=200, bias=True)
  (fe11): Linear(in_features=500, out_features=200, bias=True)
  (fc120): Linear(in_features=200, out_features=1, bias=True)
  (fc121): Linear(in_features=1, out_features=200, bias=True)
  (fe12): Linear(in_features=500, out_features=200, bias=True)
  (fc130): Linear(in_features=200, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=200, bias=True)
  (fe13): Linear(in_features=500, out_features=200, bias=True)
  (fc140): Linear(in_features=200, out_features=2, bias=True)
  (fc141): Linear(in_features=2, out_features=200, bias=True)
  (fe14): Linear(in_features=500, out_features=200, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=105, out_features=100, bias=True)
  (inputbn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=100, out_features=100, bias=True)
  (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=100, out_features=100, bias=True)
  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=100, out_features=100, bias=True)
  (bn3): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc4): Linear(in_features=100, out_features=100, bias=True)
  (bn4): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=100, out_features=1, bias=True)
)
(0, False, 105)
-----------Epoch 0-----------
iterator 100, D_Loss:1.3941893577575684, G_Loss:0.9640283584594727

iterator 200, D_Loss:1.3815721273422241, G_Loss:1.0401577949523926

iterator 300, D_Loss:1.376521348953247, G_Loss:1.0522286891937256

iterator 400, D_Loss:1.355560541152954, G_Loss:0.9860408902168274

iterator 500, D_Loss:1.3721238374710083, G_Loss:0.9825740456581116

iterator 600, D_Loss:1.3579421043395996, G_Loss:1.0845974683761597

iterator 700, D_Loss:1.302463173866272, G_Loss:1.0945148468017578

iterator 800, D_Loss:1.1583912372589111, G_Loss:1.5215625762939453

iterator 900, D_Loss:1.0063601732254028, G_Loss:2.5046141147613525

iterator 1000, D_Loss:0.7640471458435059, G_Loss:2.607482671737671

iterator 1100, D_Loss:0.7253730297088623, G_Loss:3.5558547973632812

iterator 1200, D_Loss:0.878463625907898, G_Loss:4.508261680603027

iterator 1300, D_Loss:0.6180700063705444, G_Loss:5.73902702331543

iterator 1400, D_Loss:0.6441966891288757, G_Loss:4.815688610076904

iterator 1500, D_Loss:0.5183959007263184, G_Loss:6.29015588760376

iterator 1600, D_Loss:0.4720289707183838, G_Loss:6.602813720703125

iterator 1700, D_Loss:0.4551534950733185, G_Loss:7.241456985473633

iterator 1800, D_Loss:0.4418821930885315, G_Loss:6.953902244567871

iterator 1900, D_Loss:0.47228533029556274, G_Loss:7.124261856079102

iterator 2000, D_Loss:0.46097633242607117, G_Loss:8.887290954589844

iterator 2100, D_Loss:0.46092239022254944, G_Loss:7.654571056365967

iterator 2200, D_Loss:0.44340625405311584, G_Loss:8.044960975646973

iterator 2300, D_Loss:0.42178112268447876, G_Loss:7.120928764343262

iterator 2400, D_Loss:0.4244830906391144, G_Loss:8.373937606811523

iterator 2500, D_Loss:0.45833930373191833, G_Loss:10.861368179321289

iterator 2600, D_Loss:0.4214562475681305, G_Loss:11.3184814453125

iterator 2700, D_Loss:0.43442502617836, G_Loss:9.2307767868042

iterator 2800, D_Loss:0.4320142865180969, G_Loss:10.856435775756836

iterator 2900, D_Loss:0.41880300641059875, G_Loss:10.201523780822754

iterator 3000, D_Loss:0.4479600787162781, G_Loss:9.728647232055664

iterator 3100, D_Loss:0.4534047245979309, G_Loss:10.650581359863281

iterator 3200, D_Loss:0.4192928075790405, G_Loss:11.036684036254883

iterator 3300, D_Loss:0.42250320315361023, G_Loss:7.948007106781006

iterator 3400, D_Loss:0.42253413796424866, G_Loss:9.692373275756836

iterator 3500, D_Loss:0.4249342381954193, G_Loss:11.400615692138672

iterator 3600, D_Loss:0.441079318523407, G_Loss:10.111763954162598

iterator 3700, D_Loss:0.4458807408809662, G_Loss:11.71963119506836

iterator 3800, D_Loss:0.41546475887298584, G_Loss:11.406384468078613

iterator 3900, D_Loss:0.4325849413871765, G_Loss:11.383105278015137

iterator 4000, D_Loss:0.434268593788147, G_Loss:12.332962036132812

iterator 4100, D_Loss:0.45152339339256287, G_Loss:12.479957580566406

iterator 4200, D_Loss:0.3999733030796051, G_Loss:12.140316009521484

iterator 4300, D_Loss:0.4204859733581543, G_Loss:13.58361530303955

iterator 4400, D_Loss:0.43161922693252563, G_Loss:11.471324920654297

iterator 4500, D_Loss:0.43951404094696045, G_Loss:13.190364837646484

iterator 4600, D_Loss:0.5384776592254639, G_Loss:11.576574325561523

iterator 4700, D_Loss:0.44234421849250793, G_Loss:11.869945526123047

iterator 4800, D_Loss:0.43494486808776855, G_Loss:12.792501449584961

iterator 4900, D_Loss:0.42308154702186584, G_Loss:11.047724723815918

iterator 5000, D_Loss:0.404428631067276, G_Loss:10.868905067443848

-----------Epoch 1-----------
iterator 100, D_Loss:0.4249836206436157, G_Loss:12.465861320495605

iterator 200, D_Loss:0.4302590489387512, G_Loss:12.387733459472656

iterator 300, D_Loss:0.4236758053302765, G_Loss:11.708791732788086

iterator 400, D_Loss:0.5186766386032104, G_Loss:11.558181762695312

iterator 500, D_Loss:0.4590301513671875, G_Loss:15.774948120117188

iterator 600, D_Loss:0.44578948616981506, G_Loss:19.22747230529785

iterator 700, D_Loss:0.41967061161994934, G_Loss:21.949424743652344

iterator 800, D_Loss:0.4375631809234619, G_Loss:19.070384979248047

iterator 900, D_Loss:0.414772629737854, G_Loss:20.806312561035156

iterator 1000, D_Loss:0.437804251909256, G_Loss:20.35023307800293

iterator 1100, D_Loss:0.4167822003364563, G_Loss:21.358863830566406

iterator 1200, D_Loss:0.44932860136032104, G_Loss:19.57560920715332

iterator 1300, D_Loss:0.4503951668739319, G_Loss:16.771440505981445

iterator 1400, D_Loss:0.42968833446502686, G_Loss:17.740257263183594

iterator 1500, D_Loss:0.4199948012828827, G_Loss:18.082866668701172

iterator 1600, D_Loss:0.43688151240348816, G_Loss:17.524538040161133

iterator 1700, D_Loss:0.4379931688308716, G_Loss:18.580821990966797

iterator 1800, D_Loss:0.40429478883743286, G_Loss:19.900432586669922

iterator 1900, D_Loss:0.41809725761413574, G_Loss:20.253345489501953

iterator 2000, D_Loss:0.4003824293613434, G_Loss:18.902833938598633

iterator 2100, D_Loss:0.41874992847442627, G_Loss:17.703310012817383

iterator 2200, D_Loss:0.42593735456466675, G_Loss:18.191930770874023

iterator 2300, D_Loss:0.4410645365715027, G_Loss:17.75143814086914

iterator 2400, D_Loss:0.42213553190231323, G_Loss:19.908458709716797

iterator 2500, D_Loss:0.417833536863327, G_Loss:18.289794921875

iterator 2600, D_Loss:0.406531423330307, G_Loss:16.43221664428711

iterator 2700, D_Loss:0.4298773407936096, G_Loss:19.672119140625

iterator 2800, D_Loss:0.4090989828109741, G_Loss:17.936725616455078

iterator 2900, D_Loss:0.4405301511287689, G_Loss:20.697839736938477

iterator 3000, D_Loss:0.42025458812713623, G_Loss:19.782550811767578

iterator 3100, D_Loss:0.4211772084236145, G_Loss:22.092269897460938

iterator 3200, D_Loss:0.4112601578235626, G_Loss:19.06174087524414

iterator 3300, D_Loss:0.40215352177619934, G_Loss:15.994752883911133

iterator 3400, D_Loss:0.4108392894268036, G_Loss:20.71123504638672

iterator 3500, D_Loss:0.4152868688106537, G_Loss:22.65509605407715

iterator 3600, D_Loss:0.3996713161468506, G_Loss:21.337921142578125

iterator 3700, D_Loss:0.41186657547950745, G_Loss:20.32489013671875

iterator 3800, D_Loss:0.44571173191070557, G_Loss:20.392372131347656

iterator 3900, D_Loss:0.4174109101295471, G_Loss:20.938735961914062

iterator 4000, D_Loss:0.4509817063808441, G_Loss:18.267671585083008

iterator 4100, D_Loss:0.42578327655792236, G_Loss:19.9808406829834

iterator 4200, D_Loss:0.4534212648868561, G_Loss:19.539337158203125

iterator 4300, D_Loss:0.3848476707935333, G_Loss:18.725791931152344

iterator 4400, D_Loss:0.4235035479068756, G_Loss:16.509498596191406

iterator 4500, D_Loss:0.43959349393844604, G_Loss:18.652320861816406

iterator 4600, D_Loss:0.42210057377815247, G_Loss:17.4439640045166

iterator 4700, D_Loss:0.42468056082725525, G_Loss:17.14910316467285

iterator 4800, D_Loss:0.43484407663345337, G_Loss:18.741180419921875

iterator 4900, D_Loss:0.4031311869621277, G_Loss:17.80368423461914

iterator 5000, D_Loss:0.4256451427936554, G_Loss:17.42006492614746

-----------Epoch 2-----------
iterator 100, D_Loss:0.4130270481109619, G_Loss:14.556315422058105

iterator 200, D_Loss:0.4275575280189514, G_Loss:12.091482162475586

iterator 300, D_Loss:0.42526519298553467, G_Loss:12.532815933227539

iterator 400, D_Loss:0.43170592188835144, G_Loss:13.277081489562988

iterator 500, D_Loss:0.4106808602809906, G_Loss:15.299688339233398

iterator 600, D_Loss:0.424712210893631, G_Loss:13.581820487976074

iterator 700, D_Loss:0.4278150200843811, G_Loss:13.693561553955078

iterator 800, D_Loss:0.42394179105758667, G_Loss:15.222715377807617

iterator 900, D_Loss:0.44446247816085815, G_Loss:16.103275299072266

iterator 1000, D_Loss:0.39513927698135376, G_Loss:13.364587783813477

iterator 1100, D_Loss:0.4013371765613556, G_Loss:14.932740211486816

iterator 1200, D_Loss:0.41076788306236267, G_Loss:12.29463005065918

iterator 1300, D_Loss:0.4253544509410858, G_Loss:14.553872108459473

iterator 1400, D_Loss:0.4284343719482422, G_Loss:12.072114944458008

iterator 1500, D_Loss:0.4372430443763733, G_Loss:14.356285095214844

iterator 1600, D_Loss:0.4258558750152588, G_Loss:10.069912910461426

iterator 1700, D_Loss:0.3893362879753113, G_Loss:14.2027006149292

iterator 1800, D_Loss:0.4448147714138031, G_Loss:14.202630043029785

iterator 1900, D_Loss:0.3997436761856079, G_Loss:13.382112503051758

iterator 2000, D_Loss:0.4415254592895508, G_Loss:13.063648223876953

iterator 2100, D_Loss:0.45446231961250305, G_Loss:15.086164474487305

iterator 2200, D_Loss:0.42710059881210327, G_Loss:13.847002029418945

iterator 2300, D_Loss:0.4442732036113739, G_Loss:14.553726196289062

iterator 2400, D_Loss:0.4112068712711334, G_Loss:15.772232055664062

iterator 2500, D_Loss:0.42103806138038635, G_Loss:13.996337890625

iterator 2600, D_Loss:0.41977936029434204, G_Loss:14.292058944702148

iterator 2700, D_Loss:0.41993528604507446, G_Loss:14.23249626159668

iterator 2800, D_Loss:0.4297105371952057, G_Loss:15.838865280151367

iterator 2900, D_Loss:0.437340646982193, G_Loss:15.235982894897461

iterator 3000, D_Loss:0.4254114329814911, G_Loss:14.251638412475586

iterator 3100, D_Loss:0.38736316561698914, G_Loss:14.929436683654785

iterator 3200, D_Loss:0.43504971265792847, G_Loss:13.355644226074219

iterator 3300, D_Loss:0.4274853765964508, G_Loss:14.623695373535156

iterator 3400, D_Loss:0.42915359139442444, G_Loss:15.294511795043945

iterator 3500, D_Loss:0.4278247058391571, G_Loss:14.017003059387207

iterator 3600, D_Loss:0.4403635263442993, G_Loss:14.822099685668945

iterator 3700, D_Loss:0.40734434127807617, G_Loss:15.450630187988281

iterator 3800, D_Loss:0.4230872690677643, G_Loss:14.308691024780273

iterator 3900, D_Loss:0.37901413440704346, G_Loss:14.733711242675781

iterator 4000, D_Loss:0.4190766513347626, G_Loss:13.586711883544922

iterator 4100, D_Loss:0.4144805073738098, G_Loss:13.457880973815918

iterator 4200, D_Loss:0.4164847731590271, G_Loss:10.715265274047852

iterator 4300, D_Loss:0.4035283327102661, G_Loss:12.932435989379883

iterator 4400, D_Loss:0.4390150308609009, G_Loss:12.215887069702148

iterator 4500, D_Loss:0.44974619150161743, G_Loss:12.360405921936035

iterator 4600, D_Loss:0.4500928819179535, G_Loss:14.697796821594238

iterator 4700, D_Loss:0.4458547532558441, G_Loss:14.0101318359375

iterator 4800, D_Loss:0.4139692783355713, G_Loss:15.31403923034668

iterator 4900, D_Loss:0.4446364641189575, G_Loss:14.686253547668457

iterator 5000, D_Loss:0.4457656741142273, G_Loss:15.804620742797852

-----------Epoch 3-----------
iterator 100, D_Loss:0.4314270317554474, G_Loss:12.806879043579102

iterator 200, D_Loss:0.43428078293800354, G_Loss:14.048579216003418

iterator 300, D_Loss:0.4011218249797821, G_Loss:13.872031211853027

iterator 400, D_Loss:0.41628286242485046, G_Loss:12.726449966430664

iterator 500, D_Loss:0.42371755838394165, G_Loss:13.432177543640137

iterator 600, D_Loss:0.4039541482925415, G_Loss:13.54979133605957

iterator 700, D_Loss:0.4364885091781616, G_Loss:13.255548477172852

iterator 800, D_Loss:0.4166191518306732, G_Loss:13.168378829956055

iterator 900, D_Loss:0.4355829954147339, G_Loss:14.446223258972168

iterator 1000, D_Loss:0.41630086302757263, G_Loss:14.07398796081543

iterator 1100, D_Loss:0.4241960942745209, G_Loss:12.706589698791504

iterator 1200, D_Loss:0.43083539605140686, G_Loss:12.52868366241455

iterator 1300, D_Loss:0.4163815677165985, G_Loss:13.264997482299805

iterator 1400, D_Loss:0.4202190339565277, G_Loss:14.73126220703125

iterator 1500, D_Loss:0.4454612135887146, G_Loss:12.836505889892578

iterator 1600, D_Loss:0.44400322437286377, G_Loss:12.475363731384277

iterator 1700, D_Loss:0.4279189705848694, G_Loss:12.422338485717773

iterator 1800, D_Loss:0.4292455017566681, G_Loss:13.23624038696289

iterator 1900, D_Loss:0.3998745083808899, G_Loss:11.836368560791016

iterator 2000, D_Loss:0.41531044244766235, G_Loss:11.886239051818848

iterator 2100, D_Loss:0.43690910935401917, G_Loss:12.740252494812012

iterator 2200, D_Loss:0.4276406764984131, G_Loss:12.52269458770752

iterator 2300, D_Loss:0.417186975479126, G_Loss:13.873010635375977

iterator 2400, D_Loss:0.43044087290763855, G_Loss:12.77643871307373

iterator 2500, D_Loss:0.42780977487564087, G_Loss:12.198060989379883

iterator 2600, D_Loss:0.45256584882736206, G_Loss:12.88909912109375

iterator 2700, D_Loss:0.43468567728996277, G_Loss:12.153754234313965

iterator 2800, D_Loss:0.3937622904777527, G_Loss:12.617851257324219

iterator 2900, D_Loss:0.42658084630966187, G_Loss:11.83240032196045

iterator 3000, D_Loss:0.4327200949192047, G_Loss:12.28514289855957

iterator 3100, D_Loss:0.4416077136993408, G_Loss:12.071358680725098

iterator 3200, D_Loss:0.4234926998615265, G_Loss:13.862104415893555

iterator 3300, D_Loss:0.41800835728645325, G_Loss:14.094282150268555

iterator 3400, D_Loss:0.437965989112854, G_Loss:14.087530136108398

iterator 3500, D_Loss:0.4148666560649872, G_Loss:13.155204772949219

iterator 3600, D_Loss:0.42568492889404297, G_Loss:14.050086975097656

iterator 3700, D_Loss:0.42307788133621216, G_Loss:13.893896102905273

iterator 3800, D_Loss:0.41827481985092163, G_Loss:12.331801414489746

iterator 3900, D_Loss:0.4159696400165558, G_Loss:12.807080268859863

iterator 4000, D_Loss:0.38440442085266113, G_Loss:12.439085006713867

iterator 4100, D_Loss:0.419689416885376, G_Loss:12.834750175476074

iterator 4200, D_Loss:0.4524741768836975, G_Loss:11.376004219055176

iterator 4300, D_Loss:0.41369953751564026, G_Loss:12.443958282470703

iterator 4400, D_Loss:0.4404600262641907, G_Loss:11.919242858886719

iterator 4500, D_Loss:0.4084090292453766, G_Loss:12.42587661743164

iterator 4600, D_Loss:0.44022098183631897, G_Loss:12.997614860534668

iterator 4700, D_Loss:0.42903175950050354, G_Loss:12.314437866210938

iterator 4800, D_Loss:0.4056996703147888, G_Loss:11.92005729675293

iterator 4900, D_Loss:0.4373573064804077, G_Loss:13.030073165893555

iterator 5000, D_Loss:0.42133837938308716, G_Loss:12.608211517333984

-----------Epoch 4-----------
iterator 100, D_Loss:0.40130820870399475, G_Loss:12.506348609924316

iterator 200, D_Loss:0.43234097957611084, G_Loss:12.605694770812988

iterator 300, D_Loss:0.40812578797340393, G_Loss:12.13386058807373

iterator 400, D_Loss:0.42858630418777466, G_Loss:13.18413257598877

iterator 500, D_Loss:0.4402366876602173, G_Loss:12.926732063293457

iterator 600, D_Loss:0.4077121913433075, G_Loss:11.868522644042969

iterator 700, D_Loss:0.4152873456478119, G_Loss:12.520748138427734

iterator 800, D_Loss:0.44946473836898804, G_Loss:13.45301342010498

iterator 900, D_Loss:0.4369446039199829, G_Loss:11.18834400177002

iterator 1000, D_Loss:0.40623268485069275, G_Loss:11.709325790405273

iterator 1100, D_Loss:0.4213848114013672, G_Loss:11.340205192565918

iterator 1200, D_Loss:0.420096218585968, G_Loss:12.073278427124023

iterator 1300, D_Loss:0.439951628446579, G_Loss:11.866138458251953

iterator 1400, D_Loss:0.4143175184726715, G_Loss:11.874702453613281

iterator 1500, D_Loss:0.4344513714313507, G_Loss:12.279873847961426

iterator 1600, D_Loss:0.43445268273353577, G_Loss:10.821998596191406

iterator 1700, D_Loss:0.41001737117767334, G_Loss:12.469539642333984

iterator 1800, D_Loss:0.40868693590164185, G_Loss:12.16486930847168

iterator 1900, D_Loss:0.42509788274765015, G_Loss:11.582113265991211

iterator 2000, D_Loss:0.4017728865146637, G_Loss:12.264101028442383

iterator 2100, D_Loss:0.40049129724502563, G_Loss:13.052764892578125

iterator 2200, D_Loss:0.40376025438308716, G_Loss:12.865299224853516

iterator 2300, D_Loss:0.4190063774585724, G_Loss:12.465364456176758

iterator 2400, D_Loss:0.41770419478416443, G_Loss:11.455078125

iterator 2500, D_Loss:0.4412342309951782, G_Loss:11.763345718383789

iterator 2600, D_Loss:0.4164459705352783, G_Loss:11.782864570617676

iterator 2700, D_Loss:0.44598644971847534, G_Loss:12.232645034790039

iterator 2800, D_Loss:0.40788811445236206, G_Loss:10.972546577453613

iterator 2900, D_Loss:0.43134647607803345, G_Loss:13.150089263916016

iterator 3000, D_Loss:0.42402997612953186, G_Loss:13.233444213867188

iterator 3100, D_Loss:0.43310773372650146, G_Loss:12.70199966430664

iterator 3200, D_Loss:0.39017218351364136, G_Loss:11.613454818725586

iterator 3300, D_Loss:0.4055067002773285, G_Loss:12.532652854919434

iterator 3400, D_Loss:0.4031585156917572, G_Loss:12.50278377532959

iterator 3500, D_Loss:0.45685452222824097, G_Loss:14.452412605285645

iterator 3600, D_Loss:0.4279967248439789, G_Loss:11.847110748291016

iterator 3700, D_Loss:0.44620683789253235, G_Loss:14.658008575439453

iterator 3800, D_Loss:0.4283214211463928, G_Loss:15.107688903808594

iterator 3900, D_Loss:0.4678531587123871, G_Loss:16.04004669189453

iterator 4000, D_Loss:0.40558019280433655, G_Loss:14.795995712280273

iterator 4100, D_Loss:0.4239383339881897, G_Loss:13.066743850708008

iterator 4200, D_Loss:0.40899035334587097, G_Loss:14.339144706726074

iterator 4300, D_Loss:0.415743887424469, G_Loss:14.167876243591309

iterator 4400, D_Loss:0.4291544556617737, G_Loss:13.688157081604004

iterator 4500, D_Loss:0.41585949063301086, G_Loss:14.086832046508789

iterator 4600, D_Loss:0.411079466342926, G_Loss:14.550337791442871

iterator 4700, D_Loss:0.41810745000839233, G_Loss:12.71967601776123

iterator 4800, D_Loss:0.4216705560684204, G_Loss:13.74911117553711

iterator 4900, D_Loss:0.4272133708000183, G_Loss:15.436237335205078

iterator 5000, D_Loss:0.3948381245136261, G_Loss:16.67111587524414

-----------Epoch 5-----------
iterator 100, D_Loss:0.4150962829589844, G_Loss:14.831640243530273

iterator 200, D_Loss:0.4017309248447418, G_Loss:16.07604217529297

iterator 300, D_Loss:0.4314531087875366, G_Loss:16.494979858398438

iterator 400, D_Loss:0.4270724058151245, G_Loss:14.968942642211914

iterator 500, D_Loss:0.4231776297092438, G_Loss:14.575092315673828

iterator 600, D_Loss:0.4408211410045624, G_Loss:15.000541687011719

iterator 700, D_Loss:0.4429984390735626, G_Loss:14.59084415435791

iterator 800, D_Loss:0.4319436550140381, G_Loss:13.799610137939453

iterator 900, D_Loss:0.41940852999687195, G_Loss:14.40091323852539

iterator 1000, D_Loss:0.43346700072288513, G_Loss:14.89393424987793

iterator 1100, D_Loss:0.44510021805763245, G_Loss:13.887669563293457

iterator 1200, D_Loss:0.42520809173583984, G_Loss:14.306170463562012

iterator 1300, D_Loss:0.452497661113739, G_Loss:15.104074478149414

iterator 1400, D_Loss:0.4291148781776428, G_Loss:13.640772819519043

iterator 1500, D_Loss:0.42766299843788147, G_Loss:13.875700950622559

iterator 1600, D_Loss:0.41071805357933044, G_Loss:12.634295463562012

iterator 1700, D_Loss:0.42362266778945923, G_Loss:12.238789558410645

iterator 1800, D_Loss:0.43799975514411926, G_Loss:11.723231315612793

iterator 1900, D_Loss:0.41428402066230774, G_Loss:10.976658821105957

iterator 2000, D_Loss:0.413176029920578, G_Loss:12.02554702758789

iterator 2100, D_Loss:0.441402792930603, G_Loss:13.488978385925293

iterator 2200, D_Loss:0.4250149428844452, G_Loss:11.648618698120117

iterator 2300, D_Loss:0.43979620933532715, G_Loss:15.894840240478516

iterator 2400, D_Loss:0.4055262506008148, G_Loss:15.974614143371582

iterator 2500, D_Loss:0.41492176055908203, G_Loss:14.451862335205078

iterator 2600, D_Loss:0.40828990936279297, G_Loss:13.68579387664795

iterator 2700, D_Loss:0.41737908124923706, G_Loss:13.515719413757324

iterator 2800, D_Loss:0.4341221749782562, G_Loss:14.7499361038208

iterator 2900, D_Loss:0.4457515776157379, G_Loss:15.374390602111816

iterator 3000, D_Loss:0.44787365198135376, G_Loss:14.513340950012207

iterator 3100, D_Loss:0.436225563287735, G_Loss:13.178827285766602

iterator 3200, D_Loss:0.4363803267478943, G_Loss:13.600347518920898

iterator 3300, D_Loss:0.42742279171943665, G_Loss:17.12226676940918

iterator 3400, D_Loss:0.4353509843349457, G_Loss:15.702795028686523

iterator 3500, D_Loss:0.43155956268310547, G_Loss:14.944819450378418

iterator 3600, D_Loss:0.43208634853363037, G_Loss:14.687496185302734

iterator 3700, D_Loss:0.4193296432495117, G_Loss:15.318148612976074

iterator 3800, D_Loss:0.403321236371994, G_Loss:15.325289726257324

iterator 3900, D_Loss:0.41999754309654236, G_Loss:14.18004035949707

iterator 4000, D_Loss:0.42835065722465515, G_Loss:14.611189842224121

iterator 4100, D_Loss:0.4102382957935333, G_Loss:13.669697761535645

iterator 4200, D_Loss:0.41888880729675293, G_Loss:14.104198455810547

iterator 4300, D_Loss:0.42474794387817383, G_Loss:13.653990745544434

iterator 4400, D_Loss:0.4239022135734558, G_Loss:13.959044456481934

iterator 4500, D_Loss:0.4345627725124359, G_Loss:13.108381271362305

iterator 4600, D_Loss:0.4185176193714142, G_Loss:13.29292106628418

iterator 4700, D_Loss:0.4147038459777832, G_Loss:13.705791473388672

iterator 4800, D_Loss:0.4444199502468109, G_Loss:13.954310417175293

iterator 4900, D_Loss:0.4333215355873108, G_Loss:14.10108757019043

iterator 5000, D_Loss:0.40222692489624023, G_Loss:12.694522857666016

-----------Epoch 6-----------
iterator 100, D_Loss:0.42511773109436035, G_Loss:12.028944969177246

iterator 200, D_Loss:0.3976629376411438, G_Loss:12.09997272491455

iterator 300, D_Loss:0.45769545435905457, G_Loss:13.707806587219238

iterator 400, D_Loss:0.42691582441329956, G_Loss:13.361777305603027

iterator 500, D_Loss:0.42086538672447205, G_Loss:13.273124694824219

iterator 600, D_Loss:0.40774255990982056, G_Loss:12.209114074707031

iterator 700, D_Loss:0.4272185266017914, G_Loss:12.228067398071289

iterator 800, D_Loss:0.42656612396240234, G_Loss:13.146696090698242

iterator 900, D_Loss:0.4272943139076233, G_Loss:12.075925827026367

iterator 1000, D_Loss:0.40045714378356934, G_Loss:12.631272315979004

iterator 1100, D_Loss:0.4269447922706604, G_Loss:12.498120307922363

iterator 1200, D_Loss:0.42231208086013794, G_Loss:13.623857498168945

iterator 1300, D_Loss:0.3971598744392395, G_Loss:13.032659530639648

iterator 1400, D_Loss:0.42883363366127014, G_Loss:13.056110382080078

iterator 1500, D_Loss:0.4252256453037262, G_Loss:12.308084487915039

iterator 1600, D_Loss:0.4354614317417145, G_Loss:11.804374694824219

iterator 1700, D_Loss:0.39402124285697937, G_Loss:12.577653884887695

iterator 1800, D_Loss:0.39839717745780945, G_Loss:13.096332550048828

iterator 1900, D_Loss:0.4399757981300354, G_Loss:12.578200340270996

iterator 2000, D_Loss:0.4349135756492615, G_Loss:12.606526374816895

iterator 2100, D_Loss:0.42415350675582886, G_Loss:12.914871215820312

iterator 2200, D_Loss:0.43979477882385254, G_Loss:12.817846298217773

iterator 2300, D_Loss:0.43793559074401855, G_Loss:11.982824325561523

iterator 2400, D_Loss:0.40947017073631287, G_Loss:11.607645034790039

iterator 2500, D_Loss:0.40949586033821106, G_Loss:12.606974601745605

iterator 2600, D_Loss:0.40418845415115356, G_Loss:11.902437210083008

iterator 2700, D_Loss:0.39896509051322937, G_Loss:11.783166885375977

iterator 2800, D_Loss:0.4312441349029541, G_Loss:12.101418495178223

iterator 2900, D_Loss:0.4246949255466461, G_Loss:13.218301773071289

iterator 3000, D_Loss:0.4169633388519287, G_Loss:12.984267234802246

iterator 3100, D_Loss:0.39502304792404175, G_Loss:13.739835739135742

iterator 3200, D_Loss:0.43314915895462036, G_Loss:12.175981521606445

iterator 3300, D_Loss:0.4162651598453522, G_Loss:12.39680290222168

iterator 3400, D_Loss:0.4312215745449066, G_Loss:12.636213302612305

iterator 3500, D_Loss:0.41139987111091614, G_Loss:13.226081848144531

iterator 3600, D_Loss:0.44249585270881653, G_Loss:12.401493072509766

iterator 3700, D_Loss:0.40463119745254517, G_Loss:12.429852485656738

iterator 3800, D_Loss:0.41957929730415344, G_Loss:11.895013809204102

iterator 3900, D_Loss:0.4330523610115051, G_Loss:11.326156616210938

iterator 4000, D_Loss:0.4029567539691925, G_Loss:12.424741744995117

iterator 4100, D_Loss:0.4187435507774353, G_Loss:12.277970314025879

iterator 4200, D_Loss:0.39701980352401733, G_Loss:12.608932495117188

iterator 4300, D_Loss:0.41606947779655457, G_Loss:12.081144332885742

iterator 4400, D_Loss:0.42848044633865356, G_Loss:12.800320625305176

iterator 4500, D_Loss:0.42628276348114014, G_Loss:12.649870872497559

iterator 4600, D_Loss:0.4501063823699951, G_Loss:12.410823822021484

iterator 4700, D_Loss:0.4315555989742279, G_Loss:13.462210655212402

iterator 4800, D_Loss:0.4206058382987976, G_Loss:12.606582641601562

iterator 4900, D_Loss:0.466539204120636, G_Loss:12.601906776428223

iterator 5000, D_Loss:0.4193171560764313, G_Loss:12.763455390930176

-----------Epoch 7-----------
iterator 100, D_Loss:0.4329383969306946, G_Loss:12.575818061828613

iterator 200, D_Loss:0.413119375705719, G_Loss:12.693154335021973

iterator 300, D_Loss:0.40434086322784424, G_Loss:13.33475399017334

iterator 400, D_Loss:0.4058853089809418, G_Loss:12.605864524841309

iterator 500, D_Loss:0.4160936176776886, G_Loss:13.151276588439941

iterator 600, D_Loss:0.43112999200820923, G_Loss:13.218330383300781

iterator 700, D_Loss:0.4490334689617157, G_Loss:12.726137161254883

iterator 800, D_Loss:0.43010273575782776, G_Loss:11.928932189941406

iterator 900, D_Loss:0.41882359981536865, G_Loss:12.165245056152344

iterator 1000, D_Loss:0.41993141174316406, G_Loss:12.488825798034668

iterator 1100, D_Loss:0.4370673894882202, G_Loss:12.528471946716309

iterator 1200, D_Loss:0.4479382634162903, G_Loss:12.560154914855957

iterator 1300, D_Loss:0.42068901658058167, G_Loss:12.408713340759277

iterator 1400, D_Loss:0.4181061387062073, G_Loss:9.597618103027344

iterator 1500, D_Loss:0.4122483730316162, G_Loss:11.304932594299316

iterator 1600, D_Loss:0.4199298918247223, G_Loss:10.758415222167969

iterator 1700, D_Loss:0.41520780324935913, G_Loss:11.74502182006836

iterator 1800, D_Loss:0.42586880922317505, G_Loss:12.438272476196289

iterator 1900, D_Loss:0.4255196154117584, G_Loss:11.890419960021973

iterator 2000, D_Loss:0.4076853096485138, G_Loss:13.302362442016602

iterator 2100, D_Loss:0.41723528504371643, G_Loss:13.11941909790039

iterator 2200, D_Loss:0.4492321014404297, G_Loss:9.990943908691406

iterator 2300, D_Loss:0.42909395694732666, G_Loss:13.007645606994629

iterator 2400, D_Loss:0.44290924072265625, G_Loss:15.1241455078125

iterator 2500, D_Loss:0.4250611662864685, G_Loss:14.065593719482422

iterator 2600, D_Loss:0.4277041256427765, G_Loss:13.545507431030273

iterator 2700, D_Loss:0.4160960912704468, G_Loss:13.066041946411133

iterator 2800, D_Loss:0.4316985011100769, G_Loss:14.744933128356934

iterator 2900, D_Loss:0.3998803496360779, G_Loss:14.419297218322754

iterator 3000, D_Loss:0.41445392370224, G_Loss:14.571590423583984

iterator 3100, D_Loss:0.4284629225730896, G_Loss:14.319912910461426

iterator 3200, D_Loss:0.4276803135871887, G_Loss:13.16182804107666

iterator 3300, D_Loss:0.4115523099899292, G_Loss:15.248226165771484

iterator 3400, D_Loss:0.39737266302108765, G_Loss:12.581820487976074

iterator 3500, D_Loss:0.43289071321487427, G_Loss:14.48488998413086

iterator 3600, D_Loss:0.43191075325012207, G_Loss:14.965214729309082

iterator 3700, D_Loss:0.45178112387657166, G_Loss:14.832855224609375

iterator 3800, D_Loss:0.42113474011421204, G_Loss:15.864850044250488

iterator 3900, D_Loss:0.4552879333496094, G_Loss:14.556727409362793

iterator 4000, D_Loss:0.43836238980293274, G_Loss:15.332978248596191

iterator 4100, D_Loss:0.42309728264808655, G_Loss:14.665850639343262

iterator 4200, D_Loss:0.43956688046455383, G_Loss:14.369050979614258

iterator 4300, D_Loss:0.44258904457092285, G_Loss:15.359842300415039

iterator 4400, D_Loss:0.4622015655040741, G_Loss:15.589977264404297

iterator 4500, D_Loss:0.4160518944263458, G_Loss:14.844781875610352

iterator 4600, D_Loss:0.4260345697402954, G_Loss:15.659493446350098

iterator 4700, D_Loss:0.4263623058795929, G_Loss:14.11577033996582

iterator 4800, D_Loss:0.4332643449306488, G_Loss:12.693397521972656

iterator 4900, D_Loss:0.4615604877471924, G_Loss:15.36075496673584

iterator 5000, D_Loss:0.41586747765541077, G_Loss:15.88106632232666

-----------Epoch 8-----------
iterator 100, D_Loss:0.4434937834739685, G_Loss:14.189220428466797

iterator 200, D_Loss:0.4205678701400757, G_Loss:13.819992065429688

iterator 300, D_Loss:0.41614019870758057, G_Loss:13.162927627563477

iterator 400, D_Loss:0.41385507583618164, G_Loss:13.974935531616211

iterator 500, D_Loss:0.4527623653411865, G_Loss:14.447510719299316

iterator 600, D_Loss:0.4194009006023407, G_Loss:13.716680526733398

iterator 700, D_Loss:0.41775381565093994, G_Loss:13.19914436340332

iterator 800, D_Loss:0.4277731478214264, G_Loss:13.466821670532227

iterator 900, D_Loss:0.44199827313423157, G_Loss:13.930830001831055

iterator 1000, D_Loss:0.41967540979385376, G_Loss:13.243006706237793

iterator 1100, D_Loss:0.3946518898010254, G_Loss:13.915078163146973

iterator 1200, D_Loss:0.4535379707813263, G_Loss:14.214493751525879

iterator 1300, D_Loss:0.4419219493865967, G_Loss:13.143932342529297

iterator 1400, D_Loss:0.40370526909828186, G_Loss:13.682605743408203

iterator 1500, D_Loss:0.4189879298210144, G_Loss:12.964986801147461

iterator 1600, D_Loss:0.42399072647094727, G_Loss:13.334283828735352

iterator 1700, D_Loss:0.4397042393684387, G_Loss:12.815763473510742

iterator 1800, D_Loss:0.4115220010280609, G_Loss:12.748910903930664

iterator 1900, D_Loss:0.41756877303123474, G_Loss:11.680721282958984

iterator 2000, D_Loss:0.4255344867706299, G_Loss:13.952539443969727

iterator 2100, D_Loss:0.40554937720298767, G_Loss:13.312005043029785

iterator 2200, D_Loss:0.4436342418193817, G_Loss:13.669198989868164

iterator 2300, D_Loss:0.4346199035644531, G_Loss:13.692680358886719

iterator 2400, D_Loss:0.42549121379852295, G_Loss:13.99494743347168

iterator 2500, D_Loss:0.4412207007408142, G_Loss:13.556462287902832

iterator 2600, D_Loss:0.40270572900772095, G_Loss:14.46049690246582

iterator 2700, D_Loss:0.40860018134117126, G_Loss:14.068256378173828

iterator 2800, D_Loss:0.42535194754600525, G_Loss:14.192316055297852

iterator 2900, D_Loss:0.43374234437942505, G_Loss:11.179559707641602

iterator 3000, D_Loss:0.4113958477973938, G_Loss:13.867729187011719

iterator 3100, D_Loss:0.41540277004241943, G_Loss:12.770475387573242

iterator 3200, D_Loss:0.4232656955718994, G_Loss:12.926074981689453

iterator 3300, D_Loss:0.42671722173690796, G_Loss:13.635232925415039

iterator 3400, D_Loss:0.41570886969566345, G_Loss:13.973788261413574

iterator 3500, D_Loss:0.42424866557121277, G_Loss:12.829387664794922

iterator 3600, D_Loss:0.43084707856178284, G_Loss:13.411898612976074

iterator 3700, D_Loss:0.42563000321388245, G_Loss:14.525181770324707

iterator 3800, D_Loss:0.42936450242996216, G_Loss:14.253320693969727

iterator 3900, D_Loss:0.4054761826992035, G_Loss:14.204306602478027

iterator 4000, D_Loss:0.44109275937080383, G_Loss:13.766024589538574

iterator 4100, D_Loss:0.43309274315834045, G_Loss:14.184412956237793

iterator 4200, D_Loss:0.4264405071735382, G_Loss:14.424792289733887

iterator 4300, D_Loss:0.41419464349746704, G_Loss:13.961956024169922

iterator 4400, D_Loss:0.42610275745391846, G_Loss:13.901334762573242

iterator 4500, D_Loss:0.4297375977039337, G_Loss:13.531881332397461

iterator 4600, D_Loss:0.43103817105293274, G_Loss:14.393125534057617

iterator 4700, D_Loss:0.43070751428604126, G_Loss:13.74931526184082

iterator 4800, D_Loss:0.3954913914203644, G_Loss:15.687129974365234

iterator 4900, D_Loss:0.4270244836807251, G_Loss:16.23246192932129

iterator 5000, D_Loss:0.44699907302856445, G_Loss:13.633990287780762

-----------Epoch 9-----------
iterator 100, D_Loss:0.4119805693626404, G_Loss:12.48123550415039

iterator 200, D_Loss:0.421193927526474, G_Loss:13.791704177856445

iterator 300, D_Loss:0.3981596529483795, G_Loss:13.227787017822266

iterator 400, D_Loss:0.40861546993255615, G_Loss:13.306068420410156

iterator 500, D_Loss:0.4334143102169037, G_Loss:13.977909088134766

iterator 600, D_Loss:0.43479248881340027, G_Loss:14.139266014099121

iterator 700, D_Loss:0.41915613412857056, G_Loss:13.62765884399414

iterator 800, D_Loss:0.4039662182331085, G_Loss:13.364189147949219

iterator 900, D_Loss:0.447102814912796, G_Loss:14.295263290405273

iterator 1000, D_Loss:0.41619569063186646, G_Loss:13.831868171691895

iterator 1100, D_Loss:0.4235839247703552, G_Loss:14.305977821350098

iterator 1200, D_Loss:0.4220591187477112, G_Loss:13.197425842285156

iterator 1300, D_Loss:0.42185190320014954, G_Loss:13.415234565734863

iterator 1400, D_Loss:0.4286024272441864, G_Loss:11.830160140991211

iterator 1500, D_Loss:0.4380483329296112, G_Loss:12.796825408935547

iterator 1600, D_Loss:0.43301430344581604, G_Loss:13.263404846191406

iterator 1700, D_Loss:0.4186570346355438, G_Loss:13.234867095947266

iterator 1800, D_Loss:0.4382277727127075, G_Loss:12.868097305297852

iterator 1900, D_Loss:0.4197019636631012, G_Loss:13.337347984313965

iterator 2000, D_Loss:0.42943915724754333, G_Loss:12.436666488647461

iterator 2100, D_Loss:0.41945186257362366, G_Loss:13.539299964904785

iterator 2200, D_Loss:0.40512439608573914, G_Loss:14.296902656555176

iterator 2300, D_Loss:0.4268813729286194, G_Loss:14.289669036865234

iterator 2400, D_Loss:0.42044296860694885, G_Loss:12.653828620910645

iterator 2500, D_Loss:0.4196263253688812, G_Loss:12.145517349243164

iterator 2600, D_Loss:0.4174822270870209, G_Loss:12.403070449829102

iterator 2700, D_Loss:0.4511592388153076, G_Loss:12.48890495300293

iterator 2800, D_Loss:0.4119279980659485, G_Loss:12.168403625488281

iterator 2900, D_Loss:0.43829652667045593, G_Loss:13.864787101745605

iterator 3000, D_Loss:0.441430002450943, G_Loss:14.028860092163086

iterator 3100, D_Loss:0.4439822733402252, G_Loss:13.984221458435059

iterator 3200, D_Loss:0.4170563817024231, G_Loss:13.092552185058594

iterator 3300, D_Loss:0.4250542223453522, G_Loss:12.810336112976074

iterator 3400, D_Loss:0.4000716805458069, G_Loss:14.83051872253418

iterator 3500, D_Loss:0.42055925726890564, G_Loss:15.984200477600098

iterator 3600, D_Loss:0.4480895698070526, G_Loss:14.315770149230957

iterator 3700, D_Loss:0.4509347975254059, G_Loss:14.457094192504883

iterator 3800, D_Loss:0.434273898601532, G_Loss:13.614527702331543

iterator 3900, D_Loss:0.4136297106742859, G_Loss:14.712202072143555

iterator 4000, D_Loss:0.4196585714817047, G_Loss:14.488643646240234

iterator 4100, D_Loss:0.4059889614582062, G_Loss:13.493967056274414

iterator 4200, D_Loss:0.438477098941803, G_Loss:13.360628128051758

iterator 4300, D_Loss:0.4328051805496216, G_Loss:13.970056533813477

iterator 4400, D_Loss:0.45361801981925964, G_Loss:13.697795867919922

iterator 4500, D_Loss:0.4299699366092682, G_Loss:14.007841110229492

iterator 4600, D_Loss:0.40713804960250854, G_Loss:13.821433067321777

iterator 4700, D_Loss:0.41456541419029236, G_Loss:14.240747451782227

iterator 4800, D_Loss:0.42247316241264343, G_Loss:12.939737319946289

iterator 4900, D_Loss:0.4143858850002289, G_Loss:13.137472152709961

iterator 5000, D_Loss:0.4492139220237732, G_Loss:12.69886302947998

train row : 30148
sample row: 30148
LGAN_generator(
  (LSTM): LSTMCell(450, 200)
  (fc00): Linear(in_features=400, out_features=1, bias=True)
  (fc01): Linear(in_features=1, out_features=400, bias=True)
  (fe0): Linear(in_features=200, out_features=400, bias=True)
  (fc10): Linear(in_features=400, out_features=1, bias=True)
  (fc11): Linear(in_features=1, out_features=400, bias=True)
  (fe1): Linear(in_features=200, out_features=400, bias=True)
  (fc20): Linear(in_features=400, out_features=1, bias=True)
  (fc21): Linear(in_features=1, out_features=400, bias=True)
  (fe2): Linear(in_features=200, out_features=400, bias=True)
  (fc30): Linear(in_features=400, out_features=1, bias=True)
  (fc31): Linear(in_features=1, out_features=400, bias=True)
  (fe3): Linear(in_features=200, out_features=400, bias=True)
  (fc40): Linear(in_features=400, out_features=1, bias=True)
  (fc41): Linear(in_features=1, out_features=400, bias=True)
  (fe4): Linear(in_features=200, out_features=400, bias=True)
  (fc50): Linear(in_features=400, out_features=1, bias=True)
  (fc51): Linear(in_features=1, out_features=400, bias=True)
  (fe5): Linear(in_features=200, out_features=400, bias=True)
  (fc60): Linear(in_features=400, out_features=1, bias=True)
  (fc61): Linear(in_features=1, out_features=400, bias=True)
  (fe6): Linear(in_features=200, out_features=400, bias=True)
  (fc70): Linear(in_features=400, out_features=1, bias=True)
  (fc71): Linear(in_features=1, out_features=400, bias=True)
  (fe7): Linear(in_features=200, out_features=400, bias=True)
  (fc80): Linear(in_features=400, out_features=1, bias=True)
  (fc81): Linear(in_features=1, out_features=400, bias=True)
  (fe8): Linear(in_features=200, out_features=400, bias=True)
  (fc90): Linear(in_features=400, out_features=1, bias=True)
  (fc91): Linear(in_features=1, out_features=400, bias=True)
  (fe9): Linear(in_features=200, out_features=400, bias=True)
  (fc100): Linear(in_features=400, out_features=1, bias=True)
  (fc101): Linear(in_features=1, out_features=400, bias=True)
  (fe10): Linear(in_features=200, out_features=400, bias=True)
  (fc110): Linear(in_features=400, out_features=1, bias=True)
  (fc111): Linear(in_features=1, out_features=400, bias=True)
  (fe11): Linear(in_features=200, out_features=400, bias=True)
  (fc120): Linear(in_features=400, out_features=1, bias=True)
  (fc121): Linear(in_features=1, out_features=400, bias=True)
  (fe12): Linear(in_features=200, out_features=400, bias=True)
  (fc130): Linear(in_features=400, out_features=1, bias=True)
  (fc131): Linear(in_features=1, out_features=400, bias=True)
  (fe13): Linear(in_features=200, out_features=400, bias=True)
  (fc140): Linear(in_features=400, out_features=1, bias=True)
  (fc141): Linear(in_features=1, out_features=400, bias=True)
  (fe14): Linear(in_features=200, out_features=400, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=15, out_features=400, bias=True)
  (inputbn): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=400, out_features=400, bias=True)
  (bn0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=400, out_features=1, bias=True)
)
(0, False, 15)
-----------Epoch 0-----------
iterator 100, D_Loss:1.351661205291748, G_Loss:0.9234269857406616

iterator 200, D_Loss:1.2765438556671143, G_Loss:0.9586442708969116

iterator 300, D_Loss:1.2328250408172607, G_Loss:0.9953333139419556

iterator 400, D_Loss:1.2125712633132935, G_Loss:1.1328496932983398

iterator 500, D_Loss:1.129941463470459, G_Loss:1.192495584487915

iterator 600, D_Loss:1.1051095724105835, G_Loss:1.2513854503631592

iterator 700, D_Loss:1.0868724584579468, G_Loss:1.244411826133728

iterator 800, D_Loss:1.1892904043197632, G_Loss:1.0858176946640015

iterator 900, D_Loss:1.2236895561218262, G_Loss:1.023055911064148

iterator 1000, D_Loss:1.1518886089324951, G_Loss:1.0889469385147095

iterator 1100, D_Loss:1.1219887733459473, G_Loss:1.019303560256958

iterator 1200, D_Loss:1.1339808702468872, G_Loss:1.2752881050109863

iterator 1300, D_Loss:1.016800880432129, G_Loss:1.2553857564926147

iterator 1400, D_Loss:1.1076884269714355, G_Loss:1.227262020111084

iterator 1500, D_Loss:1.0857131481170654, G_Loss:1.3074309825897217

iterator 1600, D_Loss:1.3116333484649658, G_Loss:1.0191619396209717

iterator 1700, D_Loss:1.2474133968353271, G_Loss:0.9452359676361084

iterator 1800, D_Loss:1.2643142938613892, G_Loss:1.0477533340454102

iterator 1900, D_Loss:1.293968677520752, G_Loss:1.017162799835205

iterator 2000, D_Loss:1.2247567176818848, G_Loss:1.0496102571487427

iterator 2100, D_Loss:1.2774490118026733, G_Loss:1.0332390069961548

iterator 2200, D_Loss:1.3109209537506104, G_Loss:0.928612232208252

iterator 2300, D_Loss:1.2184642553329468, G_Loss:1.023223876953125

iterator 2400, D_Loss:1.3222613334655762, G_Loss:1.0410091876983643

iterator 2500, D_Loss:1.3633159399032593, G_Loss:0.9285946488380432

iterator 2600, D_Loss:1.3561336994171143, G_Loss:0.9943288564682007

iterator 2700, D_Loss:1.2950959205627441, G_Loss:1.0152548551559448

iterator 2800, D_Loss:1.3422396183013916, G_Loss:0.9755451083183289

iterator 2900, D_Loss:1.3334612846374512, G_Loss:0.921989381313324

iterator 3000, D_Loss:1.2577146291732788, G_Loss:0.9388344287872314

iterator 3100, D_Loss:1.2958663702011108, G_Loss:1.0111616849899292

iterator 3200, D_Loss:1.3594820499420166, G_Loss:0.9927918910980225

iterator 3300, D_Loss:1.3562171459197998, G_Loss:1.0053445100784302

iterator 3400, D_Loss:1.381117582321167, G_Loss:1.055954933166504

iterator 3500, D_Loss:1.2812660932540894, G_Loss:0.9350732564926147

iterator 3600, D_Loss:1.3288283348083496, G_Loss:0.9547612071037292

iterator 3700, D_Loss:1.3207998275756836, G_Loss:0.8953729271888733

iterator 3800, D_Loss:1.4731982946395874, G_Loss:0.9038074016571045

iterator 3900, D_Loss:1.3187767267227173, G_Loss:0.9169162511825562

iterator 4000, D_Loss:1.3625285625457764, G_Loss:0.9551247358322144

iterator 4100, D_Loss:1.2585017681121826, G_Loss:0.9245245456695557

iterator 4200, D_Loss:1.3883419036865234, G_Loss:0.9395293593406677

iterator 4300, D_Loss:1.3340156078338623, G_Loss:0.9100345373153687

iterator 4400, D_Loss:1.3067374229431152, G_Loss:0.9097564220428467

iterator 4500, D_Loss:1.342873454093933, G_Loss:0.9144611358642578

iterator 4600, D_Loss:1.3216757774353027, G_Loss:0.8620196580886841

iterator 4700, D_Loss:1.385181188583374, G_Loss:0.9446596503257751

iterator 4800, D_Loss:1.3519043922424316, G_Loss:0.9592908620834351

iterator 4900, D_Loss:1.3585808277130127, G_Loss:0.909456729888916

iterator 5000, D_Loss:1.331030249595642, G_Loss:0.9290008544921875

-----------Epoch 1-----------
iterator 100, D_Loss:1.3319296836853027, G_Loss:0.8954184651374817

iterator 200, D_Loss:1.3089303970336914, G_Loss:0.9617148041725159

iterator 300, D_Loss:1.3634494543075562, G_Loss:0.948081374168396

iterator 400, D_Loss:1.4497849941253662, G_Loss:0.9106276035308838

iterator 500, D_Loss:1.3752305507659912, G_Loss:0.9171733260154724

iterator 600, D_Loss:1.3399029970169067, G_Loss:0.9230125546455383

iterator 700, D_Loss:1.367048978805542, G_Loss:0.8945685625076294

iterator 800, D_Loss:1.348982334136963, G_Loss:0.8978103399276733

iterator 900, D_Loss:1.360999584197998, G_Loss:0.8667177557945251

iterator 1000, D_Loss:1.3375743627548218, G_Loss:0.8974652886390686

iterator 1100, D_Loss:1.3442788124084473, G_Loss:0.8680411577224731

iterator 1200, D_Loss:1.327351689338684, G_Loss:0.9310540556907654

iterator 1300, D_Loss:1.3539495468139648, G_Loss:0.9099671840667725

iterator 1400, D_Loss:1.3715424537658691, G_Loss:0.8643547296524048

iterator 1500, D_Loss:1.410905361175537, G_Loss:0.8670923113822937

iterator 1600, D_Loss:1.3262999057769775, G_Loss:0.9611942768096924

iterator 1700, D_Loss:1.3763046264648438, G_Loss:0.8919916749000549

iterator 1800, D_Loss:1.3314664363861084, G_Loss:0.9109403491020203

iterator 1900, D_Loss:1.3545715808868408, G_Loss:0.8910499811172485

iterator 2000, D_Loss:1.3561391830444336, G_Loss:0.8703479766845703

iterator 2100, D_Loss:1.3725366592407227, G_Loss:0.8919878602027893

iterator 2200, D_Loss:1.3447003364562988, G_Loss:0.910877525806427

iterator 2300, D_Loss:1.370528221130371, G_Loss:0.8580861687660217

iterator 2400, D_Loss:1.3416101932525635, G_Loss:0.8725215196609497

iterator 2500, D_Loss:1.3704378604888916, G_Loss:0.8680351376533508

iterator 2600, D_Loss:1.3240973949432373, G_Loss:0.866925060749054

iterator 2700, D_Loss:1.32623291015625, G_Loss:0.902567982673645

iterator 2800, D_Loss:1.3642420768737793, G_Loss:0.9037216305732727

iterator 2900, D_Loss:1.3340859413146973, G_Loss:0.906242311000824

iterator 3000, D_Loss:1.3343437910079956, G_Loss:0.9582673907279968

iterator 3100, D_Loss:1.3554978370666504, G_Loss:0.929220974445343

iterator 3200, D_Loss:1.3226014375686646, G_Loss:0.9162502288818359

iterator 3300, D_Loss:1.3249757289886475, G_Loss:0.9305114150047302

iterator 3400, D_Loss:1.3526309728622437, G_Loss:0.8638119697570801

iterator 3500, D_Loss:1.3554399013519287, G_Loss:0.903077244758606

iterator 3600, D_Loss:1.367084264755249, G_Loss:0.8714005351066589

iterator 3700, D_Loss:1.3510165214538574, G_Loss:0.8931551575660706

iterator 3800, D_Loss:1.3723875284194946, G_Loss:0.8832330107688904

iterator 3900, D_Loss:1.332923173904419, G_Loss:0.8931872844696045

iterator 4000, D_Loss:1.3713500499725342, G_Loss:0.8332604765892029

iterator 4100, D_Loss:1.3377509117126465, G_Loss:0.8823692202568054

iterator 4200, D_Loss:1.3301706314086914, G_Loss:0.8486700654029846

iterator 4300, D_Loss:1.3654098510742188, G_Loss:0.8803040385246277

iterator 4400, D_Loss:1.3386015892028809, G_Loss:0.8853527903556824

iterator 4500, D_Loss:1.3529484272003174, G_Loss:0.9140502214431763

iterator 4600, D_Loss:1.3449666500091553, G_Loss:0.8882642388343811

iterator 4700, D_Loss:1.364950180053711, G_Loss:0.8693956136703491

iterator 4800, D_Loss:1.3459267616271973, G_Loss:0.8676804900169373

iterator 4900, D_Loss:1.3696696758270264, G_Loss:0.8918249607086182

iterator 5000, D_Loss:1.3568295240402222, G_Loss:0.9045290350914001

-----------Epoch 2-----------
iterator 100, D_Loss:1.3270788192749023, G_Loss:0.8938852548599243

iterator 200, D_Loss:1.3778245449066162, G_Loss:0.8858467936515808

iterator 300, D_Loss:1.3386728763580322, G_Loss:0.845293402671814

iterator 400, D_Loss:1.3774259090423584, G_Loss:0.8777204751968384

iterator 500, D_Loss:1.333836555480957, G_Loss:0.8843713998794556

iterator 600, D_Loss:1.3292145729064941, G_Loss:0.9010375738143921

iterator 700, D_Loss:1.364471435546875, G_Loss:0.8704583644866943

iterator 800, D_Loss:1.3730676174163818, G_Loss:0.8798863887786865

iterator 900, D_Loss:1.3653981685638428, G_Loss:0.889870285987854

iterator 1000, D_Loss:1.3323400020599365, G_Loss:0.8709544539451599

iterator 1100, D_Loss:1.341871738433838, G_Loss:0.8578291535377502

iterator 1200, D_Loss:1.3520485162734985, G_Loss:0.9181104898452759

iterator 1300, D_Loss:1.3754169940948486, G_Loss:0.9289799332618713

iterator 1400, D_Loss:1.3767750263214111, G_Loss:0.8902825713157654

iterator 1500, D_Loss:1.3478572368621826, G_Loss:0.9014089703559875

iterator 1600, D_Loss:1.3360350131988525, G_Loss:0.8872846961021423

iterator 1700, D_Loss:1.3536274433135986, G_Loss:0.920644223690033

iterator 1800, D_Loss:1.3263614177703857, G_Loss:0.9286186695098877

iterator 1900, D_Loss:1.360743761062622, G_Loss:0.8865301012992859

iterator 2000, D_Loss:1.3733456134796143, G_Loss:0.865245521068573

iterator 2100, D_Loss:1.340104103088379, G_Loss:0.8799995183944702

iterator 2200, D_Loss:1.3518823385238647, G_Loss:0.8489845395088196

iterator 2300, D_Loss:1.3435627222061157, G_Loss:0.8706433176994324

iterator 2400, D_Loss:1.3561890125274658, G_Loss:0.888721764087677

iterator 2500, D_Loss:1.3415268659591675, G_Loss:0.8880929350852966

iterator 2600, D_Loss:1.3599522113800049, G_Loss:0.8837860226631165

iterator 2700, D_Loss:1.356658935546875, G_Loss:0.9040409922599792

iterator 2800, D_Loss:1.3603317737579346, G_Loss:0.9234915375709534

iterator 2900, D_Loss:1.3435810804367065, G_Loss:0.9015326499938965

iterator 3000, D_Loss:1.364375114440918, G_Loss:0.9074926972389221

iterator 3100, D_Loss:1.3735451698303223, G_Loss:0.8768604397773743

iterator 3200, D_Loss:1.3188657760620117, G_Loss:0.8949517011642456

iterator 3300, D_Loss:1.3508925437927246, G_Loss:0.8749600052833557

iterator 3400, D_Loss:1.3729488849639893, G_Loss:0.8835198283195496

iterator 3500, D_Loss:1.3468289375305176, G_Loss:0.8639679551124573

iterator 3600, D_Loss:1.354182481765747, G_Loss:0.902957022190094

iterator 3700, D_Loss:1.3685832023620605, G_Loss:0.878607988357544

iterator 3800, D_Loss:1.3319201469421387, G_Loss:0.9036933779716492

iterator 3900, D_Loss:1.3744478225708008, G_Loss:0.8777331709861755

iterator 4000, D_Loss:1.3467546701431274, G_Loss:0.9101357460021973

iterator 4100, D_Loss:1.3623125553131104, G_Loss:0.8649022579193115

iterator 4200, D_Loss:1.3577308654785156, G_Loss:0.9026906490325928

iterator 4300, D_Loss:1.3534140586853027, G_Loss:0.8975260853767395

iterator 4400, D_Loss:1.3470484018325806, G_Loss:0.8843583464622498

iterator 4500, D_Loss:1.334536075592041, G_Loss:0.8841424584388733

iterator 4600, D_Loss:1.354654312133789, G_Loss:0.8970633149147034

iterator 4700, D_Loss:1.3268561363220215, G_Loss:0.891832709312439

iterator 4800, D_Loss:1.398653268814087, G_Loss:0.8820427656173706

iterator 4900, D_Loss:1.3390376567840576, G_Loss:0.8884851932525635

iterator 5000, D_Loss:1.3334522247314453, G_Loss:0.904629111289978

-----------Epoch 3-----------
iterator 100, D_Loss:1.330418348312378, G_Loss:0.8832783699035645

iterator 200, D_Loss:1.3269414901733398, G_Loss:0.8849558234214783

iterator 300, D_Loss:1.3642287254333496, G_Loss:0.8751376867294312

iterator 400, D_Loss:1.3391817808151245, G_Loss:0.8969153761863708

iterator 500, D_Loss:1.336634874343872, G_Loss:0.8824724555015564

iterator 600, D_Loss:1.363492488861084, G_Loss:0.9277694821357727

iterator 700, D_Loss:1.3251546621322632, G_Loss:0.868705689907074

iterator 800, D_Loss:1.3516781330108643, G_Loss:0.8950189352035522

iterator 900, D_Loss:1.3215762376785278, G_Loss:0.9170346260070801

iterator 1000, D_Loss:1.347933053970337, G_Loss:0.8856271505355835

iterator 1100, D_Loss:1.362306833267212, G_Loss:0.8810867071151733

iterator 1200, D_Loss:1.3609018325805664, G_Loss:0.9094622731208801

iterator 1300, D_Loss:1.354212999343872, G_Loss:0.8743501305580139

iterator 1400, D_Loss:1.348803997039795, G_Loss:0.9027860164642334

iterator 1500, D_Loss:1.3496522903442383, G_Loss:0.8979897499084473

iterator 1600, D_Loss:1.3441002368927002, G_Loss:0.8988863229751587

iterator 1700, D_Loss:1.3421249389648438, G_Loss:0.9063007235527039

iterator 1800, D_Loss:1.3590848445892334, G_Loss:0.8749417662620544

iterator 1900, D_Loss:1.3559839725494385, G_Loss:0.9200618267059326

iterator 2000, D_Loss:1.339045763015747, G_Loss:0.8728736639022827

iterator 2100, D_Loss:1.337909460067749, G_Loss:0.9089646935462952

iterator 2200, D_Loss:1.3055709600448608, G_Loss:0.9006720185279846

iterator 2300, D_Loss:1.3541221618652344, G_Loss:0.8615077137947083

iterator 2400, D_Loss:1.3760905265808105, G_Loss:0.8963930010795593

iterator 2500, D_Loss:1.3191039562225342, G_Loss:0.9466715455055237

iterator 2600, D_Loss:1.3614060878753662, G_Loss:0.8664159178733826

iterator 2700, D_Loss:1.3219921588897705, G_Loss:0.9277327060699463

iterator 2800, D_Loss:1.3885807991027832, G_Loss:0.8197890520095825

iterator 2900, D_Loss:1.3271021842956543, G_Loss:0.8952977061271667

iterator 3000, D_Loss:1.3373219966888428, G_Loss:0.8744732737541199

iterator 3100, D_Loss:1.3553681373596191, G_Loss:0.8852226138114929

iterator 3200, D_Loss:1.323764443397522, G_Loss:0.9093641042709351

iterator 3300, D_Loss:1.3236644268035889, G_Loss:0.9342736005783081

iterator 3400, D_Loss:1.3537355661392212, G_Loss:0.8723013401031494

iterator 3500, D_Loss:1.3270690441131592, G_Loss:0.878714382648468

iterator 3600, D_Loss:1.322109341621399, G_Loss:0.9021854996681213

iterator 3700, D_Loss:1.3572499752044678, G_Loss:0.8947611451148987

iterator 3800, D_Loss:1.3589760065078735, G_Loss:0.9326612949371338

iterator 3900, D_Loss:1.2890945672988892, G_Loss:0.9354913234710693

iterator 4000, D_Loss:1.3242487907409668, G_Loss:0.8741353750228882

iterator 4100, D_Loss:1.2912119626998901, G_Loss:0.8603019118309021

iterator 4200, D_Loss:1.3705737590789795, G_Loss:0.9121649265289307

iterator 4300, D_Loss:1.3531863689422607, G_Loss:0.8975627422332764

iterator 4400, D_Loss:1.3458209037780762, G_Loss:0.8752270340919495

iterator 4500, D_Loss:1.3147118091583252, G_Loss:0.9079205393791199

iterator 4600, D_Loss:1.368018627166748, G_Loss:0.8993676900863647

iterator 4700, D_Loss:1.3850607872009277, G_Loss:0.8888034820556641

iterator 4800, D_Loss:1.2977219820022583, G_Loss:0.9132102131843567

iterator 4900, D_Loss:1.339900016784668, G_Loss:0.9036865830421448

iterator 5000, D_Loss:1.3857202529907227, G_Loss:0.9106936454772949

-----------Epoch 4-----------
iterator 100, D_Loss:1.337171196937561, G_Loss:0.8954954743385315

iterator 200, D_Loss:1.3506624698638916, G_Loss:0.9133691191673279

iterator 300, D_Loss:1.3440077304840088, G_Loss:0.877288818359375

iterator 400, D_Loss:1.3363558053970337, G_Loss:0.9420616626739502

iterator 500, D_Loss:1.3166401386260986, G_Loss:0.912065863609314

iterator 600, D_Loss:1.2926790714263916, G_Loss:0.9226236939430237

iterator 700, D_Loss:1.3477346897125244, G_Loss:0.9400933980941772

iterator 800, D_Loss:1.2829004526138306, G_Loss:0.9775616526603699

iterator 900, D_Loss:1.2698248624801636, G_Loss:0.9545367360115051

iterator 1000, D_Loss:1.3076069355010986, G_Loss:0.9103918671607971

iterator 1100, D_Loss:1.3118045330047607, G_Loss:0.9134271144866943

iterator 1200, D_Loss:1.3294172286987305, G_Loss:0.9468036890029907

iterator 1300, D_Loss:1.33063542842865, G_Loss:0.9522604942321777

iterator 1400, D_Loss:1.3225593566894531, G_Loss:0.9204131364822388

iterator 1500, D_Loss:1.3119291067123413, G_Loss:0.9225389957427979

iterator 1600, D_Loss:1.326359510421753, G_Loss:0.9448201656341553

iterator 1700, D_Loss:1.3519783020019531, G_Loss:0.9527212381362915

iterator 1800, D_Loss:1.2827389240264893, G_Loss:0.93513023853302

iterator 1900, D_Loss:1.322319746017456, G_Loss:0.9242231249809265

iterator 2000, D_Loss:1.29483962059021, G_Loss:0.9515372514724731

iterator 2100, D_Loss:1.3756382465362549, G_Loss:0.9074285626411438

iterator 2200, D_Loss:1.317865252494812, G_Loss:0.8996080756187439

iterator 2300, D_Loss:1.3409394025802612, G_Loss:0.8917427659034729

iterator 2400, D_Loss:1.328418254852295, G_Loss:0.928467333316803

iterator 2500, D_Loss:1.280019998550415, G_Loss:0.9864900708198547

iterator 2600, D_Loss:1.3480043411254883, G_Loss:0.993564248085022

iterator 2700, D_Loss:1.303260087966919, G_Loss:0.9705025553703308

iterator 2800, D_Loss:1.2953202724456787, G_Loss:0.9173758625984192

iterator 2900, D_Loss:1.3457834720611572, G_Loss:0.9545987844467163

iterator 3000, D_Loss:1.408060073852539, G_Loss:0.895955502986908

iterator 3100, D_Loss:1.321842074394226, G_Loss:0.9704649448394775

iterator 3200, D_Loss:1.321061372756958, G_Loss:0.8955676555633545

iterator 3300, D_Loss:1.3513667583465576, G_Loss:0.861467719078064

iterator 3400, D_Loss:1.2999595403671265, G_Loss:1.0064336061477661

iterator 3500, D_Loss:1.2937911748886108, G_Loss:0.9285699725151062

iterator 3600, D_Loss:1.3069062232971191, G_Loss:0.9755747318267822

iterator 3700, D_Loss:1.2922720909118652, G_Loss:0.9490556120872498

iterator 3800, D_Loss:1.3179881572723389, G_Loss:0.9517906308174133

iterator 3900, D_Loss:1.3422260284423828, G_Loss:0.9017373919487

iterator 4000, D_Loss:1.3496766090393066, G_Loss:0.936553955078125

iterator 4100, D_Loss:1.313028335571289, G_Loss:0.9309669733047485

iterator 4200, D_Loss:1.3302006721496582, G_Loss:0.9176695346832275

iterator 4300, D_Loss:1.373187780380249, G_Loss:0.9299872517585754

iterator 4400, D_Loss:1.3294169902801514, G_Loss:0.9420337080955505

iterator 4500, D_Loss:1.2968205213546753, G_Loss:0.8999562859535217

iterator 4600, D_Loss:1.3602930307388306, G_Loss:0.9351106882095337

iterator 4700, D_Loss:1.3477544784545898, G_Loss:0.943848729133606

iterator 4800, D_Loss:1.3418352603912354, G_Loss:0.9148393273353577

iterator 4900, D_Loss:1.3032541275024414, G_Loss:0.9242206811904907

iterator 5000, D_Loss:1.3507695198059082, G_Loss:0.883286714553833

-----------Epoch 5-----------
iterator 100, D_Loss:1.3557628393173218, G_Loss:0.9028247594833374

iterator 200, D_Loss:1.3333039283752441, G_Loss:0.9039660096168518

iterator 300, D_Loss:1.3268996477127075, G_Loss:0.9175758957862854

iterator 400, D_Loss:1.3591229915618896, G_Loss:0.9598334431648254

iterator 500, D_Loss:1.3342692852020264, G_Loss:0.9162180423736572

iterator 600, D_Loss:1.3261873722076416, G_Loss:0.9289221167564392

iterator 700, D_Loss:1.3179680109024048, G_Loss:0.9287256598472595

iterator 800, D_Loss:1.2910361289978027, G_Loss:0.9343129992485046

iterator 900, D_Loss:1.299141526222229, G_Loss:1.0365221500396729

iterator 1000, D_Loss:1.3336235284805298, G_Loss:0.9288068413734436

iterator 1100, D_Loss:1.288775086402893, G_Loss:0.9185474514961243

iterator 1200, D_Loss:1.3611247539520264, G_Loss:0.8845901489257812

iterator 1300, D_Loss:1.3120248317718506, G_Loss:0.9265016913414001

iterator 1400, D_Loss:1.3053717613220215, G_Loss:0.9112962484359741

iterator 1500, D_Loss:1.3164558410644531, G_Loss:0.9160082340240479

iterator 1600, D_Loss:1.300166130065918, G_Loss:0.9381198883056641

iterator 1700, D_Loss:1.309417486190796, G_Loss:0.9188703894615173

iterator 1800, D_Loss:1.3360366821289062, G_Loss:0.8962290287017822

iterator 1900, D_Loss:1.3313398361206055, G_Loss:1.0122920274734497

iterator 2000, D_Loss:1.3427646160125732, G_Loss:0.9099963307380676

iterator 2100, D_Loss:1.333712100982666, G_Loss:0.9624449014663696

iterator 2200, D_Loss:1.3078391551971436, G_Loss:0.8932192921638489

iterator 2300, D_Loss:1.312546730041504, G_Loss:0.9069266319274902

iterator 2400, D_Loss:1.3583102226257324, G_Loss:0.8986149430274963

iterator 2500, D_Loss:1.3587130308151245, G_Loss:0.9207596778869629

iterator 2600, D_Loss:1.3483588695526123, G_Loss:0.8795650005340576

iterator 2700, D_Loss:1.3377413749694824, G_Loss:0.8880895972251892

iterator 2800, D_Loss:1.3197309970855713, G_Loss:0.9285508990287781

iterator 2900, D_Loss:1.347977638244629, G_Loss:0.9009071588516235

iterator 3000, D_Loss:1.3170247077941895, G_Loss:0.8903282284736633

iterator 3100, D_Loss:1.3179726600646973, G_Loss:0.928244948387146

iterator 3200, D_Loss:1.330751657485962, G_Loss:0.8871102929115295

iterator 3300, D_Loss:1.3208032846450806, G_Loss:0.9435034990310669

iterator 3400, D_Loss:1.3738136291503906, G_Loss:0.9946001172065735

iterator 3500, D_Loss:1.3272544145584106, G_Loss:0.9553061723709106

iterator 3600, D_Loss:1.3223285675048828, G_Loss:0.9325781464576721

iterator 3700, D_Loss:1.3473761081695557, G_Loss:0.8838779330253601

iterator 3800, D_Loss:1.3332300186157227, G_Loss:0.920249342918396

iterator 3900, D_Loss:1.3618403673171997, G_Loss:0.9147403836250305

iterator 4000, D_Loss:1.3334070444107056, G_Loss:0.956768274307251

iterator 4100, D_Loss:1.3358583450317383, G_Loss:0.9523541331291199

iterator 4200, D_Loss:1.3545598983764648, G_Loss:0.9510737657546997

iterator 4300, D_Loss:1.3297460079193115, G_Loss:0.9656254053115845

iterator 4400, D_Loss:1.2987595796585083, G_Loss:0.9237420558929443

iterator 4500, D_Loss:1.2912650108337402, G_Loss:0.9511675238609314

iterator 4600, D_Loss:1.2821389436721802, G_Loss:0.9876648187637329

iterator 4700, D_Loss:1.3092694282531738, G_Loss:0.9615268707275391

iterator 4800, D_Loss:1.2790782451629639, G_Loss:0.9427627325057983

iterator 4900, D_Loss:1.2487518787384033, G_Loss:1.0015867948532104

iterator 5000, D_Loss:1.2484115362167358, G_Loss:1.0164475440979004

-----------Epoch 6-----------
iterator 100, D_Loss:1.2118524312973022, G_Loss:1.0216608047485352

iterator 200, D_Loss:1.263623833656311, G_Loss:1.04386568069458

iterator 300, D_Loss:1.2490203380584717, G_Loss:1.0656687021255493

iterator 400, D_Loss:1.2702869176864624, G_Loss:1.0570094585418701

iterator 500, D_Loss:1.2951812744140625, G_Loss:0.9598331451416016

iterator 600, D_Loss:1.2289501428604126, G_Loss:0.9942396283149719

iterator 700, D_Loss:1.27870774269104, G_Loss:1.0614619255065918

iterator 800, D_Loss:1.1015074253082275, G_Loss:1.154760718345642

iterator 900, D_Loss:1.1564089059829712, G_Loss:1.0977931022644043

iterator 1000, D_Loss:1.1658694744110107, G_Loss:1.1836410760879517

iterator 1100, D_Loss:1.12648606300354, G_Loss:1.1452640295028687

iterator 1200, D_Loss:1.1693451404571533, G_Loss:1.1641656160354614

iterator 1300, D_Loss:1.127791404724121, G_Loss:1.22134268283844

iterator 1400, D_Loss:1.103994607925415, G_Loss:1.310840129852295

iterator 1500, D_Loss:1.0522608757019043, G_Loss:1.269354224205017

iterator 1600, D_Loss:1.4205069541931152, G_Loss:0.9048399925231934

iterator 1700, D_Loss:1.3632599115371704, G_Loss:0.9908053874969482

iterator 1800, D_Loss:1.2964591979980469, G_Loss:1.1728157997131348

iterator 1900, D_Loss:1.2248305082321167, G_Loss:1.115854263305664

iterator 2000, D_Loss:1.1979007720947266, G_Loss:1.1146081686019897

iterator 2100, D_Loss:1.1722118854522705, G_Loss:1.169304370880127

iterator 2200, D_Loss:1.1262965202331543, G_Loss:1.1771595478057861

iterator 2300, D_Loss:1.1382941007614136, G_Loss:1.2768620252609253

iterator 2400, D_Loss:1.2951316833496094, G_Loss:1.2649781703948975

iterator 2500, D_Loss:1.1791330575942993, G_Loss:1.0777003765106201

iterator 2600, D_Loss:1.015328049659729, G_Loss:1.3126510381698608

iterator 2700, D_Loss:1.0437463521957397, G_Loss:1.3230717182159424

iterator 2800, D_Loss:0.9748490452766418, G_Loss:1.3915793895721436

iterator 2900, D_Loss:1.4841086864471436, G_Loss:1.0440746545791626

iterator 3000, D_Loss:1.259582757949829, G_Loss:1.081421136856079

iterator 3100, D_Loss:1.304223656654358, G_Loss:1.115932822227478

iterator 3200, D_Loss:1.393378496170044, G_Loss:0.9588430523872375

iterator 3300, D_Loss:1.3875000476837158, G_Loss:1.0451617240905762

iterator 3400, D_Loss:1.4377901554107666, G_Loss:0.8957773447036743

iterator 3500, D_Loss:1.3521745204925537, G_Loss:0.9817314743995667

iterator 3600, D_Loss:1.3396408557891846, G_Loss:0.9600067734718323

iterator 3700, D_Loss:1.3771164417266846, G_Loss:1.011627197265625

iterator 3800, D_Loss:1.3477191925048828, G_Loss:1.037797212600708

iterator 3900, D_Loss:1.2335591316223145, G_Loss:1.0616307258605957

iterator 4000, D_Loss:1.3335305452346802, G_Loss:0.9539162516593933

iterator 4100, D_Loss:1.250579595565796, G_Loss:0.9900975823402405

iterator 4200, D_Loss:1.3103220462799072, G_Loss:1.005800724029541

iterator 4300, D_Loss:1.2749063968658447, G_Loss:0.988141655921936

iterator 4400, D_Loss:1.2619675397872925, G_Loss:0.9515190124511719

iterator 4500, D_Loss:1.2937190532684326, G_Loss:1.0234640836715698

iterator 4600, D_Loss:1.2716377973556519, G_Loss:0.9628977179527283

iterator 4700, D_Loss:1.2990224361419678, G_Loss:0.9559710621833801

iterator 4800, D_Loss:1.283341407775879, G_Loss:1.0393471717834473

iterator 4900, D_Loss:1.3204888105392456, G_Loss:0.9571387767791748

iterator 5000, D_Loss:1.3152192831039429, G_Loss:0.9600675106048584

-----------Epoch 7-----------
iterator 100, D_Loss:1.3132305145263672, G_Loss:0.9598868489265442

iterator 200, D_Loss:1.3202099800109863, G_Loss:0.9810436367988586

iterator 300, D_Loss:1.3105329275131226, G_Loss:0.9213603138923645

iterator 400, D_Loss:1.4996848106384277, G_Loss:0.9532353281974792

iterator 500, D_Loss:1.3004560470581055, G_Loss:0.9623454213142395

iterator 600, D_Loss:1.2982375621795654, G_Loss:0.9781992435455322

iterator 700, D_Loss:1.2428994178771973, G_Loss:0.9500179886817932

iterator 800, D_Loss:1.3407032489776611, G_Loss:1.000522494316101

iterator 900, D_Loss:1.249114990234375, G_Loss:1.0441365242004395

iterator 1000, D_Loss:1.3087210655212402, G_Loss:0.9996339678764343

iterator 1100, D_Loss:1.251220941543579, G_Loss:0.9346349835395813

iterator 1200, D_Loss:1.25542414188385, G_Loss:0.9865185618400574

iterator 1300, D_Loss:1.2495546340942383, G_Loss:0.952535092830658

iterator 1400, D_Loss:1.28921377658844, G_Loss:0.977918803691864

iterator 1500, D_Loss:1.3134685754776, G_Loss:1.093318223953247

iterator 1600, D_Loss:1.295442819595337, G_Loss:1.0337773561477661

iterator 1700, D_Loss:1.2611453533172607, G_Loss:0.9922733306884766

iterator 1800, D_Loss:1.171770453453064, G_Loss:0.983877420425415

iterator 1900, D_Loss:1.3457603454589844, G_Loss:1.0044069290161133

iterator 2000, D_Loss:1.2783747911453247, G_Loss:1.0451301336288452

iterator 2100, D_Loss:1.3562285900115967, G_Loss:0.9616628885269165

iterator 2200, D_Loss:1.2703417539596558, G_Loss:1.025563359260559

iterator 2300, D_Loss:1.2435392141342163, G_Loss:1.0126323699951172

iterator 2400, D_Loss:1.2556196451187134, G_Loss:0.9844801425933838

iterator 2500, D_Loss:1.3255589008331299, G_Loss:0.9992771744728088

iterator 2600, D_Loss:1.2622781991958618, G_Loss:0.9884608387947083

iterator 2700, D_Loss:1.2620654106140137, G_Loss:1.0367261171340942

iterator 2800, D_Loss:1.2679322957992554, G_Loss:1.013000726699829

iterator 2900, D_Loss:1.2160923480987549, G_Loss:1.0119786262512207

iterator 3000, D_Loss:1.2752702236175537, G_Loss:0.9741061925888062

iterator 3100, D_Loss:1.2203556299209595, G_Loss:1.0357102155685425

iterator 3200, D_Loss:1.2628517150878906, G_Loss:1.0242003202438354

iterator 3300, D_Loss:1.249969482421875, G_Loss:0.9870709180831909

iterator 3400, D_Loss:1.2629354000091553, G_Loss:0.9933006763458252

iterator 3500, D_Loss:1.245208740234375, G_Loss:0.9621822834014893

iterator 3600, D_Loss:1.2266101837158203, G_Loss:0.9642369747161865

iterator 3700, D_Loss:1.2879124879837036, G_Loss:1.0274094343185425

iterator 3800, D_Loss:1.2510960102081299, G_Loss:1.0011974573135376

iterator 3900, D_Loss:1.2585593461990356, G_Loss:1.0234863758087158

iterator 4000, D_Loss:1.2953882217407227, G_Loss:0.9524650573730469

iterator 4100, D_Loss:1.2841782569885254, G_Loss:0.9698576927185059

iterator 4200, D_Loss:1.3053401708602905, G_Loss:1.0411832332611084

iterator 4300, D_Loss:1.272505760192871, G_Loss:0.9894886016845703

iterator 4400, D_Loss:1.278611421585083, G_Loss:1.0103057622909546

iterator 4500, D_Loss:1.2036828994750977, G_Loss:0.9898537397384644

iterator 4600, D_Loss:1.2234790325164795, G_Loss:0.9546141028404236

iterator 4700, D_Loss:1.2165374755859375, G_Loss:1.029335379600525

iterator 4800, D_Loss:1.2336629629135132, G_Loss:1.0367236137390137

iterator 4900, D_Loss:1.2840896844863892, G_Loss:1.0541073083877563

iterator 5000, D_Loss:1.2557055950164795, G_Loss:0.9733733534812927

-----------Epoch 8-----------
iterator 100, D_Loss:1.3111655712127686, G_Loss:0.9791690111160278

iterator 200, D_Loss:1.2703849077224731, G_Loss:0.9933799505233765

iterator 300, D_Loss:1.1988016366958618, G_Loss:0.9982239603996277

iterator 400, D_Loss:1.3567255735397339, G_Loss:1.0209580659866333

iterator 500, D_Loss:1.2258200645446777, G_Loss:0.9781394004821777

iterator 600, D_Loss:1.204480528831482, G_Loss:1.0023716688156128

iterator 700, D_Loss:1.2323987483978271, G_Loss:1.0614185333251953

iterator 800, D_Loss:1.2884178161621094, G_Loss:0.8923496007919312

iterator 900, D_Loss:1.2345315217971802, G_Loss:1.0283384323120117

iterator 1000, D_Loss:1.2904696464538574, G_Loss:1.052126407623291

iterator 1100, D_Loss:1.2536348104476929, G_Loss:0.955172061920166

iterator 1200, D_Loss:1.2535200119018555, G_Loss:0.9729900360107422

iterator 1300, D_Loss:1.2782666683197021, G_Loss:0.9817959666252136

iterator 1400, D_Loss:1.1674860715866089, G_Loss:1.005650520324707

iterator 1500, D_Loss:1.3297102451324463, G_Loss:1.156898856163025

iterator 1600, D_Loss:1.2095857858657837, G_Loss:1.205857276916504

iterator 1700, D_Loss:1.2219864130020142, G_Loss:0.9859858751296997

iterator 1800, D_Loss:1.2283085584640503, G_Loss:1.0219537019729614

iterator 1900, D_Loss:1.3030803203582764, G_Loss:1.0707892179489136

iterator 2000, D_Loss:1.2646511793136597, G_Loss:1.0827465057373047

iterator 2100, D_Loss:1.286006212234497, G_Loss:1.0047262907028198

iterator 2200, D_Loss:1.2895126342773438, G_Loss:1.1130342483520508

iterator 2300, D_Loss:1.234947919845581, G_Loss:1.046667456626892

iterator 2400, D_Loss:1.2351089715957642, G_Loss:1.074175238609314

iterator 2500, D_Loss:1.3212716579437256, G_Loss:1.0054166316986084

iterator 2600, D_Loss:1.2571755647659302, G_Loss:1.0010361671447754

iterator 2700, D_Loss:1.324661135673523, G_Loss:1.0815117359161377

iterator 2800, D_Loss:1.2367873191833496, G_Loss:1.06331467628479

iterator 2900, D_Loss:1.1899017095565796, G_Loss:1.0173183679580688

iterator 3000, D_Loss:1.2855280637741089, G_Loss:0.9725820422172546

iterator 3100, D_Loss:1.3431758880615234, G_Loss:1.4380351305007935

iterator 3200, D_Loss:1.3041760921478271, G_Loss:0.9616426229476929

iterator 3300, D_Loss:1.313603401184082, G_Loss:1.201465129852295

iterator 3400, D_Loss:1.2798266410827637, G_Loss:1.0073715448379517

iterator 3500, D_Loss:1.2413005828857422, G_Loss:0.9857323169708252

iterator 3600, D_Loss:1.1836246252059937, G_Loss:1.1359646320343018

iterator 3700, D_Loss:1.285502314567566, G_Loss:0.9662886261940002

iterator 3800, D_Loss:1.2537288665771484, G_Loss:1.044039249420166

iterator 3900, D_Loss:1.2138652801513672, G_Loss:0.9862900376319885

iterator 4000, D_Loss:1.2717299461364746, G_Loss:0.9761319756507874

iterator 4100, D_Loss:1.2779581546783447, G_Loss:0.9640078544616699

iterator 4200, D_Loss:1.3175166845321655, G_Loss:1.1852632761001587

iterator 4300, D_Loss:1.1904408931732178, G_Loss:1.0042526721954346

iterator 4400, D_Loss:1.28110671043396, G_Loss:1.029143214225769

iterator 4500, D_Loss:1.169670820236206, G_Loss:0.9683687686920166

iterator 4600, D_Loss:1.2574613094329834, G_Loss:1.005479335784912

iterator 4700, D_Loss:1.2217836380004883, G_Loss:1.0805346965789795

iterator 4800, D_Loss:1.193817138671875, G_Loss:0.9986798167228699

iterator 4900, D_Loss:1.255115270614624, G_Loss:1.1801502704620361

iterator 5000, D_Loss:1.2896873950958252, G_Loss:1.1435495615005493

-----------Epoch 9-----------
iterator 100, D_Loss:1.2281988859176636, G_Loss:1.1422169208526611

iterator 200, D_Loss:1.2578834295272827, G_Loss:0.9771009087562561

iterator 300, D_Loss:1.2276111841201782, G_Loss:0.9567010998725891

iterator 400, D_Loss:1.3927967548370361, G_Loss:0.9768024682998657

iterator 500, D_Loss:1.1667594909667969, G_Loss:1.179018497467041

iterator 600, D_Loss:1.1979788541793823, G_Loss:1.0546330213546753

iterator 700, D_Loss:1.213404893875122, G_Loss:1.0667266845703125

iterator 800, D_Loss:1.333175778388977, G_Loss:1.0854251384735107

iterator 900, D_Loss:1.2584407329559326, G_Loss:0.9968346953392029

iterator 1000, D_Loss:1.2823784351348877, G_Loss:0.9633994102478027

iterator 1100, D_Loss:1.0746876001358032, G_Loss:1.0233207941055298

iterator 1200, D_Loss:1.2207921743392944, G_Loss:1.1583592891693115

iterator 1300, D_Loss:1.2252793312072754, G_Loss:1.064894199371338

iterator 1400, D_Loss:1.2523975372314453, G_Loss:0.9561221599578857

iterator 1500, D_Loss:1.322347640991211, G_Loss:0.9741013050079346

iterator 1600, D_Loss:1.2770652770996094, G_Loss:1.0782047510147095

iterator 1700, D_Loss:1.180114984512329, G_Loss:1.1408355236053467

iterator 1800, D_Loss:1.1987619400024414, G_Loss:0.9656723737716675

iterator 1900, D_Loss:1.3314170837402344, G_Loss:1.0508174896240234

iterator 2000, D_Loss:1.3735666275024414, G_Loss:0.9669071435928345

iterator 2100, D_Loss:1.3445119857788086, G_Loss:1.2523823976516724

iterator 2200, D_Loss:1.3242604732513428, G_Loss:1.0462390184402466

iterator 2300, D_Loss:1.1762408018112183, G_Loss:1.0397343635559082

iterator 2400, D_Loss:1.2041521072387695, G_Loss:1.0511420965194702

iterator 2500, D_Loss:1.2811322212219238, G_Loss:1.1185026168823242

iterator 2600, D_Loss:1.2057557106018066, G_Loss:0.9582492709159851

iterator 2700, D_Loss:1.2560198307037354, G_Loss:1.0259038209915161

iterator 2800, D_Loss:1.0996949672698975, G_Loss:1.2316460609436035

iterator 2900, D_Loss:1.1777918338775635, G_Loss:1.0453498363494873

iterator 3000, D_Loss:1.3259124755859375, G_Loss:0.9959082007408142

iterator 3100, D_Loss:1.3183032274246216, G_Loss:1.1134892702102661

iterator 3200, D_Loss:1.123760461807251, G_Loss:1.2776882648468018

iterator 3300, D_Loss:1.22306489944458, G_Loss:1.0586700439453125

iterator 3400, D_Loss:1.0871151685714722, G_Loss:1.535996675491333

iterator 3500, D_Loss:1.0865333080291748, G_Loss:1.027747392654419

iterator 3600, D_Loss:1.2246358394622803, G_Loss:0.9293459057807922

iterator 3700, D_Loss:1.3762454986572266, G_Loss:1.4986565113067627

iterator 3800, D_Loss:1.2724370956420898, G_Loss:1.1019141674041748

iterator 3900, D_Loss:1.1726549863815308, G_Loss:1.0684326887130737

iterator 4000, D_Loss:1.3399090766906738, G_Loss:1.2286334037780762

iterator 4100, D_Loss:1.1391853094100952, G_Loss:1.149924397468567

iterator 4200, D_Loss:1.2484171390533447, G_Loss:1.0284379720687866

iterator 4300, D_Loss:1.2751615047454834, G_Loss:1.2107248306274414

iterator 4400, D_Loss:1.282968521118164, G_Loss:1.0130237340927124

iterator 4500, D_Loss:1.1280759572982788, G_Loss:1.0485893487930298

iterator 4600, D_Loss:1.170364260673523, G_Loss:1.0746867656707764

iterator 4700, D_Loss:1.1953336000442505, G_Loss:1.0433071851730347

iterator 4800, D_Loss:1.1899983882904053, G_Loss:1.7615848779678345

iterator 4900, D_Loss:1.2170145511627197, G_Loss:1.0349445343017578

iterator 5000, D_Loss:1.3182175159454346, G_Loss:1.140721321105957

LGAN_generator(
  (LSTM): LSTMCell(350, 200)
  (fc00): Linear(in_features=300, out_features=1, bias=True)
  (fc01): Linear(in_features=1, out_features=300, bias=True)
  (fe0): Linear(in_features=200, out_features=300, bias=True)
  (fc10): Linear(in_features=300, out_features=1, bias=True)
  (fc11): Linear(in_features=1, out_features=300, bias=True)
  (fe1): Linear(in_features=200, out_features=300, bias=True)
  (fc20): Linear(in_features=300, out_features=1, bias=True)
  (fc21): Linear(in_features=1, out_features=300, bias=True)
  (fe2): Linear(in_features=200, out_features=300, bias=True)
  (fc30): Linear(in_features=300, out_features=1, bias=True)
  (fc31): Linear(in_features=1, out_features=300, bias=True)
  (fe3): Linear(in_features=200, out_features=300, bias=True)
  (fc40): Linear(in_features=300, out_features=1, bias=True)
  (fc41): Linear(in_features=1, out_features=300, bias=True)
  (fe4): Linear(in_features=200, out_features=300, bias=True)
  (fc50): Linear(in_features=300, out_features=1, bias=True)
  (fc51): Linear(in_features=1, out_features=300, bias=True)
  (fe5): Linear(in_features=200, out_features=300, bias=True)
  (fc60): Linear(in_features=300, out_features=1, bias=True)
  (fc61): Linear(in_features=1, out_features=300, bias=True)
  (fe6): Linear(in_features=200, out_features=300, bias=True)
  (fc70): Linear(in_features=300, out_features=1, bias=True)
  (fc71): Linear(in_features=1, out_features=300, bias=True)
  (fe7): Linear(in_features=200, out_features=300, bias=True)
  (fc80): Linear(in_features=300, out_features=1, bias=True)
  (fc81): Linear(in_features=1, out_features=300, bias=True)
  (fe8): Linear(in_features=200, out_features=300, bias=True)
  (fc90): Linear(in_features=300, out_features=1, bias=True)
  (fc91): Linear(in_features=1, out_features=300, bias=True)
  (fe9): Linear(in_features=200, out_features=300, bias=True)
  (fc100): Linear(in_features=300, out_features=1, bias=True)
  (fc101): Linear(in_features=1, out_features=300, bias=True)
  (fe10): Linear(in_features=200, out_features=300, bias=True)
  (fc110): Linear(in_features=300, out_features=1, bias=True)
  (fc111): Linear(in_features=1, out_features=300, bias=True)
  (fe11): Linear(in_features=200, out_features=300, bias=True)
  (fc120): Linear(in_features=300, out_features=1, bias=True)
  (fc121): Linear(in_features=1, out_features=300, bias=True)
  (fe12): Linear(in_features=200, out_features=300, bias=True)
  (fc130): Linear(in_features=300, out_features=1, bias=True)
  (fc131): Linear(in_features=1, out_features=300, bias=True)
  (fe13): Linear(in_features=200, out_features=300, bias=True)
  (fc140): Linear(in_features=300, out_features=1, bias=True)
  (fc141): Linear(in_features=1, out_features=300, bias=True)
  (fe14): Linear(in_features=200, out_features=300, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=15, out_features=200, bias=True)
  (inputbn): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=200, out_features=200, bias=True)
  (bn0): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=200, out_features=200, bias=True)
  (bn1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=200, out_features=200, bias=True)
  (bn2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=200, out_features=200, bias=True)
  (bn3): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=200, out_features=1, bias=True)
)
(0, False, 15)
-----------Epoch 0-----------
iterator 100, D_Loss:1.4125065803527832, G_Loss:0.8605183362960815

iterator 200, D_Loss:1.4038705825805664, G_Loss:0.8839970231056213

iterator 300, D_Loss:1.3695533275604248, G_Loss:0.8565579056739807

iterator 400, D_Loss:1.396059274673462, G_Loss:0.8050363659858704

iterator 500, D_Loss:1.3745739459991455, G_Loss:0.791837215423584

iterator 600, D_Loss:1.3627874851226807, G_Loss:0.8261107802391052

iterator 700, D_Loss:1.3240172863006592, G_Loss:0.7715522050857544

iterator 800, D_Loss:1.274354338645935, G_Loss:1.022099256515503

iterator 900, D_Loss:1.2640316486358643, G_Loss:1.0269619226455688

iterator 1000, D_Loss:1.030105710029602, G_Loss:1.3674274682998657

iterator 1100, D_Loss:0.943420946598053, G_Loss:1.5819635391235352

iterator 1200, D_Loss:0.8153865337371826, G_Loss:1.760973334312439

iterator 1300, D_Loss:0.7854641079902649, G_Loss:2.264145612716675

iterator 1400, D_Loss:0.6284189224243164, G_Loss:2.3605291843414307

iterator 1500, D_Loss:0.6702960729598999, G_Loss:2.2401344776153564

iterator 1600, D_Loss:0.7306772470474243, G_Loss:2.5257327556610107

iterator 1700, D_Loss:0.620232343673706, G_Loss:3.1831798553466797

iterator 1800, D_Loss:0.545499861240387, G_Loss:3.1183950901031494

iterator 1900, D_Loss:0.5331713557243347, G_Loss:3.726767063140869

iterator 2000, D_Loss:0.5102450251579285, G_Loss:2.965761423110962

iterator 2100, D_Loss:0.4815800189971924, G_Loss:3.4472479820251465

iterator 2200, D_Loss:0.5480577349662781, G_Loss:3.6207799911499023

iterator 2300, D_Loss:0.5412258505821228, G_Loss:4.258060932159424

iterator 2400, D_Loss:0.5143846273422241, G_Loss:3.6158013343811035

iterator 2500, D_Loss:0.48564407229423523, G_Loss:4.4834489822387695

iterator 2600, D_Loss:0.4581153690814972, G_Loss:4.958246231079102

iterator 2700, D_Loss:0.4864698648452759, G_Loss:5.084701061248779

iterator 2800, D_Loss:0.4987950623035431, G_Loss:3.874074697494507

iterator 2900, D_Loss:0.5568872690200806, G_Loss:4.4982404708862305

iterator 3000, D_Loss:0.48457297682762146, G_Loss:4.872315883636475

iterator 3100, D_Loss:0.4784873425960541, G_Loss:5.170628070831299

iterator 3200, D_Loss:0.4848874509334564, G_Loss:5.416845321655273

iterator 3300, D_Loss:0.46679171919822693, G_Loss:5.330056190490723

iterator 3400, D_Loss:0.45889776945114136, G_Loss:5.867213249206543

iterator 3500, D_Loss:0.4224749207496643, G_Loss:6.116334438323975

iterator 3600, D_Loss:0.4620063900947571, G_Loss:6.0708417892456055

iterator 3700, D_Loss:0.45599329471588135, G_Loss:6.2074809074401855

iterator 3800, D_Loss:0.4500848352909088, G_Loss:6.492434024810791

iterator 3900, D_Loss:0.438313752412796, G_Loss:6.4400410652160645

iterator 4000, D_Loss:0.4364646077156067, G_Loss:6.607970714569092

iterator 4100, D_Loss:0.4430049657821655, G_Loss:6.526940822601318

iterator 4200, D_Loss:0.4404433071613312, G_Loss:6.572388172149658

iterator 4300, D_Loss:0.41406264901161194, G_Loss:7.015316009521484

iterator 4400, D_Loss:0.4567101001739502, G_Loss:6.992605209350586

iterator 4500, D_Loss:0.4361788034439087, G_Loss:6.783929347991943

iterator 4600, D_Loss:0.45064064860343933, G_Loss:6.953131675720215

iterator 4700, D_Loss:0.436612069606781, G_Loss:6.98984432220459

iterator 4800, D_Loss:0.4417475759983063, G_Loss:7.078240871429443

iterator 4900, D_Loss:0.46512606739997864, G_Loss:6.149223804473877

iterator 5000, D_Loss:0.42784059047698975, G_Loss:6.546749114990234

-----------Epoch 1-----------
iterator 100, D_Loss:0.4572494328022003, G_Loss:6.379856109619141

iterator 200, D_Loss:0.44240978360176086, G_Loss:6.396367073059082

iterator 300, D_Loss:0.45308032631874084, G_Loss:7.009993076324463

iterator 400, D_Loss:0.4359532594680786, G_Loss:6.8406291007995605

iterator 500, D_Loss:0.43915775418281555, G_Loss:6.9282121658325195

iterator 600, D_Loss:0.43698814511299133, G_Loss:7.411843299865723

iterator 700, D_Loss:0.4400705397129059, G_Loss:7.570619106292725

iterator 800, D_Loss:0.4316883683204651, G_Loss:7.2913079261779785

iterator 900, D_Loss:0.5146807432174683, G_Loss:5.652942657470703

iterator 1000, D_Loss:0.4268783628940582, G_Loss:7.993957996368408

iterator 1100, D_Loss:0.4377346634864807, G_Loss:7.463165283203125

iterator 1200, D_Loss:0.4612431824207306, G_Loss:8.034576416015625

iterator 1300, D_Loss:0.4342389404773712, G_Loss:6.212301254272461

iterator 1400, D_Loss:0.437157541513443, G_Loss:7.2499799728393555

iterator 1500, D_Loss:0.4359913766384125, G_Loss:7.9356842041015625

iterator 1600, D_Loss:0.4137553870677948, G_Loss:8.257698059082031

iterator 1700, D_Loss:0.5030706524848938, G_Loss:6.9653639793396

iterator 1800, D_Loss:0.4416169226169586, G_Loss:7.558679580688477

iterator 1900, D_Loss:0.4397564232349396, G_Loss:8.567584991455078

iterator 2000, D_Loss:0.42340222001075745, G_Loss:7.9368815422058105

iterator 2100, D_Loss:0.5083222389221191, G_Loss:7.660365104675293

iterator 2200, D_Loss:0.4287293255329132, G_Loss:7.417787075042725

iterator 2300, D_Loss:0.4330950975418091, G_Loss:9.98074722290039

iterator 2400, D_Loss:0.4218391180038452, G_Loss:8.76467514038086

iterator 2500, D_Loss:0.4353085458278656, G_Loss:8.154465675354004

iterator 2600, D_Loss:0.42651548981666565, G_Loss:8.571324348449707

iterator 2700, D_Loss:0.4285884499549866, G_Loss:8.496478080749512

iterator 2800, D_Loss:0.43752267956733704, G_Loss:8.982109069824219

iterator 2900, D_Loss:0.4329620897769928, G_Loss:8.534046173095703

iterator 3000, D_Loss:0.43693310022354126, G_Loss:9.407970428466797

iterator 3100, D_Loss:0.4189702272415161, G_Loss:9.299988746643066

iterator 3200, D_Loss:0.4345138967037201, G_Loss:8.370451927185059

iterator 3300, D_Loss:0.42477941513061523, G_Loss:8.27899169921875

iterator 3400, D_Loss:0.4316389858722687, G_Loss:8.744817733764648

iterator 3500, D_Loss:0.4169456660747528, G_Loss:9.550139427185059

iterator 3600, D_Loss:0.4169093668460846, G_Loss:8.232039451599121

iterator 3700, D_Loss:0.4116261899471283, G_Loss:8.938172340393066

iterator 3800, D_Loss:0.4422125816345215, G_Loss:9.642669677734375

iterator 3900, D_Loss:0.42057004570961, G_Loss:8.812817573547363

iterator 4000, D_Loss:0.4329714775085449, G_Loss:9.249815940856934

iterator 4100, D_Loss:0.4251868426799774, G_Loss:9.558130264282227

iterator 4200, D_Loss:0.4217481315135956, G_Loss:9.771095275878906

iterator 4300, D_Loss:0.42597129940986633, G_Loss:10.346735000610352

iterator 4400, D_Loss:0.422507643699646, G_Loss:10.187445640563965

iterator 4500, D_Loss:0.43669724464416504, G_Loss:9.969952583312988

iterator 4600, D_Loss:0.4190741777420044, G_Loss:8.698772430419922

iterator 4700, D_Loss:0.42714396119117737, G_Loss:9.846822738647461

iterator 4800, D_Loss:0.43459373712539673, G_Loss:9.75674819946289

iterator 4900, D_Loss:0.42969560623168945, G_Loss:10.013848304748535

iterator 5000, D_Loss:0.4264046251773834, G_Loss:10.089469909667969

-----------Epoch 2-----------
iterator 100, D_Loss:0.4378397464752197, G_Loss:10.198158264160156

iterator 200, D_Loss:0.4206516146659851, G_Loss:9.747345924377441

iterator 300, D_Loss:0.41762199997901917, G_Loss:9.196067810058594

iterator 400, D_Loss:0.43269380927085876, G_Loss:10.048558235168457

iterator 500, D_Loss:0.4194537103176117, G_Loss:10.64440631866455

iterator 600, D_Loss:0.4269890785217285, G_Loss:9.79399585723877

iterator 700, D_Loss:0.4210074841976166, G_Loss:10.5176420211792

iterator 800, D_Loss:0.43349605798721313, G_Loss:10.496899604797363

iterator 900, D_Loss:0.4412578344345093, G_Loss:10.848609924316406

iterator 1000, D_Loss:0.40629974007606506, G_Loss:10.58498764038086

iterator 1100, D_Loss:0.4401821494102478, G_Loss:10.1524076461792

iterator 1200, D_Loss:0.4314788281917572, G_Loss:10.434528350830078

iterator 1300, D_Loss:0.4279315769672394, G_Loss:10.233854293823242

iterator 1400, D_Loss:0.43527722358703613, G_Loss:11.208352088928223

iterator 1500, D_Loss:0.4311315715312958, G_Loss:10.280784606933594

iterator 1600, D_Loss:0.4278585910797119, G_Loss:10.897435188293457

iterator 1700, D_Loss:0.4480743408203125, G_Loss:10.64806842803955

iterator 1800, D_Loss:0.41830745339393616, G_Loss:11.584517478942871

iterator 1900, D_Loss:0.43018990755081177, G_Loss:10.855423927307129

iterator 2000, D_Loss:0.42910847067832947, G_Loss:11.440618515014648

iterator 2100, D_Loss:0.4329037070274353, G_Loss:11.251330375671387

iterator 2200, D_Loss:0.4289736747741699, G_Loss:11.126190185546875

iterator 2300, D_Loss:0.41936054825782776, G_Loss:11.305682182312012

iterator 2400, D_Loss:0.4173963963985443, G_Loss:11.960540771484375

iterator 2500, D_Loss:0.4294421672821045, G_Loss:11.313872337341309

iterator 2600, D_Loss:0.4431995153427124, G_Loss:12.101268768310547

iterator 2700, D_Loss:0.4188397526741028, G_Loss:10.875615119934082

iterator 2800, D_Loss:0.4369947612285614, G_Loss:12.496647834777832

iterator 2900, D_Loss:0.4349372386932373, G_Loss:11.645303726196289

iterator 3000, D_Loss:0.43027275800704956, G_Loss:11.583745956420898

iterator 3100, D_Loss:0.4205990433692932, G_Loss:11.00402545928955

iterator 3200, D_Loss:0.4204806387424469, G_Loss:11.415531158447266

iterator 3300, D_Loss:0.42428746819496155, G_Loss:11.434228897094727

iterator 3400, D_Loss:0.4163380265235901, G_Loss:10.209418296813965

iterator 3500, D_Loss:0.41598501801490784, G_Loss:11.913985252380371

iterator 3600, D_Loss:0.4301253855228424, G_Loss:12.274397850036621

iterator 3700, D_Loss:0.4260110557079315, G_Loss:11.388725280761719

iterator 3800, D_Loss:0.42789992690086365, G_Loss:11.49209213256836

iterator 3900, D_Loss:0.43416404724121094, G_Loss:12.050856590270996

iterator 4000, D_Loss:0.4494858980178833, G_Loss:11.715784072875977

iterator 4100, D_Loss:0.40435323119163513, G_Loss:11.919719696044922

iterator 4200, D_Loss:0.41939330101013184, G_Loss:11.765708923339844

iterator 4300, D_Loss:0.4104720950126648, G_Loss:10.251496315002441

iterator 4400, D_Loss:0.4191477596759796, G_Loss:10.905426979064941

iterator 4500, D_Loss:0.43025830388069153, G_Loss:11.374933242797852

iterator 4600, D_Loss:0.43356290459632874, G_Loss:12.773240089416504

iterator 4700, D_Loss:0.44218185544013977, G_Loss:12.396086692810059

iterator 4800, D_Loss:0.4118422269821167, G_Loss:12.188899040222168

iterator 4900, D_Loss:0.4251847267150879, G_Loss:11.998063087463379

iterator 5000, D_Loss:0.444144606590271, G_Loss:12.939374923706055

-----------Epoch 3-----------
iterator 100, D_Loss:0.4333994388580322, G_Loss:12.490717887878418

iterator 200, D_Loss:0.42204758524894714, G_Loss:12.21593952178955

iterator 300, D_Loss:0.4265761077404022, G_Loss:11.648908615112305

iterator 400, D_Loss:0.4162956476211548, G_Loss:11.213308334350586

iterator 500, D_Loss:0.4205523729324341, G_Loss:14.043316841125488

iterator 600, D_Loss:0.4175493121147156, G_Loss:9.65407943725586

iterator 700, D_Loss:0.44531047344207764, G_Loss:9.69286823272705

iterator 800, D_Loss:0.43612632155418396, G_Loss:11.74970817565918

iterator 900, D_Loss:0.4254482090473175, G_Loss:10.050359725952148

iterator 1000, D_Loss:0.42586207389831543, G_Loss:10.374180793762207

iterator 1100, D_Loss:0.4224098324775696, G_Loss:11.091988563537598

iterator 1200, D_Loss:0.4286268949508667, G_Loss:11.774518966674805

iterator 1300, D_Loss:0.4212439954280853, G_Loss:11.859441757202148

iterator 1400, D_Loss:0.4202871024608612, G_Loss:12.71142292022705

iterator 1500, D_Loss:0.42984241247177124, G_Loss:13.421138763427734

iterator 1600, D_Loss:0.43551433086395264, G_Loss:12.570782661437988

iterator 1700, D_Loss:0.4317536950111389, G_Loss:12.12818717956543

iterator 1800, D_Loss:0.42420440912246704, G_Loss:12.159833908081055

iterator 1900, D_Loss:0.430597186088562, G_Loss:11.714141845703125

iterator 2000, D_Loss:0.4187702238559723, G_Loss:13.118487358093262

iterator 2100, D_Loss:0.4299474060535431, G_Loss:12.734650611877441

iterator 2200, D_Loss:0.43133285641670227, G_Loss:12.165111541748047

iterator 2300, D_Loss:0.4131638705730438, G_Loss:13.180390357971191

iterator 2400, D_Loss:0.41336727142333984, G_Loss:13.119964599609375

iterator 2500, D_Loss:0.43441757559776306, G_Loss:12.149620056152344

iterator 2600, D_Loss:0.42784687876701355, G_Loss:12.753443717956543

iterator 2700, D_Loss:0.41722986102104187, G_Loss:11.47177505493164

iterator 2800, D_Loss:0.42586395144462585, G_Loss:13.1411714553833

iterator 2900, D_Loss:0.43162772059440613, G_Loss:12.562779426574707

iterator 3000, D_Loss:0.4050065577030182, G_Loss:12.628622055053711

iterator 3100, D_Loss:0.413258820772171, G_Loss:12.800162315368652

iterator 3200, D_Loss:0.4423505961894989, G_Loss:12.485496520996094

iterator 3300, D_Loss:0.4060545265674591, G_Loss:12.778225898742676

iterator 3400, D_Loss:0.4112441837787628, G_Loss:12.802014350891113

iterator 3500, D_Loss:0.4288737177848816, G_Loss:13.694746971130371

iterator 3600, D_Loss:0.4436274468898773, G_Loss:12.9814453125

iterator 3700, D_Loss:0.4175620675086975, G_Loss:11.863414764404297

iterator 3800, D_Loss:0.41856712102890015, G_Loss:13.691437721252441

iterator 3900, D_Loss:0.41553235054016113, G_Loss:12.03198528289795

iterator 4000, D_Loss:0.42708632349967957, G_Loss:12.794137954711914

iterator 4100, D_Loss:0.41244128346443176, G_Loss:13.37454605102539

iterator 4200, D_Loss:0.42907285690307617, G_Loss:11.660175323486328

iterator 4300, D_Loss:0.43356794118881226, G_Loss:11.459312438964844

iterator 4400, D_Loss:0.4317569136619568, G_Loss:10.519658088684082

iterator 4500, D_Loss:0.4180200695991516, G_Loss:10.830513954162598

iterator 4600, D_Loss:0.423017680644989, G_Loss:13.686659812927246

iterator 4700, D_Loss:0.42487630248069763, G_Loss:13.721173286437988

iterator 4800, D_Loss:0.4347396492958069, G_Loss:11.306845664978027

iterator 4900, D_Loss:0.4285529553890228, G_Loss:12.526192665100098

iterator 5000, D_Loss:0.42066314816474915, G_Loss:12.169594764709473

-----------Epoch 4-----------
iterator 100, D_Loss:0.419134259223938, G_Loss:12.573790550231934

iterator 200, D_Loss:0.40760311484336853, G_Loss:11.528324127197266

iterator 300, D_Loss:0.4166373014450073, G_Loss:11.87503433227539

iterator 400, D_Loss:0.4270266592502594, G_Loss:13.072330474853516

iterator 500, D_Loss:0.41588401794433594, G_Loss:11.750554084777832

iterator 600, D_Loss:0.4189961552619934, G_Loss:12.071712493896484

iterator 700, D_Loss:0.4113990068435669, G_Loss:11.299530982971191

iterator 800, D_Loss:0.4330490231513977, G_Loss:12.193192481994629

iterator 900, D_Loss:0.4125196933746338, G_Loss:12.881562232971191

iterator 1000, D_Loss:0.4258202910423279, G_Loss:13.23373794555664

iterator 1100, D_Loss:0.4270387291908264, G_Loss:12.239729881286621

iterator 1200, D_Loss:0.43340301513671875, G_Loss:11.469322204589844

iterator 1300, D_Loss:0.4259287714958191, G_Loss:13.06397819519043

iterator 1400, D_Loss:0.4280034005641937, G_Loss:12.469457626342773

iterator 1500, D_Loss:0.41579529643058777, G_Loss:13.388392448425293

iterator 1600, D_Loss:0.4155062139034271, G_Loss:12.625053405761719

iterator 1700, D_Loss:0.442360520362854, G_Loss:12.261037826538086

iterator 1800, D_Loss:0.39795321226119995, G_Loss:13.8159818649292

iterator 1900, D_Loss:0.4184698760509491, G_Loss:12.800920486450195

iterator 2000, D_Loss:0.4170297384262085, G_Loss:13.280096054077148

iterator 2100, D_Loss:0.4311569035053253, G_Loss:12.781111717224121

iterator 2200, D_Loss:0.4236009418964386, G_Loss:13.735308647155762

iterator 2300, D_Loss:0.4044824242591858, G_Loss:13.573772430419922

iterator 2400, D_Loss:0.4245340824127197, G_Loss:13.180071830749512

iterator 2500, D_Loss:0.4559210240840912, G_Loss:12.688721656799316

iterator 2600, D_Loss:0.4242628812789917, G_Loss:12.872718811035156

iterator 2700, D_Loss:0.43898481130599976, G_Loss:12.907073020935059

iterator 2800, D_Loss:0.43864697217941284, G_Loss:11.950640678405762

iterator 2900, D_Loss:0.4249517619609833, G_Loss:12.847838401794434

iterator 3000, D_Loss:0.4436848759651184, G_Loss:12.269600868225098

iterator 3100, D_Loss:0.41157636046409607, G_Loss:12.813157081604004

iterator 3200, D_Loss:0.4200053811073303, G_Loss:13.019830703735352

iterator 3300, D_Loss:0.4236130118370056, G_Loss:12.933012962341309

iterator 3400, D_Loss:0.4133698344230652, G_Loss:12.475041389465332

iterator 3500, D_Loss:0.44743087887763977, G_Loss:12.492936134338379

iterator 3600, D_Loss:0.4126357436180115, G_Loss:12.2294340133667

iterator 3700, D_Loss:0.42432841658592224, G_Loss:12.853612899780273

iterator 3800, D_Loss:0.4130077064037323, G_Loss:13.484723091125488

iterator 3900, D_Loss:0.4126228988170624, G_Loss:13.226702690124512

iterator 4000, D_Loss:0.4278450012207031, G_Loss:11.478148460388184

iterator 4100, D_Loss:0.40700021386146545, G_Loss:12.770257949829102

iterator 4200, D_Loss:0.41985851526260376, G_Loss:13.186461448669434

iterator 4300, D_Loss:0.41987645626068115, G_Loss:13.086434364318848

iterator 4400, D_Loss:0.4263664186000824, G_Loss:13.133825302124023

iterator 4500, D_Loss:0.42530471086502075, G_Loss:12.37424087524414

iterator 4600, D_Loss:0.4222784638404846, G_Loss:12.845483779907227

iterator 4700, D_Loss:0.43064817786216736, G_Loss:12.25112533569336

iterator 4800, D_Loss:0.4107760190963745, G_Loss:11.745633125305176

iterator 4900, D_Loss:0.42124509811401367, G_Loss:12.086956024169922

iterator 5000, D_Loss:0.4659835398197174, G_Loss:11.75136947631836

-----------Epoch 5-----------
iterator 100, D_Loss:0.4254668951034546, G_Loss:12.25600814819336

iterator 200, D_Loss:0.4210279881954193, G_Loss:12.369603157043457

iterator 300, D_Loss:0.4163804054260254, G_Loss:13.177279472351074

iterator 400, D_Loss:0.41716039180755615, G_Loss:11.868316650390625

iterator 500, D_Loss:0.4167723059654236, G_Loss:12.944293975830078

iterator 600, D_Loss:0.4305550754070282, G_Loss:12.991433143615723

iterator 700, D_Loss:0.4326592683792114, G_Loss:11.470647811889648

iterator 800, D_Loss:0.43590062856674194, G_Loss:12.11981201171875

iterator 900, D_Loss:0.4361008405685425, G_Loss:12.312816619873047

iterator 1000, D_Loss:0.4423721134662628, G_Loss:11.365715026855469

iterator 1100, D_Loss:0.4309696555137634, G_Loss:12.228607177734375

iterator 1200, D_Loss:0.40931540727615356, G_Loss:12.651917457580566

iterator 1300, D_Loss:0.4421299397945404, G_Loss:12.78160285949707

iterator 1400, D_Loss:0.4054618775844574, G_Loss:12.768054962158203

iterator 1500, D_Loss:0.4226320683956146, G_Loss:12.621857643127441

iterator 1600, D_Loss:0.42688992619514465, G_Loss:11.917144775390625

iterator 1700, D_Loss:0.43076589703559875, G_Loss:12.70071029663086

iterator 1800, D_Loss:0.4266737103462219, G_Loss:13.210491180419922

iterator 1900, D_Loss:0.42065295577049255, G_Loss:12.079324722290039

iterator 2000, D_Loss:0.41917356848716736, G_Loss:13.058237075805664

iterator 2100, D_Loss:0.4224275052547455, G_Loss:12.093701362609863

iterator 2200, D_Loss:0.4316222369670868, G_Loss:12.73658561706543

iterator 2300, D_Loss:0.4433392882347107, G_Loss:11.837952613830566

iterator 2400, D_Loss:0.4259386658668518, G_Loss:12.318909645080566

iterator 2500, D_Loss:0.4316236972808838, G_Loss:12.374987602233887

iterator 2600, D_Loss:0.43683624267578125, G_Loss:12.450273513793945

iterator 2700, D_Loss:0.4243457019329071, G_Loss:12.443869590759277

iterator 2800, D_Loss:0.4272269606590271, G_Loss:12.761859893798828

iterator 2900, D_Loss:0.4289807677268982, G_Loss:12.059453964233398

iterator 3000, D_Loss:0.4344826340675354, G_Loss:12.561650276184082

iterator 3100, D_Loss:0.40113282203674316, G_Loss:12.451648712158203

iterator 3200, D_Loss:0.4382700026035309, G_Loss:12.516919136047363

iterator 3300, D_Loss:0.43023020029067993, G_Loss:12.464071273803711

iterator 3400, D_Loss:0.4238166809082031, G_Loss:12.454124450683594

iterator 3500, D_Loss:0.41751205921173096, G_Loss:11.892189025878906

iterator 3600, D_Loss:0.42001160979270935, G_Loss:11.61874771118164

iterator 3700, D_Loss:0.4431309103965759, G_Loss:12.215373992919922

iterator 3800, D_Loss:0.43621009588241577, G_Loss:12.905731201171875

iterator 3900, D_Loss:0.4088868200778961, G_Loss:12.093711853027344

iterator 4000, D_Loss:0.4248872995376587, G_Loss:11.625926971435547

iterator 4100, D_Loss:0.42604708671569824, G_Loss:12.110444068908691

iterator 4200, D_Loss:0.4369460344314575, G_Loss:12.591765403747559

iterator 4300, D_Loss:0.42703336477279663, G_Loss:12.64613151550293

iterator 4400, D_Loss:0.4359031915664673, G_Loss:12.085441589355469

iterator 4500, D_Loss:0.3996395766735077, G_Loss:11.512412071228027

iterator 4600, D_Loss:0.41765719652175903, G_Loss:11.788993835449219

iterator 4700, D_Loss:0.42131391167640686, G_Loss:12.076380729675293

iterator 4800, D_Loss:0.4293881356716156, G_Loss:12.513625144958496

iterator 4900, D_Loss:0.41318172216415405, G_Loss:12.509259223937988

iterator 5000, D_Loss:0.42457717657089233, G_Loss:12.424212455749512

-----------Epoch 6-----------
iterator 100, D_Loss:0.4207541346549988, G_Loss:11.950382232666016

iterator 200, D_Loss:0.42100512981414795, G_Loss:12.647237777709961

iterator 300, D_Loss:0.44176748394966125, G_Loss:12.337933540344238

iterator 400, D_Loss:0.4360799491405487, G_Loss:11.729267120361328

iterator 500, D_Loss:0.42015114426612854, G_Loss:12.566893577575684

iterator 600, D_Loss:0.41054508090019226, G_Loss:12.436994552612305

iterator 700, D_Loss:0.4192218482494354, G_Loss:12.475555419921875

iterator 800, D_Loss:0.449143648147583, G_Loss:12.25556755065918

iterator 900, D_Loss:0.43355241417884827, G_Loss:12.227834701538086

iterator 1000, D_Loss:0.44005438685417175, G_Loss:12.558971405029297

iterator 1100, D_Loss:0.4399147927761078, G_Loss:12.064960479736328

iterator 1200, D_Loss:0.43410536646842957, G_Loss:12.672565460205078

iterator 1300, D_Loss:0.43145421147346497, G_Loss:11.354209899902344

iterator 1400, D_Loss:0.4256685972213745, G_Loss:10.228476524353027

iterator 1500, D_Loss:0.42048180103302, G_Loss:11.506596565246582

iterator 1600, D_Loss:0.41929522156715393, G_Loss:12.098586082458496

iterator 1700, D_Loss:0.41828376054763794, G_Loss:12.835670471191406

iterator 1800, D_Loss:0.4278263747692108, G_Loss:12.674251556396484

iterator 1900, D_Loss:0.4421802759170532, G_Loss:11.948495864868164

iterator 2000, D_Loss:0.411857932806015, G_Loss:12.358814239501953

iterator 2100, D_Loss:0.43412691354751587, G_Loss:12.606108665466309

iterator 2200, D_Loss:0.41774243116378784, G_Loss:11.436718940734863

iterator 2300, D_Loss:0.42392510175704956, G_Loss:12.497203826904297

iterator 2400, D_Loss:0.4198290705680847, G_Loss:12.365901947021484

iterator 2500, D_Loss:0.4257715046405792, G_Loss:12.028790473937988

iterator 2600, D_Loss:0.40646862983703613, G_Loss:12.07686996459961

iterator 2700, D_Loss:0.40774503350257874, G_Loss:11.502486228942871

iterator 2800, D_Loss:0.4146525263786316, G_Loss:12.090670585632324

iterator 2900, D_Loss:0.42996054887771606, G_Loss:12.523584365844727

iterator 3000, D_Loss:0.4320060610771179, G_Loss:12.406001091003418

iterator 3100, D_Loss:0.4085477590560913, G_Loss:11.95722770690918

iterator 3200, D_Loss:0.4249533712863922, G_Loss:13.000036239624023

iterator 3300, D_Loss:0.4272058606147766, G_Loss:11.730134010314941

iterator 3400, D_Loss:0.41579851508140564, G_Loss:12.259759902954102

iterator 3500, D_Loss:0.420003205537796, G_Loss:11.402170181274414

iterator 3600, D_Loss:0.4161582291126251, G_Loss:12.605935096740723

iterator 3700, D_Loss:0.4262959361076355, G_Loss:12.364755630493164

iterator 3800, D_Loss:0.4229779839515686, G_Loss:12.492349624633789

iterator 3900, D_Loss:0.42009684443473816, G_Loss:11.918087005615234

iterator 4000, D_Loss:0.4010240137577057, G_Loss:12.166386604309082

iterator 4100, D_Loss:0.41380590200424194, G_Loss:12.559165954589844

iterator 4200, D_Loss:0.42934685945510864, G_Loss:12.641868591308594

iterator 4300, D_Loss:0.42810121178627014, G_Loss:12.869742393493652

iterator 4400, D_Loss:0.4184885621070862, G_Loss:12.607540130615234

iterator 4500, D_Loss:0.4364360272884369, G_Loss:12.6444673538208

iterator 4600, D_Loss:0.4306463599205017, G_Loss:12.099628448486328

iterator 4700, D_Loss:0.4303567111492157, G_Loss:12.252689361572266

iterator 4800, D_Loss:0.43174102902412415, G_Loss:11.682843208312988

iterator 4900, D_Loss:0.43832796812057495, G_Loss:11.386972427368164

iterator 5000, D_Loss:0.42344027757644653, G_Loss:11.716497421264648

-----------Epoch 7-----------
iterator 100, D_Loss:0.43530839681625366, G_Loss:12.456877708435059

iterator 200, D_Loss:0.43372204899787903, G_Loss:12.324450492858887

iterator 300, D_Loss:0.4243113696575165, G_Loss:12.376441955566406

iterator 400, D_Loss:0.41987091302871704, G_Loss:12.202404022216797

iterator 500, D_Loss:0.4142417013645172, G_Loss:12.396202087402344

iterator 600, D_Loss:0.4255065321922302, G_Loss:12.31784439086914

iterator 700, D_Loss:0.42773956060409546, G_Loss:11.975711822509766

iterator 800, D_Loss:0.4372011721134186, G_Loss:12.459892272949219

iterator 900, D_Loss:0.4341917932033539, G_Loss:12.227977752685547

iterator 1000, D_Loss:0.40616628527641296, G_Loss:12.054725646972656

iterator 1100, D_Loss:0.4303956627845764, G_Loss:11.657422065734863

iterator 1200, D_Loss:0.4081837236881256, G_Loss:11.766217231750488

iterator 1300, D_Loss:0.4305505156517029, G_Loss:12.256841659545898

iterator 1400, D_Loss:0.41687071323394775, G_Loss:12.443565368652344

iterator 1500, D_Loss:0.4197666347026825, G_Loss:12.537686347961426

iterator 1600, D_Loss:0.42105022072792053, G_Loss:12.445817947387695

iterator 1700, D_Loss:0.4288446605205536, G_Loss:11.837715148925781

iterator 1800, D_Loss:0.433027446269989, G_Loss:11.857434272766113

iterator 1900, D_Loss:0.41330891847610474, G_Loss:12.255184173583984

iterator 2000, D_Loss:0.42493778467178345, G_Loss:11.525195121765137

iterator 2100, D_Loss:0.429169237613678, G_Loss:12.200425148010254

iterator 2200, D_Loss:0.4421619474887848, G_Loss:8.25329303741455

iterator 2300, D_Loss:0.43021535873413086, G_Loss:11.252062797546387

iterator 2400, D_Loss:0.41679710149765015, G_Loss:10.93682861328125

iterator 2500, D_Loss:0.44915512204170227, G_Loss:11.184226989746094

iterator 2600, D_Loss:0.41904178261756897, G_Loss:10.889504432678223

iterator 2700, D_Loss:0.4224686920642853, G_Loss:11.056005477905273

iterator 2800, D_Loss:0.4340352714061737, G_Loss:11.192146301269531

iterator 2900, D_Loss:0.42332932353019714, G_Loss:11.436120986938477

iterator 3000, D_Loss:0.41277799010276794, G_Loss:11.4566011428833

iterator 3100, D_Loss:0.44974595308303833, G_Loss:12.008877754211426

iterator 3200, D_Loss:0.4328366219997406, G_Loss:11.673925399780273

iterator 3300, D_Loss:0.4287806749343872, G_Loss:11.170633316040039

iterator 3400, D_Loss:0.4247024357318878, G_Loss:11.536890029907227

iterator 3500, D_Loss:0.43311893939971924, G_Loss:11.01585578918457

iterator 3600, D_Loss:0.42946764826774597, G_Loss:11.973589897155762

iterator 3700, D_Loss:0.41784635186195374, G_Loss:11.175498962402344

iterator 3800, D_Loss:0.41676390171051025, G_Loss:11.918831825256348

iterator 3900, D_Loss:0.4327998459339142, G_Loss:12.141246795654297

iterator 4000, D_Loss:0.4147292673587799, G_Loss:12.081287384033203

iterator 4100, D_Loss:0.42214831709861755, G_Loss:11.510712623596191

iterator 4200, D_Loss:0.42123594880104065, G_Loss:12.225257873535156

iterator 4300, D_Loss:0.4257814288139343, G_Loss:11.9337158203125

iterator 4400, D_Loss:0.4363178610801697, G_Loss:11.9812593460083

iterator 4500, D_Loss:0.4199734330177307, G_Loss:12.232192039489746

iterator 4600, D_Loss:0.42081883549690247, G_Loss:12.334961891174316

iterator 4700, D_Loss:0.4468517601490021, G_Loss:11.78255844116211

iterator 4800, D_Loss:0.4285266399383545, G_Loss:12.224508285522461

iterator 4900, D_Loss:0.42689424753189087, G_Loss:12.203052520751953

iterator 5000, D_Loss:0.4306642413139343, G_Loss:11.750967979431152

-----------Epoch 8-----------
iterator 100, D_Loss:0.4031948149204254, G_Loss:12.775334358215332

iterator 200, D_Loss:0.4007420241832733, G_Loss:12.032745361328125

iterator 300, D_Loss:0.4348641037940979, G_Loss:12.226279258728027

iterator 400, D_Loss:0.4239681363105774, G_Loss:12.395465850830078

iterator 500, D_Loss:0.4158915877342224, G_Loss:11.698022842407227

iterator 600, D_Loss:0.4195181131362915, G_Loss:12.123427391052246

iterator 700, D_Loss:0.4319556653499603, G_Loss:11.500566482543945

iterator 800, D_Loss:0.4220682680606842, G_Loss:12.1362886428833

iterator 900, D_Loss:0.42805567383766174, G_Loss:12.224417686462402

iterator 1000, D_Loss:0.40784022212028503, G_Loss:12.278764724731445

iterator 1100, D_Loss:0.41923820972442627, G_Loss:12.074945449829102

iterator 1200, D_Loss:0.42416200041770935, G_Loss:12.531205177307129

iterator 1300, D_Loss:0.40313097834587097, G_Loss:11.82507038116455

iterator 1400, D_Loss:0.42061835527420044, G_Loss:12.536742210388184

iterator 1500, D_Loss:0.42324045300483704, G_Loss:11.722725868225098

iterator 1600, D_Loss:0.4207322597503662, G_Loss:11.948749542236328

iterator 1700, D_Loss:0.43783968687057495, G_Loss:10.822863578796387

iterator 1800, D_Loss:0.4248988628387451, G_Loss:11.796173095703125

iterator 1900, D_Loss:0.40941399335861206, G_Loss:11.795644760131836

iterator 2000, D_Loss:0.43042054772377014, G_Loss:11.028341293334961

iterator 2100, D_Loss:0.4203176200389862, G_Loss:11.680222511291504

iterator 2200, D_Loss:0.437192440032959, G_Loss:10.711333274841309

iterator 2300, D_Loss:0.415547639131546, G_Loss:11.172457695007324

iterator 2400, D_Loss:0.43538928031921387, G_Loss:11.89433479309082

iterator 2500, D_Loss:0.43555113673210144, G_Loss:10.820701599121094

iterator 2600, D_Loss:0.42035800218582153, G_Loss:11.465789794921875

iterator 2700, D_Loss:0.43601682782173157, G_Loss:11.481311798095703

iterator 2800, D_Loss:0.42906174063682556, G_Loss:10.553071022033691

iterator 2900, D_Loss:0.4154506027698517, G_Loss:10.508513450622559

iterator 3000, D_Loss:0.4442101716995239, G_Loss:10.098323822021484

iterator 3100, D_Loss:0.4253079891204834, G_Loss:10.93940544128418

iterator 3200, D_Loss:0.44158899784088135, G_Loss:7.7664313316345215

iterator 3300, D_Loss:0.42870014905929565, G_Loss:7.317184925079346

iterator 3400, D_Loss:0.44859370589256287, G_Loss:9.552285194396973

iterator 3500, D_Loss:0.4083918333053589, G_Loss:9.840577125549316

iterator 3600, D_Loss:0.4188677668571472, G_Loss:9.156362533569336

iterator 3700, D_Loss:0.4258723855018616, G_Loss:10.905261039733887

iterator 3800, D_Loss:0.4270210266113281, G_Loss:8.819214820861816

iterator 3900, D_Loss:0.42957159876823425, G_Loss:10.401062965393066

iterator 4000, D_Loss:0.4391632378101349, G_Loss:10.173452377319336

iterator 4100, D_Loss:0.4309612214565277, G_Loss:11.342018127441406

iterator 4200, D_Loss:0.42851853370666504, G_Loss:8.178998947143555

iterator 4300, D_Loss:0.4132973551750183, G_Loss:10.438541412353516

iterator 4400, D_Loss:0.4246613681316376, G_Loss:10.175036430358887

iterator 4500, D_Loss:0.4244771897792816, G_Loss:10.852399826049805

iterator 4600, D_Loss:0.416044682264328, G_Loss:12.503870964050293

iterator 4700, D_Loss:0.410702645778656, G_Loss:9.935811996459961

iterator 4800, D_Loss:0.4288371801376343, G_Loss:11.134093284606934

iterator 4900, D_Loss:0.4404275417327881, G_Loss:10.859663963317871

iterator 5000, D_Loss:0.4123838245868683, G_Loss:9.69554328918457

-----------Epoch 9-----------
iterator 100, D_Loss:0.4191768765449524, G_Loss:10.753884315490723

iterator 200, D_Loss:0.4333581328392029, G_Loss:8.826895713806152

iterator 300, D_Loss:0.4323936402797699, G_Loss:10.821146011352539

iterator 400, D_Loss:0.41825246810913086, G_Loss:12.048116683959961

iterator 500, D_Loss:0.4267660677433014, G_Loss:8.343692779541016

iterator 600, D_Loss:0.4525667726993561, G_Loss:7.795038223266602

iterator 700, D_Loss:0.43854066729545593, G_Loss:9.917816162109375

iterator 800, D_Loss:0.44570350646972656, G_Loss:10.694923400878906

iterator 900, D_Loss:0.43099743127822876, G_Loss:8.116910934448242

iterator 1000, D_Loss:0.4070805013179779, G_Loss:12.231467247009277

iterator 1100, D_Loss:0.42536649107933044, G_Loss:10.53376579284668

iterator 1200, D_Loss:0.42637354135513306, G_Loss:10.162871360778809

iterator 1300, D_Loss:0.42925000190734863, G_Loss:10.750556945800781

iterator 1400, D_Loss:0.42848703265190125, G_Loss:10.044371604919434

iterator 1500, D_Loss:0.4377613067626953, G_Loss:11.887663841247559

iterator 1600, D_Loss:0.4455612003803253, G_Loss:10.197333335876465

iterator 1700, D_Loss:0.440773069858551, G_Loss:11.531147003173828

iterator 1800, D_Loss:0.41305801272392273, G_Loss:10.952906608581543

iterator 1900, D_Loss:0.4186989665031433, G_Loss:11.385379791259766

iterator 2000, D_Loss:0.4253636598587036, G_Loss:11.715317726135254

iterator 2100, D_Loss:0.4023197591304779, G_Loss:12.047972679138184

iterator 2200, D_Loss:0.43158695101737976, G_Loss:11.404561996459961

iterator 2300, D_Loss:0.4279065728187561, G_Loss:12.134590148925781

iterator 2400, D_Loss:0.41497159004211426, G_Loss:12.091480255126953

iterator 2500, D_Loss:0.42582154273986816, G_Loss:11.381129264831543

iterator 2600, D_Loss:0.4141938388347626, G_Loss:11.797510147094727

iterator 2700, D_Loss:0.41888508200645447, G_Loss:12.452949523925781

iterator 2800, D_Loss:0.4294549822807312, G_Loss:11.051314353942871

iterator 2900, D_Loss:0.4224061965942383, G_Loss:11.708019256591797

iterator 3000, D_Loss:0.42351171374320984, G_Loss:10.578614234924316

iterator 3100, D_Loss:0.44646066427230835, G_Loss:12.669554710388184

iterator 3200, D_Loss:0.4336029589176178, G_Loss:12.904626846313477

iterator 3300, D_Loss:0.44964635372161865, G_Loss:11.705025672912598

iterator 3400, D_Loss:0.4026569724082947, G_Loss:12.903509140014648

iterator 3500, D_Loss:0.4195304214954376, G_Loss:12.966263771057129

iterator 3600, D_Loss:0.4346277117729187, G_Loss:12.212299346923828

iterator 3700, D_Loss:0.4227488338947296, G_Loss:11.590570449829102

iterator 3800, D_Loss:0.4299317002296448, G_Loss:12.065882682800293

iterator 3900, D_Loss:0.4214818477630615, G_Loss:13.204795837402344

iterator 4000, D_Loss:0.42070430517196655, G_Loss:14.82933235168457

iterator 4100, D_Loss:0.42872628569602966, G_Loss:11.96512222290039

iterator 4200, D_Loss:0.4410649240016937, G_Loss:12.748678207397461

iterator 4300, D_Loss:0.44035378098487854, G_Loss:13.672979354858398

iterator 4400, D_Loss:0.41356584429740906, G_Loss:12.755824089050293

iterator 4500, D_Loss:0.41581791639328003, G_Loss:13.682525634765625

iterator 4600, D_Loss:0.434098482131958, G_Loss:12.726000785827637

iterator 4700, D_Loss:0.4365842044353485, G_Loss:12.978784561157227

iterator 4800, D_Loss:0.4171723425388336, G_Loss:13.038106918334961

iterator 4900, D_Loss:0.4314604699611664, G_Loss:11.57992172241211

iterator 5000, D_Loss:0.43416473269462585, G_Loss:13.134411811828613

train row : 30148
sample row: 30148
LGAN_generator(
  (LSTM): LSTMCell(602, 200)
  (gmfc00): Linear(in_features=500, out_features=1, bias=True)
  (gmfc01): Linear(in_features=500, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=500, bias=True)
  (gmfe00): Linear(in_features=200, out_features=500, bias=True)
  (gmfe01): Linear(in_features=200, out_features=500, bias=True)
  (fc10): Linear(in_features=500, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=500, bias=True)
  (fe1): Linear(in_features=200, out_features=500, bias=True)
  (gmfc20): Linear(in_features=500, out_features=1, bias=True)
  (gmfc21): Linear(in_features=500, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=500, bias=True)
  (gmfe20): Linear(in_features=200, out_features=500, bias=True)
  (gmfe21): Linear(in_features=200, out_features=500, bias=True)
  (fc30): Linear(in_features=500, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=500, bias=True)
  (fe3): Linear(in_features=200, out_features=500, bias=True)
  (gmfc40): Linear(in_features=500, out_features=1, bias=True)
  (gmfc41): Linear(in_features=500, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=500, bias=True)
  (gmfe40): Linear(in_features=200, out_features=500, bias=True)
  (gmfe41): Linear(in_features=200, out_features=500, bias=True)
  (fc50): Linear(in_features=500, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=500, bias=True)
  (fe5): Linear(in_features=200, out_features=500, bias=True)
  (fc60): Linear(in_features=500, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=500, bias=True)
  (fe6): Linear(in_features=200, out_features=500, bias=True)
  (fc70): Linear(in_features=500, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=500, bias=True)
  (fe7): Linear(in_features=200, out_features=500, bias=True)
  (fc80): Linear(in_features=500, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=500, bias=True)
  (fe8): Linear(in_features=200, out_features=500, bias=True)
  (fc90): Linear(in_features=500, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=500, bias=True)
  (fe9): Linear(in_features=200, out_features=500, bias=True)
  (gmfc100): Linear(in_features=500, out_features=1, bias=True)
  (gmfc101): Linear(in_features=500, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=500, bias=True)
  (gmfe100): Linear(in_features=200, out_features=500, bias=True)
  (gmfe101): Linear(in_features=200, out_features=500, bias=True)
  (gmfc110): Linear(in_features=500, out_features=1, bias=True)
  (gmfc111): Linear(in_features=500, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=500, bias=True)
  (gmfe110): Linear(in_features=200, out_features=500, bias=True)
  (gmfe111): Linear(in_features=200, out_features=500, bias=True)
  (gmfc120): Linear(in_features=500, out_features=1, bias=True)
  (gmfc121): Linear(in_features=500, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=500, bias=True)
  (gmfe120): Linear(in_features=200, out_features=500, bias=True)
  (gmfe121): Linear(in_features=200, out_features=500, bias=True)
  (fc130): Linear(in_features=500, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=500, bias=True)
  (fe13): Linear(in_features=200, out_features=500, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=100, bias=True)
  (inputbn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=100, out_features=100, bias=True)
  (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=100, out_features=1, bias=True)
)
(2, True, 133)
(30148, 2)
-----------Epoch 0-----------
iterator 0, D_Loss:1.5013387203216553, G_Loss:12.996711730957031

iterator 100, D_Loss:1.3223602771759033, G_Loss:1.0857635736465454

iterator 200, D_Loss:1.3194347620010376, G_Loss:1.0725460052490234

iterator 300, D_Loss:1.2831971645355225, G_Loss:1.0948065519332886

iterator 400, D_Loss:1.2438498735427856, G_Loss:1.1175849437713623

iterator 500, D_Loss:1.2922844886779785, G_Loss:0.976330041885376

iterator 600, D_Loss:1.2829691171646118, G_Loss:1.078209400177002

iterator 700, D_Loss:1.2524131536483765, G_Loss:1.1512943506240845

iterator 800, D_Loss:1.3181583881378174, G_Loss:1.120548963546753

iterator 900, D_Loss:1.3438161611557007, G_Loss:1.163554310798645

iterator 1000, D_Loss:1.3783659934997559, G_Loss:1.0757534503936768

iterator 1100, D_Loss:1.2217330932617188, G_Loss:1.229548454284668

iterator 1200, D_Loss:1.2445683479309082, G_Loss:1.184288501739502

iterator 1300, D_Loss:1.2408267259597778, G_Loss:1.1483038663864136

iterator 1400, D_Loss:1.1190088987350464, G_Loss:1.45829439163208

iterator 1500, D_Loss:1.1775941848754883, G_Loss:1.1951572895050049

iterator 1600, D_Loss:1.0924947261810303, G_Loss:1.4244039058685303

iterator 1700, D_Loss:1.2102540731430054, G_Loss:1.4147998094558716

iterator 1800, D_Loss:1.1961185932159424, G_Loss:1.6058578491210938

iterator 1900, D_Loss:1.0156702995300293, G_Loss:1.7232089042663574

iterator 2000, D_Loss:1.0733453035354614, G_Loss:1.915299654006958

iterator 2100, D_Loss:1.0668489933013916, G_Loss:1.7386382818222046

iterator 2200, D_Loss:1.2665061950683594, G_Loss:1.5625542402267456

iterator 2300, D_Loss:1.0777418613433838, G_Loss:2.0441856384277344

iterator 2400, D_Loss:0.9506664276123047, G_Loss:1.930607795715332

iterator 2500, D_Loss:0.8540252447128296, G_Loss:2.4105520248413086

iterator 2600, D_Loss:0.810383677482605, G_Loss:2.563006639480591

iterator 2700, D_Loss:1.1730239391326904, G_Loss:2.5754809379577637

iterator 2800, D_Loss:0.8262900114059448, G_Loss:2.570917844772339

iterator 2900, D_Loss:0.818016767501831, G_Loss:3.118906259536743

iterator 3000, D_Loss:0.9834083914756775, G_Loss:2.221421718597412

iterator 3100, D_Loss:0.8202000260353088, G_Loss:2.5505075454711914

iterator 3200, D_Loss:0.7221229672431946, G_Loss:3.3364667892456055

iterator 3300, D_Loss:0.6831060647964478, G_Loss:3.493283987045288

iterator 3400, D_Loss:0.742510199546814, G_Loss:3.21563982963562

iterator 3500, D_Loss:0.7251023650169373, G_Loss:3.6025218963623047

iterator 3600, D_Loss:0.7384495139122009, G_Loss:4.301083564758301

iterator 3700, D_Loss:0.6091301441192627, G_Loss:5.393687725067139

iterator 3800, D_Loss:0.9330484867095947, G_Loss:1.7925355434417725

iterator 3900, D_Loss:0.9384546875953674, G_Loss:4.206033229827881

iterator 4000, D_Loss:0.8318954110145569, G_Loss:4.33119535446167

iterator 4100, D_Loss:0.8008931875228882, G_Loss:2.400456666946411

iterator 4200, D_Loss:0.8559144735336304, G_Loss:3.4188153743743896

iterator 4300, D_Loss:0.9071033000946045, G_Loss:2.366156578063965

iterator 4400, D_Loss:0.9326930046081543, G_Loss:3.012113571166992

iterator 4500, D_Loss:0.8549495935440063, G_Loss:2.6929359436035156

iterator 4600, D_Loss:1.1211533546447754, G_Loss:2.6057207584381104

iterator 4700, D_Loss:0.897988498210907, G_Loss:2.6967458724975586

iterator 4800, D_Loss:0.7877233624458313, G_Loss:3.4530482292175293

iterator 4900, D_Loss:0.7180765867233276, G_Loss:2.981902599334717

-----------Epoch 1-----------
iterator 0, D_Loss:0.8173702359199524, G_Loss:3.088824987411499

iterator 100, D_Loss:0.7463139891624451, G_Loss:3.15128755569458

iterator 200, D_Loss:0.8631657361984253, G_Loss:4.314541339874268

iterator 300, D_Loss:0.7899746894836426, G_Loss:3.608393669128418

iterator 400, D_Loss:0.9284368753433228, G_Loss:5.346632957458496

iterator 500, D_Loss:0.8331727981567383, G_Loss:4.788809776306152

iterator 600, D_Loss:0.8789933919906616, G_Loss:3.7038469314575195

iterator 700, D_Loss:0.9846667647361755, G_Loss:3.301818370819092

iterator 800, D_Loss:0.6975768804550171, G_Loss:3.0164520740509033

iterator 900, D_Loss:0.7626090049743652, G_Loss:4.255129337310791

iterator 1000, D_Loss:0.7342859506607056, G_Loss:4.558315277099609

iterator 1100, D_Loss:0.8221034407615662, G_Loss:3.0465714931488037

iterator 1200, D_Loss:0.7319207191467285, G_Loss:4.465877532958984

iterator 1300, D_Loss:0.9840430021286011, G_Loss:3.3648769855499268

iterator 1400, D_Loss:0.7049761414527893, G_Loss:3.6521573066711426

iterator 1500, D_Loss:0.7229794263839722, G_Loss:4.451473236083984

iterator 1600, D_Loss:0.7885861396789551, G_Loss:3.269989252090454

iterator 1700, D_Loss:0.6980707049369812, G_Loss:4.284543991088867

iterator 1800, D_Loss:0.7227286696434021, G_Loss:3.6968510150909424

iterator 1900, D_Loss:0.7369406819343567, G_Loss:4.481674671173096

iterator 2000, D_Loss:0.6947952508926392, G_Loss:3.584198474884033

iterator 2100, D_Loss:0.7544683218002319, G_Loss:2.67252516746521

iterator 2200, D_Loss:0.7309314012527466, G_Loss:4.509349822998047

iterator 2300, D_Loss:0.9098348021507263, G_Loss:3.3887879848480225

iterator 2400, D_Loss:0.9141532778739929, G_Loss:4.476683139801025

iterator 2500, D_Loss:0.6514413356781006, G_Loss:4.79564094543457

iterator 2600, D_Loss:0.7305184602737427, G_Loss:4.3044328689575195

iterator 2700, D_Loss:0.6720256209373474, G_Loss:3.7061429023742676

iterator 2800, D_Loss:0.7460192441940308, G_Loss:3.0478835105895996

iterator 2900, D_Loss:0.7162085771560669, G_Loss:3.9820737838745117

iterator 3000, D_Loss:0.651953935623169, G_Loss:5.08644437789917

iterator 3100, D_Loss:0.7855204343795776, G_Loss:4.810622215270996

iterator 3200, D_Loss:0.7923855781555176, G_Loss:5.633632183074951

iterator 3300, D_Loss:0.9718977212905884, G_Loss:4.686232089996338

iterator 3400, D_Loss:0.6592191457748413, G_Loss:3.8597636222839355

iterator 3500, D_Loss:0.6962093710899353, G_Loss:4.429473400115967

iterator 3600, D_Loss:0.7255949378013611, G_Loss:4.925588130950928

iterator 3700, D_Loss:0.7494847178459167, G_Loss:4.176050186157227

iterator 3800, D_Loss:0.6947147250175476, G_Loss:5.568541049957275

iterator 3900, D_Loss:0.7811049222946167, G_Loss:4.807754993438721

iterator 4000, D_Loss:0.7459993958473206, G_Loss:3.651841402053833

iterator 4100, D_Loss:0.6147785186767578, G_Loss:4.547633647918701

iterator 4200, D_Loss:0.7668154239654541, G_Loss:4.71574068069458

iterator 4300, D_Loss:0.6417252421379089, G_Loss:4.525248050689697

iterator 4400, D_Loss:0.6102935671806335, G_Loss:4.292781829833984

iterator 4500, D_Loss:0.6238179206848145, G_Loss:5.674017906188965

iterator 4600, D_Loss:0.6185833811759949, G_Loss:3.7615747451782227

iterator 4700, D_Loss:0.6250180602073669, G_Loss:4.566252708435059

iterator 4800, D_Loss:0.6436516642570496, G_Loss:3.771193742752075

iterator 4900, D_Loss:0.6101028919219971, G_Loss:4.820880889892578

-----------Epoch 2-----------
iterator 0, D_Loss:0.6156958937644958, G_Loss:5.524056434631348

iterator 100, D_Loss:0.6976425647735596, G_Loss:4.330252647399902

iterator 200, D_Loss:0.6451005935668945, G_Loss:3.9835309982299805

iterator 300, D_Loss:0.7862125635147095, G_Loss:4.587353706359863

iterator 400, D_Loss:0.597174882888794, G_Loss:6.281117916107178

iterator 500, D_Loss:0.742840588092804, G_Loss:5.159961700439453

iterator 600, D_Loss:0.6061164736747742, G_Loss:6.039992332458496

iterator 700, D_Loss:0.7938103079795837, G_Loss:5.667357921600342

iterator 800, D_Loss:0.5757383108139038, G_Loss:5.983425140380859

iterator 900, D_Loss:0.6679246425628662, G_Loss:6.188472747802734

iterator 1000, D_Loss:0.7792121767997742, G_Loss:5.75762414932251

iterator 1100, D_Loss:0.6174293756484985, G_Loss:6.887670993804932

iterator 1200, D_Loss:0.6703288555145264, G_Loss:6.384255886077881

iterator 1300, D_Loss:0.6435115933418274, G_Loss:5.312350273132324

iterator 1400, D_Loss:0.6664055585861206, G_Loss:5.215432167053223

iterator 1500, D_Loss:0.5745376348495483, G_Loss:6.099104404449463

iterator 1600, D_Loss:0.6815641522407532, G_Loss:5.710394859313965

iterator 1700, D_Loss:0.5781477689743042, G_Loss:6.723844528198242

iterator 1800, D_Loss:0.6294756531715393, G_Loss:6.431546211242676

iterator 1900, D_Loss:0.597312331199646, G_Loss:5.4070587158203125

iterator 2000, D_Loss:0.6811013221740723, G_Loss:7.17540168762207

iterator 2100, D_Loss:0.5461058616638184, G_Loss:7.491889953613281

iterator 2200, D_Loss:0.5937802791595459, G_Loss:8.286723136901855

iterator 2300, D_Loss:0.5824950337409973, G_Loss:13.221704483032227

iterator 2400, D_Loss:0.5633234977722168, G_Loss:10.40050220489502

iterator 2500, D_Loss:0.5433575510978699, G_Loss:9.778587341308594

iterator 2600, D_Loss:0.5546203255653381, G_Loss:10.637382507324219

iterator 2700, D_Loss:0.5181707739830017, G_Loss:11.324819564819336

iterator 2800, D_Loss:0.6036078929901123, G_Loss:10.258363723754883

iterator 2900, D_Loss:0.5357702374458313, G_Loss:16.096284866333008

iterator 3000, D_Loss:0.5417739152908325, G_Loss:12.62088680267334

iterator 3100, D_Loss:0.5239306092262268, G_Loss:12.945526123046875

iterator 3200, D_Loss:0.5324351787567139, G_Loss:13.550115585327148

iterator 3300, D_Loss:0.5541305541992188, G_Loss:13.668437957763672

iterator 3400, D_Loss:0.571718692779541, G_Loss:10.379098892211914

iterator 3500, D_Loss:0.5186517238616943, G_Loss:10.470853805541992

iterator 3600, D_Loss:0.5003913044929504, G_Loss:12.200037002563477

iterator 3700, D_Loss:0.5182029604911804, G_Loss:12.870765686035156

iterator 3800, D_Loss:0.4752797782421112, G_Loss:12.189741134643555

iterator 3900, D_Loss:0.4893311858177185, G_Loss:10.658051490783691

iterator 4000, D_Loss:0.5031953454017639, G_Loss:12.047203063964844

iterator 4100, D_Loss:0.5253272652626038, G_Loss:12.053552627563477

iterator 4200, D_Loss:0.49074462056159973, G_Loss:12.273683547973633

iterator 4300, D_Loss:0.4813060760498047, G_Loss:11.118152618408203

iterator 4400, D_Loss:0.5059291124343872, G_Loss:11.156332015991211

iterator 4500, D_Loss:0.5439918637275696, G_Loss:11.94021224975586

iterator 4600, D_Loss:0.5054346323013306, G_Loss:15.47004508972168

iterator 4700, D_Loss:0.5045123100280762, G_Loss:12.429912567138672

iterator 4800, D_Loss:0.5116968750953674, G_Loss:12.337223052978516

iterator 4900, D_Loss:0.5147745013237, G_Loss:12.613029479980469

-----------Epoch 3-----------
iterator 0, D_Loss:0.4731464087963104, G_Loss:12.65958309173584

iterator 100, D_Loss:0.45493048429489136, G_Loss:12.568913459777832

iterator 200, D_Loss:0.4555574059486389, G_Loss:13.530991554260254

iterator 300, D_Loss:0.5031140446662903, G_Loss:11.303340911865234

iterator 400, D_Loss:0.5893024802207947, G_Loss:13.003700256347656

iterator 500, D_Loss:0.5186218619346619, G_Loss:12.183724403381348

iterator 600, D_Loss:0.4767652750015259, G_Loss:13.542919158935547

iterator 700, D_Loss:0.48869383335113525, G_Loss:12.531394958496094

iterator 800, D_Loss:0.54714035987854, G_Loss:13.114948272705078

iterator 900, D_Loss:0.4563165307044983, G_Loss:10.088438987731934

iterator 1000, D_Loss:0.4864291548728943, G_Loss:9.776151657104492

iterator 1100, D_Loss:0.504269003868103, G_Loss:11.860885620117188

iterator 1200, D_Loss:0.4749515950679779, G_Loss:12.475314140319824

iterator 1300, D_Loss:0.4989287853240967, G_Loss:11.77723503112793

iterator 1400, D_Loss:0.52189701795578, G_Loss:11.811300277709961

iterator 1500, D_Loss:0.5230304002761841, G_Loss:12.95017147064209

iterator 1600, D_Loss:0.5268406867980957, G_Loss:14.339550018310547

iterator 1700, D_Loss:0.553730845451355, G_Loss:14.335792541503906

iterator 1800, D_Loss:0.5164245963096619, G_Loss:13.659303665161133

iterator 1900, D_Loss:0.49737972021102905, G_Loss:17.5120849609375

iterator 2000, D_Loss:0.5166164040565491, G_Loss:15.414326667785645

iterator 2100, D_Loss:0.5186223983764648, G_Loss:15.510137557983398

iterator 2200, D_Loss:0.4921438694000244, G_Loss:14.42895221710205

iterator 2300, D_Loss:0.507506787776947, G_Loss:14.918342590332031

iterator 2400, D_Loss:0.5109238624572754, G_Loss:14.407451629638672

iterator 2500, D_Loss:0.5027310252189636, G_Loss:18.593570709228516

iterator 2600, D_Loss:0.5370323061943054, G_Loss:17.239110946655273

iterator 2700, D_Loss:0.47523531317710876, G_Loss:17.162960052490234

iterator 2800, D_Loss:0.4744446277618408, G_Loss:17.298545837402344

iterator 2900, D_Loss:0.4902927577495575, G_Loss:15.033757209777832

iterator 3000, D_Loss:0.4638913571834564, G_Loss:14.163301467895508

iterator 3100, D_Loss:0.4916711151599884, G_Loss:18.246082305908203

iterator 3200, D_Loss:0.5400423407554626, G_Loss:18.04741096496582

iterator 3300, D_Loss:0.4854618310928345, G_Loss:17.20914649963379

iterator 3400, D_Loss:0.515302836894989, G_Loss:20.44530487060547

iterator 3500, D_Loss:0.48418518900871277, G_Loss:20.94725799560547

iterator 3600, D_Loss:0.45549336075782776, G_Loss:18.206321716308594

iterator 3700, D_Loss:0.47423437237739563, G_Loss:21.58386993408203

iterator 3800, D_Loss:0.4681304395198822, G_Loss:20.461864471435547

iterator 3900, D_Loss:0.4749424159526825, G_Loss:22.75261688232422

iterator 4000, D_Loss:0.4783463180065155, G_Loss:24.359455108642578

iterator 4100, D_Loss:0.45631667971611023, G_Loss:25.39112091064453

iterator 4200, D_Loss:0.49323129653930664, G_Loss:24.469303131103516

iterator 4300, D_Loss:0.5118879079818726, G_Loss:26.026643753051758

iterator 4400, D_Loss:0.4534609019756317, G_Loss:24.347217559814453

iterator 4500, D_Loss:0.4584585726261139, G_Loss:24.042346954345703

iterator 4600, D_Loss:0.46516329050064087, G_Loss:26.552459716796875

iterator 4700, D_Loss:0.4691060483455658, G_Loss:24.629980087280273

iterator 4800, D_Loss:0.47006767988204956, G_Loss:24.690385818481445

iterator 4900, D_Loss:0.4806590676307678, G_Loss:22.28764533996582

-----------Epoch 4-----------
iterator 0, D_Loss:0.5119282007217407, G_Loss:22.53082847595215

iterator 100, D_Loss:0.48619410395622253, G_Loss:23.740381240844727

iterator 200, D_Loss:0.4874582886695862, G_Loss:19.094223022460938

iterator 300, D_Loss:0.4575325548648834, G_Loss:18.67074966430664

iterator 400, D_Loss:0.47243648767471313, G_Loss:18.117015838623047

iterator 500, D_Loss:0.49645236134529114, G_Loss:17.530122756958008

iterator 600, D_Loss:0.519138753414154, G_Loss:17.511737823486328

iterator 700, D_Loss:0.48148655891418457, G_Loss:19.85478973388672

iterator 800, D_Loss:0.4672197997570038, G_Loss:22.09827995300293

iterator 900, D_Loss:0.5131120085716248, G_Loss:21.07899284362793

iterator 1000, D_Loss:0.44459268450737, G_Loss:22.669809341430664

iterator 1100, D_Loss:0.48142626881599426, G_Loss:22.777606964111328

iterator 1200, D_Loss:0.4923379719257355, G_Loss:24.94631576538086

iterator 1300, D_Loss:0.5474720597267151, G_Loss:23.213111877441406

iterator 1400, D_Loss:0.509480893611908, G_Loss:21.062713623046875

iterator 1500, D_Loss:0.5370679497718811, G_Loss:24.06437110900879

iterator 1600, D_Loss:0.6241464614868164, G_Loss:19.89349365234375

iterator 1700, D_Loss:0.6081291437149048, G_Loss:19.627243041992188

iterator 1800, D_Loss:0.5890911221504211, G_Loss:19.905498504638672

iterator 1900, D_Loss:0.5706959962844849, G_Loss:21.16485595703125

iterator 2000, D_Loss:0.5844933986663818, G_Loss:18.81838607788086

iterator 2100, D_Loss:0.5833909511566162, G_Loss:18.763710021972656

iterator 2200, D_Loss:0.5897213220596313, G_Loss:19.794809341430664

iterator 2300, D_Loss:0.5857707262039185, G_Loss:17.572969436645508

iterator 2400, D_Loss:0.5810932517051697, G_Loss:17.925050735473633

iterator 2500, D_Loss:0.685194730758667, G_Loss:18.756834030151367

iterator 2600, D_Loss:0.5519098043441772, G_Loss:19.77665901184082

iterator 2700, D_Loss:0.5592051148414612, G_Loss:20.18509864807129

iterator 2800, D_Loss:0.5521453619003296, G_Loss:17.552671432495117

iterator 2900, D_Loss:0.5676500797271729, G_Loss:17.881908416748047

iterator 3000, D_Loss:0.5384383797645569, G_Loss:19.72985076904297

iterator 3100, D_Loss:0.5393668413162231, G_Loss:18.212961196899414

iterator 3200, D_Loss:0.5725370645523071, G_Loss:18.053485870361328

iterator 3300, D_Loss:0.5817177891731262, G_Loss:20.967792510986328

iterator 3400, D_Loss:0.5770382881164551, G_Loss:17.495473861694336

iterator 3500, D_Loss:0.576759397983551, G_Loss:18.582406997680664

iterator 3600, D_Loss:0.5485400557518005, G_Loss:18.237194061279297

iterator 3700, D_Loss:0.537325382232666, G_Loss:20.834659576416016

iterator 3800, D_Loss:0.5521175861358643, G_Loss:17.884082794189453

iterator 3900, D_Loss:0.4904753267765045, G_Loss:21.190889358520508

iterator 4000, D_Loss:0.5557476282119751, G_Loss:18.276817321777344

iterator 4100, D_Loss:0.5072985887527466, G_Loss:17.607315063476562

iterator 4200, D_Loss:0.5046892166137695, G_Loss:18.894947052001953

iterator 4300, D_Loss:0.48107683658599854, G_Loss:22.596668243408203

iterator 4400, D_Loss:0.4821937382221222, G_Loss:21.112079620361328

iterator 4500, D_Loss:0.5009399652481079, G_Loss:22.914077758789062

iterator 4600, D_Loss:0.5725564360618591, G_Loss:18.555131912231445

iterator 4700, D_Loss:0.5302952527999878, G_Loss:19.882999420166016

iterator 4800, D_Loss:0.5435553789138794, G_Loss:19.889644622802734

iterator 4900, D_Loss:0.5423293709754944, G_Loss:18.755014419555664

-----------Epoch 5-----------
iterator 0, D_Loss:0.5444082021713257, G_Loss:18.41913604736328

iterator 100, D_Loss:0.5056700706481934, G_Loss:18.983522415161133

iterator 200, D_Loss:0.5396768450737, G_Loss:19.33393096923828

iterator 300, D_Loss:0.5518996119499207, G_Loss:19.22621726989746

iterator 400, D_Loss:0.5363966822624207, G_Loss:19.28717041015625

iterator 500, D_Loss:0.5410079956054688, G_Loss:18.975923538208008

iterator 600, D_Loss:0.5366271734237671, G_Loss:19.351423263549805

iterator 700, D_Loss:0.5311762094497681, G_Loss:19.267040252685547

iterator 800, D_Loss:0.532631516456604, G_Loss:19.135913848876953

iterator 900, D_Loss:0.5374509692192078, G_Loss:19.518009185791016

iterator 1000, D_Loss:0.550460934638977, G_Loss:19.408790588378906

iterator 1100, D_Loss:0.5662864446640015, G_Loss:20.584110260009766

iterator 1200, D_Loss:0.5345741510391235, G_Loss:19.81794548034668

iterator 1300, D_Loss:0.5539921522140503, G_Loss:19.269617080688477

iterator 1400, D_Loss:0.5293300747871399, G_Loss:18.715852737426758

iterator 1500, D_Loss:0.5259238481521606, G_Loss:18.919523239135742

iterator 1600, D_Loss:0.5242159962654114, G_Loss:18.643489837646484

iterator 1700, D_Loss:0.533568263053894, G_Loss:18.525060653686523

iterator 1800, D_Loss:0.5464338660240173, G_Loss:18.886911392211914

iterator 1900, D_Loss:0.5562160611152649, G_Loss:18.940750122070312

iterator 2000, D_Loss:0.5399839282035828, G_Loss:18.532917022705078

iterator 2100, D_Loss:0.5206510424613953, G_Loss:18.92620086669922

iterator 2200, D_Loss:0.531745195388794, G_Loss:18.74246597290039

iterator 2300, D_Loss:0.5376191735267639, G_Loss:18.78378677368164

iterator 2400, D_Loss:0.5157489776611328, G_Loss:18.845121383666992

iterator 2500, D_Loss:0.5386787056922913, G_Loss:18.84508514404297

iterator 2600, D_Loss:0.5152982473373413, G_Loss:19.68769073486328

iterator 2700, D_Loss:0.5521833896636963, G_Loss:18.71367645263672

iterator 2800, D_Loss:0.557671844959259, G_Loss:18.793304443359375

iterator 2900, D_Loss:0.5121185779571533, G_Loss:19.067045211791992

iterator 3000, D_Loss:0.5325414538383484, G_Loss:19.7259578704834

iterator 3100, D_Loss:0.5508557558059692, G_Loss:19.101961135864258

iterator 3200, D_Loss:0.5417816042900085, G_Loss:18.862991333007812

iterator 3300, D_Loss:0.5544683933258057, G_Loss:19.623815536499023

iterator 3400, D_Loss:0.5081243515014648, G_Loss:19.12671661376953

iterator 3500, D_Loss:0.5045631527900696, G_Loss:19.2255916595459

iterator 3600, D_Loss:0.5310297608375549, G_Loss:19.09051513671875

iterator 3700, D_Loss:0.5085586309432983, G_Loss:19.52077865600586

iterator 3800, D_Loss:0.5423741340637207, G_Loss:19.046358108520508

iterator 3900, D_Loss:0.5528926253318787, G_Loss:18.727455139160156

iterator 4000, D_Loss:0.5225104093551636, G_Loss:19.324382781982422

iterator 4100, D_Loss:0.533075213432312, G_Loss:19.206634521484375

iterator 4200, D_Loss:0.5288383364677429, G_Loss:19.326461791992188

iterator 4300, D_Loss:0.520817220211029, G_Loss:19.207609176635742

iterator 4400, D_Loss:0.538629412651062, G_Loss:18.849685668945312

iterator 4500, D_Loss:0.5191774368286133, G_Loss:19.052085876464844

iterator 4600, D_Loss:0.5041451454162598, G_Loss:19.01295280456543

iterator 4700, D_Loss:0.537705659866333, G_Loss:19.24114990234375

iterator 4800, D_Loss:0.5082800984382629, G_Loss:19.2835693359375

iterator 4900, D_Loss:0.5021242499351501, G_Loss:19.223541259765625

-----------Epoch 6-----------
iterator 0, D_Loss:0.52243572473526, G_Loss:19.01913070678711

iterator 100, D_Loss:0.5133019685745239, G_Loss:19.246736526489258

iterator 200, D_Loss:0.7924695014953613, G_Loss:18.509092330932617

iterator 300, D_Loss:0.516573965549469, G_Loss:19.214679718017578

iterator 400, D_Loss:0.5224932432174683, G_Loss:18.811641693115234

iterator 500, D_Loss:0.561550498008728, G_Loss:19.18162727355957

iterator 600, D_Loss:0.5102588534355164, G_Loss:19.16593360900879

iterator 700, D_Loss:0.5298066735267639, G_Loss:19.287294387817383

iterator 800, D_Loss:0.520302414894104, G_Loss:19.161338806152344

iterator 900, D_Loss:0.5167211890220642, G_Loss:19.520357131958008

iterator 1000, D_Loss:0.5761060118675232, G_Loss:20.025588989257812

iterator 1100, D_Loss:0.619175136089325, G_Loss:19.601394653320312

iterator 1200, D_Loss:0.523837685585022, G_Loss:19.640827178955078

iterator 1300, D_Loss:0.5497169494628906, G_Loss:20.159387588500977

iterator 1400, D_Loss:0.5370436310768127, G_Loss:19.570018768310547

iterator 1500, D_Loss:0.5593956708908081, G_Loss:20.47228240966797

iterator 1600, D_Loss:0.5243473052978516, G_Loss:21.057113647460938

iterator 1700, D_Loss:0.5119653344154358, G_Loss:20.143884658813477

iterator 1800, D_Loss:0.5634263157844543, G_Loss:21.237594604492188

iterator 1900, D_Loss:0.5304509401321411, G_Loss:19.772642135620117

iterator 2000, D_Loss:0.6879134178161621, G_Loss:19.933090209960938

iterator 2100, D_Loss:0.5156939625740051, G_Loss:20.20827865600586

iterator 2200, D_Loss:0.5601400136947632, G_Loss:19.537376403808594

iterator 2300, D_Loss:0.5432074666023254, G_Loss:19.030763626098633

iterator 2400, D_Loss:0.544427216053009, G_Loss:19.215911865234375

iterator 2500, D_Loss:0.575194239616394, G_Loss:19.115432739257812

iterator 2600, D_Loss:0.5345566868782043, G_Loss:19.301586151123047

iterator 2700, D_Loss:0.5315236449241638, G_Loss:19.10479164123535

iterator 2800, D_Loss:0.5276307463645935, G_Loss:18.89655113220215

iterator 2900, D_Loss:0.5377293825149536, G_Loss:19.341476440429688

iterator 3000, D_Loss:0.5270947217941284, G_Loss:18.997005462646484

iterator 3100, D_Loss:0.5276734232902527, G_Loss:19.054168701171875

iterator 3200, D_Loss:0.5362666845321655, G_Loss:19.710840225219727

iterator 3300, D_Loss:0.5649425387382507, G_Loss:20.26675796508789

iterator 3400, D_Loss:0.5354405045509338, G_Loss:20.325929641723633

iterator 3500, D_Loss:0.5319265723228455, G_Loss:20.30453109741211

iterator 3600, D_Loss:0.5351666808128357, G_Loss:20.40808868408203

iterator 3700, D_Loss:0.5543098449707031, G_Loss:19.785432815551758

iterator 3800, D_Loss:0.49715521931648254, G_Loss:20.26715850830078

iterator 3900, D_Loss:0.5424368381500244, G_Loss:20.93358039855957

iterator 4000, D_Loss:0.5028720498085022, G_Loss:20.111984252929688

iterator 4100, D_Loss:0.536275327205658, G_Loss:19.360797882080078

iterator 4200, D_Loss:0.5175867080688477, G_Loss:19.160676956176758

iterator 4300, D_Loss:0.5179166197776794, G_Loss:19.317487716674805

iterator 4400, D_Loss:0.5189605951309204, G_Loss:19.152267456054688

iterator 4500, D_Loss:0.5423421263694763, G_Loss:19.479890823364258

iterator 4600, D_Loss:0.5018724799156189, G_Loss:19.442943572998047

iterator 4700, D_Loss:0.49551036953926086, G_Loss:19.118640899658203

iterator 4800, D_Loss:0.5165820717811584, G_Loss:19.700075149536133

iterator 4900, D_Loss:0.5240733623504639, G_Loss:19.357664108276367

-----------Epoch 7-----------
iterator 0, D_Loss:0.5431408882141113, G_Loss:19.077194213867188

iterator 100, D_Loss:0.5388078689575195, G_Loss:19.233192443847656

iterator 200, D_Loss:0.5019482970237732, G_Loss:19.329002380371094

iterator 300, D_Loss:0.5070152282714844, G_Loss:18.714290618896484

iterator 400, D_Loss:0.507619321346283, G_Loss:19.01810073852539

iterator 500, D_Loss:0.5193061232566833, G_Loss:19.264236450195312

iterator 600, D_Loss:0.5197026133537292, G_Loss:19.642866134643555

iterator 700, D_Loss:0.5169743299484253, G_Loss:19.04401397705078

iterator 800, D_Loss:0.5278643369674683, G_Loss:19.514711380004883

iterator 900, D_Loss:0.5222927927970886, G_Loss:19.57516098022461

iterator 1000, D_Loss:0.528174638748169, G_Loss:19.30258560180664

iterator 1100, D_Loss:0.5583215951919556, G_Loss:21.2739315032959

iterator 1200, D_Loss:0.543207049369812, G_Loss:20.84474754333496

iterator 1300, D_Loss:0.5317128300666809, G_Loss:19.450641632080078

iterator 1400, D_Loss:0.5323663353919983, G_Loss:20.050813674926758

iterator 1500, D_Loss:0.5552368760108948, G_Loss:19.869522094726562

iterator 1600, D_Loss:0.5372147560119629, G_Loss:20.569026947021484

iterator 1700, D_Loss:0.5182389616966248, G_Loss:20.378599166870117

iterator 1800, D_Loss:0.5415428280830383, G_Loss:20.27370834350586

iterator 1900, D_Loss:0.5696117877960205, G_Loss:19.584491729736328

iterator 2000, D_Loss:0.5090521574020386, G_Loss:20.03997802734375

iterator 2100, D_Loss:0.5457578897476196, G_Loss:19.495174407958984

iterator 2200, D_Loss:0.5143114328384399, G_Loss:19.57520866394043

iterator 2300, D_Loss:0.5130966901779175, G_Loss:20.944705963134766

iterator 2400, D_Loss:0.5480639338493347, G_Loss:23.163429260253906

iterator 2500, D_Loss:0.7338904142379761, G_Loss:23.69040870666504

iterator 2600, D_Loss:0.5408741235733032, G_Loss:20.44951629638672

iterator 2700, D_Loss:0.5309359431266785, G_Loss:21.160831451416016

iterator 2800, D_Loss:0.5099548697471619, G_Loss:20.470691680908203

iterator 2900, D_Loss:0.5487098097801208, G_Loss:20.1945743560791

iterator 3000, D_Loss:0.5086380839347839, G_Loss:20.727436065673828

iterator 3100, D_Loss:0.5403431057929993, G_Loss:22.863054275512695

iterator 3200, D_Loss:0.4994661509990692, G_Loss:23.25596809387207

iterator 3300, D_Loss:0.5506761074066162, G_Loss:23.893932342529297

iterator 3400, D_Loss:0.529426097869873, G_Loss:23.110279083251953

iterator 3500, D_Loss:0.5526608228683472, G_Loss:23.672922134399414

iterator 3600, D_Loss:0.5399407148361206, G_Loss:20.58102035522461

iterator 3700, D_Loss:0.5368394255638123, G_Loss:21.248069763183594

iterator 3800, D_Loss:0.5089648365974426, G_Loss:20.647274017333984

iterator 3900, D_Loss:0.5120216608047485, G_Loss:21.008363723754883

iterator 4000, D_Loss:0.5386839509010315, G_Loss:23.479623794555664

iterator 4100, D_Loss:0.5242490172386169, G_Loss:23.46474838256836

iterator 4200, D_Loss:0.510722815990448, G_Loss:24.25103759765625

iterator 4300, D_Loss:0.5117661952972412, G_Loss:20.58543586730957

iterator 4400, D_Loss:0.5191254019737244, G_Loss:21.078189849853516

iterator 4500, D_Loss:0.5503032803535461, G_Loss:21.52680015563965

iterator 4600, D_Loss:0.504503607749939, G_Loss:20.900482177734375

iterator 4700, D_Loss:0.5622793436050415, G_Loss:23.323688507080078

iterator 4800, D_Loss:0.5362763404846191, G_Loss:20.842134475708008

iterator 4900, D_Loss:0.48439374566078186, G_Loss:20.845809936523438

-----------Epoch 8-----------
iterator 0, D_Loss:0.5178501009941101, G_Loss:20.648683547973633

iterator 100, D_Loss:0.6118307113647461, G_Loss:23.330883026123047

iterator 200, D_Loss:0.5327059626579285, G_Loss:20.482460021972656

iterator 300, D_Loss:0.5505115389823914, G_Loss:23.501705169677734

iterator 400, D_Loss:0.5399055480957031, G_Loss:20.576427459716797

iterator 500, D_Loss:0.5102789402008057, G_Loss:20.80759048461914

iterator 600, D_Loss:0.5004229545593262, G_Loss:20.399742126464844

iterator 700, D_Loss:0.5171515941619873, G_Loss:20.559568405151367

iterator 800, D_Loss:0.5312632322311401, G_Loss:20.20005989074707

iterator 900, D_Loss:0.5125761032104492, G_Loss:20.59906578063965

iterator 1000, D_Loss:0.5340735912322998, G_Loss:24.297204971313477

iterator 1100, D_Loss:0.505564272403717, G_Loss:20.81969451904297

iterator 1200, D_Loss:0.509037435054779, G_Loss:20.752849578857422

iterator 1300, D_Loss:0.508030891418457, G_Loss:26.485055923461914

iterator 1400, D_Loss:0.4962359666824341, G_Loss:23.559541702270508

iterator 1500, D_Loss:0.5033062696456909, G_Loss:22.742265701293945

iterator 1600, D_Loss:0.4891991913318634, G_Loss:21.112110137939453

iterator 1700, D_Loss:0.5176233649253845, G_Loss:21.065675735473633

iterator 1800, D_Loss:0.5058466792106628, G_Loss:20.593868255615234

iterator 1900, D_Loss:0.5081416368484497, G_Loss:19.910789489746094

iterator 2000, D_Loss:0.5244925618171692, G_Loss:22.925657272338867

iterator 2100, D_Loss:0.5233849883079529, G_Loss:21.58283042907715

iterator 2200, D_Loss:0.5715434551239014, G_Loss:24.514976501464844

iterator 2300, D_Loss:0.5440171360969543, G_Loss:23.582416534423828

iterator 2400, D_Loss:0.5696027874946594, G_Loss:25.5391845703125

iterator 2500, D_Loss:0.5516930222511292, G_Loss:20.89902114868164

iterator 2600, D_Loss:0.5531798005104065, G_Loss:22.542848587036133

iterator 2700, D_Loss:0.5617616772651672, G_Loss:21.18633270263672

iterator 2800, D_Loss:0.5370627641677856, G_Loss:21.80520248413086

iterator 2900, D_Loss:0.522278368473053, G_Loss:21.85386848449707

iterator 3000, D_Loss:0.5110854506492615, G_Loss:26.605222702026367

iterator 3100, D_Loss:0.5408589839935303, G_Loss:22.91843605041504

iterator 3200, D_Loss:0.5325473546981812, G_Loss:20.681520462036133

iterator 3300, D_Loss:0.5457050204277039, G_Loss:20.429086685180664

iterator 3400, D_Loss:0.5154139995574951, G_Loss:19.775196075439453

iterator 3500, D_Loss:0.5224475264549255, G_Loss:20.402896881103516

iterator 3600, D_Loss:0.5234354734420776, G_Loss:19.725940704345703

iterator 3700, D_Loss:0.5056563019752502, G_Loss:23.46965789794922

iterator 3800, D_Loss:0.54021155834198, G_Loss:25.76504898071289

iterator 3900, D_Loss:0.5261088013648987, G_Loss:23.787151336669922

iterator 4000, D_Loss:0.5811646580696106, G_Loss:23.20856475830078

iterator 4100, D_Loss:0.5185213088989258, G_Loss:23.379467010498047

iterator 4200, D_Loss:0.5303835868835449, G_Loss:25.393184661865234

iterator 4300, D_Loss:0.5185258984565735, G_Loss:19.93618392944336

iterator 4400, D_Loss:0.5377666354179382, G_Loss:23.88608169555664

iterator 4500, D_Loss:0.5201997756958008, G_Loss:19.92154884338379

iterator 4600, D_Loss:0.5253833532333374, G_Loss:20.044530868530273

iterator 4700, D_Loss:0.5152658224105835, G_Loss:26.05753517150879

iterator 4800, D_Loss:0.5147936940193176, G_Loss:20.608718872070312

iterator 4900, D_Loss:0.512967050075531, G_Loss:22.184370040893555

-----------Epoch 9-----------
iterator 0, D_Loss:0.5747414827346802, G_Loss:23.621562957763672

iterator 100, D_Loss:0.5071462392807007, G_Loss:20.659128189086914

iterator 200, D_Loss:0.5380972027778625, G_Loss:20.718860626220703

iterator 300, D_Loss:0.5729158520698547, G_Loss:21.110027313232422

iterator 400, D_Loss:0.6299773454666138, G_Loss:22.909189224243164

iterator 500, D_Loss:0.5612269043922424, G_Loss:24.801706314086914

iterator 600, D_Loss:0.5323784947395325, G_Loss:26.26966094970703

iterator 700, D_Loss:0.5315710306167603, G_Loss:20.843664169311523

iterator 800, D_Loss:0.5377053022384644, G_Loss:23.807788848876953

iterator 900, D_Loss:0.5275222659111023, G_Loss:21.406877517700195

iterator 1000, D_Loss:0.4965866506099701, G_Loss:22.856983184814453

iterator 1100, D_Loss:0.5079514980316162, G_Loss:20.79201889038086

iterator 1200, D_Loss:0.5521051287651062, G_Loss:23.82293701171875

iterator 1300, D_Loss:0.5338653922080994, G_Loss:23.153003692626953

iterator 1400, D_Loss:0.5311485528945923, G_Loss:21.603946685791016

iterator 1500, D_Loss:0.5556890964508057, G_Loss:19.891855239868164

iterator 1600, D_Loss:0.5168429613113403, G_Loss:22.949726104736328

iterator 1700, D_Loss:0.5000867247581482, G_Loss:21.318450927734375

iterator 1800, D_Loss:0.5001963973045349, G_Loss:24.190298080444336

iterator 1900, D_Loss:0.49146008491516113, G_Loss:20.03339385986328

iterator 2000, D_Loss:0.5250702500343323, G_Loss:23.94145965576172

iterator 2100, D_Loss:0.5227336287498474, G_Loss:25.965072631835938

iterator 2200, D_Loss:0.5180608630180359, G_Loss:20.071727752685547

iterator 2300, D_Loss:0.5294349193572998, G_Loss:23.07695770263672

iterator 2400, D_Loss:0.49319392442703247, G_Loss:23.524158477783203

iterator 2500, D_Loss:0.5283620953559875, G_Loss:20.21134376525879

iterator 2600, D_Loss:0.5134701728820801, G_Loss:20.21484375

iterator 2700, D_Loss:0.5098048448562622, G_Loss:20.368850708007812

iterator 2800, D_Loss:0.5202534198760986, G_Loss:23.37726593017578

iterator 2900, D_Loss:0.4964703619480133, G_Loss:23.90497589111328

iterator 3000, D_Loss:0.558828592300415, G_Loss:24.49891471862793

iterator 3100, D_Loss:0.5316614508628845, G_Loss:21.254501342773438

iterator 3200, D_Loss:0.534216046333313, G_Loss:21.31230926513672

iterator 3300, D_Loss:0.514314591884613, G_Loss:20.533029556274414

iterator 3400, D_Loss:0.5147824287414551, G_Loss:20.719741821289062

iterator 3500, D_Loss:0.5123380422592163, G_Loss:24.422428131103516

iterator 3600, D_Loss:0.5137364864349365, G_Loss:20.092226028442383

iterator 3700, D_Loss:0.49490681290626526, G_Loss:22.798418045043945

iterator 3800, D_Loss:0.5099151730537415, G_Loss:20.289335250854492

iterator 3900, D_Loss:0.5076514482498169, G_Loss:22.108810424804688

iterator 4000, D_Loss:0.5320598483085632, G_Loss:19.36699867248535

iterator 4100, D_Loss:0.5133917331695557, G_Loss:19.982431411743164

iterator 4200, D_Loss:0.5177642703056335, G_Loss:21.967498779296875

iterator 4300, D_Loss:0.5190576910972595, G_Loss:19.856210708618164

iterator 4400, D_Loss:0.5014886260032654, G_Loss:23.78472137451172

iterator 4500, D_Loss:0.5267449021339417, G_Loss:23.45346450805664

iterator 4600, D_Loss:0.5159794092178345, G_Loss:19.851428985595703

iterator 4700, D_Loss:0.5594583749771118, G_Loss:23.901968002319336

iterator 4800, D_Loss:0.5626057982444763, G_Loss:23.871822357177734

iterator 4900, D_Loss:0.5528672337532043, G_Loss:20.75176239013672

LGAN_generator(
  (LSTM): LSTMCell(302, 100)
  (gmfc00): Linear(in_features=100, out_features=1, bias=True)
  (gmfc01): Linear(in_features=100, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=100, bias=True)
  (gmfe00): Linear(in_features=100, out_features=100, bias=True)
  (gmfe01): Linear(in_features=100, out_features=100, bias=True)
  (fc10): Linear(in_features=100, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=100, bias=True)
  (fe1): Linear(in_features=100, out_features=100, bias=True)
  (gmfc20): Linear(in_features=100, out_features=1, bias=True)
  (gmfc21): Linear(in_features=100, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=100, bias=True)
  (gmfe20): Linear(in_features=100, out_features=100, bias=True)
  (gmfe21): Linear(in_features=100, out_features=100, bias=True)
  (fc30): Linear(in_features=100, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=100, bias=True)
  (fe3): Linear(in_features=100, out_features=100, bias=True)
  (gmfc40): Linear(in_features=100, out_features=1, bias=True)
  (gmfc41): Linear(in_features=100, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=100, bias=True)
  (gmfe40): Linear(in_features=100, out_features=100, bias=True)
  (gmfe41): Linear(in_features=100, out_features=100, bias=True)
  (fc50): Linear(in_features=100, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=100, bias=True)
  (fe5): Linear(in_features=100, out_features=100, bias=True)
  (fc60): Linear(in_features=100, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=100, bias=True)
  (fe6): Linear(in_features=100, out_features=100, bias=True)
  (fc70): Linear(in_features=100, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=100, bias=True)
  (fe7): Linear(in_features=100, out_features=100, bias=True)
  (fc80): Linear(in_features=100, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=100, bias=True)
  (fe8): Linear(in_features=100, out_features=100, bias=True)
  (fc90): Linear(in_features=100, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=100, bias=True)
  (fe9): Linear(in_features=100, out_features=100, bias=True)
  (gmfc100): Linear(in_features=100, out_features=1, bias=True)
  (gmfc101): Linear(in_features=100, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=100, bias=True)
  (gmfe100): Linear(in_features=100, out_features=100, bias=True)
  (gmfe101): Linear(in_features=100, out_features=100, bias=True)
  (gmfc110): Linear(in_features=100, out_features=1, bias=True)
  (gmfc111): Linear(in_features=100, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=100, bias=True)
  (gmfe110): Linear(in_features=100, out_features=100, bias=True)
  (gmfe111): Linear(in_features=100, out_features=100, bias=True)
  (gmfc120): Linear(in_features=100, out_features=1, bias=True)
  (gmfc121): Linear(in_features=100, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=100, bias=True)
  (gmfe120): Linear(in_features=100, out_features=100, bias=True)
  (gmfe121): Linear(in_features=100, out_features=100, bias=True)
  (fc130): Linear(in_features=100, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=100, bias=True)
  (fe13): Linear(in_features=100, out_features=100, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=500, bias=True)
  (inputbn): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=500, out_features=500, bias=True)
  (bn0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=500, out_features=500, bias=True)
  (bn1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=500, out_features=500, bias=True)
  (bn2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=500, out_features=500, bias=True)
  (bn3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc4): Linear(in_features=500, out_features=500, bias=True)
  (bn4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=500, out_features=1, bias=True)
)
(2, True, 133)
(30148, 2)
-----------Epoch 0-----------
iterator 0, D_Loss:1.4599378108978271, G_Loss:7.840610980987549

iterator 100, D_Loss:1.417277216911316, G_Loss:9.103790283203125

iterator 200, D_Loss:1.4254894256591797, G_Loss:1.334517240524292

iterator 300, D_Loss:1.4064898490905762, G_Loss:1.606318712234497

iterator 400, D_Loss:1.369500756263733, G_Loss:1.216951608657837

iterator 500, D_Loss:1.383747935295105, G_Loss:1.409221887588501

iterator 600, D_Loss:1.3595399856567383, G_Loss:1.3521974086761475

iterator 700, D_Loss:1.3767905235290527, G_Loss:1.221894383430481

iterator 800, D_Loss:1.3803191184997559, G_Loss:1.1123340129852295

iterator 900, D_Loss:1.361412525177002, G_Loss:1.1278823614120483

iterator 1000, D_Loss:1.3614614009857178, G_Loss:1.1361478567123413

iterator 1100, D_Loss:1.3748788833618164, G_Loss:1.0328211784362793

iterator 1200, D_Loss:1.3682539463043213, G_Loss:1.0156753063201904

iterator 1300, D_Loss:1.3777904510498047, G_Loss:0.9984976649284363

iterator 1400, D_Loss:1.3601977825164795, G_Loss:0.9797395467758179

iterator 1500, D_Loss:1.3665461540222168, G_Loss:0.9533766508102417

iterator 1600, D_Loss:1.3691918849945068, G_Loss:0.9266672730445862

iterator 1700, D_Loss:1.357288122177124, G_Loss:0.995023787021637

iterator 1800, D_Loss:1.3532767295837402, G_Loss:0.9754838347434998

iterator 1900, D_Loss:1.3378708362579346, G_Loss:0.9853387475013733

iterator 2000, D_Loss:1.3293108940124512, G_Loss:0.9738821983337402

iterator 2100, D_Loss:1.3309247493743896, G_Loss:1.0006943941116333

iterator 2200, D_Loss:1.2743240594863892, G_Loss:1.146101474761963

iterator 2300, D_Loss:1.228623390197754, G_Loss:1.2245630025863647

iterator 2400, D_Loss:1.152630090713501, G_Loss:1.4319775104522705

iterator 2500, D_Loss:0.9828622341156006, G_Loss:1.6433910131454468

iterator 2600, D_Loss:0.9572573304176331, G_Loss:1.7164933681488037

iterator 2700, D_Loss:0.8926060199737549, G_Loss:2.0309646129608154

iterator 2800, D_Loss:0.7706416845321655, G_Loss:2.010471820831299

iterator 2900, D_Loss:0.8304125070571899, G_Loss:1.881346583366394

iterator 3000, D_Loss:0.7341920733451843, G_Loss:2.3899002075195312

iterator 3100, D_Loss:0.5877313613891602, G_Loss:2.9635040760040283

iterator 3200, D_Loss:0.6032495498657227, G_Loss:2.6576976776123047

iterator 3300, D_Loss:0.7571152448654175, G_Loss:3.3980753421783447

iterator 3400, D_Loss:0.6029528975486755, G_Loss:3.4665088653564453

iterator 3500, D_Loss:0.5274098515510559, G_Loss:3.0312559604644775

iterator 3600, D_Loss:0.6123889684677124, G_Loss:2.906165599822998

iterator 3700, D_Loss:0.5184811353683472, G_Loss:1.1980913877487183

iterator 3800, D_Loss:0.7176781892776489, G_Loss:3.636422634124756

iterator 3900, D_Loss:0.904664158821106, G_Loss:3.146899700164795

iterator 4000, D_Loss:0.5443809628486633, G_Loss:1.7956819534301758

iterator 4100, D_Loss:0.5285833477973938, G_Loss:2.8625221252441406

iterator 4200, D_Loss:0.5944932103157043, G_Loss:2.82547926902771

iterator 4300, D_Loss:0.5603747367858887, G_Loss:4.068248748779297

iterator 4400, D_Loss:0.552577793598175, G_Loss:3.827965259552002

iterator 4500, D_Loss:0.605492115020752, G_Loss:2.3288915157318115

iterator 4600, D_Loss:0.48760032653808594, G_Loss:3.682769298553467

iterator 4700, D_Loss:0.5411206483840942, G_Loss:4.079690933227539

iterator 4800, D_Loss:0.4962858259677887, G_Loss:3.7798075675964355

iterator 4900, D_Loss:0.4703179597854614, G_Loss:3.4590578079223633

-----------Epoch 1-----------
iterator 0, D_Loss:0.6121386289596558, G_Loss:4.66165018081665

iterator 100, D_Loss:0.5215955376625061, G_Loss:3.449408531188965

iterator 200, D_Loss:0.526246190071106, G_Loss:3.3673717975616455

iterator 300, D_Loss:0.5973836779594421, G_Loss:3.5296072959899902

iterator 400, D_Loss:0.7271682024002075, G_Loss:4.52094841003418

iterator 500, D_Loss:0.5658121109008789, G_Loss:3.0536999702453613

iterator 600, D_Loss:0.5353334546089172, G_Loss:4.153990745544434

iterator 700, D_Loss:0.5343866944313049, G_Loss:4.712296485900879

iterator 800, D_Loss:0.4976584017276764, G_Loss:4.401603698730469

iterator 900, D_Loss:0.48414361476898193, G_Loss:3.6793556213378906

iterator 1000, D_Loss:0.4632497727870941, G_Loss:4.672596454620361

iterator 1100, D_Loss:0.5535842180252075, G_Loss:3.4585700035095215

iterator 1200, D_Loss:0.5229520201683044, G_Loss:3.788142442703247

iterator 1300, D_Loss:0.5154615640640259, G_Loss:4.572540760040283

iterator 1400, D_Loss:0.4476132094860077, G_Loss:3.159632444381714

iterator 1500, D_Loss:0.49852055311203003, G_Loss:5.69301700592041

iterator 1600, D_Loss:0.47044435143470764, G_Loss:5.8725080490112305

iterator 1700, D_Loss:0.46321210265159607, G_Loss:5.47336483001709

iterator 1800, D_Loss:0.5214259028434753, G_Loss:5.587010860443115

iterator 1900, D_Loss:0.49407902359962463, G_Loss:4.955116271972656

iterator 2000, D_Loss:0.4745762348175049, G_Loss:5.295536994934082

iterator 2100, D_Loss:0.9151573181152344, G_Loss:2.698507070541382

iterator 2200, D_Loss:0.43734732270240784, G_Loss:3.850306510925293

iterator 2300, D_Loss:0.462367981672287, G_Loss:4.141400337219238

iterator 2400, D_Loss:0.7875092625617981, G_Loss:3.9242331981658936

iterator 2500, D_Loss:0.5309507846832275, G_Loss:3.436342477798462

iterator 2600, D_Loss:0.5632364749908447, G_Loss:3.2830212116241455

iterator 2700, D_Loss:0.5328596830368042, G_Loss:2.930164337158203

iterator 2800, D_Loss:0.4683128595352173, G_Loss:4.533490180969238

iterator 2900, D_Loss:0.46295636892318726, G_Loss:3.79495906829834

iterator 3000, D_Loss:0.513214647769928, G_Loss:5.31054162979126

iterator 3100, D_Loss:0.5725642442703247, G_Loss:4.7578511238098145

iterator 3200, D_Loss:0.5253278613090515, G_Loss:6.571164131164551

iterator 3300, D_Loss:0.6850069761276245, G_Loss:4.0655198097229

iterator 3400, D_Loss:0.5094136595726013, G_Loss:3.0248942375183105

iterator 3500, D_Loss:0.7921061515808105, G_Loss:4.355213165283203

iterator 3600, D_Loss:0.5800442695617676, G_Loss:1.4727418422698975

iterator 3700, D_Loss:0.5457769632339478, G_Loss:2.6750917434692383

iterator 3800, D_Loss:0.6768785119056702, G_Loss:4.111899375915527

iterator 3900, D_Loss:0.47053825855255127, G_Loss:5.1305437088012695

iterator 4000, D_Loss:0.5134952664375305, G_Loss:5.5968852043151855

iterator 4100, D_Loss:0.8904266357421875, G_Loss:4.4716362953186035

iterator 4200, D_Loss:0.4590546488761902, G_Loss:3.6703197956085205

iterator 4300, D_Loss:0.64158695936203, G_Loss:3.8609066009521484

iterator 4400, D_Loss:0.4883289337158203, G_Loss:3.745952606201172

iterator 4500, D_Loss:0.6009084582328796, G_Loss:5.9445414543151855

iterator 4600, D_Loss:0.515315592288971, G_Loss:2.1011440753936768

iterator 4700, D_Loss:1.0819200277328491, G_Loss:4.7805562019348145

iterator 4800, D_Loss:0.48444515466690063, G_Loss:4.82257604598999

iterator 4900, D_Loss:0.6071645021438599, G_Loss:4.032607555389404

-----------Epoch 2-----------
iterator 0, D_Loss:0.5416236519813538, G_Loss:3.417585849761963

iterator 100, D_Loss:0.7161492109298706, G_Loss:4.012195587158203

iterator 200, D_Loss:0.6094464063644409, G_Loss:2.24119234085083

iterator 300, D_Loss:0.517497181892395, G_Loss:3.7608718872070312

iterator 400, D_Loss:0.5848022103309631, G_Loss:4.059596061706543

iterator 500, D_Loss:0.47901326417922974, G_Loss:4.347413063049316

iterator 600, D_Loss:0.5597405433654785, G_Loss:3.6356441974639893

iterator 700, D_Loss:0.48522812128067017, G_Loss:4.393503665924072

iterator 800, D_Loss:0.48300907015800476, G_Loss:6.422138214111328

iterator 900, D_Loss:0.4809719920158386, G_Loss:4.7101945877075195

iterator 1000, D_Loss:0.4473126232624054, G_Loss:5.013862133026123

iterator 1100, D_Loss:0.4909973442554474, G_Loss:5.337482929229736

iterator 1200, D_Loss:0.45009854435920715, G_Loss:5.2963666915893555

iterator 1300, D_Loss:0.466436505317688, G_Loss:3.534827947616577

iterator 1400, D_Loss:0.4258788824081421, G_Loss:3.4165990352630615

iterator 1500, D_Loss:0.4564765989780426, G_Loss:5.679152488708496

iterator 1600, D_Loss:0.5744346380233765, G_Loss:6.024858474731445

iterator 1700, D_Loss:0.539432942867279, G_Loss:1.986188530921936

iterator 1800, D_Loss:0.5297261476516724, G_Loss:4.561207294464111

iterator 1900, D_Loss:0.4987896680831909, G_Loss:3.13163423538208

iterator 2000, D_Loss:0.5255661606788635, G_Loss:1.188321590423584

iterator 2100, D_Loss:0.4462163746356964, G_Loss:4.977185249328613

iterator 2200, D_Loss:0.6091338992118835, G_Loss:4.205686569213867

iterator 2300, D_Loss:0.8784099221229553, G_Loss:3.666921854019165

iterator 2400, D_Loss:0.4636906683444977, G_Loss:5.533965587615967

iterator 2500, D_Loss:0.4915451109409332, G_Loss:4.289694786071777

iterator 2600, D_Loss:0.4965812861919403, G_Loss:3.2235960960388184

iterator 2700, D_Loss:0.6450344920158386, G_Loss:4.990520477294922

iterator 2800, D_Loss:0.5123871564865112, G_Loss:1.2925522327423096

iterator 2900, D_Loss:0.5007717609405518, G_Loss:3.932750701904297

iterator 3000, D_Loss:0.4562430679798126, G_Loss:7.0834221839904785

iterator 3100, D_Loss:0.4752937853336334, G_Loss:5.826668739318848

iterator 3200, D_Loss:0.48003602027893066, G_Loss:6.968997955322266

iterator 3300, D_Loss:0.49437475204467773, G_Loss:7.138538837432861

iterator 3400, D_Loss:0.7260188460350037, G_Loss:5.263688087463379

iterator 3500, D_Loss:0.5645424127578735, G_Loss:4.443134784698486

iterator 3600, D_Loss:0.650453507900238, G_Loss:2.584717273712158

iterator 3700, D_Loss:0.6012663841247559, G_Loss:6.0938310623168945

iterator 3800, D_Loss:0.8629357218742371, G_Loss:6.195189952850342

iterator 3900, D_Loss:1.05251944065094, G_Loss:4.758119106292725

iterator 4000, D_Loss:0.5539072751998901, G_Loss:3.967982769012451

iterator 4100, D_Loss:0.6272780895233154, G_Loss:2.821126937866211

iterator 4200, D_Loss:0.46207258105278015, G_Loss:2.9358105659484863

iterator 4300, D_Loss:0.4707176983356476, G_Loss:3.463743209838867

iterator 4400, D_Loss:0.4519490897655487, G_Loss:3.8936758041381836

iterator 4500, D_Loss:0.9726490378379822, G_Loss:4.147324085235596

iterator 4600, D_Loss:0.46738865971565247, G_Loss:1.0604143142700195

iterator 4700, D_Loss:0.7157020568847656, G_Loss:5.040689945220947

iterator 4800, D_Loss:0.47272977232933044, G_Loss:4.601232528686523

iterator 4900, D_Loss:0.520716667175293, G_Loss:3.8922572135925293

-----------Epoch 3-----------
iterator 0, D_Loss:0.6247480511665344, G_Loss:4.041558265686035

iterator 100, D_Loss:0.5338899493217468, G_Loss:3.1861281394958496

iterator 200, D_Loss:0.4492489993572235, G_Loss:5.1349592208862305

iterator 300, D_Loss:0.4498867392539978, G_Loss:5.136251449584961

iterator 400, D_Loss:0.45995256304740906, G_Loss:4.129376411437988

iterator 500, D_Loss:0.6443239450454712, G_Loss:1.653358817100525

iterator 600, D_Loss:0.4524678587913513, G_Loss:5.588172435760498

iterator 700, D_Loss:0.44999244809150696, G_Loss:6.383047103881836

iterator 800, D_Loss:0.4674166738986969, G_Loss:6.911268711090088

iterator 900, D_Loss:0.54646897315979, G_Loss:5.614208698272705

iterator 1000, D_Loss:0.44452735781669617, G_Loss:6.823050498962402

iterator 1100, D_Loss:0.5117493867874146, G_Loss:2.798848867416382

iterator 1200, D_Loss:0.5282190442085266, G_Loss:5.111298561096191

iterator 1300, D_Loss:0.999674379825592, G_Loss:4.497596263885498

iterator 1400, D_Loss:0.45437687635421753, G_Loss:6.282287120819092

iterator 1500, D_Loss:0.48038020730018616, G_Loss:5.725303649902344

iterator 1600, D_Loss:0.6540943384170532, G_Loss:3.5972280502319336

iterator 1700, D_Loss:0.48006728291511536, G_Loss:5.318674564361572

iterator 1800, D_Loss:0.46456730365753174, G_Loss:4.540984153747559

iterator 1900, D_Loss:0.45138147473335266, G_Loss:6.242825508117676

iterator 2000, D_Loss:0.4568484425544739, G_Loss:5.58815336227417

iterator 2100, D_Loss:0.5308235287666321, G_Loss:4.141031742095947

iterator 2200, D_Loss:0.5144035816192627, G_Loss:4.845022201538086

iterator 2300, D_Loss:0.44959232211112976, G_Loss:4.630934238433838

iterator 2400, D_Loss:0.5003700256347656, G_Loss:5.253252983093262

iterator 2500, D_Loss:0.4713040590286255, G_Loss:2.9193387031555176

iterator 2600, D_Loss:0.45097628235816956, G_Loss:7.743488788604736

iterator 2700, D_Loss:0.5078241229057312, G_Loss:5.141251087188721

iterator 2800, D_Loss:0.5066616535186768, G_Loss:4.603048324584961

iterator 2900, D_Loss:0.49610838294029236, G_Loss:3.9129490852355957

iterator 3000, D_Loss:0.49684974551200867, G_Loss:7.276479244232178

iterator 3100, D_Loss:0.4977536201477051, G_Loss:3.7128167152404785

iterator 3200, D_Loss:0.5014598965644836, G_Loss:8.164151191711426

iterator 3300, D_Loss:0.44568854570388794, G_Loss:5.293821334838867

iterator 3400, D_Loss:0.4432116150856018, G_Loss:6.832340717315674

iterator 3500, D_Loss:0.5671579241752625, G_Loss:4.711300849914551

iterator 3600, D_Loss:0.45712268352508545, G_Loss:5.749223232269287

iterator 3700, D_Loss:0.4481656849384308, G_Loss:4.430877685546875

iterator 3800, D_Loss:0.4544563293457031, G_Loss:5.508240222930908

iterator 3900, D_Loss:0.44386205077171326, G_Loss:3.5761969089508057

iterator 4000, D_Loss:0.5263733267784119, G_Loss:4.632775783538818

iterator 4100, D_Loss:0.4807814359664917, G_Loss:7.391148567199707

iterator 4200, D_Loss:0.4143918752670288, G_Loss:8.14849853515625

iterator 4300, D_Loss:0.4395814538002014, G_Loss:8.509267807006836

iterator 4400, D_Loss:0.5190905332565308, G_Loss:5.731826305389404

iterator 4500, D_Loss:0.7397109270095825, G_Loss:5.959664344787598

iterator 4600, D_Loss:0.5328811407089233, G_Loss:6.781264781951904

iterator 4700, D_Loss:0.4339042603969574, G_Loss:6.178966522216797

iterator 4800, D_Loss:0.46356141567230225, G_Loss:7.620502948760986

iterator 4900, D_Loss:0.43523868918418884, G_Loss:6.886191368103027

-----------Epoch 4-----------
iterator 0, D_Loss:0.4666157364845276, G_Loss:4.01779317855835

iterator 100, D_Loss:0.4835983216762543, G_Loss:8.805818557739258

iterator 200, D_Loss:0.4512150287628174, G_Loss:6.086332321166992

iterator 300, D_Loss:0.4460422098636627, G_Loss:3.8522603511810303

iterator 400, D_Loss:0.4560210108757019, G_Loss:2.7673873901367188

iterator 500, D_Loss:0.452593058347702, G_Loss:4.054033279418945

iterator 600, D_Loss:0.4299010634422302, G_Loss:8.576568603515625

iterator 700, D_Loss:1.757241129875183, G_Loss:7.486294746398926

iterator 800, D_Loss:0.4456346929073334, G_Loss:5.230391502380371

iterator 900, D_Loss:0.5332472920417786, G_Loss:6.72618293762207

iterator 1000, D_Loss:0.4407106041908264, G_Loss:5.0338029861450195

iterator 1100, D_Loss:0.44705456495285034, G_Loss:6.389373779296875

iterator 1200, D_Loss:5.7765984535217285, G_Loss:5.119082927703857

iterator 1300, D_Loss:0.517818033695221, G_Loss:6.813522815704346

iterator 1400, D_Loss:0.441757470369339, G_Loss:5.574695587158203

iterator 1500, D_Loss:0.42601248621940613, G_Loss:6.269338607788086

iterator 1600, D_Loss:0.4389531910419464, G_Loss:7.418091773986816

iterator 1700, D_Loss:0.45504945516586304, G_Loss:3.0827817916870117

iterator 1800, D_Loss:0.4547405540943146, G_Loss:4.163635730743408

iterator 1900, D_Loss:0.9930026531219482, G_Loss:10.985795974731445

iterator 2000, D_Loss:0.42429444193840027, G_Loss:6.946290493011475

iterator 2100, D_Loss:0.4564130902290344, G_Loss:6.012655735015869

iterator 2200, D_Loss:0.4750540554523468, G_Loss:6.383386611938477

iterator 2300, D_Loss:0.4437863230705261, G_Loss:8.856098175048828

iterator 2400, D_Loss:0.44536322355270386, G_Loss:8.256234169006348

iterator 2500, D_Loss:0.44071152806282043, G_Loss:9.183402061462402

iterator 2600, D_Loss:0.4294913411140442, G_Loss:8.424141883850098

iterator 2700, D_Loss:0.48404380679130554, G_Loss:4.134758949279785

iterator 2800, D_Loss:0.42160114645957947, G_Loss:2.9867024421691895

iterator 2900, D_Loss:0.42190253734588623, G_Loss:6.935187339782715

iterator 3000, D_Loss:0.4878872334957123, G_Loss:7.134913444519043

iterator 3100, D_Loss:0.4355103671550751, G_Loss:5.980331897735596

iterator 3200, D_Loss:0.45310965180397034, G_Loss:5.462894916534424

iterator 3300, D_Loss:0.4544888138771057, G_Loss:9.745850563049316

iterator 3400, D_Loss:0.4519093632698059, G_Loss:9.336702346801758

iterator 3500, D_Loss:0.4564882516860962, G_Loss:2.9329910278320312

iterator 3600, D_Loss:0.43825963139533997, G_Loss:7.257789611816406

iterator 3700, D_Loss:0.4957398474216461, G_Loss:7.039464473724365

iterator 3800, D_Loss:0.4325655996799469, G_Loss:9.749253273010254

iterator 3900, D_Loss:0.43408268690109253, G_Loss:5.7416090965271

iterator 4000, D_Loss:0.40765103697776794, G_Loss:4.741863250732422

iterator 4100, D_Loss:0.6061050295829773, G_Loss:2.059663772583008

iterator 4200, D_Loss:0.4570808410644531, G_Loss:6.717350482940674

iterator 4300, D_Loss:0.4860020875930786, G_Loss:3.2443392276763916

iterator 4400, D_Loss:0.46318694949150085, G_Loss:5.400389671325684

iterator 4500, D_Loss:0.4832063615322113, G_Loss:7.385538101196289

iterator 4600, D_Loss:0.4418109357357025, G_Loss:7.04721736907959

iterator 4700, D_Loss:0.4483183026313782, G_Loss:6.16431188583374

iterator 4800, D_Loss:0.4583999812602997, G_Loss:7.161328315734863

iterator 4900, D_Loss:0.44927313923835754, G_Loss:4.3218560218811035

-----------Epoch 5-----------
iterator 0, D_Loss:0.44890064001083374, G_Loss:7.481235027313232

iterator 100, D_Loss:0.449989914894104, G_Loss:6.820298671722412

iterator 200, D_Loss:0.4437097907066345, G_Loss:6.075721263885498

iterator 300, D_Loss:0.4479372799396515, G_Loss:8.043129920959473

iterator 400, D_Loss:0.44093939661979675, G_Loss:5.127844333648682

iterator 500, D_Loss:0.42237791419029236, G_Loss:10.189661026000977

iterator 600, D_Loss:0.44411545991897583, G_Loss:7.663398742675781

iterator 700, D_Loss:0.44073280692100525, G_Loss:7.17876672744751

iterator 800, D_Loss:3.5895049571990967, G_Loss:8.756797790527344

iterator 900, D_Loss:0.4357481300830841, G_Loss:8.049962997436523

iterator 1000, D_Loss:0.44805529713630676, G_Loss:8.476165771484375

iterator 1100, D_Loss:0.48183950781822205, G_Loss:9.059296607971191

iterator 1200, D_Loss:0.449954092502594, G_Loss:10.701433181762695

iterator 1300, D_Loss:0.43575796484947205, G_Loss:10.522214889526367

iterator 1400, D_Loss:0.44044002890586853, G_Loss:7.262268543243408

iterator 1500, D_Loss:0.45069587230682373, G_Loss:10.125353813171387

iterator 1600, D_Loss:0.43331706523895264, G_Loss:8.39537239074707

iterator 1700, D_Loss:0.4235047399997711, G_Loss:9.377880096435547

iterator 1800, D_Loss:0.4177001416683197, G_Loss:10.178434371948242

iterator 1900, D_Loss:0.4169243574142456, G_Loss:9.117084503173828

iterator 2000, D_Loss:0.43491408228874207, G_Loss:10.019354820251465

iterator 2100, D_Loss:0.42133501172065735, G_Loss:10.248980522155762

iterator 2200, D_Loss:0.4305833876132965, G_Loss:8.326748847961426

iterator 2300, D_Loss:0.4176763892173767, G_Loss:10.63779067993164

iterator 2400, D_Loss:0.4310302734375, G_Loss:9.695063591003418

iterator 2500, D_Loss:0.4290030598640442, G_Loss:8.361571311950684

iterator 2600, D_Loss:0.4207824766635895, G_Loss:11.073080062866211

iterator 2700, D_Loss:0.41009989380836487, G_Loss:10.078413009643555

iterator 2800, D_Loss:0.4533245265483856, G_Loss:10.087982177734375

iterator 2900, D_Loss:0.4322091341018677, G_Loss:8.774696350097656

iterator 3000, D_Loss:0.4337129592895508, G_Loss:8.991561889648438

iterator 3100, D_Loss:0.4311375617980957, G_Loss:10.890121459960938

iterator 3200, D_Loss:0.4430201053619385, G_Loss:10.14407730102539

iterator 3300, D_Loss:0.4523659348487854, G_Loss:10.77412223815918

iterator 3400, D_Loss:0.4371976852416992, G_Loss:11.730502128601074

iterator 3500, D_Loss:0.4333858788013458, G_Loss:11.832338333129883

iterator 3600, D_Loss:0.4358229637145996, G_Loss:10.369060516357422

iterator 3700, D_Loss:0.4119808077812195, G_Loss:5.975619792938232

iterator 3800, D_Loss:0.4320792853832245, G_Loss:9.861844062805176

iterator 3900, D_Loss:0.44031822681427, G_Loss:9.595622062683105

iterator 4000, D_Loss:0.42325228452682495, G_Loss:10.565661430358887

iterator 4100, D_Loss:0.4171614348888397, G_Loss:10.175829887390137

iterator 4200, D_Loss:0.4290323853492737, G_Loss:9.659594535827637

iterator 4300, D_Loss:0.42646878957748413, G_Loss:9.616365432739258

iterator 4400, D_Loss:0.43536072969436646, G_Loss:10.19258975982666

iterator 4500, D_Loss:0.4027433395385742, G_Loss:10.244386672973633

iterator 4600, D_Loss:0.43787461519241333, G_Loss:9.481502532958984

iterator 4700, D_Loss:0.4410021901130676, G_Loss:10.83211898803711

iterator 4800, D_Loss:0.42069417238235474, G_Loss:7.935827255249023

iterator 4900, D_Loss:0.42220938205718994, G_Loss:10.796171188354492

-----------Epoch 6-----------
iterator 0, D_Loss:0.43723732233047485, G_Loss:9.818991661071777

iterator 100, D_Loss:0.43353071808815, G_Loss:9.0693941116333

iterator 200, D_Loss:0.3933525085449219, G_Loss:10.65004825592041

iterator 300, D_Loss:0.42404651641845703, G_Loss:10.009740829467773

iterator 400, D_Loss:0.4325193762779236, G_Loss:10.217379570007324

iterator 500, D_Loss:0.41597485542297363, G_Loss:11.091012001037598

iterator 600, D_Loss:0.43409276008605957, G_Loss:12.05108642578125

iterator 700, D_Loss:0.4455360770225525, G_Loss:9.77629280090332

iterator 800, D_Loss:0.41781315207481384, G_Loss:11.111385345458984

iterator 900, D_Loss:0.426693320274353, G_Loss:9.10610580444336

iterator 1000, D_Loss:0.41498345136642456, G_Loss:10.390533447265625

iterator 1100, D_Loss:0.4359196126461029, G_Loss:10.154261589050293

iterator 1200, D_Loss:0.4306493103504181, G_Loss:9.972201347351074

iterator 1300, D_Loss:0.4222077429294586, G_Loss:11.229607582092285

iterator 1400, D_Loss:0.44665229320526123, G_Loss:10.29185962677002

iterator 1500, D_Loss:0.43438684940338135, G_Loss:10.460688591003418

iterator 1600, D_Loss:0.43968021869659424, G_Loss:9.2400541305542

iterator 1700, D_Loss:0.4297846257686615, G_Loss:8.765920639038086

iterator 1800, D_Loss:0.4324713945388794, G_Loss:10.227228164672852

iterator 1900, D_Loss:0.4337552785873413, G_Loss:10.505741119384766

iterator 2000, D_Loss:0.41091325879096985, G_Loss:9.289176940917969

iterator 2100, D_Loss:0.417438805103302, G_Loss:10.783035278320312

iterator 2200, D_Loss:0.440812349319458, G_Loss:9.63010025024414

iterator 2300, D_Loss:0.4365076422691345, G_Loss:10.063807487487793

iterator 2400, D_Loss:0.4138486981391907, G_Loss:9.877511024475098

iterator 2500, D_Loss:0.41122034192085266, G_Loss:10.296242713928223

iterator 2600, D_Loss:0.42429471015930176, G_Loss:9.024248123168945

iterator 2700, D_Loss:0.443217009305954, G_Loss:9.567842483520508

iterator 2800, D_Loss:0.43231526017189026, G_Loss:10.245614051818848

iterator 2900, D_Loss:0.428970068693161, G_Loss:9.533422470092773

iterator 3000, D_Loss:0.43965944647789, G_Loss:10.827607154846191

iterator 3100, D_Loss:0.4274558126926422, G_Loss:10.929021835327148

iterator 3200, D_Loss:0.4239443242549896, G_Loss:9.560678482055664

iterator 3300, D_Loss:0.41724488139152527, G_Loss:10.43799877166748

iterator 3400, D_Loss:0.4263923764228821, G_Loss:9.765409469604492

iterator 3500, D_Loss:0.4164443910121918, G_Loss:10.690286636352539

iterator 3600, D_Loss:0.4435487985610962, G_Loss:10.865900993347168

iterator 3700, D_Loss:0.4232511818408966, G_Loss:10.04793930053711

iterator 3800, D_Loss:0.43668434023857117, G_Loss:10.115107536315918

iterator 3900, D_Loss:0.4397895038127899, G_Loss:10.366954803466797

iterator 4000, D_Loss:0.4103551506996155, G_Loss:11.394584655761719

iterator 4100, D_Loss:0.4265650808811188, G_Loss:12.54228401184082

iterator 4200, D_Loss:0.4268679916858673, G_Loss:11.011208534240723

iterator 4300, D_Loss:0.4087579846382141, G_Loss:11.35515022277832

iterator 4400, D_Loss:0.42608168721199036, G_Loss:11.964412689208984

iterator 4500, D_Loss:0.4209499657154083, G_Loss:12.403463363647461

iterator 4600, D_Loss:0.41059908270835876, G_Loss:11.167276382446289

iterator 4700, D_Loss:0.42268106341362, G_Loss:10.94876766204834

iterator 4800, D_Loss:0.43315473198890686, G_Loss:11.222540855407715

iterator 4900, D_Loss:0.43300512433052063, G_Loss:11.092671394348145

-----------Epoch 7-----------
iterator 0, D_Loss:0.43111130595207214, G_Loss:10.747504234313965

iterator 100, D_Loss:0.41119909286499023, G_Loss:12.036759376525879

iterator 200, D_Loss:0.43221402168273926, G_Loss:11.316835403442383

iterator 300, D_Loss:0.4259530305862427, G_Loss:9.638505935668945

iterator 400, D_Loss:0.429027795791626, G_Loss:11.267380714416504

iterator 500, D_Loss:0.43419206142425537, G_Loss:12.3556489944458

iterator 600, D_Loss:0.43145349621772766, G_Loss:11.969782829284668

iterator 700, D_Loss:0.40664777159690857, G_Loss:9.419450759887695

iterator 800, D_Loss:0.44051462411880493, G_Loss:10.213640213012695

iterator 900, D_Loss:0.42317619919776917, G_Loss:8.231267929077148

iterator 1000, D_Loss:0.42158475518226624, G_Loss:10.801704406738281

iterator 1100, D_Loss:0.44286248087882996, G_Loss:11.2017822265625

iterator 1200, D_Loss:0.4319312274456024, G_Loss:10.78385066986084

iterator 1300, D_Loss:0.427756130695343, G_Loss:11.556884765625

iterator 1400, D_Loss:0.4396130442619324, G_Loss:10.778526306152344

iterator 1500, D_Loss:0.4264727532863617, G_Loss:11.463541030883789

iterator 1600, D_Loss:0.4326644539833069, G_Loss:11.10615348815918

iterator 1700, D_Loss:0.41971555352211, G_Loss:10.549821853637695

iterator 1800, D_Loss:0.43688979744911194, G_Loss:9.340958595275879

iterator 1900, D_Loss:0.4102466404438019, G_Loss:11.082000732421875

iterator 2000, D_Loss:0.4258106052875519, G_Loss:10.76738166809082

iterator 2100, D_Loss:0.42210128903388977, G_Loss:13.247331619262695

iterator 2200, D_Loss:0.41772472858428955, G_Loss:12.443246841430664

iterator 2300, D_Loss:0.4213429093360901, G_Loss:11.280559539794922

iterator 2400, D_Loss:0.4171271324157715, G_Loss:10.146970748901367

iterator 2500, D_Loss:0.4282056987285614, G_Loss:11.095598220825195

iterator 2600, D_Loss:0.4312947690486908, G_Loss:10.490128517150879

iterator 2700, D_Loss:0.42421045899391174, G_Loss:11.177323341369629

iterator 2800, D_Loss:0.43494483828544617, G_Loss:10.73955249786377

iterator 2900, D_Loss:0.4294019937515259, G_Loss:11.587237358093262

iterator 3000, D_Loss:0.4231323301792145, G_Loss:10.619060516357422

iterator 3100, D_Loss:0.40015825629234314, G_Loss:12.5950927734375

iterator 3200, D_Loss:0.42459636926651, G_Loss:12.243755340576172

iterator 3300, D_Loss:0.41480809450149536, G_Loss:12.74732494354248

iterator 3400, D_Loss:0.41313979029655457, G_Loss:11.839488983154297

iterator 3500, D_Loss:0.41560983657836914, G_Loss:11.955999374389648

iterator 3600, D_Loss:0.4063102900981903, G_Loss:12.490547180175781

iterator 3700, D_Loss:0.4192427694797516, G_Loss:12.201820373535156

iterator 3800, D_Loss:0.43669191002845764, G_Loss:12.046578407287598

iterator 3900, D_Loss:0.4291263818740845, G_Loss:12.79935073852539

iterator 4000, D_Loss:0.4262845516204834, G_Loss:11.868106842041016

iterator 4100, D_Loss:0.4392302632331848, G_Loss:11.733649253845215

iterator 4200, D_Loss:0.42376449704170227, G_Loss:12.01085376739502

iterator 4300, D_Loss:0.40549445152282715, G_Loss:12.344429969787598

iterator 4400, D_Loss:0.4189509153366089, G_Loss:12.371296882629395

iterator 4500, D_Loss:0.4354868233203888, G_Loss:12.607797622680664

iterator 4600, D_Loss:0.42037785053253174, G_Loss:12.116415977478027

iterator 4700, D_Loss:0.4215176999568939, G_Loss:12.825883865356445

iterator 4800, D_Loss:0.4443824887275696, G_Loss:12.647339820861816

iterator 4900, D_Loss:0.4415077865123749, G_Loss:13.75906753540039

-----------Epoch 8-----------
iterator 0, D_Loss:0.41127946972846985, G_Loss:13.651358604431152

iterator 100, D_Loss:0.44514843821525574, G_Loss:11.839853286743164

iterator 200, D_Loss:0.41904816031455994, G_Loss:13.03111457824707

iterator 300, D_Loss:0.4241071939468384, G_Loss:12.341657638549805

iterator 400, D_Loss:0.4201168715953827, G_Loss:12.582063674926758

iterator 500, D_Loss:0.4269358217716217, G_Loss:13.869965553283691

iterator 600, D_Loss:0.4304049015045166, G_Loss:13.75444507598877

iterator 700, D_Loss:0.42409375309944153, G_Loss:12.74062728881836

iterator 800, D_Loss:0.4227098822593689, G_Loss:13.192459106445312

iterator 900, D_Loss:0.4210045635700226, G_Loss:13.209609031677246

iterator 1000, D_Loss:0.420197069644928, G_Loss:12.311639785766602

iterator 1100, D_Loss:0.43951162695884705, G_Loss:12.467828750610352

iterator 1200, D_Loss:0.4224397838115692, G_Loss:12.985062599182129

iterator 1300, D_Loss:0.41027766466140747, G_Loss:12.651631355285645

iterator 1400, D_Loss:0.4279577136039734, G_Loss:13.539125442504883

iterator 1500, D_Loss:0.4178716242313385, G_Loss:12.021157264709473

iterator 1600, D_Loss:0.42699551582336426, G_Loss:13.163673400878906

iterator 1700, D_Loss:0.43718600273132324, G_Loss:13.142784118652344

iterator 1800, D_Loss:0.40478959679603577, G_Loss:12.157944679260254

iterator 1900, D_Loss:0.41622886061668396, G_Loss:12.355979919433594

iterator 2000, D_Loss:0.4370182156562805, G_Loss:13.497262001037598

iterator 2100, D_Loss:0.4288347363471985, G_Loss:12.510957717895508

iterator 2200, D_Loss:0.42105770111083984, G_Loss:11.630236625671387

iterator 2300, D_Loss:0.43462613224983215, G_Loss:13.108604431152344

iterator 2400, D_Loss:0.40693509578704834, G_Loss:12.150151252746582

iterator 2500, D_Loss:0.43535444140434265, G_Loss:12.734332084655762

iterator 2600, D_Loss:0.4376920163631439, G_Loss:13.163984298706055

iterator 2700, D_Loss:0.4152132272720337, G_Loss:13.244138717651367

iterator 2800, D_Loss:0.4311646819114685, G_Loss:13.671731948852539

iterator 2900, D_Loss:0.4270162284374237, G_Loss:14.116671562194824

iterator 3000, D_Loss:0.4326157867908478, G_Loss:12.867058753967285

iterator 3100, D_Loss:0.42407381534576416, G_Loss:13.19619083404541

iterator 3200, D_Loss:0.42785659432411194, G_Loss:13.623490333557129

iterator 3300, D_Loss:0.4350987374782562, G_Loss:13.853879928588867

iterator 3400, D_Loss:0.4315277934074402, G_Loss:13.997247695922852

iterator 3500, D_Loss:0.4265306890010834, G_Loss:13.258331298828125

iterator 3600, D_Loss:0.41081172227859497, G_Loss:13.441146850585938

iterator 3700, D_Loss:0.429918497800827, G_Loss:12.924158096313477

iterator 3800, D_Loss:0.42244696617126465, G_Loss:13.761880874633789

iterator 3900, D_Loss:0.44574129581451416, G_Loss:14.139522552490234

iterator 4000, D_Loss:0.44247496128082275, G_Loss:13.951407432556152

iterator 4100, D_Loss:0.4190784692764282, G_Loss:13.956470489501953

iterator 4200, D_Loss:0.402554452419281, G_Loss:14.463373184204102

iterator 4300, D_Loss:0.44146451354026794, G_Loss:14.279386520385742

iterator 4400, D_Loss:0.42539098858833313, G_Loss:13.825603485107422

iterator 4500, D_Loss:0.4337538480758667, G_Loss:13.725641250610352

iterator 4600, D_Loss:0.40817829966545105, G_Loss:12.682867050170898

iterator 4700, D_Loss:0.43283793330192566, G_Loss:15.184001922607422

iterator 4800, D_Loss:0.4078241288661957, G_Loss:13.610901832580566

iterator 4900, D_Loss:0.4270637333393097, G_Loss:13.369073867797852

-----------Epoch 9-----------
iterator 0, D_Loss:0.4259129464626312, G_Loss:13.083230972290039

iterator 100, D_Loss:0.4312906265258789, G_Loss:14.688326835632324

iterator 200, D_Loss:0.4223986268043518, G_Loss:13.630748748779297

iterator 300, D_Loss:0.42924433946609497, G_Loss:15.001941680908203

iterator 400, D_Loss:0.41553404927253723, G_Loss:15.234241485595703

iterator 500, D_Loss:0.4270150363445282, G_Loss:13.517621994018555

iterator 600, D_Loss:0.4166465401649475, G_Loss:14.254926681518555

iterator 700, D_Loss:0.42981818318367004, G_Loss:14.260744094848633

iterator 800, D_Loss:0.4196070432662964, G_Loss:13.920286178588867

iterator 900, D_Loss:0.42454996705055237, G_Loss:13.91209602355957

iterator 1000, D_Loss:0.4272471070289612, G_Loss:15.25112533569336

iterator 1100, D_Loss:0.4212220311164856, G_Loss:15.13791275024414

iterator 1200, D_Loss:0.42365074157714844, G_Loss:15.140702247619629

iterator 1300, D_Loss:0.42132431268692017, G_Loss:14.577812194824219

iterator 1400, D_Loss:0.4209456443786621, G_Loss:14.476000785827637

iterator 1500, D_Loss:0.4173801839351654, G_Loss:14.39276123046875

iterator 1600, D_Loss:0.42526352405548096, G_Loss:14.453579902648926

iterator 1700, D_Loss:0.4137057960033417, G_Loss:15.401065826416016

iterator 1800, D_Loss:0.4262993633747101, G_Loss:14.28904914855957

iterator 1900, D_Loss:0.4140125513076782, G_Loss:14.73037338256836

iterator 2000, D_Loss:0.4145914614200592, G_Loss:14.459878921508789

iterator 2100, D_Loss:0.4389803111553192, G_Loss:15.162862777709961

iterator 2200, D_Loss:0.43692636489868164, G_Loss:15.387918472290039

iterator 2300, D_Loss:0.4127843379974365, G_Loss:14.812153816223145

iterator 2400, D_Loss:0.41392630338668823, G_Loss:14.771663665771484

iterator 2500, D_Loss:0.4341980218887329, G_Loss:15.413125991821289

iterator 2600, D_Loss:0.41775503754615784, G_Loss:14.552135467529297

iterator 2700, D_Loss:0.43692901730537415, G_Loss:14.828693389892578

iterator 2800, D_Loss:0.42626333236694336, G_Loss:14.369779586791992

iterator 2900, D_Loss:0.43640652298927307, G_Loss:14.700654029846191

iterator 3000, D_Loss:0.4180517792701721, G_Loss:14.607413291931152

iterator 3100, D_Loss:0.41085243225097656, G_Loss:14.557052612304688

iterator 3200, D_Loss:0.4380892515182495, G_Loss:14.302935600280762

iterator 3300, D_Loss:0.419696182012558, G_Loss:14.515552520751953

iterator 3400, D_Loss:0.4096919000148773, G_Loss:14.70355224609375

iterator 3500, D_Loss:0.4341925084590912, G_Loss:14.267745018005371

iterator 3600, D_Loss:0.41381120681762695, G_Loss:13.74133586883545

iterator 3700, D_Loss:0.42870306968688965, G_Loss:14.11185073852539

iterator 3800, D_Loss:0.4164564609527588, G_Loss:14.002103805541992

iterator 3900, D_Loss:0.4073159992694855, G_Loss:14.573619842529297

iterator 4000, D_Loss:0.44635745882987976, G_Loss:15.508539199829102

iterator 4100, D_Loss:0.42937538027763367, G_Loss:15.289731979370117

iterator 4200, D_Loss:0.41844436526298523, G_Loss:15.427818298339844

iterator 4300, D_Loss:0.4205591678619385, G_Loss:15.476934432983398

iterator 4400, D_Loss:0.4375836253166199, G_Loss:15.273957252502441

iterator 4500, D_Loss:0.41516464948654175, G_Loss:14.904179573059082

iterator 4600, D_Loss:0.4281652867794037, G_Loss:14.633126258850098

iterator 4700, D_Loss:0.4169968366622925, G_Loss:15.856027603149414

iterator 4800, D_Loss:0.43608522415161133, G_Loss:14.283327102661133

iterator 4900, D_Loss:0.4260728061199188, G_Loss:14.14745807647705

train row : 30148
sample row: 30148
LGAN_generator(
  (LSTM): LSTMCell(302, 400)
  (gmfc00): Linear(in_features=100, out_features=1, bias=True)
  (gmfc01): Linear(in_features=100, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=100, bias=True)
  (gmfe00): Linear(in_features=400, out_features=100, bias=True)
  (gmfe01): Linear(in_features=400, out_features=100, bias=True)
  (fc10): Linear(in_features=100, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=100, bias=True)
  (fe1): Linear(in_features=400, out_features=100, bias=True)
  (gmfc20): Linear(in_features=100, out_features=1, bias=True)
  (gmfc21): Linear(in_features=100, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=100, bias=True)
  (gmfe20): Linear(in_features=400, out_features=100, bias=True)
  (gmfe21): Linear(in_features=400, out_features=100, bias=True)
  (fc30): Linear(in_features=100, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=100, bias=True)
  (fe3): Linear(in_features=400, out_features=100, bias=True)
  (gmfc40): Linear(in_features=100, out_features=1, bias=True)
  (gmfc41): Linear(in_features=100, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=100, bias=True)
  (gmfe40): Linear(in_features=400, out_features=100, bias=True)
  (gmfe41): Linear(in_features=400, out_features=100, bias=True)
  (fc50): Linear(in_features=100, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=100, bias=True)
  (fe5): Linear(in_features=400, out_features=100, bias=True)
  (fc60): Linear(in_features=100, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=100, bias=True)
  (fe6): Linear(in_features=400, out_features=100, bias=True)
  (fc70): Linear(in_features=100, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=100, bias=True)
  (fe7): Linear(in_features=400, out_features=100, bias=True)
  (fc80): Linear(in_features=100, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=100, bias=True)
  (fe8): Linear(in_features=400, out_features=100, bias=True)
  (fc90): Linear(in_features=100, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=100, bias=True)
  (fe9): Linear(in_features=400, out_features=100, bias=True)
  (gmfc100): Linear(in_features=100, out_features=1, bias=True)
  (gmfc101): Linear(in_features=100, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=100, bias=True)
  (gmfe100): Linear(in_features=400, out_features=100, bias=True)
  (gmfe101): Linear(in_features=400, out_features=100, bias=True)
  (gmfc110): Linear(in_features=100, out_features=1, bias=True)
  (gmfc111): Linear(in_features=100, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=100, bias=True)
  (gmfe110): Linear(in_features=400, out_features=100, bias=True)
  (gmfe111): Linear(in_features=400, out_features=100, bias=True)
  (gmfc120): Linear(in_features=100, out_features=1, bias=True)
  (gmfc121): Linear(in_features=100, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=100, bias=True)
  (gmfe120): Linear(in_features=400, out_features=100, bias=True)
  (gmfe121): Linear(in_features=400, out_features=100, bias=True)
  (fc130): Linear(in_features=100, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=100, bias=True)
  (fe13): Linear(in_features=400, out_features=100, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=400, bias=True)
  (inputbn): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=400, out_features=400, bias=True)
  (bn0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=400, bias=True)
  (bn1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=400, out_features=400, bias=True)
  (bn2): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=400, out_features=400, bias=True)
  (bn3): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=400, out_features=1, bias=True)
)
-----------Epoch 0-----------
iterator 100, D_Loss:1.3956518173217773, G_Loss:1.0337049961090088

iterator 200, D_Loss:1.4026219844818115, G_Loss:1.0144422054290771

iterator 300, D_Loss:1.407767653465271, G_Loss:1.0739567279815674

iterator 400, D_Loss:1.4016032218933105, G_Loss:1.0859519243240356

iterator 500, D_Loss:1.3999183177947998, G_Loss:0.9755454659461975

iterator 600, D_Loss:1.418188214302063, G_Loss:0.9517318606376648

iterator 700, D_Loss:1.3986684083938599, G_Loss:0.9630717039108276

iterator 800, D_Loss:1.384863018989563, G_Loss:0.9997704029083252

iterator 900, D_Loss:1.3421094417572021, G_Loss:1.003222107887268

iterator 1000, D_Loss:1.3557242155075073, G_Loss:0.9423270225524902

iterator 1100, D_Loss:1.3637579679489136, G_Loss:1.0206282138824463

iterator 1200, D_Loss:1.360511302947998, G_Loss:1.0000104904174805

iterator 1300, D_Loss:1.3535181283950806, G_Loss:1.0623804330825806

iterator 1400, D_Loss:1.31058669090271, G_Loss:0.9882122874259949

iterator 1500, D_Loss:1.2703251838684082, G_Loss:1.0771409273147583

iterator 1600, D_Loss:1.2636818885803223, G_Loss:1.1298006772994995

iterator 1700, D_Loss:1.2047077417373657, G_Loss:1.2846050262451172

iterator 1800, D_Loss:1.1754423379898071, G_Loss:1.3279448747634888

iterator 1900, D_Loss:1.047573208808899, G_Loss:1.4309178590774536

iterator 2000, D_Loss:0.9755781292915344, G_Loss:1.5963671207427979

iterator 2100, D_Loss:0.8367837071418762, G_Loss:1.699011206626892

iterator 2200, D_Loss:0.8172270059585571, G_Loss:1.8499056100845337

iterator 2300, D_Loss:0.7542364001274109, G_Loss:2.1067073345184326

iterator 2400, D_Loss:0.7170277237892151, G_Loss:2.2890496253967285

iterator 2500, D_Loss:0.7210034728050232, G_Loss:2.4159491062164307

iterator 2600, D_Loss:0.6214211583137512, G_Loss:2.45172381401062

iterator 2700, D_Loss:0.5932551622390747, G_Loss:2.6939518451690674

iterator 2800, D_Loss:0.6779106259346008, G_Loss:2.879055976867676

iterator 2900, D_Loss:0.5863037109375, G_Loss:2.7088782787323

iterator 3000, D_Loss:0.5842613577842712, G_Loss:2.716684579849243

iterator 3100, D_Loss:0.6415159702301025, G_Loss:2.542182683944702

iterator 3200, D_Loss:0.6284841299057007, G_Loss:2.89896821975708

iterator 3300, D_Loss:0.6324772834777832, G_Loss:2.8275504112243652

iterator 3400, D_Loss:0.7617802023887634, G_Loss:2.8544135093688965

iterator 3500, D_Loss:0.8467887043952942, G_Loss:2.1846120357513428

iterator 3600, D_Loss:0.743153989315033, G_Loss:2.797146797180176

iterator 3700, D_Loss:0.5857623219490051, G_Loss:3.1849727630615234

iterator 3800, D_Loss:0.7035097479820251, G_Loss:3.3383708000183105

iterator 3900, D_Loss:0.7528724074363708, G_Loss:3.1114501953125

iterator 4000, D_Loss:0.7440991401672363, G_Loss:3.1560873985290527

iterator 4100, D_Loss:0.916107177734375, G_Loss:2.5874733924865723

iterator 4200, D_Loss:1.0381929874420166, G_Loss:3.956613540649414

iterator 4300, D_Loss:0.727582573890686, G_Loss:2.6807568073272705

iterator 4400, D_Loss:0.706501305103302, G_Loss:4.108114719390869

iterator 4500, D_Loss:0.7744579911231995, G_Loss:3.740074634552002

iterator 4600, D_Loss:0.8665298223495483, G_Loss:2.9772958755493164

iterator 4700, D_Loss:0.6508750915527344, G_Loss:2.769348621368408

iterator 4800, D_Loss:0.602661669254303, G_Loss:3.5653750896453857

iterator 4900, D_Loss:0.7435071468353271, G_Loss:3.264458656311035

iterator 5000, D_Loss:0.687107264995575, G_Loss:4.223548889160156

-----------Epoch 1-----------
iterator 100, D_Loss:0.5308933258056641, G_Loss:3.845466375350952

iterator 200, D_Loss:0.5977916121482849, G_Loss:2.897542953491211

iterator 300, D_Loss:0.7412112951278687, G_Loss:3.5144872665405273

iterator 400, D_Loss:0.5316196084022522, G_Loss:1.992372751235962

iterator 500, D_Loss:0.8649007081985474, G_Loss:3.4212067127227783

iterator 600, D_Loss:0.5423964858055115, G_Loss:3.8335647583007812

iterator 700, D_Loss:0.7119318842887878, G_Loss:2.1596972942352295

iterator 800, D_Loss:0.754751443862915, G_Loss:3.304312229156494

iterator 900, D_Loss:0.6103389859199524, G_Loss:1.844794750213623

iterator 1000, D_Loss:0.5850750803947449, G_Loss:2.9989445209503174

iterator 1100, D_Loss:0.715888261795044, G_Loss:2.5081140995025635

iterator 1200, D_Loss:0.6632320880889893, G_Loss:2.660076856613159

iterator 1300, D_Loss:0.7098379135131836, G_Loss:2.119046449661255

iterator 1400, D_Loss:0.8340945243835449, G_Loss:4.032110214233398

iterator 1500, D_Loss:0.8209047317504883, G_Loss:3.2494568824768066

iterator 1600, D_Loss:0.9364259243011475, G_Loss:3.952716827392578

iterator 1700, D_Loss:0.6397957801818848, G_Loss:3.6303369998931885

iterator 1800, D_Loss:0.6089105010032654, G_Loss:3.1609175205230713

iterator 1900, D_Loss:0.8193380832672119, G_Loss:1.6937546730041504

iterator 2000, D_Loss:0.7122607231140137, G_Loss:4.427902698516846

iterator 2100, D_Loss:0.6059702634811401, G_Loss:1.9092611074447632

iterator 2200, D_Loss:0.5793647766113281, G_Loss:3.9582934379577637

iterator 2300, D_Loss:0.5901501178741455, G_Loss:5.0450334548950195

iterator 2400, D_Loss:0.5885428190231323, G_Loss:4.695088863372803

iterator 2500, D_Loss:0.5287925004959106, G_Loss:3.0955607891082764

iterator 2600, D_Loss:0.5590009093284607, G_Loss:2.61867094039917

iterator 2700, D_Loss:0.6411148309707642, G_Loss:3.4811782836914062

iterator 2800, D_Loss:0.9576277136802673, G_Loss:3.754262924194336

iterator 2900, D_Loss:0.5165126323699951, G_Loss:4.236032485961914

iterator 3000, D_Loss:0.8156096935272217, G_Loss:2.7176220417022705

iterator 3100, D_Loss:0.5187340378761292, G_Loss:3.116213798522949

iterator 3200, D_Loss:0.6787999272346497, G_Loss:4.814425945281982

iterator 3300, D_Loss:0.9346181154251099, G_Loss:2.8286468982696533

iterator 3400, D_Loss:0.5569908618927002, G_Loss:4.613368988037109

iterator 3500, D_Loss:0.9727808237075806, G_Loss:4.8881754875183105

iterator 3600, D_Loss:0.48740819096565247, G_Loss:4.760907173156738

iterator 3700, D_Loss:0.7875970005989075, G_Loss:5.264835357666016

iterator 3800, D_Loss:0.6951999664306641, G_Loss:3.5695204734802246

iterator 3900, D_Loss:0.5177494287490845, G_Loss:4.971389293670654

iterator 4000, D_Loss:0.6054366230964661, G_Loss:5.070956707000732

iterator 4100, D_Loss:0.5420233607292175, G_Loss:4.200974941253662

iterator 4200, D_Loss:0.5935292840003967, G_Loss:4.96725606918335

iterator 4300, D_Loss:0.6424040794372559, G_Loss:5.141839504241943

iterator 4400, D_Loss:0.5157109498977661, G_Loss:3.288013458251953

iterator 4500, D_Loss:0.7165960669517517, G_Loss:3.1847755908966064

iterator 4600, D_Loss:0.5004847049713135, G_Loss:1.4433975219726562

iterator 4700, D_Loss:0.959453821182251, G_Loss:1.736555814743042

iterator 4800, D_Loss:0.7753622531890869, G_Loss:2.649275541305542

iterator 4900, D_Loss:0.9419885277748108, G_Loss:3.2317512035369873

iterator 5000, D_Loss:0.6664242744445801, G_Loss:4.010397434234619

-----------Epoch 2-----------
iterator 100, D_Loss:0.6127985715866089, G_Loss:1.812273621559143

iterator 200, D_Loss:1.3865660429000854, G_Loss:3.7277002334594727

iterator 300, D_Loss:1.3326425552368164, G_Loss:3.938753604888916

iterator 400, D_Loss:0.6218295097351074, G_Loss:4.927337169647217

iterator 500, D_Loss:1.040979027748108, G_Loss:5.514592170715332

iterator 600, D_Loss:1.0207593441009521, G_Loss:3.2238125801086426

iterator 700, D_Loss:1.0117160081863403, G_Loss:4.057106018066406

iterator 800, D_Loss:1.3108850717544556, G_Loss:3.029895782470703

iterator 900, D_Loss:0.7387067675590515, G_Loss:3.773510217666626

iterator 1000, D_Loss:0.6393462419509888, G_Loss:3.202939033508301

iterator 1100, D_Loss:0.49650558829307556, G_Loss:4.071903228759766

iterator 1200, D_Loss:0.5115194916725159, G_Loss:4.5207366943359375

iterator 1300, D_Loss:0.7706029415130615, G_Loss:3.7105307579040527

iterator 1400, D_Loss:0.6377952098846436, G_Loss:4.330020427703857

iterator 1500, D_Loss:0.5941777229309082, G_Loss:2.9993515014648438

iterator 1600, D_Loss:0.6885553598403931, G_Loss:3.752800464630127

iterator 1700, D_Loss:0.7783044576644897, G_Loss:1.5944509506225586

iterator 1800, D_Loss:0.6704166531562805, G_Loss:5.73692512512207

iterator 1900, D_Loss:1.1323635578155518, G_Loss:2.4797611236572266

iterator 2000, D_Loss:0.6579654812812805, G_Loss:3.955841541290283

iterator 2100, D_Loss:0.5436773896217346, G_Loss:3.36082124710083

iterator 2200, D_Loss:0.6997309923171997, G_Loss:2.6306700706481934

iterator 2300, D_Loss:1.3591258525848389, G_Loss:3.9602885246276855

iterator 2400, D_Loss:0.47685518860816956, G_Loss:2.3374361991882324

iterator 2500, D_Loss:0.9079974889755249, G_Loss:3.9741437435150146

iterator 2600, D_Loss:0.6940786838531494, G_Loss:3.120979070663452

iterator 2700, D_Loss:0.7546992301940918, G_Loss:3.4259274005889893

iterator 2800, D_Loss:0.7972480058670044, G_Loss:2.825528383255005

iterator 2900, D_Loss:1.1180033683776855, G_Loss:3.1291418075561523

iterator 3000, D_Loss:1.3912718296051025, G_Loss:2.5704166889190674

iterator 3100, D_Loss:0.9356850385665894, G_Loss:4.098247528076172

iterator 3200, D_Loss:1.2101311683654785, G_Loss:3.680372714996338

iterator 3300, D_Loss:0.7670645713806152, G_Loss:4.2525506019592285

iterator 3400, D_Loss:0.602082371711731, G_Loss:3.4364919662475586

iterator 3500, D_Loss:0.8238549828529358, G_Loss:3.5096235275268555

iterator 3600, D_Loss:1.8157628774642944, G_Loss:3.282144546508789

iterator 3700, D_Loss:0.5607199668884277, G_Loss:3.2425787448883057

iterator 3800, D_Loss:0.557040810585022, G_Loss:3.802375316619873

iterator 3900, D_Loss:0.9627906084060669, G_Loss:3.6320629119873047

iterator 4000, D_Loss:0.866676390171051, G_Loss:3.4667487144470215

iterator 4100, D_Loss:0.7977943420410156, G_Loss:3.216948986053467

iterator 4200, D_Loss:0.6615303754806519, G_Loss:3.364771842956543

iterator 4300, D_Loss:1.015708088874817, G_Loss:3.221607208251953

iterator 4400, D_Loss:0.7516191601753235, G_Loss:4.1155877113342285

iterator 4500, D_Loss:1.2273461818695068, G_Loss:3.1607954502105713

iterator 4600, D_Loss:0.686221718788147, G_Loss:3.5600128173828125

iterator 4700, D_Loss:0.8176507949829102, G_Loss:2.4445483684539795

iterator 4800, D_Loss:0.6245517730712891, G_Loss:2.6574137210845947

iterator 4900, D_Loss:1.6073811054229736, G_Loss:1.780851125717163

iterator 5000, D_Loss:0.5511624813079834, G_Loss:3.0920615196228027

-----------Epoch 3-----------
iterator 100, D_Loss:1.1165059804916382, G_Loss:3.8776910305023193

iterator 200, D_Loss:0.49504658579826355, G_Loss:3.005105495452881

iterator 300, D_Loss:1.4822427034378052, G_Loss:3.705432415008545

iterator 400, D_Loss:0.6879035830497742, G_Loss:2.7184250354766846

iterator 500, D_Loss:0.593917965888977, G_Loss:2.8281455039978027

iterator 600, D_Loss:1.3915815353393555, G_Loss:1.9035800695419312

iterator 700, D_Loss:0.6889896988868713, G_Loss:3.7116341590881348

iterator 800, D_Loss:0.6815956830978394, G_Loss:4.0021748542785645

iterator 900, D_Loss:1.2881529331207275, G_Loss:1.7292407751083374

iterator 1000, D_Loss:0.7123720049858093, G_Loss:4.080179691314697

iterator 1100, D_Loss:0.5252628922462463, G_Loss:2.2157859802246094

iterator 1200, D_Loss:0.667829692363739, G_Loss:2.52780818939209

iterator 1300, D_Loss:1.7232118844985962, G_Loss:4.826659679412842

iterator 1400, D_Loss:0.9622831344604492, G_Loss:3.3801209926605225

iterator 1500, D_Loss:1.4696584939956665, G_Loss:1.5207626819610596

iterator 1600, D_Loss:0.5218871235847473, G_Loss:2.7994589805603027

iterator 1700, D_Loss:1.1306744813919067, G_Loss:3.1301121711730957

iterator 1800, D_Loss:0.7744671106338501, G_Loss:4.482599258422852

iterator 1900, D_Loss:0.5871454477310181, G_Loss:4.4368672370910645

iterator 2000, D_Loss:1.1631827354431152, G_Loss:3.367746591567993

iterator 2100, D_Loss:0.7264033555984497, G_Loss:4.652303695678711

iterator 2200, D_Loss:1.1373951435089111, G_Loss:3.855116128921509

iterator 2300, D_Loss:1.6630918979644775, G_Loss:3.700352191925049

iterator 2400, D_Loss:1.3590751886367798, G_Loss:1.3468914031982422

iterator 2500, D_Loss:0.4836154282093048, G_Loss:3.7175700664520264

iterator 2600, D_Loss:0.8290339112281799, G_Loss:1.2653448581695557

iterator 2700, D_Loss:0.9267994165420532, G_Loss:2.559113025665283

iterator 2800, D_Loss:0.7566702961921692, G_Loss:4.17831563949585

iterator 2900, D_Loss:0.5167294144630432, G_Loss:3.398221969604492

iterator 3000, D_Loss:0.7931884527206421, G_Loss:2.0449907779693604

iterator 3100, D_Loss:0.5264590382575989, G_Loss:1.8231256008148193

iterator 3200, D_Loss:0.5683082342147827, G_Loss:4.374772548675537

iterator 3300, D_Loss:0.6536112427711487, G_Loss:4.037486553192139

iterator 3400, D_Loss:0.8795803785324097, G_Loss:2.57900333404541

iterator 3500, D_Loss:1.2268909215927124, G_Loss:3.5040364265441895

iterator 3600, D_Loss:0.5813648700714111, G_Loss:1.463813304901123

iterator 3700, D_Loss:1.271104335784912, G_Loss:2.0851216316223145

iterator 3800, D_Loss:0.8692923784255981, G_Loss:3.639779806137085

iterator 3900, D_Loss:0.8678976893424988, G_Loss:2.3655874729156494

iterator 4000, D_Loss:0.6432361006736755, G_Loss:4.651704788208008

iterator 4100, D_Loss:1.0899865627288818, G_Loss:4.7464799880981445

iterator 4200, D_Loss:1.5130590200424194, G_Loss:2.4998369216918945

iterator 4300, D_Loss:0.6216245889663696, G_Loss:2.694174289703369

iterator 4400, D_Loss:0.5864330530166626, G_Loss:3.0512356758117676

iterator 4500, D_Loss:1.0892256498336792, G_Loss:4.163255214691162

iterator 4600, D_Loss:1.1757720708847046, G_Loss:4.751346588134766

iterator 4700, D_Loss:0.6186097860336304, G_Loss:4.170724868774414

iterator 4800, D_Loss:0.6310450434684753, G_Loss:2.773426055908203

iterator 4900, D_Loss:0.851145327091217, G_Loss:3.240419387817383

iterator 5000, D_Loss:0.6259902119636536, G_Loss:4.572218418121338

-----------Epoch 4-----------
iterator 100, D_Loss:1.020376205444336, G_Loss:3.254347801208496

iterator 200, D_Loss:0.9367657899856567, G_Loss:2.9901413917541504

iterator 300, D_Loss:0.8452874422073364, G_Loss:3.3002169132232666

iterator 400, D_Loss:0.7133660316467285, G_Loss:2.430863380432129

iterator 500, D_Loss:0.8341524600982666, G_Loss:3.6297974586486816

iterator 600, D_Loss:0.5901451706886292, G_Loss:3.2152299880981445

iterator 700, D_Loss:0.6615416407585144, G_Loss:2.9402642250061035

iterator 800, D_Loss:0.621311366558075, G_Loss:3.198443651199341

iterator 900, D_Loss:0.6234614253044128, G_Loss:3.1023788452148438

iterator 1000, D_Loss:0.6019162535667419, G_Loss:3.4384260177612305

iterator 1100, D_Loss:0.5992715358734131, G_Loss:6.331014633178711

iterator 1200, D_Loss:0.5468757748603821, G_Loss:1.6185033321380615

iterator 1300, D_Loss:0.992232084274292, G_Loss:1.3477805852890015

iterator 1400, D_Loss:0.7258256077766418, G_Loss:3.793548345565796

iterator 1500, D_Loss:0.7763477563858032, G_Loss:2.1117892265319824

iterator 1600, D_Loss:0.6630445718765259, G_Loss:3.9649858474731445

iterator 1700, D_Loss:1.027577519416809, G_Loss:2.824434757232666

iterator 1800, D_Loss:0.5604850053787231, G_Loss:3.8472747802734375

iterator 1900, D_Loss:0.6965723037719727, G_Loss:3.3229470252990723

iterator 2000, D_Loss:1.2177008390426636, G_Loss:3.421384811401367

iterator 2100, D_Loss:0.4715338349342346, G_Loss:2.8553566932678223

iterator 2200, D_Loss:0.5374889969825745, G_Loss:4.883774757385254

iterator 2300, D_Loss:0.8673409223556519, G_Loss:3.1614503860473633

iterator 2400, D_Loss:0.7158531546592712, G_Loss:3.666677474975586

iterator 2500, D_Loss:0.5161679983139038, G_Loss:3.3290610313415527

iterator 2600, D_Loss:0.4822620153427124, G_Loss:1.6463185548782349

iterator 2700, D_Loss:0.620274543762207, G_Loss:3.2347092628479004

iterator 2800, D_Loss:0.8680490255355835, G_Loss:3.457026243209839

iterator 2900, D_Loss:0.548351526260376, G_Loss:1.5972952842712402

iterator 3000, D_Loss:0.8528345823287964, G_Loss:4.376979827880859

iterator 3100, D_Loss:0.9428484439849854, G_Loss:3.3480277061462402

iterator 3200, D_Loss:0.8523547649383545, G_Loss:2.6492176055908203

iterator 3300, D_Loss:0.6755456924438477, G_Loss:3.886730909347534

iterator 3400, D_Loss:1.2144880294799805, G_Loss:4.861277103424072

iterator 3500, D_Loss:0.6038496494293213, G_Loss:4.474588871002197

iterator 3600, D_Loss:0.6136950254440308, G_Loss:3.72395396232605

iterator 3700, D_Loss:0.8377298712730408, G_Loss:3.7609360218048096

iterator 3800, D_Loss:0.9340845346450806, G_Loss:4.6617326736450195

iterator 3900, D_Loss:0.7910856008529663, G_Loss:3.494234561920166

iterator 4000, D_Loss:0.8042930364608765, G_Loss:3.5387914180755615

iterator 4100, D_Loss:1.2344558238983154, G_Loss:2.659506320953369

iterator 4200, D_Loss:0.763550877571106, G_Loss:3.1687989234924316

iterator 4300, D_Loss:0.7256197929382324, G_Loss:2.6906933784484863

iterator 4400, D_Loss:1.387096643447876, G_Loss:2.3649344444274902

iterator 4500, D_Loss:0.6241711974143982, G_Loss:4.815738677978516

iterator 4600, D_Loss:0.5628916621208191, G_Loss:4.9870991706848145

iterator 4700, D_Loss:0.6401515007019043, G_Loss:2.033400058746338

iterator 4800, D_Loss:1.4040372371673584, G_Loss:4.787771701812744

iterator 4900, D_Loss:0.6152247786521912, G_Loss:5.166539669036865

iterator 5000, D_Loss:0.8422303199768066, G_Loss:2.8810198307037354

-----------Epoch 5-----------
iterator 100, D_Loss:0.49394482374191284, G_Loss:2.6581125259399414

iterator 200, D_Loss:0.7250299453735352, G_Loss:4.712706089019775

iterator 300, D_Loss:0.7253394722938538, G_Loss:2.164851665496826

iterator 400, D_Loss:1.0985653400421143, G_Loss:2.765925407409668

iterator 500, D_Loss:0.5826346278190613, G_Loss:3.2743921279907227

iterator 600, D_Loss:0.6295671463012695, G_Loss:2.617870330810547

iterator 700, D_Loss:0.6013147830963135, G_Loss:4.810404300689697

iterator 800, D_Loss:0.8826562166213989, G_Loss:3.8304474353790283

iterator 900, D_Loss:0.6681386232376099, G_Loss:3.3091840744018555

iterator 1000, D_Loss:0.5635244846343994, G_Loss:4.319794654846191

iterator 1100, D_Loss:0.5821473002433777, G_Loss:5.17506217956543

iterator 1200, D_Loss:0.7960079908370972, G_Loss:2.1713645458221436

iterator 1300, D_Loss:0.6439892053604126, G_Loss:3.783188819885254

iterator 1400, D_Loss:0.6441370844841003, G_Loss:3.3843538761138916

iterator 1500, D_Loss:0.724655032157898, G_Loss:2.8853111267089844

iterator 1600, D_Loss:0.8800047636032104, G_Loss:4.803811550140381

iterator 1700, D_Loss:1.2237203121185303, G_Loss:3.688202381134033

iterator 1800, D_Loss:0.5088098645210266, G_Loss:3.812295436859131

iterator 1900, D_Loss:0.7167421579360962, G_Loss:3.9518072605133057

iterator 2000, D_Loss:1.2303802967071533, G_Loss:1.985329031944275

iterator 2100, D_Loss:0.9791198372840881, G_Loss:4.287158489227295

iterator 2200, D_Loss:0.5439086556434631, G_Loss:1.844658374786377

iterator 2300, D_Loss:0.7914944887161255, G_Loss:1.6901583671569824

iterator 2400, D_Loss:1.0878515243530273, G_Loss:1.785712480545044

iterator 2500, D_Loss:1.8519303798675537, G_Loss:3.16514253616333

iterator 2600, D_Loss:0.5326539874076843, G_Loss:3.16917085647583

iterator 2700, D_Loss:2.897474527359009, G_Loss:3.1935648918151855

iterator 2800, D_Loss:1.1028146743774414, G_Loss:3.392630100250244

iterator 2900, D_Loss:0.5749870538711548, G_Loss:3.4093284606933594

iterator 3000, D_Loss:1.8913935422897339, G_Loss:2.572702646255493

iterator 3100, D_Loss:0.5514280200004578, G_Loss:4.999804496765137

iterator 3200, D_Loss:1.4195845127105713, G_Loss:2.5955593585968018

iterator 3300, D_Loss:0.5300496816635132, G_Loss:4.979583740234375

iterator 3400, D_Loss:0.8249301910400391, G_Loss:3.9080448150634766

iterator 3500, D_Loss:0.5622982978820801, G_Loss:3.327369451522827

iterator 3600, D_Loss:0.5571928024291992, G_Loss:4.217875003814697

iterator 3700, D_Loss:0.6329460144042969, G_Loss:4.383604049682617

iterator 3800, D_Loss:0.8980442881584167, G_Loss:4.22113037109375

iterator 3900, D_Loss:0.46036437153816223, G_Loss:2.076383590698242

iterator 4000, D_Loss:0.6192961931228638, G_Loss:4.504095077514648

iterator 4100, D_Loss:0.8362321853637695, G_Loss:4.2782135009765625

iterator 4200, D_Loss:1.0041226148605347, G_Loss:2.317831516265869

iterator 4300, D_Loss:0.5789595246315002, G_Loss:3.4492835998535156

iterator 4400, D_Loss:0.6126168966293335, G_Loss:2.8736157417297363

iterator 4500, D_Loss:0.5657140016555786, G_Loss:4.425021648406982

iterator 4600, D_Loss:0.6512486338615417, G_Loss:4.72909688949585

iterator 4700, D_Loss:0.7155318260192871, G_Loss:5.275516033172607

iterator 4800, D_Loss:0.6158969402313232, G_Loss:2.289013147354126

iterator 4900, D_Loss:0.6119390726089478, G_Loss:2.736870050430298

iterator 5000, D_Loss:0.6028549075126648, G_Loss:3.7262043952941895

-----------Epoch 6-----------
iterator 100, D_Loss:0.5581388473510742, G_Loss:1.859976053237915

iterator 200, D_Loss:0.6987711787223816, G_Loss:3.8012187480926514

iterator 300, D_Loss:0.6876925230026245, G_Loss:2.678910732269287

iterator 400, D_Loss:0.4804283082485199, G_Loss:3.2680065631866455

iterator 500, D_Loss:0.48038673400878906, G_Loss:4.244115829467773

iterator 600, D_Loss:1.130794644355774, G_Loss:2.2365589141845703

iterator 700, D_Loss:0.8158490061759949, G_Loss:3.4281606674194336

iterator 800, D_Loss:0.7511115074157715, G_Loss:3.766207695007324

iterator 900, D_Loss:0.4716784954071045, G_Loss:4.668745994567871

iterator 1000, D_Loss:0.46203622221946716, G_Loss:1.4934463500976562

iterator 1100, D_Loss:0.5897420644760132, G_Loss:3.427079677581787

iterator 1200, D_Loss:0.773658037185669, G_Loss:3.318851947784424

iterator 1300, D_Loss:1.3824355602264404, G_Loss:5.026203155517578

iterator 1400, D_Loss:0.6998872756958008, G_Loss:1.6392288208007812

iterator 1500, D_Loss:1.4375653266906738, G_Loss:6.343208312988281

iterator 1600, D_Loss:0.6580932140350342, G_Loss:2.9081413745880127

iterator 1700, D_Loss:0.7947198152542114, G_Loss:5.146772384643555

iterator 1800, D_Loss:0.625942587852478, G_Loss:3.7399935722351074

iterator 1900, D_Loss:0.778127908706665, G_Loss:3.7105088233947754

iterator 2000, D_Loss:0.6808547973632812, G_Loss:1.2198419570922852

iterator 2100, D_Loss:0.7208815217018127, G_Loss:4.00903844833374

iterator 2200, D_Loss:0.5381091833114624, G_Loss:5.5811767578125

iterator 2300, D_Loss:0.7964310050010681, G_Loss:2.17086124420166

iterator 2400, D_Loss:1.9182517528533936, G_Loss:2.382401466369629

iterator 2500, D_Loss:0.6921426057815552, G_Loss:2.2529566287994385

iterator 2600, D_Loss:0.8965007066726685, G_Loss:4.103728294372559

iterator 2700, D_Loss:1.2468152046203613, G_Loss:6.704631805419922

iterator 2800, D_Loss:0.9990904927253723, G_Loss:5.225269317626953

iterator 2900, D_Loss:1.0408427715301514, G_Loss:3.4169511795043945

iterator 3000, D_Loss:0.6491327285766602, G_Loss:4.230316162109375

iterator 3100, D_Loss:0.47526589035987854, G_Loss:3.742042303085327

iterator 3200, D_Loss:2.2937426567077637, G_Loss:3.1749534606933594

iterator 3300, D_Loss:0.5745359063148499, G_Loss:3.104036808013916

iterator 3400, D_Loss:1.5196797847747803, G_Loss:3.5848073959350586

iterator 3500, D_Loss:0.9031966924667358, G_Loss:3.6088008880615234

iterator 3600, D_Loss:1.2056803703308105, G_Loss:4.0839128494262695

iterator 3700, D_Loss:0.5209164619445801, G_Loss:5.2451677322387695

iterator 3800, D_Loss:0.6573041677474976, G_Loss:3.353949785232544

iterator 3900, D_Loss:0.6526647806167603, G_Loss:5.270249366760254

iterator 4000, D_Loss:0.9567790627479553, G_Loss:3.1962971687316895

iterator 4100, D_Loss:0.5483719110488892, G_Loss:2.7034711837768555

iterator 4200, D_Loss:0.4793659448623657, G_Loss:4.487547397613525

iterator 4300, D_Loss:0.7751524448394775, G_Loss:2.501518964767456

iterator 4400, D_Loss:0.5061879754066467, G_Loss:2.301877975463867

iterator 4500, D_Loss:0.5761021971702576, G_Loss:1.8257756233215332

iterator 4600, D_Loss:0.5163744688034058, G_Loss:3.3220701217651367

iterator 4700, D_Loss:0.5250074863433838, G_Loss:4.437418460845947

iterator 4800, D_Loss:0.5086750984191895, G_Loss:4.093752384185791

iterator 4900, D_Loss:0.7724061012268066, G_Loss:2.571078300476074

iterator 5000, D_Loss:0.6629688739776611, G_Loss:6.036922931671143

-----------Epoch 7-----------
iterator 100, D_Loss:0.49817991256713867, G_Loss:5.123846530914307

iterator 200, D_Loss:0.453570693731308, G_Loss:3.77864408493042

iterator 300, D_Loss:0.6486685276031494, G_Loss:1.9642599821090698

iterator 400, D_Loss:0.992430567741394, G_Loss:4.246066570281982

iterator 500, D_Loss:0.6652891039848328, G_Loss:3.516298294067383

iterator 600, D_Loss:0.5526585578918457, G_Loss:4.111372947692871

iterator 700, D_Loss:0.5368517637252808, G_Loss:2.1243677139282227

iterator 800, D_Loss:0.9204264879226685, G_Loss:3.5615222454071045

iterator 900, D_Loss:0.6387428641319275, G_Loss:2.6108269691467285

iterator 1000, D_Loss:0.5608192682266235, G_Loss:3.8199527263641357

iterator 1100, D_Loss:0.5528013110160828, G_Loss:4.839619159698486

iterator 1200, D_Loss:0.983232855796814, G_Loss:3.6970999240875244

iterator 1300, D_Loss:0.521233856678009, G_Loss:4.175666809082031

iterator 1400, D_Loss:0.5640073418617249, G_Loss:2.9579477310180664

iterator 1500, D_Loss:0.7926539182662964, G_Loss:5.196185111999512

iterator 1600, D_Loss:0.5093949437141418, G_Loss:3.0982165336608887

iterator 1700, D_Loss:0.7248027324676514, G_Loss:2.490114450454712

iterator 1800, D_Loss:1.4543671607971191, G_Loss:1.9876266717910767

iterator 1900, D_Loss:0.5743300914764404, G_Loss:4.201577186584473

iterator 2000, D_Loss:0.450213760137558, G_Loss:4.040453910827637

iterator 2100, D_Loss:0.5381731986999512, G_Loss:3.4133806228637695

iterator 2200, D_Loss:1.2221461534500122, G_Loss:2.6765854358673096

iterator 2300, D_Loss:0.6804209351539612, G_Loss:3.2856075763702393

iterator 2400, D_Loss:1.083399772644043, G_Loss:4.971389293670654

iterator 2500, D_Loss:0.8965041637420654, G_Loss:2.9311726093292236

iterator 2600, D_Loss:0.7916299700737, G_Loss:4.061123847961426

iterator 2700, D_Loss:0.6274811625480652, G_Loss:4.4025654792785645

iterator 2800, D_Loss:1.6218990087509155, G_Loss:4.128796577453613

iterator 2900, D_Loss:0.6473039388656616, G_Loss:4.823993682861328

iterator 3000, D_Loss:0.7612173557281494, G_Loss:5.558371543884277

iterator 3100, D_Loss:0.8823783993721008, G_Loss:3.715142011642456

iterator 3200, D_Loss:0.7592706680297852, G_Loss:5.251279830932617

iterator 3300, D_Loss:0.928877592086792, G_Loss:1.0994020700454712

iterator 3400, D_Loss:0.8926587104797363, G_Loss:0.9211251735687256

iterator 3500, D_Loss:0.7482781410217285, G_Loss:3.4572715759277344

iterator 3600, D_Loss:1.0360057353973389, G_Loss:1.6644630432128906

iterator 3700, D_Loss:1.0340602397918701, G_Loss:2.3550076484680176

iterator 3800, D_Loss:0.7077630758285522, G_Loss:4.095072269439697

iterator 3900, D_Loss:0.7617045044898987, G_Loss:1.3250434398651123

iterator 4000, D_Loss:0.5583869814872742, G_Loss:4.298259258270264

iterator 4100, D_Loss:1.0914843082427979, G_Loss:1.7205438613891602

iterator 4200, D_Loss:0.7827386856079102, G_Loss:1.815450668334961

iterator 4300, D_Loss:0.6951377391815186, G_Loss:2.8152670860290527

iterator 4400, D_Loss:0.7309516072273254, G_Loss:3.0726709365844727

iterator 4500, D_Loss:0.7552645802497864, G_Loss:2.534675121307373

iterator 4600, D_Loss:1.1086493730545044, G_Loss:1.4310470819473267

iterator 4700, D_Loss:1.0967086553573608, G_Loss:3.6943769454956055

iterator 4800, D_Loss:0.597000241279602, G_Loss:4.161592960357666

iterator 4900, D_Loss:1.5748411417007446, G_Loss:1.5098645687103271

iterator 5000, D_Loss:0.6914617419242859, G_Loss:2.2595112323760986

-----------Epoch 8-----------
iterator 100, D_Loss:0.6700047254562378, G_Loss:1.5695849657058716

iterator 200, D_Loss:1.1215174198150635, G_Loss:2.6182217597961426

iterator 300, D_Loss:0.8363474011421204, G_Loss:1.5697040557861328

iterator 400, D_Loss:0.5539067983627319, G_Loss:2.844170570373535

iterator 500, D_Loss:1.3228750228881836, G_Loss:3.7321925163269043

iterator 600, D_Loss:0.6304675340652466, G_Loss:1.8595408201217651

iterator 700, D_Loss:0.6899144053459167, G_Loss:2.8653275966644287

iterator 800, D_Loss:0.7892683148384094, G_Loss:4.171004295349121

iterator 900, D_Loss:1.0850101709365845, G_Loss:2.4040169715881348

iterator 1000, D_Loss:0.7702577710151672, G_Loss:1.8722209930419922

iterator 1100, D_Loss:0.6206240057945251, G_Loss:2.3918616771698

iterator 1200, D_Loss:1.0452539920806885, G_Loss:2.5095021724700928

iterator 1300, D_Loss:1.3867101669311523, G_Loss:1.6596312522888184

iterator 1400, D_Loss:0.7042040824890137, G_Loss:4.937748432159424

iterator 1500, D_Loss:0.6409223675727844, G_Loss:1.879019021987915

iterator 1600, D_Loss:1.8520686626434326, G_Loss:2.7461607456207275

iterator 1700, D_Loss:1.87492036819458, G_Loss:1.8789023160934448

iterator 1800, D_Loss:0.7068369388580322, G_Loss:3.834855079650879

iterator 1900, D_Loss:0.6580072045326233, G_Loss:1.1382787227630615

iterator 2000, D_Loss:0.7688262462615967, G_Loss:1.8018417358398438

iterator 2100, D_Loss:0.81923907995224, G_Loss:1.8065502643585205

iterator 2200, D_Loss:1.3004844188690186, G_Loss:4.03235387802124

iterator 2300, D_Loss:1.1984310150146484, G_Loss:2.089327335357666

iterator 2400, D_Loss:0.7234002351760864, G_Loss:2.2354373931884766

iterator 2500, D_Loss:0.8778567314147949, G_Loss:3.5568044185638428

iterator 2600, D_Loss:0.6965371370315552, G_Loss:3.2670724391937256

iterator 2700, D_Loss:2.4430007934570312, G_Loss:1.877120018005371

iterator 2800, D_Loss:0.9027211666107178, G_Loss:1.3329471349716187

iterator 2900, D_Loss:0.6006675958633423, G_Loss:1.4739347696304321

iterator 3000, D_Loss:0.913952648639679, G_Loss:4.149413585662842

iterator 3100, D_Loss:0.7854950428009033, G_Loss:1.6837716102600098

iterator 3200, D_Loss:1.1078438758850098, G_Loss:4.347667217254639

iterator 3300, D_Loss:0.6768133044242859, G_Loss:0.9075020551681519

iterator 3400, D_Loss:1.266587734222412, G_Loss:3.3851685523986816

iterator 3500, D_Loss:0.5251802802085876, G_Loss:2.3270246982574463

iterator 3600, D_Loss:1.3354023694992065, G_Loss:1.9226343631744385

iterator 3700, D_Loss:0.8365604877471924, G_Loss:3.335477352142334

iterator 3800, D_Loss:0.565256655216217, G_Loss:2.416236400604248

iterator 3900, D_Loss:0.8675224184989929, G_Loss:2.63628888130188

iterator 4000, D_Loss:1.3573925495147705, G_Loss:1.5382577180862427

iterator 4100, D_Loss:1.5281121730804443, G_Loss:3.7412397861480713

iterator 4200, D_Loss:1.0131330490112305, G_Loss:2.4370737075805664

iterator 4300, D_Loss:1.6041216850280762, G_Loss:1.6727583408355713

iterator 4400, D_Loss:0.6906876564025879, G_Loss:3.826645851135254

iterator 4500, D_Loss:0.796379804611206, G_Loss:1.858687162399292

iterator 4600, D_Loss:0.6662299633026123, G_Loss:4.137266159057617

iterator 4700, D_Loss:1.201751708984375, G_Loss:3.5645737648010254

iterator 4800, D_Loss:0.6756088733673096, G_Loss:2.33223032951355

iterator 4900, D_Loss:0.5995128154754639, G_Loss:2.6541619300842285

iterator 5000, D_Loss:0.5562701225280762, G_Loss:3.4045748710632324

-----------Epoch 9-----------
iterator 100, D_Loss:0.9023044109344482, G_Loss:4.602149963378906

iterator 200, D_Loss:0.7657904624938965, G_Loss:2.3088457584381104

iterator 300, D_Loss:0.6313605308532715, G_Loss:2.7119014263153076

iterator 400, D_Loss:0.7843894362449646, G_Loss:3.3134117126464844

iterator 500, D_Loss:0.5525472164154053, G_Loss:5.484759330749512

iterator 600, D_Loss:0.5345375537872314, G_Loss:3.493448495864868

iterator 700, D_Loss:0.7987493276596069, G_Loss:1.4552733898162842

iterator 800, D_Loss:0.713118314743042, G_Loss:3.6673223972320557

iterator 900, D_Loss:1.1550204753875732, G_Loss:3.0689377784729004

iterator 1000, D_Loss:0.7624457478523254, G_Loss:2.6132473945617676

iterator 1100, D_Loss:1.6143392324447632, G_Loss:5.083096981048584

iterator 1200, D_Loss:0.8407998085021973, G_Loss:1.6725852489471436

iterator 1300, D_Loss:0.5261741876602173, G_Loss:2.5471694469451904

iterator 1400, D_Loss:1.3395106792449951, G_Loss:3.6350390911102295

iterator 1500, D_Loss:1.1801644563674927, G_Loss:5.120630741119385

iterator 1600, D_Loss:0.8303272128105164, G_Loss:3.2487361431121826

iterator 1700, D_Loss:1.0347659587860107, G_Loss:5.0913848876953125

iterator 1800, D_Loss:1.3053514957427979, G_Loss:2.498098850250244

iterator 1900, D_Loss:0.9777317047119141, G_Loss:1.6623425483703613

iterator 2000, D_Loss:0.6219475269317627, G_Loss:3.530022621154785

iterator 2100, D_Loss:0.5406650900840759, G_Loss:1.97975492477417

iterator 2200, D_Loss:0.7084627747535706, G_Loss:4.047440528869629

iterator 2300, D_Loss:0.5099545121192932, G_Loss:1.866429090499878

iterator 2400, D_Loss:1.6873399019241333, G_Loss:3.2508397102355957

iterator 2500, D_Loss:0.7145111560821533, G_Loss:4.074941158294678

iterator 2600, D_Loss:1.2376422882080078, G_Loss:2.147672653198242

iterator 2700, D_Loss:0.9950459003448486, G_Loss:1.9242486953735352

iterator 2800, D_Loss:1.0768117904663086, G_Loss:1.6471505165100098

iterator 2900, D_Loss:0.6062602996826172, G_Loss:1.8471262454986572

iterator 3000, D_Loss:0.6050636768341064, G_Loss:2.2079010009765625

iterator 3100, D_Loss:0.6174352169036865, G_Loss:3.0202620029449463

iterator 3200, D_Loss:1.2145981788635254, G_Loss:1.1239076852798462

iterator 3300, D_Loss:1.6270896196365356, G_Loss:3.014172077178955

iterator 3400, D_Loss:0.9189783334732056, G_Loss:4.0027756690979

iterator 3500, D_Loss:0.819306492805481, G_Loss:1.8306812047958374

iterator 3600, D_Loss:1.1503164768218994, G_Loss:5.5173444747924805

iterator 3700, D_Loss:0.5789581537246704, G_Loss:2.219041347503662

iterator 3800, D_Loss:0.9872015714645386, G_Loss:0.7472491264343262

iterator 3900, D_Loss:0.862212598323822, G_Loss:0.9668890237808228

iterator 4000, D_Loss:1.0372661352157593, G_Loss:2.974104642868042

iterator 4100, D_Loss:0.6861681342124939, G_Loss:2.670093059539795

iterator 4200, D_Loss:0.7362778782844543, G_Loss:4.691817283630371

iterator 4300, D_Loss:1.0770703554153442, G_Loss:2.577655076980591

iterator 4400, D_Loss:1.2326889038085938, G_Loss:1.833812952041626

iterator 4500, D_Loss:0.8232936263084412, G_Loss:1.5352790355682373

iterator 4600, D_Loss:0.5368011593818665, G_Loss:2.568051815032959

iterator 4700, D_Loss:0.5428078174591064, G_Loss:2.102471351623535

iterator 4800, D_Loss:0.6196309328079224, G_Loss:2.716496706008911

iterator 4900, D_Loss:1.9284814596176147, G_Loss:3.2707390785217285

iterator 5000, D_Loss:1.4473992586135864, G_Loss:3.391218662261963

LGAN_generator(
  (LSTM): LSTMCell(352, 300)
  (gmfc00): Linear(in_features=300, out_features=1, bias=True)
  (gmfc01): Linear(in_features=300, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=300, bias=True)
  (gmfe00): Linear(in_features=300, out_features=300, bias=True)
  (gmfe01): Linear(in_features=300, out_features=300, bias=True)
  (fc10): Linear(in_features=300, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=300, bias=True)
  (fe1): Linear(in_features=300, out_features=300, bias=True)
  (gmfc20): Linear(in_features=300, out_features=1, bias=True)
  (gmfc21): Linear(in_features=300, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=300, bias=True)
  (gmfe20): Linear(in_features=300, out_features=300, bias=True)
  (gmfe21): Linear(in_features=300, out_features=300, bias=True)
  (fc30): Linear(in_features=300, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=300, bias=True)
  (fe3): Linear(in_features=300, out_features=300, bias=True)
  (gmfc40): Linear(in_features=300, out_features=1, bias=True)
  (gmfc41): Linear(in_features=300, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=300, bias=True)
  (gmfe40): Linear(in_features=300, out_features=300, bias=True)
  (gmfe41): Linear(in_features=300, out_features=300, bias=True)
  (fc50): Linear(in_features=300, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=300, bias=True)
  (fe5): Linear(in_features=300, out_features=300, bias=True)
  (fc60): Linear(in_features=300, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=300, bias=True)
  (fe6): Linear(in_features=300, out_features=300, bias=True)
  (fc70): Linear(in_features=300, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=300, bias=True)
  (fe7): Linear(in_features=300, out_features=300, bias=True)
  (fc80): Linear(in_features=300, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=300, bias=True)
  (fe8): Linear(in_features=300, out_features=300, bias=True)
  (fc90): Linear(in_features=300, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=300, bias=True)
  (fe9): Linear(in_features=300, out_features=300, bias=True)
  (gmfc100): Linear(in_features=300, out_features=1, bias=True)
  (gmfc101): Linear(in_features=300, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=300, bias=True)
  (gmfe100): Linear(in_features=300, out_features=300, bias=True)
  (gmfe101): Linear(in_features=300, out_features=300, bias=True)
  (gmfc110): Linear(in_features=300, out_features=1, bias=True)
  (gmfc111): Linear(in_features=300, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=300, bias=True)
  (gmfe110): Linear(in_features=300, out_features=300, bias=True)
  (gmfe111): Linear(in_features=300, out_features=300, bias=True)
  (gmfc120): Linear(in_features=300, out_features=1, bias=True)
  (gmfc121): Linear(in_features=300, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=300, bias=True)
  (gmfe120): Linear(in_features=300, out_features=300, bias=True)
  (gmfe121): Linear(in_features=300, out_features=300, bias=True)
  (fc130): Linear(in_features=300, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=300, bias=True)
  (fe13): Linear(in_features=300, out_features=300, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=300, bias=True)
  (inputbn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=300, out_features=300, bias=True)
  (bn0): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=300, out_features=300, bias=True)
  (bn1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=300, out_features=300, bias=True)
  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=300, out_features=300, bias=True)
  (bn3): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc4): Linear(in_features=300, out_features=300, bias=True)
  (bn4): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=300, out_features=1, bias=True)
)
-----------Epoch 0-----------
iterator 100, D_Loss:1.4470856189727783, G_Loss:1.0534709692001343

iterator 200, D_Loss:1.420881986618042, G_Loss:1.018615484237671

iterator 300, D_Loss:1.4484204053878784, G_Loss:1.2583987712860107

iterator 400, D_Loss:1.4439313411712646, G_Loss:1.1657198667526245

iterator 500, D_Loss:1.3718132972717285, G_Loss:1.196414828300476

iterator 600, D_Loss:1.4574555158615112, G_Loss:1.1355308294296265

iterator 700, D_Loss:1.3819866180419922, G_Loss:1.0827014446258545

iterator 800, D_Loss:1.4166476726531982, G_Loss:1.0994783639907837

iterator 900, D_Loss:1.373844861984253, G_Loss:1.1429866552352905

iterator 1000, D_Loss:1.383152723312378, G_Loss:1.0917879343032837

iterator 1100, D_Loss:1.3786015510559082, G_Loss:1.2090710401535034

iterator 1200, D_Loss:1.3624517917633057, G_Loss:1.1203603744506836

iterator 1300, D_Loss:1.4206387996673584, G_Loss:1.0729573965072632

iterator 1400, D_Loss:1.3744500875473022, G_Loss:1.0739952325820923

iterator 1500, D_Loss:1.3599352836608887, G_Loss:1.0529862642288208

iterator 1600, D_Loss:1.3633627891540527, G_Loss:1.185882329940796

iterator 1700, D_Loss:1.381898283958435, G_Loss:1.0725812911987305

iterator 1800, D_Loss:1.3886973857879639, G_Loss:1.0958343744277954

iterator 1900, D_Loss:1.365492343902588, G_Loss:1.124374508857727

iterator 2000, D_Loss:1.3711119890213013, G_Loss:1.0577951669692993

iterator 2100, D_Loss:1.3885302543640137, G_Loss:1.1386988162994385

iterator 2200, D_Loss:1.3865749835968018, G_Loss:1.0756723880767822

iterator 2300, D_Loss:1.371250033378601, G_Loss:0.970116376876831

iterator 2400, D_Loss:1.3629999160766602, G_Loss:1.127931833267212

iterator 2500, D_Loss:1.3825206756591797, G_Loss:1.094122290611267

iterator 2600, D_Loss:1.3819568157196045, G_Loss:1.022731065750122

iterator 2700, D_Loss:1.393823504447937, G_Loss:1.1174405813217163

iterator 2800, D_Loss:1.3479201793670654, G_Loss:1.0907858610153198

iterator 2900, D_Loss:1.364393949508667, G_Loss:1.0933254957199097

iterator 3000, D_Loss:1.36001718044281, G_Loss:1.2636816501617432

iterator 3100, D_Loss:1.3582204580307007, G_Loss:1.230352759361267

iterator 3200, D_Loss:1.3669462203979492, G_Loss:1.0697517395019531

iterator 3300, D_Loss:1.3484218120574951, G_Loss:1.0420618057250977

iterator 3400, D_Loss:1.3470830917358398, G_Loss:1.2371165752410889

iterator 3500, D_Loss:1.328589916229248, G_Loss:1.2835102081298828

iterator 3600, D_Loss:1.3190720081329346, G_Loss:1.2353317737579346

iterator 3700, D_Loss:1.2822442054748535, G_Loss:1.2524033784866333

iterator 3800, D_Loss:1.2525861263275146, G_Loss:1.2006157636642456

iterator 3900, D_Loss:1.341843843460083, G_Loss:1.1321523189544678

iterator 4000, D_Loss:1.2947057485580444, G_Loss:1.3822064399719238

iterator 4100, D_Loss:1.2728781700134277, G_Loss:1.3459607362747192

iterator 4200, D_Loss:1.1581625938415527, G_Loss:1.4622361660003662

iterator 4300, D_Loss:1.2123879194259644, G_Loss:1.4950001239776611

iterator 4400, D_Loss:1.1615090370178223, G_Loss:1.436259150505066

iterator 4500, D_Loss:1.1214197874069214, G_Loss:1.5166351795196533

iterator 4600, D_Loss:1.1533454656600952, G_Loss:1.70194673538208

iterator 4700, D_Loss:0.8928893804550171, G_Loss:1.8057235479354858

iterator 4800, D_Loss:1.0493100881576538, G_Loss:1.8910341262817383

iterator 4900, D_Loss:0.8844296932220459, G_Loss:1.4670090675354004

iterator 5000, D_Loss:0.9356964826583862, G_Loss:1.7879186868667603

-----------Epoch 1-----------
iterator 100, D_Loss:0.9865696430206299, G_Loss:1.5868034362792969

iterator 200, D_Loss:0.9038680195808411, G_Loss:2.004563331604004

iterator 300, D_Loss:0.8435168266296387, G_Loss:2.2594211101531982

iterator 400, D_Loss:0.985844612121582, G_Loss:2.3951451778411865

iterator 500, D_Loss:0.8427673578262329, G_Loss:1.863046407699585

iterator 600, D_Loss:0.7826625108718872, G_Loss:2.251786947250366

iterator 700, D_Loss:0.8415487408638, G_Loss:2.701042890548706

iterator 800, D_Loss:0.7858566045761108, G_Loss:2.0398430824279785

iterator 900, D_Loss:0.6445738077163696, G_Loss:1.992807388305664

iterator 1000, D_Loss:0.7822775840759277, G_Loss:2.6790781021118164

iterator 1100, D_Loss:1.0175479650497437, G_Loss:2.346632957458496

iterator 1200, D_Loss:0.9793052077293396, G_Loss:1.877766728401184

iterator 1300, D_Loss:0.6419331431388855, G_Loss:1.1415927410125732

iterator 1400, D_Loss:0.7393366098403931, G_Loss:1.9852960109710693

iterator 1500, D_Loss:0.7777808904647827, G_Loss:3.2207748889923096

iterator 1600, D_Loss:0.9277727603912354, G_Loss:2.861663818359375

iterator 1700, D_Loss:0.7682211399078369, G_Loss:2.053894519805908

iterator 1800, D_Loss:0.781135082244873, G_Loss:1.9767136573791504

iterator 1900, D_Loss:0.687762439250946, G_Loss:3.1054458618164062

iterator 2000, D_Loss:0.7583712339401245, G_Loss:3.076784133911133

iterator 2100, D_Loss:0.7873243689537048, G_Loss:1.0617859363555908

iterator 2200, D_Loss:0.9360545873641968, G_Loss:3.1733758449554443

iterator 2300, D_Loss:0.7369318008422852, G_Loss:2.3881754875183105

iterator 2400, D_Loss:0.697681188583374, G_Loss:1.9882563352584839

iterator 2500, D_Loss:0.9074851870536804, G_Loss:2.371596097946167

iterator 2600, D_Loss:0.7346489429473877, G_Loss:1.976549506187439

iterator 2700, D_Loss:1.021294116973877, G_Loss:2.4222021102905273

iterator 2800, D_Loss:0.6066524982452393, G_Loss:2.409762382507324

iterator 2900, D_Loss:1.1463568210601807, G_Loss:3.232887029647827

iterator 3000, D_Loss:1.3112213611602783, G_Loss:3.2219197750091553

iterator 3100, D_Loss:0.8763606548309326, G_Loss:1.8662292957305908

iterator 3200, D_Loss:0.714759349822998, G_Loss:3.6620664596557617

iterator 3300, D_Loss:0.7666810154914856, G_Loss:2.1192843914031982

iterator 3400, D_Loss:0.63776034116745, G_Loss:3.624948740005493

iterator 3500, D_Loss:0.7709589004516602, G_Loss:1.853025197982788

iterator 3600, D_Loss:0.7380900979042053, G_Loss:3.855367660522461

iterator 3700, D_Loss:0.9850807189941406, G_Loss:3.837736129760742

iterator 3800, D_Loss:0.7719476222991943, G_Loss:2.8560757637023926

iterator 3900, D_Loss:0.9695537090301514, G_Loss:2.9887542724609375

iterator 4000, D_Loss:1.1559182405471802, G_Loss:2.8313732147216797

iterator 4100, D_Loss:0.5614291429519653, G_Loss:3.3160643577575684

iterator 4200, D_Loss:0.5603221654891968, G_Loss:3.9105417728424072

iterator 4300, D_Loss:0.8640652298927307, G_Loss:4.0554633140563965

iterator 4400, D_Loss:0.624238908290863, G_Loss:3.8037426471710205

iterator 4500, D_Loss:0.634488582611084, G_Loss:2.68800950050354

iterator 4600, D_Loss:0.7250088453292847, G_Loss:2.7572739124298096

iterator 4700, D_Loss:1.4427845478057861, G_Loss:2.590208053588867

iterator 4800, D_Loss:0.6782704591751099, G_Loss:4.0058112144470215

iterator 4900, D_Loss:0.7140648365020752, G_Loss:3.356362819671631

iterator 5000, D_Loss:0.5949233174324036, G_Loss:3.2040395736694336

-----------Epoch 2-----------
iterator 100, D_Loss:0.6291306018829346, G_Loss:3.992805004119873

iterator 200, D_Loss:0.6352509260177612, G_Loss:3.261087417602539

iterator 300, D_Loss:0.48359641432762146, G_Loss:3.3943581581115723

iterator 400, D_Loss:0.5529123544692993, G_Loss:2.5547354221343994

iterator 500, D_Loss:0.7306039333343506, G_Loss:2.892739772796631

iterator 600, D_Loss:1.0674346685409546, G_Loss:3.5749402046203613

iterator 700, D_Loss:0.5654230117797852, G_Loss:2.285358428955078

iterator 800, D_Loss:0.7312142252922058, G_Loss:2.8343191146850586

iterator 900, D_Loss:0.5722371339797974, G_Loss:3.6540863513946533

iterator 1000, D_Loss:0.6065878868103027, G_Loss:4.091276168823242

iterator 1100, D_Loss:0.6531637907028198, G_Loss:2.1196913719177246

iterator 1200, D_Loss:0.524399995803833, G_Loss:3.953528642654419

iterator 1300, D_Loss:0.5259867906570435, G_Loss:3.5024774074554443

iterator 1400, D_Loss:0.551111102104187, G_Loss:3.7632060050964355

iterator 1500, D_Loss:0.5641544461250305, G_Loss:1.997541904449463

iterator 1600, D_Loss:1.2111036777496338, G_Loss:2.1635537147521973

iterator 1700, D_Loss:1.0090699195861816, G_Loss:2.177968740463257

iterator 1800, D_Loss:0.8514719009399414, G_Loss:3.2508416175842285

iterator 1900, D_Loss:0.6035997867584229, G_Loss:3.9640684127807617

iterator 2000, D_Loss:1.1321799755096436, G_Loss:3.542541265487671

iterator 2100, D_Loss:0.6338709592819214, G_Loss:4.510530471801758

iterator 2200, D_Loss:0.5268991589546204, G_Loss:4.8099799156188965

iterator 2300, D_Loss:0.7625690698623657, G_Loss:2.7144362926483154

iterator 2400, D_Loss:0.8035056591033936, G_Loss:3.5958244800567627

iterator 2500, D_Loss:1.8890197277069092, G_Loss:2.613250255584717

iterator 2600, D_Loss:1.4563958644866943, G_Loss:3.112813711166382

iterator 2700, D_Loss:0.8214898109436035, G_Loss:4.327923774719238

iterator 2800, D_Loss:2.613124370574951, G_Loss:3.695788860321045

iterator 2900, D_Loss:1.0404512882232666, G_Loss:4.36048698425293

iterator 3000, D_Loss:1.2733798027038574, G_Loss:4.667672634124756

iterator 3100, D_Loss:0.7013746500015259, G_Loss:3.9599857330322266

iterator 3200, D_Loss:0.5300890207290649, G_Loss:4.672046184539795

iterator 3300, D_Loss:0.8355482816696167, G_Loss:1.9761812686920166

iterator 3400, D_Loss:0.5346190333366394, G_Loss:2.9514923095703125

iterator 3500, D_Loss:0.5075398087501526, G_Loss:5.5889997482299805

iterator 3600, D_Loss:0.5201348662376404, G_Loss:3.8047094345092773

iterator 3700, D_Loss:0.5399130582809448, G_Loss:3.483309268951416

iterator 3800, D_Loss:0.5679141283035278, G_Loss:3.217418670654297

iterator 3900, D_Loss:0.5444208979606628, G_Loss:5.455467700958252

iterator 4000, D_Loss:0.5252387523651123, G_Loss:5.322998523712158

iterator 4100, D_Loss:0.4973527193069458, G_Loss:3.594437599182129

iterator 4200, D_Loss:0.6917091608047485, G_Loss:4.232356071472168

iterator 4300, D_Loss:0.6514674425125122, G_Loss:3.9429359436035156

iterator 4400, D_Loss:0.5528183579444885, G_Loss:4.655628204345703

iterator 4500, D_Loss:0.6540886759757996, G_Loss:3.5916008949279785

iterator 4600, D_Loss:0.6169742345809937, G_Loss:3.3822197914123535

iterator 4700, D_Loss:0.9456674456596375, G_Loss:4.051839828491211

iterator 4800, D_Loss:0.6118999719619751, G_Loss:3.319598436355591

iterator 4900, D_Loss:0.5455586910247803, G_Loss:3.9929704666137695

iterator 5000, D_Loss:0.6189335584640503, G_Loss:4.699131488800049

-----------Epoch 3-----------
iterator 100, D_Loss:0.5237172842025757, G_Loss:3.356931209564209

iterator 200, D_Loss:0.4607759714126587, G_Loss:4.1417717933654785

iterator 300, D_Loss:0.586979866027832, G_Loss:3.7176270484924316

iterator 400, D_Loss:0.48507973551750183, G_Loss:3.931256055831909

iterator 500, D_Loss:0.5536843538284302, G_Loss:3.3170876502990723

iterator 600, D_Loss:0.7180724740028381, G_Loss:2.9976954460144043

iterator 700, D_Loss:0.560474157333374, G_Loss:3.5913076400756836

iterator 800, D_Loss:0.6330968737602234, G_Loss:5.134973526000977

iterator 900, D_Loss:0.48575150966644287, G_Loss:3.6458957195281982

iterator 1000, D_Loss:0.7142050862312317, G_Loss:3.929673194885254

iterator 1100, D_Loss:1.318788766860962, G_Loss:3.530866861343384

iterator 1200, D_Loss:0.659178614616394, G_Loss:3.7729969024658203

iterator 1300, D_Loss:0.5718156099319458, G_Loss:3.4079911708831787

iterator 1400, D_Loss:0.44190213084220886, G_Loss:4.927003860473633

iterator 1500, D_Loss:0.5890973210334778, G_Loss:4.720162391662598

iterator 1600, D_Loss:0.5078124403953552, G_Loss:2.2545762062072754

iterator 1700, D_Loss:0.5060001015663147, G_Loss:3.633389472961426

iterator 1800, D_Loss:0.6738091707229614, G_Loss:3.6441144943237305

iterator 1900, D_Loss:0.49590009450912476, G_Loss:3.363715410232544

iterator 2000, D_Loss:0.4610708951950073, G_Loss:4.748050212860107

iterator 2100, D_Loss:0.49191105365753174, G_Loss:5.712797164916992

iterator 2200, D_Loss:0.4716169238090515, G_Loss:5.425645351409912

iterator 2300, D_Loss:0.43801000714302063, G_Loss:4.476454257965088

iterator 2400, D_Loss:0.528441309928894, G_Loss:4.5865254402160645

iterator 2500, D_Loss:0.5138662457466125, G_Loss:2.8877084255218506

iterator 2600, D_Loss:0.6064850687980652, G_Loss:3.519728899002075

iterator 2700, D_Loss:0.5927101969718933, G_Loss:3.3612403869628906

iterator 2800, D_Loss:1.2865800857543945, G_Loss:2.9577131271362305

iterator 2900, D_Loss:0.5998013615608215, G_Loss:4.050338268280029

iterator 3000, D_Loss:0.7869853377342224, G_Loss:4.352819919586182

iterator 3100, D_Loss:0.5240294337272644, G_Loss:5.005985260009766

iterator 3200, D_Loss:0.5955643653869629, G_Loss:6.183149337768555

iterator 3300, D_Loss:0.49967676401138306, G_Loss:5.587162017822266

iterator 3400, D_Loss:0.4823884069919586, G_Loss:2.3311405181884766

iterator 3500, D_Loss:0.4389408826828003, G_Loss:2.7330524921417236

iterator 3600, D_Loss:0.512897253036499, G_Loss:2.7821245193481445

iterator 3700, D_Loss:0.8742556571960449, G_Loss:3.9406259059906006

iterator 3800, D_Loss:0.9020676612854004, G_Loss:4.303012847900391

iterator 3900, D_Loss:0.9084603786468506, G_Loss:1.0465679168701172

iterator 4000, D_Loss:0.5094597339630127, G_Loss:5.302365303039551

iterator 4100, D_Loss:0.46898502111434937, G_Loss:4.8467841148376465

iterator 4200, D_Loss:0.44873863458633423, G_Loss:3.712298631668091

iterator 4300, D_Loss:0.46339571475982666, G_Loss:5.315145492553711

iterator 4400, D_Loss:0.4982871413230896, G_Loss:4.06109094619751

iterator 4500, D_Loss:0.438787043094635, G_Loss:4.039095401763916

iterator 4600, D_Loss:0.4729674160480499, G_Loss:4.673130512237549

iterator 4700, D_Loss:0.46365272998809814, G_Loss:5.855925559997559

iterator 4800, D_Loss:0.47528594732284546, G_Loss:5.985340595245361

iterator 4900, D_Loss:0.4482937157154083, G_Loss:4.311349391937256

iterator 5000, D_Loss:0.4741570055484772, G_Loss:6.455808162689209

-----------Epoch 4-----------
iterator 100, D_Loss:0.481465607881546, G_Loss:4.889031410217285

iterator 200, D_Loss:0.613741934299469, G_Loss:3.9098970890045166

iterator 300, D_Loss:0.48955202102661133, G_Loss:6.801933288574219

iterator 400, D_Loss:0.4900178611278534, G_Loss:4.90677547454834

iterator 500, D_Loss:0.4689823389053345, G_Loss:4.399925708770752

iterator 600, D_Loss:0.5565314292907715, G_Loss:4.9430365562438965

iterator 700, D_Loss:0.6314003467559814, G_Loss:6.342770576477051

iterator 800, D_Loss:0.4798600375652313, G_Loss:4.133654594421387

iterator 900, D_Loss:0.47528356313705444, G_Loss:5.546300411224365

iterator 1000, D_Loss:0.5020064115524292, G_Loss:5.652715682983398

iterator 1100, D_Loss:0.4779995083808899, G_Loss:4.226505279541016

iterator 1200, D_Loss:0.5550328493118286, G_Loss:2.67659854888916

iterator 1300, D_Loss:0.46032071113586426, G_Loss:4.247051239013672

iterator 1400, D_Loss:0.47548022866249084, G_Loss:5.308792591094971

iterator 1500, D_Loss:0.5087834000587463, G_Loss:5.21628999710083

iterator 1600, D_Loss:0.630200982093811, G_Loss:4.727190971374512

iterator 1700, D_Loss:0.49749231338500977, G_Loss:4.6480393409729

iterator 1800, D_Loss:0.47069746255874634, G_Loss:4.628662109375

iterator 1900, D_Loss:1.1088513135910034, G_Loss:2.541546106338501

iterator 2000, D_Loss:0.4800814986228943, G_Loss:4.720602989196777

iterator 2100, D_Loss:0.5072969198226929, G_Loss:3.9712324142456055

iterator 2200, D_Loss:0.452487051486969, G_Loss:7.219832420349121

iterator 2300, D_Loss:0.5015344619750977, G_Loss:5.543735027313232

iterator 2400, D_Loss:0.49383828043937683, G_Loss:6.066821098327637

iterator 2500, D_Loss:0.3855438530445099, G_Loss:4.549402713775635

iterator 2600, D_Loss:0.534507155418396, G_Loss:5.7940568923950195

iterator 2700, D_Loss:0.5211186408996582, G_Loss:6.148318290710449

iterator 2800, D_Loss:0.41816237568855286, G_Loss:3.904954433441162

iterator 2900, D_Loss:0.5358290076255798, G_Loss:3.088089942932129

iterator 3000, D_Loss:1.5818397998809814, G_Loss:4.749286651611328

iterator 3100, D_Loss:0.49712762236595154, G_Loss:7.212744235992432

iterator 3200, D_Loss:0.4204038083553314, G_Loss:4.689753532409668

iterator 3300, D_Loss:0.4627498388290405, G_Loss:3.6268932819366455

iterator 3400, D_Loss:0.47678452730178833, G_Loss:5.219830513000488

iterator 3500, D_Loss:0.4481106698513031, G_Loss:6.211117744445801

iterator 3600, D_Loss:0.47138771414756775, G_Loss:6.079972743988037

iterator 3700, D_Loss:0.531613826751709, G_Loss:6.702879428863525

iterator 3800, D_Loss:0.44682222604751587, G_Loss:6.126840591430664

iterator 3900, D_Loss:0.5056237578392029, G_Loss:3.829641103744507

iterator 4000, D_Loss:0.8720182776451111, G_Loss:6.419384956359863

iterator 4100, D_Loss:0.4365246593952179, G_Loss:5.329982280731201

iterator 4200, D_Loss:0.4446597695350647, G_Loss:6.110546112060547

iterator 4300, D_Loss:0.5635412335395813, G_Loss:8.129590034484863

iterator 4400, D_Loss:0.43399733304977417, G_Loss:5.171252727508545

iterator 4500, D_Loss:0.4688223600387573, G_Loss:3.0895755290985107

iterator 4600, D_Loss:0.5000166296958923, G_Loss:6.075970649719238

iterator 4700, D_Loss:0.44093257188796997, G_Loss:3.6992104053497314

iterator 4800, D_Loss:0.44945505261421204, G_Loss:8.369845390319824

iterator 4900, D_Loss:0.45321160554885864, G_Loss:5.7702131271362305

iterator 5000, D_Loss:0.45945844054222107, G_Loss:5.766529083251953

-----------Epoch 5-----------
iterator 100, D_Loss:0.44623202085494995, G_Loss:3.0319128036499023

iterator 200, D_Loss:0.47981777787208557, G_Loss:4.790029048919678

iterator 300, D_Loss:0.48825088143348694, G_Loss:7.639400959014893

iterator 400, D_Loss:0.4984113276004791, G_Loss:4.496007919311523

iterator 500, D_Loss:0.45966729521751404, G_Loss:5.212639331817627

iterator 600, D_Loss:0.4357689321041107, G_Loss:5.133886337280273

iterator 700, D_Loss:0.4728684425354004, G_Loss:6.290914535522461

iterator 800, D_Loss:0.45162051916122437, G_Loss:5.761943340301514

iterator 900, D_Loss:0.4638086259365082, G_Loss:7.410131454467773

iterator 1000, D_Loss:0.5161827802658081, G_Loss:6.591717720031738

iterator 1100, D_Loss:0.45894941687583923, G_Loss:6.346120357513428

iterator 1200, D_Loss:0.48986849188804626, G_Loss:5.5854902267456055

iterator 1300, D_Loss:0.44354361295700073, G_Loss:4.190631866455078

iterator 1400, D_Loss:0.49391382932662964, G_Loss:6.29433012008667

iterator 1500, D_Loss:0.4213358759880066, G_Loss:7.031922817230225

iterator 1600, D_Loss:0.48921531438827515, G_Loss:2.7335309982299805

iterator 1700, D_Loss:0.4862147867679596, G_Loss:6.545919418334961

iterator 1800, D_Loss:0.4683949649333954, G_Loss:5.52762508392334

iterator 1900, D_Loss:0.4720880687236786, G_Loss:6.852820873260498

iterator 2000, D_Loss:0.4295719861984253, G_Loss:3.1250839233398438

iterator 2100, D_Loss:0.4337061643600464, G_Loss:7.840612888336182

iterator 2200, D_Loss:0.4383397400379181, G_Loss:6.312259674072266

iterator 2300, D_Loss:0.40864336490631104, G_Loss:4.829138278961182

iterator 2400, D_Loss:0.4666008949279785, G_Loss:3.637375831604004

iterator 2500, D_Loss:0.48086878657341003, G_Loss:6.947951793670654

iterator 2600, D_Loss:0.4578106999397278, G_Loss:6.207132339477539

iterator 2700, D_Loss:0.4115462899208069, G_Loss:6.180113315582275

iterator 2800, D_Loss:1.4873807430267334, G_Loss:9.103625297546387

iterator 2900, D_Loss:0.5703591108322144, G_Loss:7.815157890319824

iterator 3000, D_Loss:1.0985908508300781, G_Loss:4.91443395614624

iterator 3100, D_Loss:0.9281684160232544, G_Loss:2.3013668060302734

iterator 3200, D_Loss:0.44081324338912964, G_Loss:1.5543911457061768

iterator 3300, D_Loss:0.5049588680267334, G_Loss:1.4608924388885498

iterator 3400, D_Loss:2.2165029048919678, G_Loss:1.7871651649475098

iterator 3500, D_Loss:0.48723968863487244, G_Loss:6.273628234863281

iterator 3600, D_Loss:0.4351420998573303, G_Loss:2.4205877780914307

iterator 3700, D_Loss:0.4760148525238037, G_Loss:3.876427173614502

iterator 3800, D_Loss:0.4634076952934265, G_Loss:4.318441867828369

iterator 3900, D_Loss:0.45747110247612, G_Loss:2.7587108612060547

iterator 4000, D_Loss:0.49593085050582886, G_Loss:5.266760349273682

iterator 4100, D_Loss:0.5918518304824829, G_Loss:5.5248918533325195

iterator 4200, D_Loss:0.43669959902763367, G_Loss:4.3159050941467285

iterator 4300, D_Loss:0.48396968841552734, G_Loss:7.262809753417969

iterator 4400, D_Loss:0.4726606607437134, G_Loss:6.628714084625244

iterator 4500, D_Loss:0.4291350245475769, G_Loss:6.42384672164917

iterator 4600, D_Loss:0.4241338074207306, G_Loss:5.349700927734375

iterator 4700, D_Loss:0.39117154479026794, G_Loss:7.881704807281494

iterator 4800, D_Loss:0.4642156958580017, G_Loss:7.786064147949219

iterator 4900, D_Loss:0.49570757150650024, G_Loss:7.6074323654174805

iterator 5000, D_Loss:0.4707503318786621, G_Loss:8.17830753326416

-----------Epoch 6-----------
iterator 100, D_Loss:0.4231659770011902, G_Loss:5.72606086730957

iterator 200, D_Loss:0.43928998708724976, G_Loss:6.655695915222168

iterator 300, D_Loss:0.4623025357723236, G_Loss:7.393004894256592

iterator 400, D_Loss:0.4375918507575989, G_Loss:6.335190773010254

iterator 500, D_Loss:0.46013975143432617, G_Loss:6.444439888000488

iterator 600, D_Loss:0.4700222313404083, G_Loss:8.677624702453613

iterator 700, D_Loss:0.47644373774528503, G_Loss:9.951175689697266

iterator 800, D_Loss:0.4580978453159332, G_Loss:5.7220940589904785

iterator 900, D_Loss:0.4573688805103302, G_Loss:7.1318864822387695

iterator 1000, D_Loss:0.42771705985069275, G_Loss:6.477167129516602

iterator 1100, D_Loss:0.6536473035812378, G_Loss:8.361454963684082

iterator 1200, D_Loss:0.6297049522399902, G_Loss:6.194997787475586

iterator 1300, D_Loss:0.4304003417491913, G_Loss:5.29770565032959

iterator 1400, D_Loss:0.4166432023048401, G_Loss:8.378937721252441

iterator 1500, D_Loss:0.4404265880584717, G_Loss:6.434370994567871

iterator 1600, D_Loss:0.4526638686656952, G_Loss:7.060300827026367

iterator 1700, D_Loss:0.42696690559387207, G_Loss:9.118762016296387

iterator 1800, D_Loss:0.49545058608055115, G_Loss:7.568512916564941

iterator 1900, D_Loss:0.4162760078907013, G_Loss:8.384241104125977

iterator 2000, D_Loss:0.47676852345466614, G_Loss:9.17824649810791

iterator 2100, D_Loss:0.45771318674087524, G_Loss:8.896873474121094

iterator 2200, D_Loss:0.4991397559642792, G_Loss:7.748778343200684

iterator 2300, D_Loss:0.4736006557941437, G_Loss:7.5201239585876465

iterator 2400, D_Loss:0.46073850989341736, G_Loss:6.319956302642822

iterator 2500, D_Loss:0.4557911455631256, G_Loss:6.067656993865967

iterator 2600, D_Loss:0.4417704939842224, G_Loss:6.626434803009033

iterator 2700, D_Loss:0.4713161885738373, G_Loss:8.926298141479492

iterator 2800, D_Loss:0.43030792474746704, G_Loss:8.167596817016602

iterator 2900, D_Loss:0.46512341499328613, G_Loss:7.467378616333008

iterator 3000, D_Loss:0.7247818112373352, G_Loss:8.442819595336914

iterator 3100, D_Loss:0.44600966572761536, G_Loss:9.571654319763184

iterator 3200, D_Loss:0.46043160557746887, G_Loss:7.3208489418029785

iterator 3300, D_Loss:0.4203709661960602, G_Loss:8.673901557922363

iterator 3400, D_Loss:0.45829644799232483, G_Loss:9.890949249267578

iterator 3500, D_Loss:0.4213521182537079, G_Loss:8.8272705078125

iterator 3600, D_Loss:0.44650113582611084, G_Loss:7.08534049987793

iterator 3700, D_Loss:0.41441231966018677, G_Loss:9.431869506835938

iterator 3800, D_Loss:0.4556981921195984, G_Loss:6.0495195388793945

iterator 3900, D_Loss:0.42230424284935, G_Loss:7.740827560424805

iterator 4000, D_Loss:0.4568384289741516, G_Loss:8.837250709533691

iterator 4100, D_Loss:0.4682065546512604, G_Loss:7.59981632232666

iterator 4200, D_Loss:0.43505167961120605, G_Loss:8.74709415435791

iterator 4300, D_Loss:0.46389856934547424, G_Loss:9.673543930053711

iterator 4400, D_Loss:0.44953083992004395, G_Loss:8.861223220825195

iterator 4500, D_Loss:0.4395594596862793, G_Loss:7.652098655700684

iterator 4600, D_Loss:0.4400973618030548, G_Loss:7.241013526916504

iterator 4700, D_Loss:0.4429669678211212, G_Loss:7.793168544769287

iterator 4800, D_Loss:0.49130356311798096, G_Loss:9.845771789550781

iterator 4900, D_Loss:0.44990038871765137, G_Loss:9.577327728271484

iterator 5000, D_Loss:0.45858779549598694, G_Loss:8.27323055267334

-----------Epoch 7-----------
iterator 100, D_Loss:0.4616177976131439, G_Loss:7.786560535430908

iterator 200, D_Loss:0.446829229593277, G_Loss:8.469016075134277

iterator 300, D_Loss:0.45675405859947205, G_Loss:9.874689102172852

iterator 400, D_Loss:0.4384841024875641, G_Loss:9.00452995300293

iterator 500, D_Loss:0.47693580389022827, G_Loss:8.175397872924805

iterator 600, D_Loss:0.4358580410480499, G_Loss:9.690086364746094

iterator 700, D_Loss:0.3861781656742096, G_Loss:10.424824714660645

iterator 800, D_Loss:0.4912186861038208, G_Loss:7.139151096343994

iterator 900, D_Loss:0.42900246381759644, G_Loss:9.660052299499512

iterator 1000, D_Loss:0.4902345538139343, G_Loss:9.653204917907715

iterator 1100, D_Loss:0.4483499526977539, G_Loss:8.358135223388672

iterator 1200, D_Loss:0.44857093691825867, G_Loss:6.432593822479248

iterator 1300, D_Loss:0.4020535945892334, G_Loss:8.022553443908691

iterator 1400, D_Loss:0.41795554757118225, G_Loss:10.352405548095703

iterator 1500, D_Loss:0.40566763281822205, G_Loss:9.062166213989258

iterator 1600, D_Loss:0.4908486008644104, G_Loss:7.440703868865967

iterator 1700, D_Loss:0.4576578140258789, G_Loss:9.405169486999512

iterator 1800, D_Loss:0.3975532352924347, G_Loss:7.132349967956543

iterator 1900, D_Loss:0.4774612784385681, G_Loss:8.567770957946777

iterator 2000, D_Loss:0.44670605659484863, G_Loss:8.683876037597656

iterator 2100, D_Loss:0.3913951516151428, G_Loss:9.820378303527832

iterator 2200, D_Loss:0.4011516869068146, G_Loss:9.279691696166992

iterator 2300, D_Loss:0.4761772155761719, G_Loss:7.993641376495361

iterator 2400, D_Loss:0.45968589186668396, G_Loss:6.766162872314453

iterator 2500, D_Loss:0.4689452350139618, G_Loss:8.144569396972656

iterator 2600, D_Loss:0.41150450706481934, G_Loss:7.638396263122559

iterator 2700, D_Loss:0.4640158712863922, G_Loss:9.309537887573242

iterator 2800, D_Loss:0.4442228078842163, G_Loss:7.587546348571777

iterator 2900, D_Loss:0.4879971444606781, G_Loss:8.202573776245117

iterator 3000, D_Loss:0.42959386110305786, G_Loss:8.358534812927246

iterator 3100, D_Loss:0.4438725411891937, G_Loss:10.47590446472168

iterator 3200, D_Loss:0.4466535449028015, G_Loss:11.177886962890625

iterator 3300, D_Loss:0.46897032856941223, G_Loss:4.35837459564209

iterator 3400, D_Loss:0.41900306940078735, G_Loss:9.960407257080078

iterator 3500, D_Loss:0.43050310015678406, G_Loss:8.075514793395996

iterator 3600, D_Loss:0.43448498845100403, G_Loss:8.24195671081543

iterator 3700, D_Loss:0.4683303236961365, G_Loss:10.62855339050293

iterator 3800, D_Loss:0.440060555934906, G_Loss:7.242981433868408

iterator 3900, D_Loss:0.8270785808563232, G_Loss:5.263838768005371

iterator 4000, D_Loss:0.6529443264007568, G_Loss:8.93078899383545

iterator 4100, D_Loss:0.4623246490955353, G_Loss:8.28504467010498

iterator 4200, D_Loss:0.4450224041938782, G_Loss:8.694185256958008

iterator 4300, D_Loss:0.45654040575027466, G_Loss:10.2567138671875

iterator 4400, D_Loss:0.4466024935245514, G_Loss:8.092706680297852

iterator 4500, D_Loss:0.4773426055908203, G_Loss:7.786154747009277

iterator 4600, D_Loss:0.49240800738334656, G_Loss:7.291470527648926

iterator 4700, D_Loss:0.45464015007019043, G_Loss:11.601167678833008

iterator 4800, D_Loss:0.5052977204322815, G_Loss:6.355099678039551

iterator 4900, D_Loss:0.4361405670642853, G_Loss:2.4779536724090576

iterator 5000, D_Loss:0.44888103008270264, G_Loss:4.185555458068848

-----------Epoch 8-----------
iterator 100, D_Loss:0.4493226408958435, G_Loss:9.272741317749023

iterator 200, D_Loss:0.4525098204612732, G_Loss:9.74711799621582

iterator 300, D_Loss:0.4394323229789734, G_Loss:9.806713104248047

iterator 400, D_Loss:0.47515857219696045, G_Loss:8.42656135559082

iterator 500, D_Loss:0.6180011630058289, G_Loss:7.725205898284912

iterator 600, D_Loss:2.1470377445220947, G_Loss:8.25121021270752

iterator 700, D_Loss:0.49443578720092773, G_Loss:9.218812942504883

iterator 800, D_Loss:0.45818695425987244, G_Loss:7.372376918792725

iterator 900, D_Loss:0.4886045753955841, G_Loss:5.6088433265686035

iterator 1000, D_Loss:0.5294569730758667, G_Loss:6.051368236541748

iterator 1100, D_Loss:0.4398943781852722, G_Loss:9.536752700805664

iterator 1200, D_Loss:0.4260399341583252, G_Loss:4.568255424499512

iterator 1300, D_Loss:0.4637104868888855, G_Loss:6.508028507232666

iterator 1400, D_Loss:0.44783052802085876, G_Loss:6.534135341644287

iterator 1500, D_Loss:0.45681217312812805, G_Loss:7.2918548583984375

iterator 1600, D_Loss:0.44480255246162415, G_Loss:11.285877227783203

iterator 1700, D_Loss:0.4597111940383911, G_Loss:6.913939952850342

iterator 1800, D_Loss:0.5255166292190552, G_Loss:2.3882577419281006

iterator 1900, D_Loss:0.4392186999320984, G_Loss:7.621551036834717

iterator 2000, D_Loss:0.4718013107776642, G_Loss:10.107705116271973

iterator 2100, D_Loss:0.5069151520729065, G_Loss:9.10745906829834

iterator 2200, D_Loss:0.4200901687145233, G_Loss:4.662413597106934

iterator 2300, D_Loss:0.44205668568611145, G_Loss:1.076333999633789

iterator 2400, D_Loss:0.44819435477256775, G_Loss:4.9919962882995605

iterator 2500, D_Loss:1.9170258045196533, G_Loss:7.752946853637695

iterator 2600, D_Loss:0.4707702100276947, G_Loss:10.040860176086426

iterator 2700, D_Loss:0.4828559160232544, G_Loss:7.4217729568481445

iterator 2800, D_Loss:0.4556509852409363, G_Loss:7.486317157745361

iterator 2900, D_Loss:0.41999998688697815, G_Loss:9.106359481811523

iterator 3000, D_Loss:2.4361536502838135, G_Loss:7.115581035614014

iterator 3100, D_Loss:0.49927863478660583, G_Loss:8.48702621459961

iterator 3200, D_Loss:0.4206828773021698, G_Loss:3.918085813522339

iterator 3300, D_Loss:0.4971763491630554, G_Loss:5.75892448425293

iterator 3400, D_Loss:0.46645405888557434, G_Loss:7.415481090545654

iterator 3500, D_Loss:0.47302454710006714, G_Loss:8.707513809204102

iterator 3600, D_Loss:0.41376444697380066, G_Loss:4.84429931640625

iterator 3700, D_Loss:0.5169332027435303, G_Loss:6.779838562011719

iterator 3800, D_Loss:0.41641849279403687, G_Loss:7.153697490692139

iterator 3900, D_Loss:0.5173385739326477, G_Loss:2.181857109069824

iterator 4000, D_Loss:0.4999377727508545, G_Loss:3.7743172645568848

iterator 4100, D_Loss:0.4849129915237427, G_Loss:2.2388880252838135

iterator 4200, D_Loss:0.4441549479961395, G_Loss:6.444733619689941

iterator 4300, D_Loss:0.45345571637153625, G_Loss:8.159027099609375

iterator 4400, D_Loss:0.44361814856529236, G_Loss:8.770658493041992

iterator 4500, D_Loss:0.4172094166278839, G_Loss:8.853262901306152

iterator 4600, D_Loss:0.48900896310806274, G_Loss:6.526103973388672

iterator 4700, D_Loss:0.4105890393257141, G_Loss:8.57204818725586

iterator 4800, D_Loss:0.46103307604789734, G_Loss:6.528792381286621

iterator 4900, D_Loss:0.47313374280929565, G_Loss:6.4059624671936035

iterator 5000, D_Loss:0.4345231354236603, G_Loss:9.810076713562012

-----------Epoch 9-----------
iterator 100, D_Loss:0.4245672821998596, G_Loss:8.466480255126953

iterator 200, D_Loss:0.4336789846420288, G_Loss:8.121874809265137

iterator 300, D_Loss:0.4422629475593567, G_Loss:7.9675750732421875

iterator 400, D_Loss:0.47606369853019714, G_Loss:9.750940322875977

iterator 500, D_Loss:0.4481506943702698, G_Loss:5.351153373718262

iterator 600, D_Loss:0.4460054934024811, G_Loss:12.332136154174805

iterator 700, D_Loss:0.47177085280418396, G_Loss:9.6397066116333

iterator 800, D_Loss:0.504797637462616, G_Loss:6.978960037231445

iterator 900, D_Loss:0.44799521565437317, G_Loss:9.091039657592773

iterator 1000, D_Loss:0.48152631521224976, G_Loss:9.948610305786133

iterator 1100, D_Loss:0.405489057302475, G_Loss:7.626470565795898

iterator 1200, D_Loss:0.514678955078125, G_Loss:4.095292568206787

iterator 1300, D_Loss:0.44159406423568726, G_Loss:6.651978015899658

iterator 1400, D_Loss:0.4611269235610962, G_Loss:8.545763969421387

iterator 1500, D_Loss:0.4121968150138855, G_Loss:10.37547492980957

iterator 1600, D_Loss:0.41871803998947144, G_Loss:7.205303192138672

iterator 1700, D_Loss:0.42006126046180725, G_Loss:8.88907241821289

iterator 1800, D_Loss:0.4667522609233856, G_Loss:8.509650230407715

iterator 1900, D_Loss:0.4590573310852051, G_Loss:8.217421531677246

iterator 2000, D_Loss:0.45813196897506714, G_Loss:10.7041015625

iterator 2100, D_Loss:0.42080485820770264, G_Loss:10.02016544342041

iterator 2200, D_Loss:0.45677560567855835, G_Loss:9.494101524353027

iterator 2300, D_Loss:0.6565600633621216, G_Loss:8.870036125183105

iterator 2400, D_Loss:0.4398334324359894, G_Loss:8.041960716247559

iterator 2500, D_Loss:0.5756303668022156, G_Loss:8.160503387451172

iterator 2600, D_Loss:0.4520778954029083, G_Loss:7.86354923248291

iterator 2700, D_Loss:0.4432525932788849, G_Loss:10.28033447265625

iterator 2800, D_Loss:0.44063812494277954, G_Loss:8.989259719848633

iterator 2900, D_Loss:0.4129384756088257, G_Loss:9.555049896240234

iterator 3000, D_Loss:0.4519350528717041, G_Loss:9.839540481567383

iterator 3100, D_Loss:0.4828285276889801, G_Loss:10.068086624145508

iterator 3200, D_Loss:0.4740048944950104, G_Loss:11.903205871582031

iterator 3300, D_Loss:0.44466423988342285, G_Loss:7.658679485321045

iterator 3400, D_Loss:0.43173277378082275, G_Loss:11.48323917388916

iterator 3500, D_Loss:0.4467103183269501, G_Loss:10.13766098022461

iterator 3600, D_Loss:0.45915621519088745, G_Loss:7.736766815185547

iterator 3700, D_Loss:0.44109827280044556, G_Loss:9.960138320922852

iterator 3800, D_Loss:0.4111941456794739, G_Loss:7.412074089050293

iterator 3900, D_Loss:0.4644376039505005, G_Loss:5.0353312492370605

iterator 4000, D_Loss:0.4052908420562744, G_Loss:9.131895065307617

iterator 4100, D_Loss:0.4505968391895294, G_Loss:11.62226390838623

iterator 4200, D_Loss:0.44524532556533813, G_Loss:10.497047424316406

iterator 4300, D_Loss:0.46884292364120483, G_Loss:12.258697509765625

iterator 4400, D_Loss:0.45693960785865784, G_Loss:9.342178344726562

iterator 4500, D_Loss:0.4490884244441986, G_Loss:8.706368446350098

iterator 4600, D_Loss:0.42492935061454773, G_Loss:8.218893051147461

iterator 4700, D_Loss:0.4733749330043793, G_Loss:9.721366882324219

iterator 4800, D_Loss:0.45201635360717773, G_Loss:8.850974082946777

iterator 4900, D_Loss:0.4522966742515564, G_Loss:8.24117660522461

iterator 5000, D_Loss:0.3975602388381958, G_Loss:8.961478233337402

train row : 30148
sample row: 30148
Process Process-72:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 69, in thread_run
    train_method = config["train_method"]
KeyError: 'train_method'
Process Process-71:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 69, in thread_run
    train_method = config["train_method"]
KeyError: 'train_method'
Process Process-73:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 69, in thread_run
    train_method = config["train_method"]
KeyError: 'train_method'
Process Process-74:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 69, in thread_run
    train_method = config["train_method"]
KeyError: 'train_method'
Process Process-76:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 69, in thread_run
    train_method = config["train_method"]
KeyError: 'train_method'
Process Process-75:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 69, in thread_run
    train_method = config["train_method"]
KeyError: 'train_method'
Process Process-77:
Traceback (most recent call last):
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "Daisy/run.py", line 69, in thread_run
    train_method = config["train_method"]
KeyError: 'train_method'
train row : 30148
sample row: 30148
LGAN_generator(
  (LSTM): LSTMCell(300, 200)
  (gmfc00): Linear(in_features=200, out_features=1, bias=True)
  (gmfc01): Linear(in_features=200, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=200, bias=True)
  (gmfe00): Linear(in_features=200, out_features=200, bias=True)
  (gmfe01): Linear(in_features=200, out_features=200, bias=True)
  (fc10): Linear(in_features=200, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=200, bias=True)
  (fe1): Linear(in_features=200, out_features=200, bias=True)
  (gmfc20): Linear(in_features=200, out_features=1, bias=True)
  (gmfc21): Linear(in_features=200, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=200, bias=True)
  (gmfe20): Linear(in_features=200, out_features=200, bias=True)
  (gmfe21): Linear(in_features=200, out_features=200, bias=True)
  (fc30): Linear(in_features=200, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=200, bias=True)
  (fe3): Linear(in_features=200, out_features=200, bias=True)
  (gmfc40): Linear(in_features=200, out_features=1, bias=True)
  (gmfc41): Linear(in_features=200, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=200, bias=True)
  (gmfe40): Linear(in_features=200, out_features=200, bias=True)
  (gmfe41): Linear(in_features=200, out_features=200, bias=True)
  (fc50): Linear(in_features=200, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=200, bias=True)
  (fe5): Linear(in_features=200, out_features=200, bias=True)
  (fc60): Linear(in_features=200, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=200, bias=True)
  (fe6): Linear(in_features=200, out_features=200, bias=True)
  (fc70): Linear(in_features=200, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=200, bias=True)
  (fe7): Linear(in_features=200, out_features=200, bias=True)
  (fc80): Linear(in_features=200, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=200, bias=True)
  (fe8): Linear(in_features=200, out_features=200, bias=True)
  (fc90): Linear(in_features=200, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=200, bias=True)
  (fe9): Linear(in_features=200, out_features=200, bias=True)
  (gmfc100): Linear(in_features=200, out_features=1, bias=True)
  (gmfc101): Linear(in_features=200, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=200, bias=True)
  (gmfe100): Linear(in_features=200, out_features=200, bias=True)
  (gmfe101): Linear(in_features=200, out_features=200, bias=True)
  (gmfc110): Linear(in_features=200, out_features=1, bias=True)
  (gmfc111): Linear(in_features=200, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=200, bias=True)
  (gmfe110): Linear(in_features=200, out_features=200, bias=True)
  (gmfe111): Linear(in_features=200, out_features=200, bias=True)
  (gmfc120): Linear(in_features=200, out_features=1, bias=True)
  (gmfc121): Linear(in_features=200, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=200, bias=True)
  (gmfe120): Linear(in_features=200, out_features=200, bias=True)
  (gmfe121): Linear(in_features=200, out_features=200, bias=True)
  (fc130): Linear(in_features=200, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=200, bias=True)
  (fe13): Linear(in_features=200, out_features=200, bias=True)
  (fc140): Linear(in_features=200, out_features=2, bias=True)
  (fc141): Linear(in_features=2, out_features=200, bias=True)
  (fe14): Linear(in_features=200, out_features=200, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=400, bias=True)
  (inputbn): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=400, out_features=400, bias=True)
  (bn0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=400, bias=True)
  (bn1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=400, out_features=400, bias=True)
  (bn2): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=400, out_features=400, bias=True)
  (bn3): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=400, out_features=1, bias=True)
)
------ng : 0-------
generator loss: -0.0008516765665262938
discriminator loss: -1.0122312232851982e-06
------ng : 100-------
generator loss: -0.00016998854698613286
discriminator loss: 8.326387614943087e-06
------ng : 200-------
generator loss: 6.396165190380998e-06
discriminator loss: -6.699840014334768e-06
------ng : 300-------
generator loss: -0.0002835391787812114
discriminator loss: 2.1439569536596537e-05
------ng : 400-------
generator loss: 0.00013645012222696096
discriminator loss: -1.1514315701788291e-05
------ng : 500-------
generator loss: -2.3569797122036107e-05
discriminator loss: 1.9680079276440665e-05
------ng : 600-------
generator loss: -0.00044788201921619475
discriminator loss: -2.8386712074279785e-05
------ng : 700-------
generator loss: -0.00019914662698283792
discriminator loss: 5.611662345472723e-05
------ng : 800-------
generator loss: 0.00016974221216514707
discriminator loss: 1.527247513877228e-05
------ng : 900-------
generator loss: -0.0001331080129602924
discriminator loss: 7.240407285280526e-06
------ng : 1000-------
generator loss: -4.6709159505553544e-05
discriminator loss: -6.968803063500673e-05
------ng : 1100-------
generator loss: -0.0001858473551692441
discriminator loss: -4.6352201025001705e-05
------ng : 1200-------
generator loss: -0.00038564286660403013
discriminator loss: 2.6182387955486774e-06
------ng : 1300-------
generator loss: -0.0003613843291532248
discriminator loss: 2.6803172659128904e-06
------ng : 1400-------
generator loss: -0.0001308448554482311
discriminator loss: 4.2292987927794456e-05
------ng : 1500-------
generator loss: 2.689658140297979e-05
discriminator loss: 1.7691199900582433e-06
------ng : 1600-------
generator loss: -0.0001388270320603624
discriminator loss: 1.596011861693114e-05
------ng : 1700-------
generator loss: 4.452350549399853e-05
discriminator loss: 3.4647033317014575e-05
------ng : 1800-------
generator loss: -8.864388655638322e-05
discriminator loss: 9.056544513441622e-06
------ng : 1900-------
generator loss: -8.145299216266721e-05
discriminator loss: 3.0324881663545966e-05
------ng : 2000-------
generator loss: 0.000178731104824692
discriminator loss: -2.370856236666441e-06
------ng : 2100-------
generator loss: 0.00035735644632950425
discriminator loss: 2.5372690288349986e-05
------ng : 2200-------
generator loss: 0.00011029801680706441
discriminator loss: 4.829798126593232e-05
------ng : 2300-------
generator loss: 0.00026949401944875717
discriminator loss: 1.2587697710841894e-05
------ng : 2400-------
generator loss: 8.543903095414862e-05
discriminator loss: -1.7006255802698433e-05
------ng : 2500-------
generator loss: -0.0001783685729606077
discriminator loss: 3.231398295611143e-05
------ng : 2600-------
generator loss: -0.0002050612383754924
discriminator loss: 3.4608019632287323e-05
------ng : 2700-------
generator loss: -0.00014675856800749898
discriminator loss: -4.890593118034303e-05
------ng : 2800-------
generator loss: -0.00026402296498417854
discriminator loss: 1.3591983588412404e-05
------ng : 2900-------
generator loss: 0.00029260801966302097
discriminator loss: -1.8466671463102102e-06
------ng : 3000-------
generator loss: 3.8200803828658536e-05
discriminator loss: 3.4130134736187756e-06
------ng : 3100-------
generator loss: -0.00016241875709965825
discriminator loss: -2.37529311561957e-05
------ng : 3200-------
generator loss: 0.00031723789288662374
discriminator loss: 3.189314156770706e-06
------ng : 3300-------
generator loss: 6.468891660915688e-05
discriminator loss: -2.5900844775605947e-06
------ng : 3400-------
generator loss: 3.486279092612676e-05
discriminator loss: 3.416429535718635e-05
------ng : 3500-------
generator loss: 0.0003929538943339139
discriminator loss: -7.115595508366823e-07
------ng : 3600-------
generator loss: 0.00035127668525092304
discriminator loss: 2.3357424652203918e-05
------ng : 3700-------
generator loss: -0.00016473601863253862
discriminator loss: -3.052104148082435e-05
------ng : 3800-------
generator loss: -7.496283069485798e-05
discriminator loss: -3.1421135645359755e-05
------ng : 3900-------
generator loss: 4.87686884298455e-05
discriminator loss: -7.676193490624428e-06
------ng : 4000-------
generator loss: -9.52306654653512e-05
discriminator loss: 1.9987965060863644e-06
------ng : 4100-------
generator loss: -9.475370461586863e-05
discriminator loss: -1.5743198673590086e-05
------ng : 4200-------
generator loss: -0.00025774072855710983
discriminator loss: 2.395146293565631e-05
------ng : 4300-------
generator loss: 0.00022427494695875794
discriminator loss: 4.348723450675607e-06
------ng : 4400-------
generator loss: -0.00021556775027420372
discriminator loss: -8.456147043034434e-06
------ng : 4500-------
generator loss: 0.00020902031974401325
discriminator loss: -2.551265060901642e-05
------ng : 4600-------
generator loss: 0.0004769307270180434
discriminator loss: -2.47609568759799e-05
------ng : 4700-------
generator loss: -4.699109194916673e-05
discriminator loss: -2.1697145712096244e-05
------ng : 4800-------
generator loss: -1.6206275859076413e-06
discriminator loss: -1.61849420692306e-05
------ng : 4900-------
generator loss: -0.00019862741464748979
discriminator loss: -2.2293534129858017e-05
LGAN_generator(
  (LSTM): LSTMCell(500, 400)
  (gmfc00): Linear(in_features=400, out_features=1, bias=True)
  (gmfc01): Linear(in_features=400, out_features=5, bias=True)
  (gmfc02): Linear(in_features=5, out_features=400, bias=True)
  (gmfe00): Linear(in_features=400, out_features=400, bias=True)
  (gmfe01): Linear(in_features=400, out_features=400, bias=True)
  (fc10): Linear(in_features=400, out_features=7, bias=True)
  (fc11): Linear(in_features=7, out_features=400, bias=True)
  (fe1): Linear(in_features=400, out_features=400, bias=True)
  (gmfc20): Linear(in_features=400, out_features=1, bias=True)
  (gmfc21): Linear(in_features=400, out_features=5, bias=True)
  (gmfc22): Linear(in_features=5, out_features=400, bias=True)
  (gmfe20): Linear(in_features=400, out_features=400, bias=True)
  (gmfe21): Linear(in_features=400, out_features=400, bias=True)
  (fc30): Linear(in_features=400, out_features=16, bias=True)
  (fc31): Linear(in_features=16, out_features=400, bias=True)
  (fe3): Linear(in_features=400, out_features=400, bias=True)
  (gmfc40): Linear(in_features=400, out_features=1, bias=True)
  (gmfc41): Linear(in_features=400, out_features=5, bias=True)
  (gmfc42): Linear(in_features=5, out_features=400, bias=True)
  (gmfe40): Linear(in_features=400, out_features=400, bias=True)
  (gmfe41): Linear(in_features=400, out_features=400, bias=True)
  (fc50): Linear(in_features=400, out_features=7, bias=True)
  (fc51): Linear(in_features=7, out_features=400, bias=True)
  (fe5): Linear(in_features=400, out_features=400, bias=True)
  (fc60): Linear(in_features=400, out_features=14, bias=True)
  (fc61): Linear(in_features=14, out_features=400, bias=True)
  (fe6): Linear(in_features=400, out_features=400, bias=True)
  (fc70): Linear(in_features=400, out_features=6, bias=True)
  (fc71): Linear(in_features=6, out_features=400, bias=True)
  (fe7): Linear(in_features=400, out_features=400, bias=True)
  (fc80): Linear(in_features=400, out_features=5, bias=True)
  (fc81): Linear(in_features=5, out_features=400, bias=True)
  (fe8): Linear(in_features=400, out_features=400, bias=True)
  (fc90): Linear(in_features=400, out_features=2, bias=True)
  (fc91): Linear(in_features=2, out_features=400, bias=True)
  (fe9): Linear(in_features=400, out_features=400, bias=True)
  (gmfc100): Linear(in_features=400, out_features=1, bias=True)
  (gmfc101): Linear(in_features=400, out_features=5, bias=True)
  (gmfc102): Linear(in_features=5, out_features=400, bias=True)
  (gmfe100): Linear(in_features=400, out_features=400, bias=True)
  (gmfe101): Linear(in_features=400, out_features=400, bias=True)
  (gmfc110): Linear(in_features=400, out_features=1, bias=True)
  (gmfc111): Linear(in_features=400, out_features=5, bias=True)
  (gmfc112): Linear(in_features=5, out_features=400, bias=True)
  (gmfe110): Linear(in_features=400, out_features=400, bias=True)
  (gmfe111): Linear(in_features=400, out_features=400, bias=True)
  (gmfc120): Linear(in_features=400, out_features=1, bias=True)
  (gmfc121): Linear(in_features=400, out_features=5, bias=True)
  (gmfc122): Linear(in_features=5, out_features=400, bias=True)
  (gmfe120): Linear(in_features=400, out_features=400, bias=True)
  (gmfe121): Linear(in_features=400, out_features=400, bias=True)
  (fc130): Linear(in_features=400, out_features=40, bias=True)
  (fc131): Linear(in_features=40, out_features=400, bias=True)
  (fe13): Linear(in_features=400, out_features=400, bias=True)
  (fc140): Linear(in_features=400, out_features=2, bias=True)
  (fc141): Linear(in_features=2, out_features=400, bias=True)
  (fe14): Linear(in_features=400, out_features=400, bias=True)
)
LGAN_discriminator(
  (Dropout): Dropout(p=0.5, inplace=False)
  (input): Linear(in_features=135, out_features=400, bias=True)
  (inputbn): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc0): Linear(in_features=400, out_features=400, bias=True)
  (bn0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=400, bias=True)
  (bn1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=400, out_features=400, bias=True)
  (bn2): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (output): Linear(in_features=400, out_features=1, bias=True)
)
------ng : 0-------
generator loss: 0.004233052022755146
discriminator loss: -0.0001000002957880497
------ng : 100-------
generator loss: 0.0016245987499132752
discriminator loss: -0.006488721817731857
------ng : 200-------
generator loss: 0.002952514449134469
discriminator loss: -0.005848695524036884
------ng : 300-------
generator loss: 0.0031944289803504944
discriminator loss: -0.00914793647825718
------ng : 400-------
generator loss: 0.0024190673138946295
discriminator loss: -0.008172010071575642
------ng : 500-------
generator loss: 0.0008290953701362014
discriminator loss: -0.007281586527824402
------ng : 600-------
generator loss: 0.0028303053695708513
discriminator loss: -0.007875820621848106
------ng : 700-------
generator loss: 0.003896159352734685
discriminator loss: -0.00629159901291132
------ng : 800-------
generator loss: 0.0007751868688501418
discriminator loss: -0.0069533102214336395
------ng : 900-------
generator loss: 0.000872127537149936
discriminator loss: -0.007666180841624737
------ng : 1000-------
generator loss: 0.0020145007874816656
discriminator loss: -0.005471596959978342
------ng : 1100-------
generator loss: 0.0025899927131831646
discriminator loss: -0.0075167641043663025
------ng : 1200-------
generator loss: 0.003284227568656206
discriminator loss: -0.007640587165951729
------ng : 1300-------
generator loss: -0.0022883370984345675
discriminator loss: -0.006164552643895149
------ng : 1400-------
generator loss: 0.002497529610991478
discriminator loss: -0.005443827714771032
------ng : 1500-------
generator loss: 0.0032577826641499996
discriminator loss: -0.005567753221839666
------ng : 1600-------
generator loss: 0.0016133073950186372
discriminator loss: -0.006416391581296921
------ng : 1700-------
generator loss: 0.002329946728423238
discriminator loss: -0.0047672828659415245
------ng : 1800-------
generator loss: 0.002506999298930168
discriminator loss: -0.007144493982195854
------ng : 1900-------
generator loss: 0.0028352767694741488
discriminator loss: -0.004601215943694115
------ng : 2000-------
generator loss: 0.0014943060232326388
discriminator loss: -0.0036494056694209576
------ng : 2100-------
generator loss: 8.832029561745003e-05
discriminator loss: -0.006347524933516979
------ng : 2200-------
generator loss: 0.0002214884734712541
discriminator loss: -0.004755556583404541
------ng : 2300-------
generator loss: 0.0018706824630498886
discriminator loss: -0.0035354706924408674
------ng : 2400-------
generator loss: -0.00140026630833745
discriminator loss: -0.005952947773039341
------ng : 2500-------
generator loss: 0.0024438765831291676
discriminator loss: -0.004683395382016897
------ng : 2600-------
generator loss: -0.004240440670400858
discriminator loss: -0.0035095023922622204
------ng : 2700-------
generator loss: 0.0013073896989226341
discriminator loss: -0.00500499876216054
------ng : 2800-------
generator loss: 0.0007531279698014259
discriminator loss: -0.0044874162413179874
------ng : 2900-------
generator loss: 0.0019339784048497677
discriminator loss: -0.002668746979907155
------ng : 3000-------
generator loss: -0.000634898548014462
discriminator loss: -0.004192138556391001
------ng : 3100-------
generator loss: 0.0020157068502157927
discriminator loss: -0.004633008036762476
------ng : 3200-------
generator loss: 0.002144932048395276
discriminator loss: -0.0013838338200002909
------ng : 3300-------
generator loss: -0.0002718354808166623
discriminator loss: -0.00520244799554348
------ng : 3400-------
generator loss: 0.001909686136059463
discriminator loss: -0.0048099360428750515
------ng : 3500-------
generator loss: 0.002121508587151766
discriminator loss: -0.0028498610481619835
------ng : 3600-------
generator loss: 0.0005756010068580508
discriminator loss: -0.0048316773027181625
------ng : 3700-------
generator loss: -0.0026206648908555508
discriminator loss: -0.0033339306246489286
------ng : 3800-------
generator loss: 0.0017248756485059857
discriminator loss: -0.002914565149694681
------ng : 3900-------
generator loss: 7.791515236021951e-05
discriminator loss: -0.0013705773744732141
------ng : 4000-------
generator loss: 0.0017240506131201982
discriminator loss: -0.0037890723906457424
------ng : 4100-------
generator loss: 0.0007070866995491087
discriminator loss: -0.0026252330280840397
------ng : 4200-------
generator loss: 0.0006165085942484438
discriminator loss: -0.0033534253016114235
------ng : 4300-------
generator loss: 0.0015174461295828223
discriminator loss: -0.0014059441164135933
------ng : 4400-------
generator loss: 0.001593755092471838
discriminator loss: -0.0026281471364200115
------ng : 4500-------
generator loss: 0.00303736818023026
discriminator loss: -0.005867450498044491
------ng : 4600-------
generator loss: 0.0017470006132498384
discriminator loss: -0.003176742233335972
------ng : 4700-------
generator loss: 0.0015966459177434444
discriminator loss: -0.0055906325578689575
------ng : 4800-------
generator loss: -0.0016475000884383917
discriminator loss: -0.0028439322486519814
------ng : 4900-------
generator loss: 0.002029148628935218
discriminator loss: -0.004378578159958124
slurmstepd: error: Detected 12521 oom-kill event(s) in StepId=29565377.batch cgroup. Some of your processes may have been killed by the cgroup out-of-memory handler.
Sep 28 21:07:20 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 21:07:20 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:71904KB rss:4024096KB rss_huge:1126400KB mapped_file:71680KB swap:0KB inactive_anon:682704KB active_anon:3413072KB inactive_file:208KB active_file:16KB unevictable:0KB
Sep 28 21:07:22 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 21:07:22 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:61568KB rss:4034432KB rss_huge:1243136KB mapped_file:61568KB swap:0KB inactive_anon:683728KB active_anon:3412096KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 21:07:26 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 21:07:26 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:51680KB rss:4044308KB rss_huge:1142784KB mapped_file:51584KB swap:0KB inactive_anon:682656KB active_anon:3412852KB inactive_file:68KB active_file:40KB unevictable:0KB
Sep 28 21:07:32 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 21:07:32 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:40960KB rss:4055040KB rss_huge:942080KB mapped_file:40960KB swap:0KB inactive_anon:682688KB active_anon:3413292KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 21:07:33 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 21:07:33 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:30720KB rss:4065280KB rss_huge:1126400KB mapped_file:30720KB swap:0KB inactive_anon:686492KB active_anon:3409480KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 21:36:49 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 21:36:49 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:72188KB rss:4023680KB rss_huge:675840KB mapped_file:72188KB swap:0KB inactive_anon:684276KB active_anon:3411036KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 21:36:53 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 21:36:53 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:62672KB rss:4033328KB rss_huge:763904KB mapped_file:61712KB swap:0KB inactive_anon:684196KB active_anon:3410572KB inactive_file:732KB active_file:500KB unevictable:0KB
Sep 28 21:36:56 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 21:36:56 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:51212KB rss:4044788KB rss_huge:780288KB mapped_file:51200KB swap:0KB inactive_anon:684584KB active_anon:3411404KB inactive_file:12KB active_file:0KB unevictable:0KB
Sep 28 21:37:00 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 21:37:00 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:41160KB rss:4054784KB rss_huge:688128KB mapped_file:41160KB swap:0KB inactive_anon:682660KB active_anon:3413040KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 21:37:01 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 21:37:01 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:30720KB rss:4065280KB rss_huge:962560KB mapped_file:30720KB swap:0KB inactive_anon:682760KB active_anon:3413232KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 22:05:03 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 22:05:03 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:71844KB rss:4024124KB rss_huge:1402880KB mapped_file:71712KB swap:0KB inactive_anon:692304KB active_anon:3403500KB inactive_file:68KB active_file:0KB unevictable:0KB
Sep 28 22:05:05 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 22:05:05 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:61952KB rss:4034048KB rss_huge:1312768KB mapped_file:61952KB swap:0KB inactive_anon:682620KB active_anon:3412816KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 22:05:09 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 22:05:09 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:51944KB rss:4044056KB rss_huge:1161216KB mapped_file:51212KB swap:0KB inactive_anon:682824KB active_anon:3412432KB inactive_file:460KB active_file:284KB unevictable:0KB
Sep 28 22:05:14 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 22:05:14 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:41088KB rss:4054912KB rss_huge:968704KB mapped_file:41088KB swap:0KB inactive_anon:687932KB active_anon:3407932KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 22:05:16 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 22:05:16 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:30720KB rss:4065280KB rss_huge:1105920KB mapped_file:30720KB swap:0KB inactive_anon:682716KB active_anon:3413244KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 22:34:54 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 22:34:54 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:72356KB rss:4023600KB rss_huge:905216KB mapped_file:72276KB swap:0KB inactive_anon:684616KB active_anon:3410648KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 22:34:56 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 22:34:56 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:64120KB rss:4031880KB rss_huge:978944KB mapped_file:61700KB swap:0KB inactive_anon:682328KB active_anon:3410992KB inactive_file:1372KB active_file:1308KB unevictable:0KB
Sep 28 22:35:00 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 22:35:00 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:51276KB rss:4044664KB rss_huge:948224KB mapped_file:51204KB swap:0KB inactive_anon:682748KB active_anon:3413116KB inactive_file:4KB active_file:4KB unevictable:0KB
Sep 28 22:35:04 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 22:35:04 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:40960KB rss:4055040KB rss_huge:788480KB mapped_file:40960KB swap:0KB inactive_anon:682752KB active_anon:3413232KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 22:35:05 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 22:35:05 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:30720KB rss:4065280KB rss_huge:1038336KB mapped_file:30720KB swap:0KB inactive_anon:682664KB active_anon:3413292KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 23:03:06 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 23:03:06 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:71820KB rss:4024180KB rss_huge:1466368KB mapped_file:71684KB swap:0KB inactive_anon:689748KB active_anon:3406112KB inactive_file:72KB active_file:68KB unevictable:0KB
Sep 28 23:03:09 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 23:03:09 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:61624KB rss:4034376KB rss_huge:1372160KB mapped_file:61440KB swap:0KB inactive_anon:682692KB active_anon:3413124KB inactive_file:52KB active_file:4KB unevictable:0KB
Sep 28 23:03:12 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 23:03:12 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:51328KB rss:4044672KB rss_huge:1304576KB mapped_file:51328KB swap:0KB inactive_anon:692104KB active_anon:3403752KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 23:03:17 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 23:03:17 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:49408KB rss:4046592KB rss_huge:1112064KB mapped_file:49408KB swap:0KB inactive_anon:694064KB active_anon:3401656KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 28 23:03:19 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 28 23:03:19 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:36864KB rss:4059136KB rss_huge:1212416KB mapped_file:36864KB swap:0KB inactive_anon:682704KB active_anon:3413276KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 29 00:32:03 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 00:32:03 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:72036KB rss:4023964KB rss_huge:946176KB mapped_file:71696KB swap:0KB inactive_anon:682676KB active_anon:3412968KB inactive_file:156KB active_file:72KB unevictable:0KB
Sep 29 00:32:05 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 00:32:05 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:61492KB rss:4034432KB rss_huge:1085440KB mapped_file:61492KB swap:0KB inactive_anon:682696KB active_anon:3413128KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 29 00:32:10 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 00:32:10 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:51208KB rss:4044792KB rss_huge:1019904KB mapped_file:51200KB swap:0KB inactive_anon:682700KB active_anon:3413292KB inactive_file:8KB active_file:0KB unevictable:0KB
Sep 29 00:32:16 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 00:32:16 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:49152KB rss:4046848KB rss_huge:854016KB mapped_file:49152KB swap:0KB inactive_anon:682672KB active_anon:3413312KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 29 00:32:18 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 00:32:18 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:36992KB rss:4059008KB rss_huge:1038336KB mapped_file:36992KB swap:0KB inactive_anon:682728KB active_anon:3413108KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 29 01:59:00 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 01:59:00 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:72744KB rss:4023256KB rss_huge:1138688KB mapped_file:72160KB swap:0KB inactive_anon:683632KB active_anon:3411304KB inactive_file:584KB active_file:480KB unevictable:0KB
Sep 29 01:59:03 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 01:59:03 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:62080KB rss:4033920KB rss_huge:1089536KB mapped_file:62080KB swap:0KB inactive_anon:682676KB active_anon:3412684KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 29 01:59:08 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 01:59:08 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:51200KB rss:4044800KB rss_huge:1007616KB mapped_file:51200KB swap:0KB inactive_anon:687884KB active_anon:3408116KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 29 01:59:15 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 01:59:15 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:49356KB rss:4046644KB rss_huge:872448KB mapped_file:49356KB swap:0KB inactive_anon:691144KB active_anon:3404648KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 29 01:59:17 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 01:59:17 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:36864KB rss:4059136KB rss_huge:1044480KB mapped_file:36864KB swap:0KB inactive_anon:682664KB active_anon:3413304KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 29 03:14:42 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 03:14:42 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:71748KB rss:4024192KB rss_huge:950272KB mapped_file:71748KB swap:0KB inactive_anon:684360KB active_anon:3411472KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 29 03:14:45 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 03:14:45 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:61696KB rss:4034304KB rss_huge:1001472KB mapped_file:61488KB swap:0KB inactive_anon:684988KB active_anon:3410756KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 29 03:14:49 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 03:14:49 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:54124KB rss:4041876KB rss_huge:964608KB mapped_file:52012KB swap:0KB inactive_anon:683888KB active_anon:3409188KB inactive_file:1468KB active_file:1456KB unevictable:0KB
Sep 29 03:14:54 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 03:14:54 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:49280KB rss:4046720KB rss_huge:806912KB mapped_file:49280KB swap:0KB inactive_anon:685880KB active_anon:3409940KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 29 03:14:55 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 03:14:55 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:36864KB rss:4059136KB rss_huge:1048576KB mapped_file:36864KB swap:0KB inactive_anon:684372KB active_anon:3411608KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 29 04:23:17 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 04:23:17 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:72288KB rss:4023712KB rss_huge:1218560KB mapped_file:71732KB swap:0KB inactive_anon:693596KB active_anon:3401796KB inactive_file:308KB active_file:300KB unevictable:0KB
Sep 29 04:23:20 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 04:23:20 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:61728KB rss:4034272KB rss_huge:1167360KB mapped_file:61728KB swap:0KB inactive_anon:700008KB active_anon:3395704KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 29 04:23:23 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 04:23:23 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:51204KB rss:4044796KB rss_huge:1079296KB mapped_file:51204KB swap:0KB inactive_anon:682752KB active_anon:3413240KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 29 04:23:30 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 04:23:30 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:49152KB rss:4046848KB rss_huge:899072KB mapped_file:49152KB swap:0KB inactive_anon:683300KB active_anon:3412688KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 29 04:23:32 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 04:23:32 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:36864KB rss:4059136KB rss_huge:1058816KB mapped_file:36864KB swap:0KB inactive_anon:682764KB active_anon:3413236KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 29 05:51:49 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 05:51:49 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:71920KB rss:4024080KB rss_huge:1347584KB mapped_file:71792KB swap:0KB inactive_anon:710384KB active_anon:3385376KB inactive_file:128KB active_file:112KB unevictable:0KB
Sep 29 05:51:51 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 05:51:51 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:61500KB rss:4034500KB rss_huge:1269760KB mapped_file:61440KB swap:0KB inactive_anon:689772KB active_anon:3406168KB inactive_file:48KB active_file:12KB unevictable:0KB
Sep 29 05:51:55 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 05:51:55 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:51328KB rss:4044672KB rss_huge:1191936KB mapped_file:51328KB swap:0KB inactive_anon:696036KB active_anon:3399824KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 29 05:52:00 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 05:52:00 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:49536KB rss:4046464KB rss_huge:989184KB mapped_file:49536KB swap:0KB inactive_anon:682676KB active_anon:3412892KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 29 05:52:02 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 05:52:02 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:36864KB rss:4059136KB rss_huge:1146880KB mapped_file:36864KB swap:0KB inactive_anon:682728KB active_anon:3413220KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 29 07:20:03 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 07:20:03 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:71684KB rss:4024316KB rss_huge:1576960KB mapped_file:71680KB swap:0KB inactive_anon:693992KB active_anon:3402004KB inactive_file:4KB active_file:0KB unevictable:0KB
Sep 29 07:20:06 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 07:20:06 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:61548KB rss:4034452KB rss_huge:1433600KB mapped_file:61440KB swap:0KB inactive_anon:700284KB active_anon:3395608KB inactive_file:68KB active_file:40KB unevictable:0KB
Sep 29 07:20:10 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 07:20:10 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:51584KB rss:4044416KB rss_huge:1351680KB mapped_file:51584KB swap:0KB inactive_anon:682868KB active_anon:3412720KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 29 07:20:16 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 07:20:16 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:49280KB rss:4046720KB rss_huge:1148928KB mapped_file:49280KB swap:0KB inactive_anon:689732KB active_anon:3406128KB inactive_file:0KB active_file:0KB unevictable:0KB
Sep 29 07:20:18 spartan-gpgpu079 kernel: Task in /slurm/uid_13885/job_29565377/step_batch killed as a result of limit of /slurm/uid_13885/job_29565377/step_batch
Sep 29 07:20:18 spartan-gpgpu079 kernel: Memory cgroup stats for /slurm/uid_13885/job_29565377/step_batch: cache:37120KB rss:4058880KB rss_huge:1196032KB mapped_file:37120KB swap:0KB inactive_anon:691220KB active_anon:3404516KB inactive_file:0KB active_file:0KB unevictable:0KB
